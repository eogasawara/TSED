Scopus
EXPORT DATE: 14 November 2023

@CONFERENCE{Yan2021221,
	author = {Yan, Yufang and Zhao, Kui and Cao, Jilong and Ma, Huimin},
	title = {Prediction research of cervical cancer clinical events based on recurrent neural network},
	year = {2021},
	journal = {Procedia Computer Science},
	volume = {183},
	pages = {221 – 229},
	doi = {10.1016/j.procs.2021.02.052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104830302&doi=10.1016%2fj.procs.2021.02.052&partnerID=40&md5=67479f6a9f1dc6152ee6cafac34aefd5},
	abstract = {Through the research on the existing time series prediction technology, most researchers mainly make predictions based on clinical events, without thinking about whether the previous clinical process is standard or not. This paper proposes a two-stage prediction model, RNN-2-DT, based on word vector representation and integrated into the standardized judgment of the diagnosis and treatment process. The model mines standardized clinical mode which is a standard of clinical process, using the method of binary K-means. Meantime, the clinical events prediction model using gated recurrent units (GRU) based on recurrent neural network (RNN) is constructed. The experimental results indicate that, compared with the clinical processes no considering standardized judgments, our model's recall rate and mean average precision are increased by 7.2% and 4.3%, respectively. © 2021 The Authors. Published by Elsevier B.V.},
	author_keywords = {Cervical Cancer; Electronic Health Record; Gated Recurrent Units Neural Network; Pattern Mining; Word Vector Representation},
	keywords = {Clinical research; Forecasting; Recurrent neural networks; Cervical cancers; Clinical process; Electronic health; Gated recurrent unit neural network; Health records; Neural-networks; Pattern mining; Prediction model; Prediction research; Word vector representation; Diseases},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{Haufe2023,
	author = {Haufe, Stefan and Isaias, Ioannis U. and Pellegrini, Franziska and Palmisano, Chiara},
	title = {Gait Event Prediction Using Surface Electromyography in Parkinsonian Patients},
	year = {2023},
	journal = {Bioengineering},
	volume = {10},
	number = {2},
	doi = {10.3390/bioengineering10020212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149068728&doi=10.3390%2fbioengineering10020212&partnerID=40&md5=ce65a98dd3af63fea2ae69110a53dce6},
	abstract = {Gait disturbances are common manifestations of Parkinson’s disease (PD), with unmet therapeutic needs. Inertial measurement units (IMUs) are capable of monitoring gait, but they lack neurophysiological information that may be crucial for studying gait disturbances in these patients. Here, we present a machine learning approach to approximate IMU angular velocity profiles and subsequently gait events using electromyographic (EMG) channels during overground walking in patients with PD. We recorded six parkinsonian patients while they walked for at least three minutes. Patient-agnostic regression models were trained on temporally embedded EMG time series of different combinations of up to five leg muscles bilaterally (i.e., tibialis anterior, soleus, gastrocnemius medialis, gastrocnemius lateralis, and vastus lateralis). Gait events could be detected with high temporal precision (median displacement of <50 ms), low numbers of missed events (<2%), and next to no false-positive event detections (<0.1%). Swing and stance phases could thus be determined with high fidelity (median F1-score of ~0.9). Interestingly, the best performance was obtained using as few as two EMG probes placed on the left and right vastus lateralis. Our results demonstrate the practical utility of the proposed EMG-based system for gait event prediction, which allows the simultaneous acquisition of an electromyographic signal to be performed. This gait analysis approach has the potential to make additional measurement devices such as IMUs and force plates less essential, thereby reducing financial and preparation overheads and discomfort factors in gait studies. © 2023 by the authors.},
	author_keywords = {electromyography; gait-phase prediction; inertial measurement units; machine learning; Parkinson’s disease},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Thiesen20191015,
	author = {Thiesen, Stephanie and Darscheid, Paul and Ehret, Uwe},
	title = {Identifying rainfall-runoff events in discharge time series: A data-driven method based on information theory},
	year = {2019},
	journal = {Hydrology and Earth System Sciences},
	volume = {23},
	number = {2},
	pages = {1015 – 1034},
	doi = {10.5194/hess-23-1015-2019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061911064&doi=10.5194%2fhess-23-1015-2019&partnerID=40&md5=0e8451f5475b403887211f506c7c1d6a},
	abstract = {In this study, we propose a data-driven approach for automatically identifying rainfall-runoff events in discharge time series. The core of the concept is to construct and apply discrete multivariate probability distributions to obtain probabilistic predictions of each time step that is part of an event. The approach permits any data to serve as predictors, and it is non-parametric in the sense that it can handle any kind of relation between the predictor(s) and the target. Each choice of a particular predictor data set is equivalent to formulating a model hypothesis. Among competing models, the best is found by comparing their predictive power in a training data set with user-classified events. For evaluation, we use measures from information theory such as Shannon entropy and conditional entropy to select the best predictors and models and, additionally, measure the risk of overfitting via cross entropy and Kullback-Leibler divergence. As all these measures are expressed in "bit", we can combine them to identify models with the best tradeoff between predictive power and robustness given the available data. We applied the method to data from the Dornbirner Ach catchment in Austria, distinguishing three different model types: Models relying on discharge data, models using both discharge and precipitation data, and recursive models, i.e., models using their own predictions of a previous time step as an additional predictor. In the case study, the additional use of precipitation reduced predictive uncertainty only by a small amount, likely because the information provided by precipitation is already contained in the discharge data. More generally, we found that the robustness of a model quickly dropped with the increase in the number of predictors used (an effect well known as the curse of dimensionality) such that, in the end, the best model was a recursive one applying four predictors (three standard and one recursive): Discharge from two distinct time steps, the relative magnitude of discharge compared with all discharge values in a surrounding 65 h time window and event predictions from the previous time step. Applying the model reduced the uncertainty in event classification by 77.8 %, decreasing conditional entropy from 0.516 to 0.114 bits. To assess the quality of the proposed method, its results were binarized and validated through a holdout method and then compared to a physically based approach. The comparison showed similar behavior of both models (both with accuracy near 90 %), and the crossvalidation reinforced the quality of the proposed model. Given enough data to build data-driven models, their potential lies in the way they learn and exploit relations between data unconstrained by functional or parametric assumptions and choices. And, beyond that, the use of these models to reproduce a hydrologist's way of identifying rainfall-runoff events is just one of many potential applications. © Author(s) 2019.},
	keywords = {Austria; Catchments; Forecasting; Information theory; Probability distributions; Rain; Risk assessment; Time series; Curse of dimensionality; Data-driven approach; Event classification; Kullback Leibler divergence; Multivariate probability distributions; Predictive uncertainty; Probabilistic prediction; Rainfall-runoff events; catchment; data set; discharge; identification method; numerical method; precipitation (climatology); prediction; rainfall-runoff modeling; Runoff},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hsu2022E149,
	author = {Hsu, William and Warren, Jim and Riddle, Patricia},
	title = {Multivariate Sequential Analytics for Cardiovascular Disease Event Prediction},
	year = {2022},
	journal = {Methods of Information in Medicine},
	volume = {61},
	number = {1},
	pages = {E149 – E171},
	doi = {10.1055/s-0042-1758687},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144636635&doi=10.1055%2fs-0042-1758687&partnerID=40&md5=0003985a23fabc619596885a5658dc7e},
	abstract = {Background Automated clinical decision support for risk assessment is a powerful tool in combating cardiovascular disease (CVD), enabling targeted early intervention that could avoid issues of overtreatment or undertreatment. However, current CVD risk prediction models use observations at baseline without explicitly representing patient history as a time series. Objective The aim of this study is to examine whether by explicitly modelling the temporal dimension of patient history event prediction may be improved. Methods This study investigates methods for multivariate sequential modelling with a particular emphasis on long short-term memory (LSTM) recurrent neural networks. Data from a CVD decision support tool is linked to routinely collected national datasets including pharmaceutical dispensing, hospitalization, laboratory test results, and deaths. The study uses a 2-year observation and a 5-year prediction window. Selected methods are applied to the linked dataset. The experiments performed focus on CVD event prediction. CVD death or hospitalization in a 5-year interval was predicted for patients with history of lipid-lowering therapy. Results The results of the experiments showed temporal models are valuable for CVD event prediction over a 5-year interval. This is especially the case for LSTM, which produced the best predictive performance among all models compared achieving AUROC of 0.801 and average precision of 0.425. The non-temporal model comparator ridge classifier (RC) trained using all quarterly data or by aggregating quarterly data (averaging time-varying features) was highly competitive achieving AUROC of 0.799 and average precision of 0.420 and AUROC of 0.800 and average precision of 0.421, respectively. Conclusion This study provides evidence that the use of deep temporal models particularly LSTM in clinical decision support for chronic disease would be advantageous with LSTM significantly improving on commonly used regression models such as logistic regression and Cox proportional hazards on the task of CVD event prediction. © 2022 Georg Thieme Verlag. All rights reserved.},
	author_keywords = {cardiovascular disease; deep learning; event prediction; machine learning},
	keywords = {Cardiovascular Diseases; Humans; Multivariate Analysis; Neural Networks, Computer; Risk Assessment; Risk Factors; cardiovascular disease; human; multivariate analysis; procedures; risk assessment; risk factor},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zamee2023,
	author = {Zamee, Muhammad Ahsan and Han, Dongjun and Cha, Heejune and Won, Dongjun},
	title = {Self-supervised online learning algorithm for electric vehicle charging station demand and event prediction},
	year = {2023},
	journal = {Journal of Energy Storage},
	volume = {71},
	doi = {10.1016/j.est.2023.108189},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164219833&doi=10.1016%2fj.est.2023.108189&partnerID=40&md5=79aff76d1d0a5d62d994dca681164545},
	abstract = {With the increasing popularity of electric vehicles (EVs), countries are setting up new charging stations to meet up the rising demand. Therefore, accurately forecasting charging demand and charging events is highly significant. Historical data are crucial for developing a quality forecasting model, but countries or locations with recently installed EV stations suffer from data inadequacy. Delayed data accumulation for forecasting model creation impedes EV's optimal operation, and an offline or fixed-sized data-based learning model may not perform optimally due to the future uncertainties of input variables. Therefore, it is required to create an online forecasting model that can learn right from the beginning of the operation of charging stations, forecast, and relearn, when necessary, by considering the impact of input/external variables. For optimal model development, impactful input variables should be chosen online using appropriate feature engineering. In this research, a unique feature engineering considering multi-level correlation with multicollinearity and simultaneous online learning General Regression Neural Network (GRNN) based on has been suggested. Also due to the discrete and asynchronous nature of the charging event a detailed data handling method has been developed to create meaningful time series data. It is interestingly realized that the proposed model outperforms general Artificial Neural Networks (ANN), various sophisticated models, such as Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Bi-LSTM, Gated Recurrent Unit (GRU), and the Deep Neural Network (DNN) model when the appropriate inputs and their delayed variables are used. © 2023 Elsevier Ltd},
	author_keywords = {Charging demand forecasting; Electric vehicle; Event detection forecasting; General Regression Neural Network; Long short term memory; Online learning},
	keywords = {Brain; Charging (batteries); Data handling; Deep neural networks; E-learning; Electric vehicles; Forecasting; Learning algorithms; Learning systems; Regression analysis; Charging demand forecasting; Charging demands; Charging station; Demand forecasting; Event detection forecasting; Events detection; Forecasting models; General regression neural network; Online learning; Regression neural networks; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rahimi2023343,
	author = {Rahimi, Mohammad Masoud and Naghizade, Elham and Stevenson, Mark and Winter, Stephan},
	title = {SentiHawkes: a sentiment-aware Hawkes point process to model service quality of public transport using Twitter data},
	year = {2023},
	journal = {Public Transport},
	volume = {15},
	number = {2},
	pages = {343 – 376},
	doi = {10.1007/s12469-022-00310-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153361162&doi=10.1007%2fs12469-022-00310-7&partnerID=40&md5=0e2c906c1300155ac8174d5825c9f7b3},
	abstract = {Responsive management of public transport nodes relies on constant monitoring of service quality. Social media content provides a unique opportunity to detect and monitor events impacting service quality in these nodes, as well as predicting future occurrences of such events. However, the confined geographic area of transport nodes exacerbates the sparsity of available feeds, raising two major challenges: limited observations—leading to biased models—and the asynchronous nature of observations—impeding the detection of causal patterns. Thus, this paper proposes a framework based on a multivariate Hawkes point process and sentiment analysis. The multivariate Hawkes point process allows effective modelling of events without making them discrete, hence it is less affected by data sparsity compared to time series models while enabling the prediction of how certain events can trigger future events. Besides, the extracted sentiments from social media feeds provide additional knowledge about passengers’ perception and thus, are used in our approach to strengthening the model. Experiments on a real-world dataset demonstrate the effectiveness of the model in identifying causal relations over the public transport nodes. They also show the efficacy of the proposed solution in predicting events over the limited context compared to state-of-the-art approaches. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {Event prediction; Hawkes process; Pattern discovery; Public transport; Service quality},
	keywords = {Forecasting; Pattern recognition; Sentiment analysis; Social networking (online); Event prediction; Geographic areas; Hawkes process; Media content; Pattern discovery; Point process; Public transport; Service Quality; Social media; Transport nodes; Quality of service},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nguyen2023,
	author = {Nguyen, Hieu T. and Vasconcellos, Henrique D. and Keck, Kimberley and Reis, Jared P. and Lewis, Cora E. and Sidney, Steven and Lloyd-Jones, Donald M. and Schreiner, Pamela J. and Guallar, Eliseo and Wu, Colin O. and Lima, João A.C. and Ambale-Venkatesh, Bharath},
	title = {Multivariate longitudinal data for survival analysis of cardiovascular event prediction in young adults: insights from a comparative explainable study},
	year = {2023},
	journal = {BMC Medical Research Methodology},
	volume = {23},
	number = {1},
	doi = {10.1186/s12874-023-01845-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146815172&doi=10.1186%2fs12874-023-01845-4&partnerID=40&md5=5304feb70f2b352b912d4726ef42808b},
	abstract = {Background: Multivariate longitudinal data are under-utilized for survival analysis compared to cross-sectional data (CS - data collected once across cohort). Particularly in cardiovascular risk prediction, despite available methods of longitudinal data analysis, the value of longitudinal information has not been established in terms of improved predictive accuracy and clinical applicability. Methods: We investigated the value of longitudinal data over and above the use of cross-sectional data via 6 distinct modeling strategies from statistics, machine learning, and deep learning that incorporate repeated measures for survival analysis of the time-to-cardiovascular event in the Coronary Artery Risk Development in Young Adults (CARDIA) cohort. We then examined and compared the use of model-specific interpretability methods (Random Survival Forest Variable Importance) and model-agnostic methods (SHapley Additive exPlanation (SHAP) and Temporal Importance Model Explanation (TIME)) in cardiovascular risk prediction using the top-performing models. Results: In a cohort of 3539 participants, longitudinal information from 35 variables that were repeatedly collected in 6 exam visits over 15 years improved subsequent long-term (17 years after) risk prediction by up to 8.3% in C-index compared to using baseline data (0.78 vs. 0.72), and up to approximately 4% compared to using the last observed CS data (0.75). Time-varying AUC was also higher in models using longitudinal data (0.86–0.87 at 5 years, 0.79–0.81 at 10 years) than using baseline or last observed CS data (0.80–0.86 at 5 years, 0.73–0.77 at 10 years). Comparative model interpretability analysis revealed the impact of longitudinal variables on model prediction on both the individual and global scales among different modeling strategies, as well as identifying the best time windows and best timing within that window for event prediction. The best strategy to incorporate longitudinal data for accuracy was time series massive feature extraction, and the easiest interpretable strategy was trajectory clustering. Conclusion: Our analysis demonstrates the added value of longitudinal data in predictive accuracy and epidemiological utility in cardiovascular risk survival analysis in young adults via a unified, scalable framework that compares model performance and explainability. The framework can be extended to a larger number of variables and other longitudinal modeling methods. Trial registration: ClinicalTrials.gov Identifier: NCT00005130, Registration Date: 26/05/2000. © 2023, The Author(s).},
	author_keywords = {CARDIA; Explainable AI; Longitudinal data; Personalized medicine; Repeated measures; Risk prediction; SHAP; Survival analysis; TIME; Time-varying covariates},
	keywords = {Cardiovascular Diseases; Cross-Sectional Studies; Humans; Survival Analysis; Young Adult; cardiovascular disease; cross-sectional study; human; survival analysis; young adult},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Guth2019,
	author = {Guth, Stephen and Sapsis, Themistoklis P.},
	title = {Machine learning predictors of extreme events occurring in complex dynamical systems},
	year = {2019},
	journal = {Entropy},
	volume = {21},
	number = {10},
	doi = {10.3390/e21100925},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074046585&doi=10.3390%2fe21100925&partnerID=40&md5=dd3487c59e241cc8d8e9ed6c2429374c},
	abstract = {The ability to characterize and predict extreme events is a vital topic in fields ranging from finance to ocean engineering. Typically, the most-extreme events are also the most-rare, and it is this property that makes data collection and direct simulation challenging. We consider the problem of deriving optimal predictors of extremes directly from data characterizing a complex system, by formulating the problem in the context of binary classification. Specifically, we assume that a training dataset consists of: (i) indicator time series specifying on whether or not an extreme event occurs; and (ii) observables time series, which are employed to formulate efficient predictors. We employ and assess standard binary classification criteria for the selection of optimal predictors, such as total and balanced error and area under the curve, in the context of extreme event prediction. For physical systems for which there is sufficient separation between the extreme and regular events, i.e., extremes are distinguishably larger compared with regular events, we prove the existence of optimal extreme event thresholds that lead to efficient predictors. Moreover, motivated by the special character of extreme events, i.e., the very low rate of occurrence, we formulate a new objective function for the selection of predictors. This objective is constructed from the same principles as receiver operating characteristic curves, and exhibits a geometric connection to the regime separation property. We demonstrate the application of the new selection criterion to the advance prediction of intermittent extreme events in two challenging complex systems: the Majda-McLaughlin-Tabak model, a 1D nonlinear, dispersive wave model, and the 2D Kolmogorov flow model, which exhibits extreme dissipation events. © 2019 by the authors.},
	author_keywords = {Binary classification; Chaotic systems; Data-driven methods; Optimal predictors; Rare extreme events},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mehrmolaei2019131,
	author = {Mehrmolaei, Soheila and Keyvanpour, Mohammad Reza},
	title = {An enhanced hybrid model for event prediction in healthcare time series},
	year = {2019},
	journal = {International Journal of Knowledge-Based and Intelligent Engineering Systems},
	volume = {23},
	number = {3},
	pages = {131 – 147},
	doi = {10.3233/KES-190406},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074449917&doi=10.3233%2fKES-190406&partnerID=40&md5=841f850957220ed4b96e069e7bddb1df},
	abstract = {Nowadays, there is a large volume of time series data, which generates by different parts of the healthcare domain such as hospitals, medical organizations, and health centers. Time series event-based prediction (TsEP) has recently become an active research trend in the healthcare domain, which is widely served outcome of it by the healthcare decision-makers. Actually, a valid and reliable prediction can play an important and key role in the society for forewarning crisis and supporting health management. Hence, the main motivation of this paper is to offer an enhanced hybrid model to the TsEP in healthcare, which is named TsEP-TC. TsEP-TC contains three components (TC) that combines relevant concepts to weighting, fuzzy logic, and metaheuristics in the TsEP problem. Experimental results indicate that TsEP-TC can provide the superior performance in comparison to the previous prediction models in the healthcare and biomedical domains. Additionally, TsEP-TC model can be introduced as a useful way for handling the complex and uncertain behaviors of time series and fuzzy events predicting in healthcare. © 2019 - IOS Press and the authors. All rights reserved.},
	author_keywords = {Event prediction; fuzzy logic; healthcare; metaheuristics; TsEP-TC; weighting},
	keywords = {Computer circuits; Decision making; Forecasting; Fuzzy logic; Heuristic algorithms; Time series; Uncertainty analysis; Biomedical domain; Event prediction; Health management; Health-care decisions; Healthcare domains; Meta heuristics; Time-series events; weighting; Health care},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Soleimani20181948,
	author = {Soleimani, Hossein and Hensman, James and Saria, Suchi},
	title = {Scalable Joint Models for Reliable Uncertainty-Aware Event Prediction},
	year = {2018},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume = {40},
	number = {8},
	pages = {1948 – 1963},
	doi = {10.1109/TPAMI.2017.2742504},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028517618&doi=10.1109%2fTPAMI.2017.2742504&partnerID=40&md5=7bddc6f64d93b0c1687d9b7c41d477d3},
	abstract = {Missing data and noisy observations pose significant challenges for reliably predicting events from irregularly sampled multivariate time series (longitudinal) data. Imputation methods, which are typically used for completing the data prior to event prediction, lack a principled mechanism to account for the uncertainty due to missingness. Alternatively, state-of-the-art joint modeling techniques can be used for jointly modeling the longitudinal and event data and compute event probabilities conditioned on the longitudinal observations. These approaches, however, make strong parametric assumptions and do not easily scale to multivariate signals with many observations. Our proposed approach consists of several key innovations. First, we develop a flexible and scalable joint model based upon sparse multiple-output Gaussian processes. Unlike state-of-the-art joint models, the proposed model can explain highly challenging structure including non-Gaussian noise while scaling to large data. Second, we derive an optimal policy for predicting events using the distribution of the event occurrence estimated by the joint model. The derived policy trades-off the cost of a delayed detection versus incorrect assessments and abstains from making decisions when the estimated event probability does not satisfy the derived confidence criteria. Experiments on a large dataset show that the proposed framework significantly outperforms state-of-the-art techniques in event prediction. © 1979-2012 IEEE.},
	author_keywords = {joint modeling; missing data; scalable Gaussian processes; survival analysis; time series; Uncertainty-aware prediction},
	keywords = {Data structures; Detectors; Forecasting; Gaussian distribution; Reliability; Reliability analysis; Time series; Time series analysis; Uncertainty analysis; Computational model; Gaussian Processes; Joint modeling; Missing data; Predictive models; Survival analysis; Uncertainty; Gaussian noise (electronic)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Li20221,
	author = {Li, Longyuan and Yan, Junchi and Zhang, Yunhao and Zhang, Jihai and Bao, Jie and Jin, Yaohui and Yang, Xiaokang},
	title = {Learning Generative RNN-ODE for Collaborative Time-Series and Event Sequence Forecasting},
	year = {2022},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	pages = {1–18},
	doi = {10.1109/TKDE.2022.3185115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133734256&doi=10.1109%2fTKDE.2022.3185115&partnerID=40&md5=f0d0408b7d854ffa572c7ea9e712f1d1},
	abstract = {Time-series and event sequences are widely collected data types in real-world applications. Modeling and forecasting of such temporal data play an important role in an informed decision-making process. A major limitation of previous methods is that they either focus on time-series or events, rather than the combination of the two worlds. In fact, the two types of data often provide complementary information, emphasizing the necessity of jointly modeling the both. In this paper, we propose the RNN-ODE collaborative model for joint modeling and forecasting of heterogeneous time-series and event sequence data, which combines several useful techniques from both Bayesian and deep learning for its interpretability. Specifically, we devise a tailored encoder to combine the advances in deep temporal point processes models and variational recurrent neural networks. To predict the probability of event occurrence over an arbitrary continuous-time horizon, we base our model on the mathematical foundation of Neural Ordinary Differential Equations (NODE). Extensive experimental results on simulations and real data sets show that compared with existing methods, our integrated approach can achieve more competitive forecasting performance of both time-series and event sequences. IEEE},
	author_keywords = {conditional variational learning; Data models; Estimation; event prediction; Forecasting; Mathematical models; ordinary differential equations; Predictive models; Probabilistic forecasting; Probabilistic logic; temporal point processes; Time series analysis; time-series; variational auto-encoder},
	keywords = {Continuous time systems; Data mining; Decision making; Learning systems; Ordinary differential equations; Probabilistic logics; Real time systems; Recurrent neural networks; Signal encoding; Time series analysis; Auto encoders; Conditional variational learning; Event prediction; Point process; Predictive models; Probabilistic forecasting; Temporal point process; Time-series analysis; Times series; Variational auto-encoder; Forecasting},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Wang2023,
	author = {Wang, Ting and Wang, Na and Cui, Yunpeng and Liu, Juan},
	title = {The Application Mode of Multi-Dimensional Time Series Data Based on a Multi-Stage Neural Network},
	year = {2023},
	journal = {Electronics (Switzerland)},
	volume = {12},
	number = {3},
	doi = {10.3390/electronics12030578},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147877749&doi=10.3390%2felectronics12030578&partnerID=40&md5=5f5990629126f1d694e7ba2ef2072037},
	abstract = {How to use multi-dimensional time series data is a huge challenge for big data analysis. Multiple trajectories of medical use in electronic medical data are typical time series data. Although many artificial-intelligence techniques have been proposed to use the multiple trajectories of medical use in predicting the risk of concurrent medical use, most existing methods pay less attention to the temporal property of medical-use trajectory and the potential correlation between the different trajectories of medical use, resulting in limited concurrent multi-trajectory applications. To address the problem, we proposed a multi-stage neural network-based application mode of multi-dimensional time series data for feature learning of high-dimensional electronic medical data in adverse event prediction. We designed a synthetic factor for the multiple -trajectories of medical use with the combination of a Long Short Term Memory–Deep Auto Encoder neural network and bisecting k-means clustering method. Then, we used a deep neural network to produce two kinds of feature vectors for risk prediction and risk-related factor analysis, respectively. We conducted extensive experiments on a real-world dataset. The results showed that our proposed method increased the accuracy by 5%~10%, and reduced the false rate by 3%~5% in the risk prediction of concurrent medical use. Our proposed method contributes not only to clinical research, where it helps clinicians make effective decisions and establish appropriate therapy programs, but also to the application optimization of multi-dimensional time series data for big data analysis. © 2023 by the authors.},
	author_keywords = {concurrent medical use; electronic medical data; feature learning; neural network; risk prediction; time series data},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Xu2022,
	author = {Xu, Dongting and Zhang, Zhisheng and Shi, Jinfei},
	title = {Training Data Selection by Categorical Variables for Better Rare Event Prediction in Multiple Products Production Line},
	year = {2022},
	journal = {Electronics (Switzerland)},
	volume = {11},
	number = {7},
	doi = {10.3390/electronics11071056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127039416&doi=10.3390%2felectronics11071056&partnerID=40&md5=be7224296da08e7c75502fafba52e826},
	abstract = {Manufacturers are struggling to use data from multiple products production lines to predict rare events. Improving the quality of training data is a common way to improve the performance of algorithms. However, there is little research about how to select training data quantitatively. In this study, a training data selection method is proposed to improve the performance of deep learning models. The proposed method can represent different time length multivariate time series spilt by categorical variables and measure the (dis)similarities by the distance matrix and clustering method. The contributions are: (1) The proposed method can find the changes to the training data caused by categorical variables in a multivariate time series dataset; (2) according to the proposed method, the multivariate time series data from the production line can be clustered into many small training datasets; and (3) same structure but different parameters prediction models are built instead of one model which is different from the traditional way. In practice, the proposed method is applied in a real multiple products production line dataset and the result shows it can not only significantly improve the performance of the reconstruction model but it can also quantitively measure the (dis)similarities of the production behaviors. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {autoencoder; categorical variables; Euclidian distance matrix; integrated feature representation; multivariate time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Dumitrescu20213,
	author = {Dumitrescu, Theodora and Dobrescu, Radu},
	title = {Improved algorithm for seismic extreme events prediction},
	year = {2021},
	journal = {UPB Scientific Bulletin, Series C: Electrical Engineering and Computer Science},
	volume = {83},
	number = {1},
	pages = {3 – 14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102928451&partnerID=40&md5=09e688d58529f42b3794a016afdc87ca},
	abstract = {The paper proposes an improved variant of the classic M8 extreme events prediction algorithm, opting for a modeling framework with additional parameters which allow better adaptation to the local characteristics of the seismic zone of interest, in this case the Vrancea region. These characteristics include: the assessment of seismic cycles, the distribution of earthquakes by magnitude, the spatio-temporal clustering of earthquakes and a seismicity model that can foreshadow large magnitude earthquakes. The efficiency of the proposed algorithm is compared with those of the classical algorithm by simulations based on numerous scenarios combining the intervals of selection of historical and prediction data, respectively. © 2021, Politechnica University of Bucharest. All rights reserved.},
	author_keywords = {Earthquakes occurrence; Extreme events; Prediction algorithms; Time series},
	keywords = {Forecasting; Extreme events; Local characteristics; Model framework; Prediction algorithms; Seismic zones; Spatio-temporal clustering; Vrancea region; Earthquakes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gmati201912,
	author = {Gmati, Fatma Ezzahra and Chakhar, Salem and Chaari, Wided Lejouad and Xu, Mark},
	title = {A taxonomy of event prediction methods},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11606 LNAI},
	pages = {12 – 26},
	doi = {10.1007/978-3-030-22999-3_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068602372&doi=10.1007%2f978-3-030-22999-3_2&partnerID=40&md5=09f40d83cbc59ba8a4cd0e89a05f7272},
	abstract = {Most of existing event prediction approaches consider event prediction problems within a specific application domain while event prediction is naturally a cross-disciplinary problem. This paper introduces a generic taxonomy of event prediction approaches. The proposed taxonomy, which oversteps the application domain, enables a better understanding of event prediction problems and allows conceiving and developing advanced and context-independent event prediction techniques. © Springer Nature Switzerland AG 2019.},
	author_keywords = {Data mining; Event prediction; Taxonomy; Time series},
	keywords = {Data mining; Intelligent systems; Taxonomies; Time series; Context independent; Cross-disciplinary; Event prediction; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Mathew201829,
	author = {Mathew, Tharindu and Raghavan, Aswin and Chai, Sek},
	title = {Event Prediction in Processors Using Deep Temporal Models},
	year = {2018},
	journal = {Proceedings - 1st Workshop on Energy Efficient Machine Learning and Cognitive Computing for Embedded Applications, EMC2 2018},
	pages = {29 – 33},
	doi = {10.1109/EMC2.2018.00014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058276764&doi=10.1109%2fEMC2.2018.00014&partnerID=40&md5=8f9f7f7d65c0bd43b42905e42039c268},
	abstract = {In order to achieve high processing efficiencies, next generation computer architecture designs need an effective Artificial Intelligence (AI)-framework to learn large-scale processor interactions. In this short paper, we present Deep Temporal Models (DTMs) that offer effective and scalable time-series representations to addresses key challenges for learning processor data: high data rate, cyclic patterns, and high dimensionality. We present our approach using DTMs to learn and predict processor events. We show comparisons using these learning models with promising initial simulation results. © 2018 IEEE.},
	author_keywords = {computer architecture; Deep learning; event prediction; temporal models},
	keywords = {Artificial intelligence; Deep learning; Energy efficiency; Forecasting; Cyclic patterns; Event prediction; High data rate; High dimensionality; Learning models; Temporal models; Computer architecture},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Durán-Rosal2018347,
	author = {Durán-Rosal, A.M. and Fernández, J.C. and Casanova-Mateo, C. and Sanz-Justo, J. and Salcedo-Sanz, S. and Hervás-Martínez, C.},
	title = {Efficient fog prediction with multi-objective evolutionary neural networks},
	year = {2018},
	journal = {Applied Soft Computing Journal},
	volume = {70},
	pages = {347 – 358},
	doi = {10.1016/j.asoc.2018.05.035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048483875&doi=10.1016%2fj.asoc.2018.05.035&partnerID=40&md5=9662c80821f8dc55e53064fb7c0a63dc},
	abstract = {This paper proposes the application of novel artificial neural networks with evolutionary training and different basic functions (sigmoidal, product and radial), for a real problem of fog events classification from meteorological input variables. Specifically, a Multiobjective Evolutionary Algorithm is considered as artificial neural network training mechanism in order to obtain a binary classification model for the detection of fog events at Valladolid airport (Spain). The evolutionary neural models developed are based on two-dimensional performance measures: traditional accuracy and the minimum sensitivity, as the lowest percentage of examples correctly predicted as belonging to each class with respect to the total number of examples in the corresponding class. These performance measures are directly related to features associated with any classifier: its global performance and the rate of the worst classified class. These two objectives are usually in conflict when the optimization process tries to construct models with a high classification rate level in the generalization dataset, and also with a good classification level for each class or minimum sensitivity. A sensitivity analysis of the proposed models is carried out, and thus the subjacent relations between the input variables and the output classification target can be better understood. © 2018 Elsevier B.V.},
	author_keywords = {Fog events prediction; Multiobjective Evolutionary Algorithm; Neural networks; Time series},
	keywords = {Classification (of information); Fog; Neural networks; Sensitivity analysis; Time series; Binary classification; Classification rates; Evolutionary training; Fog events; Meteorological input; Minimum sensitivities; Multi objective evolutionary algorithms; Multi-objective evolutionary; Evolutionary algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@CONFERENCE{Seth2020218,
	author = {Seth, Taruna and Chaudhary, Vipin},
	title = {A Predictive Analytics Framework for Insider Trading Events},
	year = {2020},
	journal = {Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020},
	pages = {218 – 225},
	doi = {10.1109/BigData50022.2020.9377791},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103855986&doi=10.1109%2fBigData50022.2020.9377791&partnerID=40&md5=145300939562141b3e5101104595d78c},
	abstract = {Financial markets are driven by complex dynamics and interplay, often stemming from convoluted investor interactions, asset and inter-market complexities. Such intricacies make it difficult to identify illegal trading activities like insider trading. Despite several advancements, the detection of such financial markets events remains elusive due to complex interactions among the market constituents. In this paper, we propose a novel solution to detect illegal trading activities driven by material nonpublic information. We accomplish this task by deploying a multistage methodology that includes a predictive modeling approach without the added constraint of having training data with the events of interest, an event prediction and detection methodology based on unstructured and structured data, a classification, and an evaluation approach to identify illegal insider trading events with good confidence. O ur r esults o n t he r eal t est d ata confirm the efficacy o f t he p roposed s olution t o d etect i nsider trading activities in the U.S. equity markets. © 2020 IEEE.},
	author_keywords = {Anomaly Detection; Classification; Deep Networks; Illegal Events Library; Illegal Insider Trading; Natural Language Processing; Time-series forecasting},
	keywords = {Big data; Classification (of information); Crime; Financial markets; Investments; Predictive analytics; Complex dynamics; Equity markets; Evaluation approach; Event prediction; Insider trading; Predictive modeling; Structured data; Training data; Commerce},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Yang2022,
	author = {Yang, Yikai and Truong, Nhan Duy and Eshraghian, Jason K. and Nikpour, Armin and Kavehei, Omid},
	title = {Weak self-supervised learning for seizure forecasting: a feasibility study},
	year = {2022},
	journal = {Royal Society Open Science},
	volume = {9},
	number = {8},
	doi = {10.1098/rsos.220374},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135717265&doi=10.1098%2frsos.220374&partnerID=40&md5=da1d072362d3916fb6f30f0bac890fcf},
	abstract = {This paper proposes an artificial intelligence system that continuously improves over time at event prediction using initially unlabelled data by using self-supervised learning. Time-series data are inherently autocorrelated. By using a detection model to generate weak labels on the fly, which are concurrently used as targets to train a prediction model on a time-shifted input data stream, this autocorrelation can effectively be harnessed to reduce the burden of manual labelling. This is critical in medical patient monitoring, as it enables the development of personalized forecasting models without demanding the annotation of long sequences of physiological signal recordings. We perform a feasibility study on seizure prediction, which is identified as an ideal test case, as pre-ictal brainwaves are patient-specific, and tailoring models to individual patients is known to improve forecasting performance significantly. Our self-supervised approach is used to train individualized forecasting models for 10 patients, showing an average relative improvement in sensitivity by 14.30% and a reduction in false alarms by 19.61% in early seizure forecasting. This proof-of-concept on the feasibility of using a continuous stream of time-series neurophysiological data paves the way towards a low-power neuromorphic neuromodulation system.  © 2022 The Authors.},
	author_keywords = {adaptive forecasting and self-learning model; epileptic seizure forecasting; neuromorphic neuromodulation; online learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Pretzner2021,
	author = {Pretzner, Barbara and Maschke, Rüdiger W. and Haiderer, Claudia and John, Gernot T. and Herwig, Christoph and Sykacek, Peter},
	title = {Predictive monitoring of shake flask cultures with online estimated growth models},
	year = {2021},
	journal = {Bioengineering},
	volume = {8},
	number = {11},
	doi = {10.3390/bioengineering8110177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119040831&doi=10.3390%2fbioengineering8110177&partnerID=40&md5=4e69d181b547b6694079656ac809df61},
	abstract = {Simplicity renders shake flasks ideal for strain selection and substrate optimization in biotechnology. Uncertainty during initial experiments may, however, cause adverse growth conditions and mislead conclusions. Using growth models for online predictions of future biomass (BM) and the arrival of critical events like low dissolved oxygen (DO) levels or when to harvest is hence important to optimize protocols. Established knowledge that unfavorable metabolites of growing microorganisms interfere with the substrate suggests that growth dynamics and, as a consequence, the growth model parameters may vary in the course of an experiment. Predictive monitoring of shake flask cultures will therefore benefit from estimating growth model parameters in an online and adaptive manner. This paper evaluates a newly developed particle filter (PF) which is specifically tailored to the requirements of biotechnological shake flask experiments. By combining stationary accuracy with fast adaptation to change the proposed PF estimates time-varying growth model parameters from iteratively measured BM and DO sensor signals in an optimal manner. Such proposition of inferring time varying parameters of Gompertz and Logistic growth models is to our best knowledge novel and here for the first time assessed for predictive monitoring of Escherichia coli (E. coli) shake flask experiments. Assessments that mimic real-time predictions of BM and DO levels under previously untested growth conditions demonstrate the efficacy of the approach. After allowing for an initialization phase where the PF learns appropriate model parameters, we obtain accurate predictions of future BM and DO levels and important temporal characteristics like when to harvest. Statically parameterized growth models that represent the dynamics of a specific setting will in general provide poor characterizations of the dynamics when we change strain or substrate. The proposed approach is thus an important innovation for scientists working on strain characterization and substrate optimization as providing accurate forecasts will improve reproducibility and efficiency in early-stage bioprocess development. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Critical event prediction; Escherichia coli; Gompertz function; Harvest time estimation; Logistic function; Particle filter; Shake flask; Strain and substrate optimization; Time series forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Vernardos20224417,
	author = {Vernardos, G.},
	title = {Simulating time-varying strong lenses},
	year = {2022},
	journal = {Monthly Notices of the Royal Astronomical Society},
	volume = {511},
	number = {3},
	pages = {4417 – 4429},
	doi = {10.1093/mnras/stac268},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128311124&doi=10.1093%2fmnras%2fstac268&partnerID=40&md5=f2c68154b076067c6ff650c0ce3737f9},
	abstract = {We present a self-consistent and versatile forward modelling software package that can produce time series and pixel-level simulations of time-varying strongly lensed systems. The time dimension, which needs to take into account different physical mechanisms for variability such as microlensing, has been missing from existing approaches and it is of direct relevance to time delay, and consequently H0, measurements and caustic crossing event predictions. Such experiments are becoming more streamlined, especially with the advent of time domain surveys, and understanding their systematic and statistical uncertainties in a model-aware and physics-driven way can help improve their accuracy and precision. Here, we demonstrate the software's capabilities by exploring the effect of measuring time delays from lensed quasars and supernovae in many wavelengths and under different microlensing and intrinsic variability assumptions. In this initial application, we find that the cadence of the observations and combining information from different wavelengths plays an important role in the correct recovery of the time delays. The mock lenses in time software package is available at https://github.com/gvernard/molet.  © 2022 The Author(s) Published by Oxford University Press on behalf of Royal Astronomical Society.},
	author_keywords = {gravitational lensing: micro; gravitational lensing: strong},
	keywords = {Software packages; Statistical Physics; Supernovae; Forward modeling; Gravitational lensing: micros; Gravitational lensing: strong; Micro-lensing; Modeling softwares; Pixel level; Time dimension; Time varying; Time-delays; Times series; Time delay},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@CONFERENCE{Cadei2019,
	author = {Cadei, L. and Camarda, G. and Montini, M. and Rossi, G. and Fier, P. and Bianco, A. and Lancia, L. and Loffreno, D. and Corneo, A. and Milana, D. and Carrettoni, M. and Silvestri, G.},
	title = {Prediction and prescription of operation upset in H2S gas sweetening unit: Implementation of an innovative big data analytics procedure},
	year = {2019},
	journal = {Offshore Mediterranean Conference and Exhibition 2019, OMC 2019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066779915&partnerID=40&md5=177f663e31df4892cee1834b52387d56},
	abstract = {This paper highlights the development and results of a machine-learning based end-to-end system for process upset and hazard events prediction in gas-sweetening procedures; this tool has been applied to production operations of an oil-and-gas field. High H2S concentration in the produced gas represents a serious issue due to its environmental impact, the impossibility to deliver acid gas to the distribution network and the asset deterioration. The proposed tool monitors the status of the equipment in near real-time. Whereby an alarm is raised, prescriptive information is provided to avoid, or mitigate, operational issues. This can be accomplished by using machine learning algorithms and data mining techniques in a Big Data Infrastructure. In the illustrated case, a complex data-lake was built by ingesting and aggregating in a Big Data Environment times-series data from field sensor network, maintenance reports and chemical analyses. A machine learning algorithm has been trained to identify faults in the gas-sweetening unit resulting in a high concentration of H2S in the processed gas. The development of the tool has been conducted in collaboration with site engineers and operators to identify the most relevant data sources describing the process and to validate the algorithm outputs. Several machine learning algorithms have been tested (Deep Learning, Random Forest, Gradient Boosting Trees) to improve model accuracy and clarify the interpretation of the phenomenon root causes. Finally, the tool is now fed with real-time data and predicts hazardous events in near real-time. The alerts raised by the system are stored and archived in the Big Data Environment for further analysis. Field operators and process engineers can therefore access those new insights, and the related data, using the tools already in use during the daily monitoring operations. Alongside, a dedicated visualization tool was designed to monitor the model performances and guarantee its life-cycle. The innovative characteristics of the tool lay in its ability to exploit the huge amount of field-data and to simulate complex phenomena through Big Data Analytics. It is now possible for the site operators to receive preventive warnings on relevant events, gather information on the possible root causes and on the recommended actions to prepare for the upcoming event. Ultimately, this framework allows to insure the constant flow of the gas into the distribution network, to avoid or mitigate halts in production and to guarantee asset integrity. © 2019 Offshore Mediterranean Conference (OMC). All rights reserved.},
	keywords = {Adaptive boosting; Advanced Analytics; Big data; Chemical analysis; Complex networks; Data Analytics; Data mining; Decision trees; Deep learning; Deterioration; Environmental impact; Gas industry; Gases; Hazards; Life cycle; Machine learning; Offshore gas fields; Offshore oil well production; Oil field development; Sensor networks; Asset deterioration; Data infrastructure; End-to-end systems; Model performance; Oil and gas fields; Operational issues; Production operations; Visualization tools; Oil field equipment},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Koo2019,
	author = {Koo, Ki-sung and Govindarasu, Manimaran and Tian, Jin},
	title = {Event prediction algorithm using neural networks for the power management system of electric vehicles},
	year = {2019},
	journal = {Applied Soft Computing Journal},
	volume = {84},
	doi = {10.1016/j.asoc.2019.105709},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071081058&doi=10.1016%2fj.asoc.2019.105709&partnerID=40&md5=58f1663061f5071d15cebd566d2a7451},
	abstract = {The power management system for electronic vehicles selectively activates Electronic Control Units (ECUs) in the electronic control system according to time-series vehicle data and predefined operation states. However, at an operation state transition, the energy overheads used for the selective ECU activation could be higher than the energy saved by deactivating ECUs. To prevent these energy-inefficient state transitions, we apply two main ideas to our proposed algorithm: (A) unacceptable state transitions and (B) adaptive training speed. For the unacceptable transitions, our energy model evaluates the breakeven time where energy saving equals to energy overheads. Based on the breakeven time, our algorithm classifies training dataset as unacceptable and acceptable event sets. Especially when the algorithm trains neural networks for the two event sets, the adaptive training speed expedites its training speed based on a history of training errors. Consequently, without violating in-vehicle time constraints, the algorithm could provide real-time predictions and save energy overheads by avoiding unacceptable transitions. In the simulation results on real driving datasets, our algorithm improves the energy dissipation of the electronic control system by 5% to 7%. © 2019 Elsevier B.V.},
	author_keywords = {Electric vehicles; Event prediction; Neural network training; Neural networks; Power management system; Real-time systems; Time-series data},
	keywords = {Control systems; Electric power measurement; Electric vehicles; Energy conservation; Energy dissipation; Forecasting; Industrial electronics; Information management; Interactive computer systems; Neural networks; Power management; Servomechanisms; Time series; Electronic control systems; Electronic control units; Electronic vehicles; Event prediction; Neural network training; Power management systems; Real-time prediction; Time-series data; Real time systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Zhong2023,
	author = {Zhong, Zihan and Lv, Shu and Shi, Kaibo},
	title = {A New Method of Time-Series Event Prediction Based on Sequence Labeling},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {9},
	doi = {10.3390/app13095329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159324875&doi=10.3390%2fapp13095329&partnerID=40&md5=1917dbd9600e4ffe57e5eede5ebe8825},
	abstract = {In the existing research on time-series event prediction (TSEP) methods, most of the work is focused on improving the algorithm for classifying subsequence sets (sets composed of multiple adjacent subsequences). However, these prediction methods ignore the timing dependence between the subsequence sets, nor do they capture the mutual transition relationship between events, the prediction effect on a small sample data set is very poor. Meanwhile, the sequence labeling problem is one of the common problems in natural language processing and image segmentation. To solve this problem, this paper proposed a new framework for time-series event prediction, which transforms the event prediction problem into a labeling problem, to better capture the timing relationship between the subsequence sets. Specifically, the framework used a sequence clustering algorithm for the first time to identify representative patterns in the time series, then represented the set of subsequences as a weighted combination of patterns, and used the eXtreme gradient boosting algorithm (XGBoost) for feature selection. After that, the selected pattern feature was used as the input of the long-term short-term memory model (LSTM) to obtain the preliminary prediction value. Furthermore, the fully-linked conditional random field (CRF) was used to smooth and refine the preliminary prediction value to obtain the final prediction result. Finally, the experimental results of event prediction on five real data sets show that the CX-LC method has a certain improvement in prediction accuracy compared with the other six models. © 2023 by the authors.},
	author_keywords = {CRF; LSTM; pattern recognition; sequence labeling; TSEP; XGBoost},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Lin20211122,
	author = {Lin, Yu-Kai and Fang, Xiao},
	title = {First, Do No Harm: Predictive Analytics to Reduce In-Hospital Adverse Events},
	year = {2021},
	journal = {Journal of Management Information Systems},
	volume = {38},
	number = {4},
	pages = {1122 – 1149},
	doi = {10.1080/07421222.2021.1990619},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122235675&doi=10.1080%2f07421222.2021.1990619&partnerID=40&md5=c14848436157fee435540d1c4cc5ddf0},
	abstract = {Inadequate patient safety is a serious issue in current medical practice. Medical errors cause adverse events (AEs) for patients and lead to premature deaths, unintended complications, prolonged hospital stays, and higher medical costs. Although the importance of AE prediction and prevention is well recognized in the information systems literature, there is a dearth of research on modeling and predicting AEs caused by medical errors. Following the design science research paradigm, this study describes the search, design, and evaluation of a novel in-hospital AE prediction model, called Stochastic Autoregressions for Latent Trajectories (SALT). The proposed model uniquely integrates generalized linear mixed model with multitask learning and stochastic time-series processes. Results from our empirical evaluation show that SALT outperforms prior state-of-the-art techniques in predicting AEs during patients’ hospital stays. Through a simulation, we further demonstrate significant cost savings potential when hospitals implement and integrate SALT in their inpatient care. This study contributes to the design science literature by formalizing the in-hospital AE prediction problem, on the one hand, and developing a novel graphical model to address the prediction problem, on the other. For healthcare practitioners and administrators, our predictive analytics approach unveils important insights to minimize AEs. © 2021 Taylor & Francis Group, LLC.},
	author_keywords = {adverse events; design science; healthcare predictive analytics; HealthTech; medical errors; patient safety},
	keywords = {Design; Errors; Forecasting; Hospitals; Learning systems; Medical information systems; Predictive analytics; Regression analysis; Stochastic models; Stochastic systems; Adverse events; Autoregression; Design science; Event prediction; Healthcare predictive analytic; Healthtech; Medical errors; Patient safety; Prediction problem; Stochastics; Health care},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Merembayev2022,
	author = {Merembayev, Timur and Amanbek, Yerlan},
	title = {Time-series event prediction for the uranium production wells using machine learning algorithms},
	year = {2022},
	journal = {56th U.S. Rock Mechanics/Geomechanics Symposium},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149229475&partnerID=40&md5=bc12552cb87eb6cab80c105c0babac9c},
	abstract = {The efficient estimation of the production rate in the uranium reservoir plays a vital role in the evaluation of operational performance. This paper presents the data-driven production model in the uranium field using LightGBM for the data from the Kazakhstan deposits. We focus on predicting the fault events of the well production solution. Numerical results of this investigation show that LightGBM achieves an accurate prediction with wavelet transformation. The evaluation of the model score is conducted by using metrics such as Recall and F1. With feature engineering by wavelet transformation, we obtained the recall of 0.84 and f1 of 0.89. The LightGBM model with the Morlet wavelet transformation can be useful to solve the issue of prediction maintenance of production well. © 2022 ARMA, American Rock Mechanics Association.},
	keywords = {Forecasting; Learning algorithms; Machine learning; Rock mechanics; Wavelet transforms; Data driven; Efficient estimation; Event prediction; Machine learning algorithms; Operational performance; Production rates; Production wells; Time-series events; Uranium production; Wavelet transformations; Uranium},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Lee2021,
	author = {Lee, Wonjae and Seo, Kangwon},
	title = {Early failure detection of paper manufacturing machinery using nearest neighbor-based feature extraction},
	year = {2021},
	journal = {Engineering Reports},
	volume = {3},
	number = {2},
	doi = {10.1002/eng2.12291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135982705&doi=10.1002%2feng2.12291&partnerID=40&md5=ce8c498c017c7b671ce5548bf0347b00},
	abstract = {In a paper manufacturing system, it is substantially important to detect machine failure before it occurs and take necessary maintenance actions to prevent an unexpected breakdown of the system. Multiple sensor data collected from a machine provides useful information on the system's health condition. However, it is hard to predict the system condition ahead of time due to the lack of clear ominous signs for future failures, a rare occurrence of failure events, and a wide range of sensor signals which might be correlated with each other. We present two versions of feature extraction techniques based on the nearest neighbor combined with machine learning algorithms to detect a failure of the paper manufacturing machinery earlier than its occurrence from the multistream system monitoring data. First, for each sensor stream, the time series data is transformed into the binary form by extracting the class label of the nearest neighbor. We feed these transformed features into the decision tree classifier for the failure classification. Second, expanding the idea, the relative distance to the local nearest neighbor has been measured, results in the real-valued feature, and the support vector machine is used as a classifier. Our proposed algorithms are applied to the dataset provided by Institute of Industrial and Systems Engineers 2019 data competition, and the results show better performance than other state-of-the-art machine learning techniques. © 2020 The Authors. Engineering Reports published by John Wiley & Sons Ltd.},
	author_keywords = {1-nearest neighbor; feature extraction; multistream time series classification; rare event prediction; relative distance},
	keywords = {Competition; Data; Extraction; Failure; Machinery; Monitoring; Paper; Systems; Competition; Data mining; Data streams; Decision trees; Extraction; Feature extraction; Learning algorithms; Machinery; Monitoring; Papermaking; Support vector machines; Turing machines; Decision tree classifiers; Early failure detection; Failure classification; Feature extraction techniques; Machine learning techniques; Maintenance Action; Paper manufacturing; Relative distances; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Molokwu2019,
	author = {Molokwu, Bonaventure C. and Kobti, Ziad},
	title = {Spatial Event Prediction via Multivariate Time Series Analysis of Neighboring Social Units using Deep Neural Networks},
	year = {2019},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	volume = {2019-July},
	doi = {10.1109/IJCNN.2019.8851730},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073243252&doi=10.1109%2fIJCNN.2019.8851730&partnerID=40&md5=6610dd8a5d6d103078db12f432977bca},
	abstract = {Event prediction in social network structures is a crucial research problem in social network analysis. This impels understanding the intrinsic relationship patterns preserving a given social network structure, based on the study of several structural properties computed on the constituent social units, with respect to space and time. In this regard, tackling problems of this nature is considered NP-Complete. Consequently, this paper proposes an original and unique approach which involves making event predictions about a target social unit, y, based on the intrinsic patterns of relationship learnt from one or more neighboring social units. Our methodology is based on Deep Learning (DL) architectures, and is developed using deep-layer stacks of Multilayer Perceptron (MLP) appended with an adjustment-bias (ab) vector at the output layer in a bid to improve the accuracy and precision of predictions made with respect to the target unit (or node). Also, we trained and tested our technique on a real world social clique comprising 5 connected cities; thereafter, we performed a comparative analysis of our approach against 9 other models drawn from the fields of Deep Learning, Machine Learning, and Statistics. © 2019 IEEE.},
	author_keywords = {Adjustment Bias; Deep Learning; Machine Learning; Multilayer Perceptron; Statistical Models},
	keywords = {Deep learning; Forecasting; Learning systems; Machine learning; Multilayer neural networks; Multilayers; Structural properties; Time series analysis; Accuracy and precision; Adjustment Bias; Comparative analysis; Event prediction; Multi layer perceptron; Multivariate time series analysis; Research problems; Social network structures; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Shen2018724,
	author = {Shen, Bilong and Liu, Miaofeng and Liang, Xiaodan and Zheng, Weimin and Ouyang, Yufeng and Carley, Kathleen M.},
	title = {StepDeep: A novel spatial-temporal mobility event prediction framework based on deep neural network},
	year = {2018},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {724 – 733},
	doi = {10.1145/3219819.3219931},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051462834&doi=10.1145%2f3219819.3219931&partnerID=40&md5=f4dfb5d4be76d603a5199cbd7b40d3bb},
	abstract = {A mobility event occurs when a passenger moves out or takes off from a particular location. Mobility event prediction is of utmost importance in the field of intelligent transportation systems. It has a huge potential in solving important problems such as minimizing passenger waiting time and maximizing the utilization of the transportation resources by planning vehicle routes and dispatching transportation resources. Recently, numerous mobility pattern mining methods have been proposed to predict the transportation supply and demand in different locations. Those methods first reveal the event patterns of each Place of Interests (POI) independently and then employ a separate region function as a post-processing step. This separate process, that disregards the intrinsic spatial and temporal pattern correlations between POI, is sub-optimal and complex, resulting in a poor generalization in different scenarios. In this work, we propose a Spatial-Temporal mobility Event Prediction framework based on Deep neural network (StepDeep) for simultaneously taking into account all correlated spatial and temporal mobility patterns. StepDeep not only simplifies the prediction process but also enhances the prediction accuracy. Our StepDeep proposes a novel problem formulation towards an end-to-end mobility prediction framework, that is, switching mobility events over time in an area into an event video and then posing the mobility prediction problem as a video prediction task. Such a novel formulation can naturally encode spatial and temporal dependencies for each POI. StepDeep thus predicts the spatial-temporal events by incorporating the new time sensitive convolution filters, spatial sensitive convolution filters, and spatial-temporal sensitive convolution filters into a single network. We conduct experimental evaluations on a real-world 547-day New York City taxi trajectory dataset, which show that StepDeep provides higher prediction accuracy than five existing baselines. Moreover, StepDeep is generalizable and can be applied to numerous spatial-temporal event prediction scenarios. © 2018 Association for Computing Machinery.},
	author_keywords = {Convolutional neural network; Deep learning; Intelligent transportation systems; Spatial temporal data mining; Time series prediction},
	keywords = {Convolution; Data mining; Deep learning; Economics; Filtration; Forecasting; Intelligent systems; Intelligent vehicle highway systems; Neural networks; Problem solving; Taxicabs; Transportation routes; Convolutional neural network; Experimental evaluation; Intelligent transportation systems; Passenger waiting time; Spatial and temporal patterns; Spatial-temporal data minings; Time series prediction; Transportation resources; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38}
}

@CONFERENCE{Hu2021580,
	author = {Hu, Wenjie and Yang, Yang and Cheng, Ziqiang and Yang, Carl and Ren, Xiang},
	title = {Time-Series Event Prediction with Evolutionary State Graph},
	year = {2021},
	journal = {WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
	pages = {580 – 588},
	doi = {10.1145/3437963.3441827},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103048620&doi=10.1145%2f3437963.3441827&partnerID=40&md5=31b52d48990cdca6e58dc87cbe40a4aa},
	abstract = {The accurate and interpretable prediction of future events in time-series data often requires the capturing of representative patterns (or referred to as states) underpinning the observed data. To this end, most existing studies focus on the representation and recognition of states, but ignore the changing transitional relations among them. In this paper, we present evolutionary state graph, a dynamic graph structure designed to systematically represent the evolving relations (edges) among states (nodes) along time. We conduct analysis on the dynamic graphs constructed from the time-series data and show that changes on the graph structures (e.g., edges connecting certain state nodes) can inform the occurrences of events (i.e., time-series fluctuation). Inspired by this, we propose a novel graph neural network model, Evolutionary State Graph Network (EvoNet), to encode the evolutionary state graph for accurate and interpretable time-series event prediction. Specifically, EvoNet models both the node-level (state-to-state) and graph-level (segment-to-segment) propagation, and captures the node-graph (state-to-segment) interactions over time. Experimental results based on five real-world datasets show that our approach not only achieves clear improvements compared with 11 baselines, but also provides more insights towards explaining the results of event predictions. © 2021 ACM.},
	author_keywords = {evolutionary state graph; graph networks; time series prediction},
	keywords = {Backpropagation; Data mining; Forecasting; Graph structures; Graphic methods; Information retrieval; Neural networks; Time series; Time series analysis; Websites; Dynamic graph; Event prediction; Graph neural networks; Observed data; Real-world datasets; Representative patterns; Time-series data; Time-series events; Graph theory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Green Open Access}
}

@ARTICLE{Gadaleta2019650,
	author = {Gadaleta, Matteo and Facchinetti, Andrea and Grisan, Enrico and Rossi, Michele},
	title = {Prediction of Adverse Glycemic Events From Continuous Glucose Monitoring Signal},
	year = {2019},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	volume = {23},
	number = {2},
	pages = {650 – 659},
	doi = {10.1109/JBHI.2018.2823763},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045188413&doi=10.1109%2fJBHI.2018.2823763&partnerID=40&md5=061ae956084b1d08a7a7c33eb8087ad9},
	abstract = {The most important objective of any diabetes therapy is to maintain the blood glucose concentration within the euglycemic range, avoiding or at least mitigating critical hypo/hyperglycemic episodes. Modern continuous glucose monitoring (CGM) devices bear the promise of providing the patients with an increased and timely awareness of glycemic conditions as these get dangerously near to hypo/hyperglycemia. The challenge is to detect, with reasonable advance, the patterns leading to risky situations, allowing the patient to make therapeutic decisions on the basis of future (predicted) glucose concentration levels. We underline that a technically sound performance comparison of the approaches proposed in recent years has yet to be done, thus it is unclear which one is preferred. The aim of this study is to fill this gap by carrying out a comparative analysis among the most common methods for glucose event prediction. Both regression and classification algorithms have been implemented and analyzed, including static and dynamic training approaches. The dataset consists of 89 CGM time series measured in diabetic subjects for 7 subsequent days. Performance metrics, specifically defined to assess and compare the event-prediction capabilities of the methods, have been introduced and analyzed. Our numerical results show that a static training approach exhibits better performance, in particular when regression methods are considered. However, classifiers show some improvement when trained for a specific event category, such as hyperglycemia, achieving performance comparable to the regressors, with the advantage of predicting the events sooner. © 2018 IEEE.},
	author_keywords = {Continuous glucose monitoring (CGM); event prediction; machine learning; signal processing; type 1 diabetes},
	keywords = {Algorithms; Blood Glucose; Diagnosis, Computer-Assisted; Humans; Hyperglycemia; Hypoglycemia; Monitoring, Ambulatory; Regression Analysis; Signal Processing, Computer-Assisted; Forecasting; Learning systems; Numerical methods; Regression analysis; Signal processing; glucose; insulin; Blood glucose concentration; Classification algorithm; Continuous glucose monitoring; Continuous glucosemonitoring (CGM); Event prediction; Glucose concentration; Performance comparison; Type 1 diabetes; adverse glycemic event; Article; blood glucose monitoring; brain computer interface; continuous glucose monitoring; diabetes mellitus; glucose blood level; human; hyperglycemia; hypoglycemia; insulin dependent diabetes mellitus; learning algorithm; machine learning; prediction; process optimization; signal noise ratio; signal processing; support vector machine; training; algorithm; ambulatory monitoring; computer assisted diagnosis; hyperglycemia; hypoglycemia; procedures; regression analysis; Glucose},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 47; All Open Access, Green Open Access}
}

@ARTICLE{Xiao20193124,
	author = {Xiao, Shuai and Yan, Junchi and Farajtabar, Mehrdad and Song, Le and Yang, Xiaokang and Zha, Hongyuan},
	title = {Learning Time Series Associated Event Sequences with Recurrent Point Process Networks},
	year = {2019},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	volume = {30},
	number = {10},
	pages = {3124 – 3136},
	doi = {10.1109/TNNLS.2018.2889776},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072615871&doi=10.1109%2fTNNLS.2018.2889776&partnerID=40&md5=2cee20e4cbf2db4def3c72589b5f6e99},
	abstract = {Real-world sequential data are often generated based on complicated and latent mechanisms, which can be formulated as event sequences occurring in the continuous time domain. In addition, continuous signals may often be associated with event sequences and be formulated as time series with fixed time lags. Traditionally, event sequences are often modeled by parametric temporal point processes, which use explicitly defined conditional intensity functions to quantify the occurrence rates of events. However, these parametric models often merely take one-side information from event sequences into account while ignoring the information from concurrent time series, and their intensity functions are usually designed for specific tasks dependent on prior knowledge. To tackle the above-mentioned problems, we propose a model called recurrent point process networks which instantiates temporal point process models with temporal recurrent neural networks (RNNs). In particular, the intensity functions of the proposed model are modeled by two RNNs: one temporal RNN capturing the relationships among events and the other RNN updating intensity functions based on time series. Furthermore, an attention mechanism is introduced, which uncovers influence strengths among events with good interpretability. Focusing on challenging tasks such as temporal event prediction and underlying relational network mining, we demonstrate the superiority of our model on both synthetic and real-world data. © 2012 IEEE.},
	author_keywords = {Attentional models; recurrent point process networks (RPPNs); relation discovery; temporal point process},
	keywords = {Continuous time systems; Real time systems; Time series; Attention mechanisms; Conditional intensity function; Intensity functions; Parametric models; Point process; Recurrent neural network (RNNs); relation discovery; Relational network; article; attention; learning; mining; prediction; process model; recurrent neural network; time series analysis; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 60; All Open Access, Bronze Open Access}
}

@ARTICLE{Mehrmolaei2021,
	author = {Mehrmolaei, Soheila},
	title = {EPTs-TL: A two-level approach for efficient event prediction in healthcare},
	year = {2021},
	journal = {Artificial Intelligence in Medicine},
	volume = {111},
	doi = {10.1016/j.artmed.2020.101999},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097713758&doi=10.1016%2fj.artmed.2020.101999&partnerID=40&md5=82c81c44ae4dd9533adfb4a8048c7238},
	abstract = {Recently, the event prediction on time series (EPTs) was discussed as one of the important and interesting research trends that its usage is growing for taking proper decisions in the various sciences. In the real-world, time series event-based analysis can pose as one of the challenging prediction problems in healthcare, which have a direct impact and a key role in supporting health management. In this paper, an efficient approach of two-level (TL) is proposed to the EPTs problem in healthcare, which named EPTs-TL. At the first level, unseen time series data is predicted by using an enhanced hybrid model based on soft computing technology. Then, a new feature extraction-based method is proposed for fuzzy detection of future events in two-level. The EPTs -TL approach employed concepts of three components: weighting, fuzzy logic, and metaheuristics in two-level of the proposed approach. The empirical results demonstrate the excellent performance of the EPTs -TL approach in comparison to conventional prediction models in healthcare and medicine. Also, the proposed approach can be introduced as a strong tool to handle the complex and uncertain behaviors of time series, analyze unusual variations of those, forewarn the possible critical situations in the society, and fuzzy predict event in healthcare. © 2020 Elsevier B.V.},
	author_keywords = {Data-point weighting; EPTs-TL; Event prediction; Fuzzy logic concept; Healthcare database; Metaheuristics},
	keywords = {Delivery of Health Care; Forecasting; Fuzzy Logic; Humans; Feature extraction; Forecasting; Fuzzy logic; Health care; Predictive analytics; Soft computing; Time series; Uncertainty analysis; Event prediction; Health management; Prediction model; Prediction problem; Research trends; Time-series data; Time-series events; Two-level approach; article; feature extraction; fuzzy logic; metaheuristics; prediction; time series analysis; forecasting; health care delivery; human; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Sun2019224,
	author = {Sun, Ying and Zhao, Zijun and Ma, Xiaobin and Du, Zhihui},
	title = {Short-Timescale Gravitational Microlensing Events Prediction with ARIMA-LSTM and ARIMA-GRU Hybrid Model},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11473 LNCS},
	pages = {224 – 238},
	doi = {10.1007/978-3-030-28061-1_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071439460&doi=10.1007%2f978-3-030-28061-1_23&partnerID=40&md5=bba95c3ed4f9868ba0604ca9ef705afc},
	abstract = {Astronomers hope to give early warnings based on light-detection data when some celestial bodies may behave abnormal in the near future, which provides a new method to detect low-mass, free-floating planets. In particular, to search short-timescale microlensing (ML) events from high-cadence and wide-field survey in real time, we combined ARIMA with LSTM and GRU recurrent neural networks (RNN) to monitor all the observed light curves and to alert before abnormal deviation. Using the good linear fitting ability of ARIMA and the strong nonlinear mapping ability of LSTM and GRU, we can form an efficient method better than single RNN network on accuracy, time consuming and computing complexity. ARIMA can reach smaller alerting time and operating time, yet costing high false prediction rate. By sacrificing 15% operating time, hybrid models of ARIMA and LSTM or GRU can achieve improved 14.5% and 13.2% accuracy, respectively. Our work also provide contrast on LSTM and GRU, while the first type is commonly used for time series predicting systems, the latter is more novel. We proved that in the case of abnormal detection of light curves, GRU can be more suitable to apply to as it is less time consuming by 8% while yielding similar results as LSTM. We can draw a conclusion that in the case for short-timescale gravitational microlensing events prediction, hybrid models of ARIMA-LSTM and ARIMA-GRU perform better than separate models. If we concentrate more on accuracy, ARIMA-LSTM is the best option; on the other hand, if we concentrate more on time consuming, ARIMA-GRU can save more time. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {ARIMA; Gravitational lensing; Recurrent neural networks; Time series prediction and alarming},
	keywords = {Forecasting; Information management; Recurrent neural networks; Time series; Abnormal detection; ARIMA; Computing complexity; Free-floating planets; Gravitational lensing; Recurrent neural network (RNN); Time series prediction; Wide-field surveys; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Yue2021477,
	author = {Yue, Xubo and Kontar, Raed Al},
	title = {Joint Models for Event Prediction From Time Series and Survival Data},
	year = {2021},
	journal = {Technometrics},
	volume = {63},
	number = {4},
	pages = {477 – 486},
	doi = {10.1080/00401706.2020.1832582},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096600632&doi=10.1080%2f00401706.2020.1832582&partnerID=40&md5=a64838700c02d8b1306e8729f1f1b109},
	abstract = {We present a nonparametric prognostic framework for individualized event prediction based on joint modeling of both time series and time-to-event data. Our approach exploits a multivariate Gaussian convolution process (MGCP) to model the evolution of time series signals and a Cox model to map time-to-event data with time series data modeled through the MGCP. Taking advantage of the unique structure imposed by convolved processes, we provide a variational inference framework to simultaneously estimate parameters in the joint MGCP-Cox model. This significantly reduces computational complexity and safeguards against model overfitting. Experiments on synthetic and real world data show that the proposed framework outperforms state-of-the art approaches built on two-stage inference and strong parametric assumptions. Technical details are available in the supplementary materials. © 2020 American Statistical Association and the American Society for Quality.},
	author_keywords = {Condition monitoring signals; Gaussian convolution process; Remaining useful life; Survival model},
	keywords = {Biometrics; Statistics; Event prediction; Gaussian convolution; State-of-the-art approach; Technical details; Time series signals; Time to events; Time-series data; Variational inference; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Cüppers20221013,
	author = {Cüppers, Joscha and Kalofolias, Janis and Vreeken, Jilles},
	title = {Omen: discovering sequential patterns with reliable prediction delays},
	year = {2022},
	journal = {Knowledge and Information Systems},
	volume = {64},
	number = {4},
	pages = {1013 – 1045},
	doi = {10.1007/s10115-022-01660-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125596929&doi=10.1007%2fs10115-022-01660-1&partnerID=40&md5=de75b774cb4c81337704389d3b7a7536},
	abstract = {Suppose we are given a discrete-valued time series X of observed events and an equally long binary sequence Y that indicates whether something of interest happened at that particular point in time. We consider the problem of mining serial episodes, sequential patterns allowing for gaps, from X that reliably predict those interesting events. With reliable we mean patterns that not only predict that an interesting event is likely to follow, but in particular that we can also accurately tell how how long until that event will happen. In other words, we are specifically interested in patterns with a highly skewed distribution of delays between pattern occurrences and predicted events. As it is unlikely that a single pattern can explain a complex real-world progress, we are after the smallest, least redundant set of such patterns that together explain the interesting events well. We formally define this problem in terms of the Minimum Description Length principle, by which we identify the best patterns as those that describe the occurrences of interesting events Y most succinctly given the data over X. As neither discovering the optimal explanation of Y given a set of patterns, nor the discovery of optimal pattern set are problems that allow for straightforward optimization, we break the problem in two and propose effective heuristics for both. Through extensive empirical evaluation, we show that both our main method, Omen, and its fast approximation fOmen, work well in practice and both quantitatively and qualitatively beat the state of the art. © 2022, The Author(s).},
	author_keywords = {Event prediction; MDL; Serial episodes; Time series},
	keywords = {Binary sequences; Forecasting; Optimization; Petroleum reservoir evaluation; Event prediction; MDL; Minimum description length principle; Pattern set; Real-world; Sequential patterns; Serial episode; Sets of patterns; Skewed distribution; Times series; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Almadhoun2019,
	author = {Almadhoun, Wael and Alashqar, Ameed},
	title = {A novel hybrid artificial intelligence predictive multi-stages model for gas compressors based on multi-factors},
	year = {2019},
	journal = {Society of Petroleum Engineers - Abu Dhabi International Petroleum Exhibition and Conference 2018, ADIPEC 2018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059978900&partnerID=40&md5=ff29bdb01520b0caeda11dd358d03172},
	abstract = {The objective of this paper is to build a hybrid predictive model for a gas compressor to overcome the operational challenges, optimize maintenance demand and reduce failures risks. This can be achieved by combining a multi layers multi models artificial intelligent techniques to capture all the historical events and improves the model overall accuracy. The time series statistical analytics is commonly used to early predict the potential machine failures or dip in performance in the process industry, by predicting events that occurred in the past and by monitoring the signal trend over time. Recently, other techniques are being used to perform predictive analytics. This includes the use of artificial neural network, the Naïve Bayesian and logistic regressions methods. Statistical time series forecasting methods are categorized in: exponential smoothing methods, autoregressive integrated moving average (ARIMA) methods, regression methods, or recurrent neural network (RNN) methods. Currently, a time series events are typically predicted by statistical methods or by artificial intelligent technique such as artificial neural network (ANN). A Hybrid approach combining more than one technique is applied to overcome the gaps on each method. The Hybrid model consists of two stages and three models, model 1 and 2 are generalized, and model 3 is detailed. In the first stage, "Model 1" is nonlinear classification model using support vector machine with a Gaussian kernel, it functions as anomaly detection and a machine status classifier. The objective is to build a robust model that can be predictive, deterministic and diagnostic. Therefore, the RNN multivariate signal prediction using long-short term memory (LSTM) is added in parallel as "Model 2". Model 1 and 2 formed the first stage as overall detector. If anomalies are detected, so the algorithm will move to the second stage which consist of individual time series sensor signals. A model for each signal is added as "Model 3" in the second stage as deterministic. The results of each model show different accuracies that varied from 70% to 96%. But the model overall confidence range is increased. The new hybrid approach provided a better understanding for each event prediction and has minimized the number of misleading alarms. © Copyright 2018, Society of Petroleum Engineers.},
	author_keywords = {Artificial Intelligence; Artificial Neural Network; Condition Monitoring; Machines Failure; Predictive Maintenance},
	keywords = {Artificial intelligence; Compressibility of gases; Condition monitoring; Forecasting; Gas compressors; Gasoline; Neural networks; Predictive analytics; Regression analysis; Time series; Artificial intelligent techniques; Auto-regressive integrated moving average; Exponential smoothing method; Hybrid artificial intelligences; Nonlinear classification; Predictive maintenance; Recurrent neural network (RNN); Time series forecasting; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Li202240,
	author = {Li, Zhipeng and Yang, Yangzhao and Liao, Yong and Yu, Nenghai and Wu, Zhe and Xie, Haiyong and Shi, Jun and Zeng, Xi},
	title = {A Survey of Recent Advances in Data-Driven Event Prediction Research; [数据驱动的事件预测技术最新研究进展]},
	year = {2022},
	journal = {Journal of Cyber Security},
	volume = {7},
	number = {1},
	pages = {40 – 55},
	doi = {10.19363/J.cnki.cn10-1380/tn.2022.01.03},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126708969&doi=10.19363%2fJ.cnki.cn10-1380%2ftn.2022.01.03&partnerID=40&md5=4b4c78706da8add066d69c80852cab0e},
	abstract = {An event is usually defined as an incident that takes place in a specific location and time, impacting either the society or the nature in a nontrivial way. Civil unrest, terrorist attacks and pandemics are commonly known events that can pose serious threats to both national security and public safety. Effectively predicting upcoming events is highly desirable in reality, as successful predictions can be of great use in designing countermeasures to prevent or reduce potential losses. Predicting events in advances plays an important role in public security, risk perception and infectious disease prevention and control, etc. Although event prediction used to be a technically challenging task, recent advances in the fields of big data analytics and machine learning have brought promising opportunities in applying these techniques to solve real world prediction problems. This paper presents a systematic survey on data-driven event prediction research studies. We first introduce the formal definition of event prediction problem and the evaluation metrics of various prediction techniques. Then, the state-of-the-art algorithms and schemes proposed in the field of event prediction are summarized and classified. All existing event prediction methods can be classified into 8 categories: frequent pattern mining, traditional classification model, time series model, temporal point processes, geospatial predictive modeling, event knowledge graph, unsupervised machine learning, multi-model fusion method. We present a systematic and comprehensive summary for each category of these methods. After that, we proceed by discussing the main real-world applications of event prediction techniques, including public security, disease prevention, smart city and natural disaster prediction. We conclude this survey by summarizing multiple open research problems and several possible directions on event prediction research. To the best of our knowledge, this study provides a comprehensive summarization of recent research and advances on data-driven event prediction. We hope this paper can be a useful booster in the research of event prediction and applying this technique in solving real world problems. © 2022, China Science Publishing & Media LTD. All right reserved.},
	author_keywords = {Computational social science; Data mining; Event graph; Event prediction; Machine learning},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Su2020,
	author = {Su, Zichun and Jiang, Jialin},
	title = {Hierarchical gated recurrent unit with semantic attention for event prediction},
	year = {2020},
	journal = {Future Internet},
	volume = {12},
	number = {2},
	doi = {10.3390/FI12020039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084110885&doi=10.3390%2fFI12020039&partnerID=40&md5=99f1956616d62b9a7117d93195177af3},
	abstract = {Event prediction plays an important role in financial risk assessment and disaster warning, which can help government decision-making and economic investment. Previous works are mainly based on time series for event prediction such as statistical language model and recurrent neural network, while ignoring the impact of prior knowledge on event prediction. This makes the direction of event prediction often biased or wrong. In this paper, we propose a hierarchical event prediction model based on time series and prior knowledge. To ensure the accuracy of the event prediction, the model obtains the time-based event information and prior knowledge of events by Gated Recurrent Unit and Associated Link Network respectively. The semantic selective attention mechanism is used to fuse the time-based event information and prior knowledge, and finally generate predicted events. Experimental results on Chinese News datasets demonstrate that our model significantly outperforms the state-of-the-art methods, and increases the accuracy by 2.8%. © 2020 by the authors.},
	author_keywords = {Associated link network; Event prediction; Semantic selective attention},
	keywords = {Decision making; Forecasting; Natural language processing systems; Risk assessment; Semantics; Time series; Disaster warnings; Event prediction; Government decisions; Link networks; Prior knowledge; Selective attention mechanism; State-of-the-art methods; Statistical language modeling; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@ARTICLE{Chen2021192,
	author = {Chen, Zheng and Wang, Yifan},
	title = {Civil Unrest Event Forecasting Using Graphical and Sequential Neural Networks},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12893 LNCS},
	pages = {192 – 203},
	doi = {10.1007/978-3-030-86365-4_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115714036&doi=10.1007%2f978-3-030-86365-4_16&partnerID=40&md5=3d9ac00f8c48473952a9143f540579ed},
	abstract = {Having the ability to forecast civil unrest events, such as violent protests, is crucial because they can lead to severe violent conflict and social instabilities. Civil unrests are comprehensive consequences of multiple factors, which could be related to political, economic, cultural, and other types of historical events. Therefore, people naturally organize such historical data into time-series data and feed it into an RNN-like model to perform the forecasting. However, how to encode discrete historical information into a unified vector space is very important. Different events may have extensive and complex relationships in time, space, and participants. Traditional methods, such as collecting indicators of various fields as features, miss the vital correlation information between events. In this work, we propose a Graph Neural Network based model to learn the representation of correlated historical event information. By using the dates, events, participants, and locations as nodes, we construct an event graph so that the relationship between events can be expressed unambiguously. We organize date-node’s representations into time-series data and use an LSTM to predict if there will be a violent protest or demonstration in the next few days. In the experiments, we use historical events from Hong Kong to evaluate our system’s forecasting ability in 1-day, 2-day, and 3-day lead-time. Our system achieves recall rates of 0.85, 0.86, 0.88, and precision rates of 0.75, 0.77, 0.75, respectively. We also discussed the impact of longer prediction lead times, and external events in China Mainland, the United States, and the United Kingdom on the Hong Kong civil unrest event prediction. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Civil unrest event; Event forecasting; Graph neural network},
	keywords = {Forecasting; Graph theory; Long short-term memory; Time series; Vector spaces; Civil unrest event; Event forecasting; Graph neural networks; Historical data; Historical information; Hong-kong; Leadtime; Multiple factors; Sequential neural networks; Time-series data; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Jin2022315,
	author = {Jin, Guangyin and Liu, Chenxi and Xi, Zhexu and Sha, Hengyu and Liu, Yanyun and Huang, Jincai},
	title = {Adaptive Dual-View WaveNet for urban spatial–temporal event prediction},
	year = {2022},
	journal = {Information Sciences},
	volume = {588},
	pages = {315 – 330},
	doi = {10.1016/j.ins.2021.12.085},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122370178&doi=10.1016%2fj.ins.2021.12.085&partnerID=40&md5=ad5d2f35eb2cadff0957e36e064577a0},
	abstract = {Spatial–temporal event prediction is a particular task for multivariate time series forecasting. Therefore, the complex entangled dynamics of space and time need to be considered. This task is an essential but crucial loop in future smart cities construction, which can be widely applied in urban traffic management, disaster monitoring and mobility analysis. In recent years, video-like spatial–temporal modelling has been the most common approach in many deep learning models. However, the video-like modelling approach cannot consider some latent region-wise correlations other than geographic spatial distance information. To overcome the limitation, we propose a novel neural network framework, Adaptive Dual-View WaveNet (ADVW-Net), for the urban spatial–temporal event prediction. By integrating the spatial representations from Convolutional Neural Network (CNN) and that from adaptive Graph convolutional neural network (GCN), our proposed model can capture not only the geographic correlations but also some latent region-wise dependencies from the input data. In addition, the effective architecture, WaveNet, can be transferred to region-wise spatial–temporal prediction scenarios for long-range temporal dependencies learning. Experimental results on three urban datasets demonstrate the superior performance of our proposed model. © 2021 Elsevier Inc.},
	author_keywords = {Graph convolutional neural network; Representation learning; Spatial–temporal prediction; WaveNet},
	keywords = {Convolution; Convolutional neural networks; Deep learning; Forecasting; Event prediction; Geographics; Multivariate time series; Representation learning; Space and time; Spatial temporals; Spatial–temporal prediction; Temporal prediction; Time series forecasting; Wavenet; Graph neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@ARTICLE{Dakiche2021303,
	author = {Dakiche, Narimene and Benbouzid-Si Tayeb, Fatima and Benatchba, Karima and Slimani, Yahya},
	title = {Tailored Network Splitting for Community Evolution Prediction in Dynamic Social Networks},
	year = {2021},
	journal = {New Generation Computing},
	volume = {39},
	number = {1},
	pages = {303 – 340},
	doi = {10.1007/s00354-021-00122-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104615306&doi=10.1007%2fs00354-021-00122-6&partnerID=40&md5=c05da1a1423e65aa840f0e64b2ddd876},
	abstract = {One of the most challenging issues dealing with dynamic social networks, with evolving community structures, is to understand and model the way in which these structures evolve over time. Studies on tracking and predicting community evolution generally split these networks into time-series of static networks, each including interactions aggregated over discrete time intervals (hours, days, and years). This choice of intervals is very often done arbitrarily. Yet, it is clear that the selection of the time interval over which the network is discretized has a great impact on the observation of community structures, the analysis of their evolution, and the prediction of their future events. In this paper, we propose a new framework that examines users’ activity distribution over time to provide the appropriate network splitting that would produce more accurate community event prediction. Our experiments on four real-world datasets show the effectiveness of our framework. © 2021, Ohmsha, Ltd. and Springer Japan KK, part of Springer Nature.},
	author_keywords = {Community evolution; Dynamic networks; Evolution events; Prediction; Tailored timeframes},
	keywords = {Computation theory; Software engineering; Activity distribution; Community evolution; Community structures; Discrete time intervals; Dynamic social networks; Event prediction; Network splitting; Real-world datasets; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Lu20231,
	author = {Lu, Chang and Reddy, Chandan K. and Wang, Ping and Nie, Dong and Ning, Yue},
	title = {Multi-Label Clinical Time-Series Generation via Conditional GAN},
	year = {2023},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	pages = {1–13},
	doi = {10.1109/TKDE.2023.3310909},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170532776&doi=10.1109%2fTKDE.2023.3310909&partnerID=40&md5=11742f0dd2a93769b3840829152ca660},
	abstract = {In recent years, deep learning has been successfully adopted in a wide range of applications related to electronic health records (EHRs) such as representation learning and clinical event prediction. However, due to privacy constraints, limited access to EHR becomes a bottleneck for deep learning research. To mitigate these concerns, generative adversarial networks (GANs) have been successfully used for generating EHR data. However, there are still challenges in high-quality EHR generation, including generating time-series EHR data and imbalanced uncommon diseases. In this work, we propose a <bold>M</bold>ulti-label <bold>T</bold>ime-series <bold>GAN</bold> (MTGAN) to generate EHR and simultaneously improve the quality of uncommon disease generation. The generator of MTGAN uses a gated recurrent unit (GRU) with a smooth conditional matrix to generate sequences and uncommon diseases. The critic gives scores using Wasserstein distance to recognize real samples from synthetic samples by considering both data and temporal features. We also propose a training strategy to calculate temporal features for real data and stabilize GAN training. Furthermore, we design multiple statistical metrics and prediction tasks to evaluate the generated data. Experimental results demonstrate the quality of the synthetic data and the effectiveness of MTGAN in generating realistic sequential EHR data, especially for uncommon diseases. IEEE},
	author_keywords = {Diseases; Electronic health records; Generative adversarial network (GAN); Generative adversarial networks; Generators; Imbalanced data; Measurement; Synthetic data; Task analysis; Time-series generation; Training},
	keywords = {Deep learning; Generative adversarial networks; Harmonic analysis; Job analysis; Records management; Time series; Time series analysis; Electronic health; Electronic health record; Generative adversarial network; Generator; Health records; Imbalanced data; Synthetic data; Task analysis; Temporal features; Time-series generation; Diseases},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Liu2022,
	author = {Liu, Jixue and Li, Jiuyong and Liu, Lin},
	title = {FastOPM—A practical method for partial match of time series},
	year = {2022},
	journal = {Pattern Recognition},
	volume = {130},
	doi = {10.1016/j.patcog.2022.108808},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131042636&doi=10.1016%2fj.patcog.2022.108808&partnerID=40&md5=7f62d4e98794dd7ac8a42ea63fa6c273},
	abstract = {In applications like stock markets, engineering, medicine, etc., a large amount of time series data has been collected. Interrogating the data for patterns is important for analysis like event prediction and event investigation. A fundamental operation to support such analysis is query processing. In this paper, we aim to efficiently find the optimal match of a query in a timeseries when the match is calculated based on the trend and allows points to be skipped from the middle and ends of the sequences. This problem requires global optimization. The solutions in the literature have prohibitively high time complexities and are not practical for long timeseries. Our method consists of three parts. The first part is an efficiency improvement algorithm called FastOPM which applies the Dijkstra algorithm to get the optimal solution in an efficient manner. The second part derives bounds for optimal solutions. The third part is an algorithm for efficiently searching the target timeseries for the best optimal match of a query. Our experiments show that our method is faster than the baseline method, the bounds are effective, and the search algorithm can identify the best optimal match efficiently. Overall, our algorithm effectively outperforms the state-of-the-art algorithms DTW and MASS in retrieving target segments. © 2022 Elsevier Ltd},
	author_keywords = {Global optimization; Partial match; Query processing; Time series},
	keywords = {Optimal systems; Query processing; Time series; Event prediction; Fundamental operations; Global optimisation; Large amounts; Optimal match; Optimal solutions; Partial matches; Practical method; Time-series data; Times series; Global optimization},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Geng2019,
	author = {Geng, Yue and Su, Lingling and Jia, Yunhong and Han, Ce},
	title = {Seismic Events Prediction Using Deep Temporal Convolution Networks},
	year = {2019},
	journal = {Journal of Electrical and Computer Engineering},
	volume = {2019},
	doi = {10.1155/2019/7343784},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065773093&doi=10.1155%2f2019%2f7343784&partnerID=40&md5=59f38b79bc0e3c9d09aa8979ba480db5},
	abstract = {Seismic events prediction is a crucial task for preventing coal mine rock burst hazards. Currently, this task attracts increasing research enthusiasms from many mining experts. Considering the temporal characteristics of monitoring data, seismic events prediction can be abstracted as a time series prediction task. This paper contributes to address the problem of long-term historical dependence on seismic time series prediction with deep temporal convolution neural networks (CNN). We propose a dilated causal temporal convolution network (DCTCNN) and a CNN long short-term memory hybrid model (CNN-LSTM) to forecast seismic events. In particular, DCTCNN is designed with dilated CNN kernels, causal strategy, and residual connections; CNN-LSTM is established in a hybrid modeling way by utilizing advantage of CNN and LSTM. Based on these manners, both of DCTCNN and CNN-LSTM can extract long-term historical features from the monitoring seismic data. The proposed models are experimentally tested on two real-life coal mine seismic datasets. Furthermore, they are also compared with one traditional time series prediction method, two classic machine learning algorithms, and two standard deep learning networks. Results show that DCTCNN and CNN-LSTM are superior than the other five algorithms, and they successfully complete the seismic prediction task. © 2019 Yue Geng et al.},
	keywords = {Coal mines; Convolution; Deep learning; Forecasting; Learning algorithms; Machine learning; Monitoring; Rock bursts; Seismology; Time series; Convolution neural network; Hybrid model; Learning network; Seismic datas; Seismic event; Seismic predictions; Temporal characteristics; Time series prediction; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tong2022338,
	author = {Tong, Lin and Guan, Zheng and Wang, Li-Wei and Yang, Wen-Tao and Yao, Yang},
	title = {New energy ramp event prediction based on time series decomposition and error correction; [基于时序分解与误差修正的新能源爬坡事件预测]},
	year = {2022},
	journal = {Zhejiang Daxue Xuebao (Gongxue Ban)/Journal of Zhejiang University (Engineering Science)},
	volume = {56},
	number = {2},
	pages = {338 – 346},
	doi = {10.3785/j.issn.1008-973X.2022.02.015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126335041&doi=10.3785%2fj.issn.1008-973X.2022.02.015&partnerID=40&md5=7a9a4db4295e88d30468f0c78714bb57},
	abstract = {A ramp prediction model based on principal component analysis, time series decomposition and correction of long short-term memory (LSTM) network was proposed, in order to improve the accuracy of ramp prediction of new energy represented by wind power and photovoltaic power. In order to fully consider the time series characteristics of power, the power was decomposed into period, trend and residual by the time series decomposition method, and the trend and residual prediction model based on LSTM was established by combining the principal components of several characteristic factors, to realize the mapping relationship between the time characteristics of power and the principal components of influencing factors. Based on the preliminary prediction of trend and residual terms by LSTM, an error correction algorithm was introduced to calculate the dynamic error of the fitting prediction model and construct a new non-stationary time series to obtain the trend and residual predicted values with better accuracy. The final power prediction was obtained by fusing the trend, residual terms and the period value obtained by using the naive method. Combined with the definition of wind power and photovoltaic ramp event, the proposed model was used to predict the wind power and photovoltaic ramp event respectively. Experimental results show that the proposed model has better accuracy than other forecasting methods in direct power prediction and indirect ramp event prediction, and it can provide a more reliable basis for power grid dispatching. Copyright ©2022 Journal of Zhejiang University (Engineering Science). All rights reserved.},
	author_keywords = {Error correction; Long short-term memory network; New energy ramp; Principal component analysis; Time series decomposition},
	keywords = {Brain; Electric load dispatching; Electric power transmission networks; Error correction; Principal component analysis; Time series; Time series analysis; Weather forecasting; Wind power; Errors correction; Long short-term memory network; Memory network; New energies; New energy ramp; Power; Prediction modelling; Principal-component analysis; Ramp events; Time series decomposition; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Vandith Sreenivas2021,
	author = {Vandith Sreenivas, K and Ganesan, M and Lavanya, R},
	title = {Classification of Arrhythmia in Time Series ECG Signals Using Image Encoding and Convolutional Neural Networks},
	year = {2021},
	journal = {Proceedings of 2021 IEEE 7th International Conference on Bio Signals, Images and Instrumentation, ICBSII 2021},
	doi = {10.1109/ICBSII51839.2021.9445177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107935223&doi=10.1109%2fICBSII51839.2021.9445177&partnerID=40&md5=1e05c976677a2fa30360b2089870976a},
	abstract = {Electrocardiograph (ECG) signal analysis has been used extensively to study a patient's heart and detect problems like arrhythmia for decades. Manual analysis of ECG in real time is laborious and therefore not practical for doctors. Deep learning helps make this job much easier due to quicker learning of signal features and event prediction. Deep Learning classifiers can help doctors differentiate between normal and abnormal ECG signals based on the basic and advanced features of ECG signals. This paper focuses on building a Convolutional Neural Network (CNN) to classify arrhythmia in dual channel ECG signals based on images generated by time series to image encoding techniques. The ECG time series signals were converted into images using Gramian Angular Fields (GAF) and Markov Transition Fields (MTF). These images were fed as input into the deep learning classifier which further classified the signals into various types. Our model achieved an accuracy of 97% for the GAF images and 85% per cent for the MTF images.  © 2021 IEEE.},
	author_keywords = {Convolutional Neural Networks; Gramian Angular Fields; Markov Transition Fields},
	keywords = {Convolution; Convolutional neural networks; Deep learning; Diseases; Electrocardiography; Encoding (symbols); Image classification; Image coding; Network coding; Time series; Event prediction; Image encoding; Learning classifiers; Manual analysis; Patient's heart; Signal features; Time series signals; Transition fields; Biomedical signal processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Chen2021296,
	author = {Chen, Yang and Kempton, Dustin J. and Ahmadzadeh, Azim and Angryk, Rafal A.},
	title = {Towards Synthetic Multivariate Time Series Generation for Flare Forecasting},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12854 LNAI},
	pages = {296 – 307},
	doi = {10.1007/978-3-030-87986-0_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117527531&doi=10.1007%2f978-3-030-87986-0_26&partnerID=40&md5=ca9a0f2c2ba51c5f4db555ed135895f0},
	abstract = {One of the limiting factors in training data-driven, rare-event prediction algorithms is the scarcity of the events of interest resulting in an extreme imbalance in the data. There have been many methods introduced in the literature for overcoming this issue; simple data manipulation through undersampling and oversampling, utilizing cost-sensitive learning algorithms, or by generating synthetic data points following the distribution of the existing data. While synthetic data generation has recently received a great deal of attention, there are real challenges involved in doing so for high-dimensional data such as multivariate time series. In this study, we explore the usefulness of the conditional generative adversarial network (CGAN) as a means to perform data-informed oversampling in order to balance a large dataset of multivariate time series. We utilize a flare forecasting benchmark dataset, named SWAN-SF, and design two verification methods to both quantitatively and qualitatively evaluate the similarity between the generated minority and the ground-truth samples. We further assess the quality of the generated samples by training a classical, supervised machine learning algorithm on synthetic data, and testing the trained model on the unseen, real data. The results show that the classifier trained on the data augmented with the synthetic multivariate time series achieves a significant improvement compared with the case where no augmentation is used. The popular flare forecasting evaluation metrics, TSS and HSS, report 20-fold and 5-fold improvements, respectively, indicating the remarkable statistical similarities, and the usefulness of CGAN-based data generation for complicated tasks such as flare forecasting. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Class imbalance; Flare forecasting; Generative adversarial network; Multivariate time series},
	keywords = {Clustering algorithms; Forecasting; Large dataset; Learning algorithms; Supervised learning; Time series; Class imbalance; Data driven; Event prediction; Flares: Forecasting; Multivariate time series; Over sampling; Prediction algorithms; Synthetic data; Time-series generation; Training data; Generative adversarial networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Alexopoulos202275,
	author = {Alexopoulos, Georgios and Zhang, Justin and Karampelas, Ioannis and Patel, Mayur and Kemp, Joanna and Coppens, Jeroen and Mattei, Tobias A. and Mercier, Philippe},
	title = {Long-Term Time Series Forecasting and Updates on Survival Analysis of Glioblastoma Multiforme: A 1975-2018 Population-Based Study},
	year = {2022},
	journal = {Neuroepidemiology},
	volume = {56},
	number = {2},
	pages = {75 – 89},
	doi = {10.1159/000522611},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128800528&doi=10.1159%2f000522611&partnerID=40&md5=cf2348dafc03c36654bbf24ba8f0c258},
	abstract = {Objective: Glioblastomas multiforme (GBMs) are the most common primary CNS tumors. Epidemiologic studies have investigated the effect of demographics on patient survival, but the literature remains inconclusive. Methods: This study included all adult patients with intracranial GBMs reported in the surveillance epidemiology and end results (SEER)-9 population database (1975-2018). The sample consisted of 32,746 unique entries. We forecast the annual GBM incidence in the US population through the year 2060 using time series analysis with autoregressive moving averages. A survival analysis of the GBM-specific time to death was also performed. Multivariate Cox proportional hazards (PH) regression revealed frank violations of the PH assumption for multiple covariates. Parametric models best described the GBM population's survival pattern; the results were compared to the semi-parametric analysis and the published literature. Results: We predicted an increasing GBM incidence, which demonstrated that by the year 2060, over 1,800 cases will be reported annually in the SEER. All eight demographic variables were significant in the univariable analysis. The calendar year 2005 was the cutoff associated with an increased survival probability. A male survival benefit was eliminated in the year-adjusted Cox. Infratentorial tumors, nonmetropolitan areas, and White patient race were the factors erroneously associated with survival in the multivariate Cox analysis. Accelerated Failure Time (AFT) lognormal regression was the best model to describe the survival pattern in our patient population, identifying age >30 years old as a poor prognostic and patients >70 years old as having the worst survival. Annual income >USD 75,000 and supratentorial tumors had good prognostics, while surgical intervention provided the strongest survival benefit. Conclusions: Annual GBM incidence rates will continue to increase by almost 50% in the upcoming 30 years. Cox regression analysis should not be utilized for time-to-event predictions in GBM survival statistics. AFT lognormal distribution best describes the GBM-specific survival pattern, and as an inherent population characteristic, it should be implemented by researchers for future studies. Surgical intervention provides the strongest survival benefit, while patient age >70 years old is the worst prognostic. Based on our study, the demographics such as gender, race, and county type should not be considered as meaningful prognostics when designing future trials.  © 2022 },
	author_keywords = {Epidemiologic studies; Glioblastoma incidence; Glioblastoma multiforme; Population-based study; Survival analysis; Time series forecasting},
	keywords = {Adult; Aged; Brain Neoplasms; Glioblastoma; Humans; Incidence; Male; Prognosis; Survival Analysis; Time Factors; adult; aged; cancer incidence; cancer prognosis; cancer specific survival; cancer surgery; Caucasian; demographics; female; forecasting; glioblastoma; human; income; major clinical study; male; overall survival; population research; Review; time series analysis; tumor localization; brain tumor; incidence; prognosis; survival analysis; time factor},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@ARTICLE{Gao20212165,
	author = {Gao, Xiaofeng and Zheng, Zuowu and Chu, Quanquan and Tang, Shaojie and Chen, Guihai and Deng, Qianni},
	title = {Popularity Prediction for Single Tweet Based on Heterogeneous Bass Model},
	year = {2021},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {33},
	number = {5},
	pages = {2165 – 2178},
	doi = {10.1109/TKDE.2019.2952856},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104006606&doi=10.1109%2fTKDE.2019.2952856&partnerID=40&md5=514d471109a704d8a2a4524f4ae2994d},
	abstract = {Predicting the popularity of a single tweet is useful for both users and enterprises. However, adopting existing topic or event prediction models cannot obtain satisfactory results. The reason is that one topic or event that consists of multiple tweets, has more features and characteristics than a single tweet. In this article, we propose two variations of Heterogeneous Bass models (HBass), originally developed in the field of marketing science, namely Spatialoral Heterogeneous Bass Model (ST-HBass) and Feature-Driven Heterogeneous Bass Model (FD-HBass), to predict the popularity of a single tweet at the early stage and the stable stage. We further design an Interaction Enhancement to improve the performance, which considers the competition and cooperation from different tweets with the common topic. In addition, it is often difficult to depict popularity quantitatively. We design an experiment to get the weight of favorite, retweet and reply, and apply the linear regression to calculate the popularity. Furthermore, we design a clustering method to bound the popular threshold. Once the weight and popular threshold are determined, the status whether a tweet will be popular or not can be justified. Our model is validated by conducting experiments on real-world Twitter data, and the results show the efficiency and accuracy of our model, with less absolute percent error and the best Precision and F-score. In all, we introduce Bass model into social network single-tweet prediction to show it can achieve excellent performance.  © 1989-2012 IEEE.},
	author_keywords = {Heterogeneous bass model; single tweet popularity; time series prediction; Twitter social network},
	keywords = {Forecasting; Bass model; Clustering methods; Competition and cooperation; Event prediction; F-score; Popularity predictions; Real-world; Predictive analytics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Ma20221224,
	author = {Ma, Yu and Liu, Zhining and Zhuang, Chenyi and Tan, Yize and Dong, Yi and Zhong, Wenliang and Gu, Jinjie},
	title = {Non-stationary Time-aware Kernelized Attention for Temporal Event Prediction},
	year = {2022},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {1224 – 1232},
	doi = {10.1145/3534678.3539470},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137145293&doi=10.1145%2f3534678.3539470&partnerID=40&md5=3333be143bd3e2a1662883ff7c47021e},
	abstract = {Modeling sequential data is essential to many applications such as natural language processing, recommendation systems, time series predictions, anomaly detection, etc. When processing sequential data, one of the critical issues is how to capture the temporal-correlation among events. Though prevalent and effective in many applications, conventional approaches such as RNNs and Transformers, struggle with handling the non-stationary characteristics (i.e., such temporal-correlation among events would change over time), which is indeed encountered in many real-world scenarios. In this paper, we present a non-stationary time-aware kernelized attention approach for input sequences of neural networks. By constructing the Generalized Spectral Mixture Kernel (GSMK), and integrating it to the attention mechanism, we mathematically reveal its representation capability in terms of the time-dependent temporal-correlation. Following that, a novel neural network structure is proposed, which would enable us to encode both stationary and non-stationary time event series. Finally, we demonstrate the performance of the proposed method on both synthetic data which presents the theoretical insights, and a variety of real-world datasets which shows its competitive performance against related work.  © 2022 ACM.},
	author_keywords = {kernelized attention; non-stationarity; temporal event prediction},
	keywords = {Data handling; Forecasting; Modeling languages; Natural language processing systems; Neural networks; Event prediction; Kernelized attention; Language processing; Natural languages; Non-stationarities; Nonstationary; Sequential data; Temporal correlations; Temporal event prediction; Time series prediction; Anomaly detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Mishra20221596,
	author = {Mishra, Sambeet and Bordin, Chiara and Taharaguchi, Kota and Purkayastha, Adri},
	title = {Predictive analytics beyond time series: Predicting series of events extracted from time series data},
	year = {2022},
	journal = {Wind Energy},
	volume = {25},
	number = {9},
	pages = {1596 – 1609},
	doi = {10.1002/we.2760},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131324797&doi=10.1002%2fwe.2760&partnerID=40&md5=75483b55f9a69353dc597e1812f0505c},
	abstract = {Realizing carbon neutral energy generation creates the challenge of accurately predicting time-series generation data for long-term capacity planning and for short-term operational decisions. The key challenges for adopting data-driven decision-making, specifically predictive analytics, can be attributed to data volume and velocity. Data volume poses challenges for data storage and retrieval. Data velocity poses challenges for processing the data near real time for operational decisions or for capacity building. This manuscript proposes a novel prediction method to tackle the above two challenges by using an event-based prediction in place of traditional time series prediction methods. The central concept is to extract meaningful information, denoted by events, from time-series data and use these events for predictive analysis. These extracted events retain the information required for predictive analytics while significantly reducing the volume of the velocity of data; consequently, a series of events present the information at a glance, effectively enabling data-driven decision-making. This method is applied to a data set consisting of six years of historical wind power capacity factor and temperature measurements. Deploying five deep learning models, a comparison is drawn between classical time-series predictions and series of events predictions based on computational time and several error metrics. The computational analysis results are presented in graphical format and a comparative discussion is drawn on the prediction results. The results indicate that the proposed method obtains the same or better prediction accuracy while significantly reducing computational time and data volume. © 2022 The Authors. Wind Energy published by John Wiley & Sons Ltd.},
	author_keywords = {features extraction; green computing; machine learning; multivariate time-series; predictive analytics; renewable energy; time-series forecasting; virtual power plants; wind energy},
	keywords = {Data mining; Decision making; Deep learning; Digital storage; E-learning; Forecasting; Temperature measurement; Time series; Time series analysis; Wind power; Data driven decision; Data volume; Decisions makings; Features extraction; Multivariate time series; Operational decisions; Renewable energies; Time series forecasting; Time-series data; Virtual power plants; alternative energy; data set; forecasting method; machine learning; multivariate analysis; real time; time series analysis; wind power; Predictive analytics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Guijo-Rubio201864,
	author = {Guijo-Rubio, D. and Gutiérrez, P.A. and Casanova-Mateo, C. and Sanz-Justo, J. and Salcedo-Sanz, S. and Hervás-Martínez, C.},
	title = {Prediction of low-visibility events due to fog using ordinal classification},
	year = {2018},
	journal = {Atmospheric Research},
	volume = {214},
	pages = {64 – 73},
	doi = {10.1016/j.atmosres.2018.07.017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050263361&doi=10.1016%2fj.atmosres.2018.07.017&partnerID=40&md5=46d20a359585d03a78ed8d5f3d717375},
	abstract = {The prediction of low-visibility events is very important in many human activities, and crucial in transportation facilities such as airports, where they can cause severe impact in flight scheduling and safety. The design of accurate predictors for low-visibility events can be approached by modelling future visibility conditions based on past values of different input variables, recorded at the airport. The use of autoregressive time series forecasters involves adjusting the order of the model (number of past series values or size of the sliding window), which usually depends on the dynamical nature of the time series. Moreover, the same window size is normally used for all the data, thought it would be reasonable to use different sliding windows. In this paper, we propose a hybrid prediction model for daily low-visibility events, which combines fixed-size and dynamic windows, and adapts its size according to the dynamics of the time series. Moreover, visibility is labelled using three ordered categories (FOG, MIST and CLEAR), and the prediction is then carried out by means of ordinal classifiers, in order to take advantage of the ordinal nature of low-visibility events. We evaluate the model using a dataset from Valladolid airport (Spain), where radiation fog is very common in autumn and winter months. The considered data set includes five different meteorological input variables (wind speed and direction, temperature, relative humidity and QNH – pressure adjusted at mean sea level) and the Runway Visual Range (RVR), which is used to characterize the low-visibility events at the airport. The results show that the proposed hybrid window model with ordinal classification leads to very robust performance prediction in daily time-horizon, improving the results obtained by the persistence model and alternative prediction schemes tested. © 2018 Elsevier B.V.},
	author_keywords = {Airports; Fog events prediction; Forecasting; Ordinal classification; Time series; Time series preprocessing.},
	keywords = {Spain; Airports; Fog; Sea level; Time series; Visibility; Wind; Event prediction; Fog event prediction; Fog events; Input variables; Low visibility; Ordinal classification; Sliding Window; Time series preprocessing.; Times series; airport; fog; forecasting method; prediction; seasonal variation; time series analysis; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30}
}

@ARTICLE{Du2023106347,
	author = {Du, Yuhao and Li, Yihong and Liu, Hui},
	title = {A New Hybrid Prediction Method of El Niño/La Niña Events by Combining TimesNet and ARIMA},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {106347 – 106360},
	doi = {10.1109/ACCESS.2023.3319395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173060099&doi=10.1109%2fACCESS.2023.3319395&partnerID=40&md5=ce2017d028140fb86d0a00b1a70b8a06},
	abstract = {El Niño/La Niña events significantly impact human society, often resulting in considerable monetary losses. Accurate prediction has become crucial with triple La Niña events in this century. This study applied TimesNet to El Niño/La Niña event prediction for the first time. We proposed a hybrid prediction method based on extracting features from time series data and initially decomposing the time series data (Niño3.4) into several Intrinsic Mode Functions (IMFs) using the Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN). Based on the characteristics of each IMF, we used a hybrid method of TimesNet and ARIMA to make adaptive forecasts for them. We selected monthly data from 1950 to 2022, with the first 63 years used for training and shifted 12 periods (12 months) ahead to forecast the Niño3.4 index values for the next ten years. The experimental results of this study show that: 1) The pre-processing method using CEEMDAN can effectively extract the original time series data features and significantly improve the prediction performance; 2) proposed approach achieved good performance in predicting El Niño/La Niña events, particularly during the transition from El Niño to La Niña events (e.g., 2016, 2019-2020); 3) evaluation results indicate that the proposed model exhibits better predictive power (stability and accuracy of prediction results) than the current best single-order predictor, the ConvLSTM model, on the validation set of the last ten years.  © 2013 IEEE.},
	author_keywords = {ARIMA; CEEMDAN; forecasting; NiÃ±o3.4 index; TimesNet},
	keywords = {Climate change; Climate models; Time series analysis; Weather forecasting; Adaptive noise; ARIMA; Complete ensemble empirical mode decomposition with adaptive noise; Empirical Mode Decomposition; Index; Nino3.4 index; Predictive models; Time-series analysis; Timesnet; Training data; Empirical mode decomposition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Ji2021106,
	author = {Ji, Anli and Arya, Akhil and Kempton, Dustin and Angryk, Rafal and Georgoulis, Manolis K. and Aydin, Berkay},
	title = {A Modular Approach to Building Solar Energetic Particle Event Forecasting Systems},
	year = {2021},
	journal = {Proceedings - 2021 IEEE 3rd International Conference on Cognitive Machine Intelligence, CogMI 2021},
	pages = {106 – 115},
	doi = {10.1109/CogMI52975.2021.00022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127809107&doi=10.1109%2fCogMI52975.2021.00022&partnerID=40&md5=376f328cda3243ec17879285a4d768a4},
	abstract = {Solar energetic particle (SEP) events, as one of the most dangerous manifestations of solar activity, can generate severe hazardous radiation when accelerated by solar flares or shock waves formed aside coronal mass ejections (CMEs). Unlike common predictions that focus on the occurrence of an event, an All-Clear forecast puts more emphasis on predicting the absence of an event. Such forecasts, while usually not addressed directly, can be crucial in operational environments. We have developed an All-Clear SEP event prediction system utilizing active region-based prediction methods together with active region scenarios (i.e., location and complexity). Within our All-Clear forecast system, signals are generated only when requested as binary predictions of YES or NO indicating 'All Clear' or 'Not All Clear', respectively. Such signals referred to the potential possibility of the occurrence of any events in the next prediction window, in our cases, the next 24 hours. Four major space weather event forecasting modules are established corresponding to the flare prediction (FP), eruptive flare prediction (ERP), CME speed prediction, and full-disk aggregation methodology, where all of them are loosely coupled without direct communications between each other. Our system design follows a modular approach for flexibility, maintainability, and extensibility that can be configured to utilize file storage or any data access mechanisms, such as file storage or database systems, outside the confines of our system.  © 2021 IEEE.},
	author_keywords = {all-clear prediction; multivariate time series classification; SEP event prediction},
	keywords = {Cosmic rays; Cosmology; Digital storage; Shock waves; Weather forecasting; Active regions; All-clear prediction; Coronal mass ejection; Event prediction; File storage; Flare predictions; Modular approach; Multivariate time series classifications; Solar energetic particle event prediction; Solar energetic particle events; Solar energy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Basu2022,
	author = {Basu, Treena and Menzer, Olaf and Ward, Joshua and Sengupta, Indranil},
	title = {A Novel Implementation of Siamese Type Neural Networks in Predicting Rare Fluctuations in Financial Time Series},
	year = {2022},
	journal = {Risks},
	volume = {10},
	number = {2},
	doi = {10.3390/risks10020039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124832525&doi=10.3390%2frisks10020039&partnerID=40&md5=2382980f595f242af5a28d8870d7f1c0},
	abstract = {Stock trading has tremendous importance not just as a profession but also as an income source for individuals. Many investment account holders use the appreciation of their portfolio (as a combination of stocks or indexes) as income for their retirement years, mostly betting on stocks or indexes with low risk/low volatility. However, every stock-based investment portfolio has an inherent risk to lose money through negative progression and crash. This study presents a novel technique to predict such rare negative events in financial time series (e.g., a drop in the S&P 500 by a certain percent in a designated period of time). We use a time series of approximately seven years (2517 values) of the S&P 500 index stocks with publicly available features: the high, low and close price (HLC). We utilize a Siamese type neural network for pattern recognition in images followed by a bootstrapped image similarity distribution to predict rare events as they pertain to financial market analysis. Extending on literature about rare event classification and stochastic modeling in financial analytics, the proposed method uses a sliding window to store the input features as tabular data (HLC price), creates an image of the time series window, and then uses the feature vector of a pre-trained convolutional neural network (CNN) to leverage pre-event images and predict rare events. This research does not just indicate that our proposed method is capable of distinguishing event images from non-event images, but more importantly, the method is effective even when only limited and strongly imbalanced data is available. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Convolutional Neural Network (CNN); Image processing; Rare event prediction; Siamese neural networks; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhou2023,
	author = {Zhou, Wang-Tao and Kang, Zhao and Tian, Ling and Su, Yi},
	title = {Intensity-free convolutional temporal point process: Incorporating local and global event contexts},
	year = {2023},
	journal = {Information Sciences},
	volume = {646},
	doi = {10.1016/j.ins.2023.119318},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166268546&doi=10.1016%2fj.ins.2023.119318&partnerID=40&md5=86f45a0967590ad905ffde14de5af790},
	abstract = {Event prediction in the continuous-time domain is a crucial but rather difficult task. Temporal point process (TPP) learning models have shown great advantages in this area. Existing models mainly focus on encoding global contexts of events using techniques like recurrent neural networks (RNNs) or self-attention mechanisms. However, local event contexts also play an important role in the occurrences of events, which has been largely ignored. Popular convolutional neural networks, which are designated for local context capturing, have never been applied to TPP modelling due to their incapability of modelling in continuous time. In this work, we propose a novel TPP modelling approach that combines local and global contexts by integrating a continuous-time convolutional event encoder with an RNN. The presented framework is flexible and scalable to handle large datasets with long sequences and complex latent patterns. The experimental result shows that the proposed model improves the performance of probabilistic sequential modelling and the accuracy of event prediction. To our best knowledge, this is the first work that applies convolutional neural networks to TPP modelling. © 2023},
	author_keywords = {Convolution; Event prediction; Local context; Temporal point process},
	keywords = {Continuous time systems; Forecasting; Large dataset; Recurrent neural networks; Signal encoding; Time domain analysis; Time series; Continous time; Convolutional neural network; Event context; Event prediction; Global context; Local contexts; Point process; Process-models; Temporal point process; Time domain; Convolution},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Wambura202060,
	author = {Wambura, Stephen and Li, He and Nigussie, Alemu},
	title = {Fast Memory-efficient Extreme Events Prediction in Complex Time series},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {60 – 69},
	doi = {10.1145/3402597.3402609},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089749918&doi=10.1145%2f3402597.3402609&partnerID=40&md5=d93e4ac3239cb4be483c8a9cb5d0930f},
	abstract = {This paper proposes a generic memory-efficient framework for realtime stochastic extreme events prediction in complex time series systems such as intrusion detection, Internet of Things (IoT), social networks, stock markets etc. Ideally we exploit the expressiveness of deep neural networks and temporal nature of sequence-to-sequence structures (parallel Convolutional and recurrent neural networks) glued on Convolutional Quantile Loss and memory network to model explicitly extreme events. Convolutional Quantile Loss is used to predict future extreme events, while memory network is used to memorize extreme events in future observations. We show that the approach can capture long and short-term temporal effects as well as other non-linear dynamic patterns across multiple probabilistic time series with reliable principled uncertainty estimates. We demonstrate and validate empirically the effectiveness of the proposed framework via extensive experiments and rigorous evaluation on large-scale real world datasets. The experimental results showcase that the proposed method is fast, robust, accurate and has superior performance compared to the well-known prediction methods. © 2020 ACM.},
	author_keywords = {events; neural networks; prediction; time series},
	keywords = {Complex networks; Convolution; Deep neural networks; Electronic trading; Forecasting; Internet of things; Intrusion detection; Large dataset; Robots; Stochastic models; Stochastic systems; Time series; Uncertainty analysis; Complex time series; Future observations; Internet of Things (IOT); Non-linear dynamics; Prediction methods; Real-world datasets; Rigorous evaluation; Uncertainty estimates; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{2022,
	title = {21st International Symposium on Knowledge and Systems Sciences, KSS 2022},
	year = {2022},
	journal = {Communications in Computer and Information Science},
	volume = {1592 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132873449&partnerID=40&md5=6cd622bbf845b726ce3e8536ba6c9b87},
	abstract = {The proceedings contain 17 papers presendted at a virtual meeting. The special focus in this conference is on Knowledge and Systems Sciences. The topics include: PM2.5 Spatial-Temporal Long Series Forecasting Based on Deep Learning and EMD; knowledge Technology and Systems - Definition and Challenges; research on Construction Method of SoS Architecture Knowledge Graph; intelligent Modeling Framework for System of Systems Architecture Based on Knowledge Graph; introducing Trigger Evolutionary Graph and Event Segment for Event Prediction; research on the Maturity Evaluation of the Public Health Emergency Response Capability of Urban Communities; metaheuristic Enhancement with Identified Elite Genes by Machine Learning; 3D Visualization Supporting Situational Awareness of Model-Based System of Systems; preface; exploring the Asymmetric Effects of Perceived Quality on Product Evaluation: A Study of Automobile Review; hierarchical Storyline Generation Based on Event-centric Temporal Knowledge Graph; aspect Based Fine-Grained Sentiment Analysis for Public Policy Opinion Mining; estimation of Network Efficiency Based on Sampling; bugCat: A Novel Approach to Bug Number Categorization with Multi-modal Time Series Learning; an End-to-end Weakly-supervised News Aggregation Framework.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ataee2022,
	author = {Ataee, Shabnam and Rayati, Mohammad and Pena, Carlos Andres and Alizadeh-Mousavi, Omid and Bozorg, Mokhtar},
	title = {A Data-Driven Algorithm for Short-Term Prediction of Over-Voltage and Under-Voltage Events in Distribution Grids},
	year = {2022},
	journal = {IEEE PES Innovative Smart Grid Technologies Conference Europe},
	volume = {2022-October},
	doi = {10.1109/ISGT-Europe54678.2022.9960543},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143800559&doi=10.1109%2fISGT-Europe54678.2022.9960543&partnerID=40&md5=cd502f3683a7abeab9692557ce3653e4},
	abstract = {This paper proposes algorithms for short-term over- and under-voltage prediction in distribution grids. The proposed algorithms are developed using time-series of voltage and current measurements, which does not require the knowledge of distribution grid model (topology and parameters of the components). Various algorithms based on random forest classifier (RFC) and random forest regressor (RFR) methods, two prominent machine learning methods, are developed regarding different feature selection possibilities. The developed algorithms are tested and validated on two real datasets (grid measurement data from GridEye devices in two low voltage grids in Switzerland). An algorithm based on RFR method, with recent information including the measurement data of the last week at the same time of prediction, outperforms other algorithms. The proposed algorithm can predict over- and under-voltage events with 85% accuracy four hours ahead of the real time.  © 2022 IEEE.},
	author_keywords = {Distribution grid; machine learning; random forest classifier (RFC); random forest regressor (RFR); voltage events prediction},
	keywords = {Forecasting; Forestry; Learning algorithms; Machine learning; Distribution grid; Event prediction; Machine-learning; Over-voltages; Random forest classifier; Random forest regressor; Random forests; Voltage event; Voltage event prediction; Topology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{2020,
	title = {Proceedings of the 2020 3rd International Conference on Robot Systems and Applications, ICRSA 2020},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123040646&partnerID=40&md5=97ec9f75c2b54cabdea6edfaa598b315},
	abstract = {The proceedings contain 17 papers. The topics discussed include: Robotario: exploration into perception of robotic agency; design of a laser-based calibration instrument for robot's location positioning on a curved surface; simulating decentralized platooning for coordinated conflict-free motion of mobile robot fleets; human parsing with discriminant feature learning for person re-identification; salient latent features for zero-shot learning; rule-based distribute topology optimization; home energy management system based on particle swarm optimization; hybrid variance reduction algorithms with adaptive epoch sizes; and fast memory-efficient extreme events prediction in complex time series.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lee2023,
	author = {Lee, Jeong Min and Hauskrecht, Milos},
	title = {Personalized event prediction for Electronic Health Records},
	year = {2023},
	journal = {Artificial Intelligence in Medicine},
	volume = {143},
	doi = {10.1016/j.artmed.2023.102620},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166294968&doi=10.1016%2fj.artmed.2023.102620&partnerID=40&md5=932e393c82d4c8f98429c3fe31098975},
	abstract = {Clinical event sequences consist of hundreds of clinical events that represent records of patient care in time. Developing accurate predictive models of such sequences is of a great importance for supporting a variety of models for interpreting/classifying the current patient condition, or predicting adverse clinical events and outcomes, all aimed to improve patient care. One important challenge of learning predictive models of clinical sequences is their patient-specific variability. Based on underlying clinical conditions, each patient's sequence may consist of different sets of clinical events (observations, lab results, medications, procedures). Hence, simple population-wide models learned from event sequences for many different patients may not accurately predict patient-specific dynamics of event sequences and their differences. To address the problem, we propose and investigate multiple new event sequence prediction models and methods that let us better adjust the prediction for individual patients and their specific conditions. The methods developed in this work pursue refinement of population-wide models to subpopulations, self-adaptation, and a meta-level model switching that is able to adaptively select the model with the best chance to support the immediate prediction. We analyze and test the performance of these models on clinical event sequences of patients in MIMIC-III database. © 2023 Elsevier B.V.},
	author_keywords = {Adaptation process; Adaptive models; Clinical event time-series; EHR; Electronic Health Records; Event prediction; Individualized prediction models; Patient-specific models; Patient-specific variabilities; Personalization; Recurrent Neural Network (RNN); Sequence prediction},
	keywords = {Databases, Factual; Electronic Health Records; Humans; Learning; Forecasting; Records management; Adaptation process; Adaptive models; Clinical event time-series; EHR; Electronic health; Electronic health record; Event prediction; Health records; Individualized prediction model; Patient specific; Patient-specific modeling; Patient-specific variability; Personalizations; Prediction modelling; Recurrent neural network; Sequence prediction; Times series; adult; article; electronic health record; human; prediction; recurrent neural network; time series analysis; factual database; learning; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Atashi2022,
	author = {Atashi, Vida and Gorji, Hamed Taheri and Shahabi, Seyed Mojtaba and Kardan, Ramtin and Lim, Yeo Howe},
	title = {Water Level Forecasting Using Deep Learning Time‐Series Analysis: A Case Study of Red River of the North},
	year = {2022},
	journal = {Water (Switzerland)},
	volume = {14},
	number = {12},
	doi = {10.3390/w14121971},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133259327&doi=10.3390%2fw14121971&partnerID=40&md5=8b321520fb5af283aefe647047579742},
	abstract = {The Red River of the North is vulnerable to floods, which have caused significant damage and economic loss to inhabitants. A better capability in flood‐event prediction is essential to deci-sion‐makers for planning flood‐loss‐reduction strategies. Over the last decades, classical statistical methods and Machine Learning (ML) algorithms have greatly contributed to the growth of data-driven forecasting systems that provide cost‐effective solutions and improved performance in simulating the complex physical processes of floods using mathematical expressions. To make improve-ments to flood prediction for the Red River of the North, this paper presents effective approaches that make use of a classical statistical method, a classical ML algorithm, and a state‐of‐the‐art Deep Learning method. Respectively, the methods are seasonal autoregressive integrated moving aver-age (SARIMA), Random Forest (RF), and Long Short‐Term Memory (LSTM). We used hourly level records from three U.S. Geological Survey (USGS), at Pembina, Drayton, and Grand Forks stations with twelve years of data (2007–2019), to evaluate the water level at six hours, twelve hours, one day, three days, and one week in advance. Pembina, at the downstream location, has a water level gauge but not a flow‐gauging station, unlike the others. The floodwater‐level‐prediction results show that the LSTM method outperforms the SARIMA and RF methods. For the one‐week‐ahead prediction, the RMSE values for Pembina, Drayton, and Grand Forks are 0.190, 0.151, and 0.107, respectively. These results demonstrate the high precision of the Deep Learning algorithm as a re-liable choice for flood‐water‐level prediction. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {flood prediction; LSTM; Red River; RF; SARIMA; water level},
	keywords = {Decision trees; Floods; Forecasting; Learning algorithms; Learning systems; Losses; Rivers; Time series analysis; Water levels; Auto-regressive; Case-studies; Flood prediction; Learning time; Machine learning algorithms; Random forests; Red River; Seasonal autoregressive integrated moving aver-age; Time-series analysis; Water level forecasting; algorithm; decision making; flood; flood damage; forecasting method; machine learning; time series analysis; vulnerability; water level; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access}
}

@ARTICLE{Kwon2022,
	author = {Kwon, Osung and Na, Wonjun and Kang, Heejun and Jun, Tae Joon and Kweon, Jihoon and Park, Gyung-Min and Cho, YongHyun and Hur, Cinyoung and Chae, Jungwoo and Kang, Do-Yoon and Lee, Pil Hyung and Ahn, Jung-Min and Park, Duk-Woo and Kang, Soo-Jin and Lee, Seung-Whan and Lee, Cheol Whan and Park, Seong-Wook and Park, Seung-Jung and Yang, Dong Hyun and Kim, Young-Hak},
	title = {Electronic Medical Record–Based Machine Learning Approach to Predict the Risk of 30-Day Adverse Cardiac Events after Invasive Coronary Treatment: Machine Learning Model Development and Validation},
	year = {2022},
	journal = {JMIR Medical Informatics},
	volume = {10},
	number = {5},
	doi = {10.2196/26801},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130586178&doi=10.2196%2f26801&partnerID=40&md5=78f5f6161a9521820e319b6323d8c606},
	abstract = {Background: Although there is a growing interest in prediction models based on electronic medical records (EMRs) to identify patients at risk of adverse cardiac events following invasive coronary treatment, robust models fully utilizing EMR data are limited. Objective: We aimed to develop and validate machine learning (ML) models by using diverse fields of EMR to predict the risk of 30-day adverse cardiac events after percutaneous intervention or bypass surgery. Methods: EMR data of 5,184,565 records of 16,793 patients at a quaternary hospital between 2006 and 2016 were categorized into static basic (eg, demographics), dynamic time-series (eg, laboratory values), and cardiac-specific data (eg, coronary angiography). The data were randomly split into training, tuning, and testing sets in a ratio of 3:1:1. Each model was evaluated with 5-fold cross-validation and with an external EMR-based cohort at a tertiary hospital. Logistic regression (LR), random forest (RF), gradient boosting machine (GBM), and feedforward neural network (FNN) algorithms were applied. The primary outcome was 30-day mortality following invasive treatment. Results: GBM showed the best performance with area under the receiver operating characteristic curve (AUROC) of 0.99; RF had a similar AUROC of 0.98. AUROCs of FNN and LR were 0.96 and 0.93, respectively. GBM had the highest area under the precision-recall curve (AUPRC) of 0.80, and the AUPRCs of RF, LR, and FNN were 0.73, 0.68, and 0.63, respectively. All models showed low Brier scores of <0.1 as well as highly fitted calibration plots, indicating a good fit of the ML-based models. On external validation, the GBM model demonstrated maximal performance with an AUROC of 0.90, while FNN had an AUROC of 0.85. The AUROCs of LR and RF were slightly lower at 0.80 and 0.79, respectively. The AUPRCs of GBM, LR, and FNN were similar at 0.47, 0.43, and 0.41, respectively, while that of RF was lower at 0.33. Among the categories in the GBM model, time-series dynamic data demonstrated a high AUROC of >0.95, contributing majorly to the excellent results. Conclusions: Exploiting the diverse fields of the EMR data set, the ML-based 30-day adverse cardiac event prediction models demonstrated outstanding results, and the applied framework could be generalized for various health care prediction models. ©Osung Kwon, Wonjun Na, Heejun Kang, Tae Joon Jun, Jihoon Kweon, Gyung-Min Park, YongHyun Cho, Cinyoung Hur, Jungwoo Chae, Do-Yoon Kang, Pil Hyung Lee, Jung-Min Ahn, Duk-Woo Park, Soo-Jin Kang, Seung-Whan Lee, Cheol Whan Lee, Seong-Wook Park, Seung-Jung Park, Dong Hyun Yang, Young-Hak Kim.},
	author_keywords = {adverse cardiac event; big data; coronary artery disease; electronic medical record; machine learning; mortality; prediction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Xie2022,
	author = {Xie, Feng and Yuan, Han and Ning, Yilin and Ong, Marcus Eng Hock and Feng, Mengling and Hsu, Wynne and Chakraborty, Bibhas and Liu, Nan},
	title = {Deep learning for temporal data representation in electronic health records: A systematic review of challenges and methodologies},
	year = {2022},
	journal = {Journal of Biomedical Informatics},
	volume = {126},
	doi = {10.1016/j.jbi.2021.103980},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122621542&doi=10.1016%2fj.jbi.2021.103980&partnerID=40&md5=65386bfe354ffab69e1846c9fd026a61},
	abstract = {Objective: Temporal electronic health records (EHRs) contain a wealth of information for secondary uses, such as clinical events prediction and chronic disease management. However, challenges exist for temporal data representation. We therefore sought to identify these challenges and evaluate novel methodologies for addressing them through a systematic examination of deep learning solutions. Methods: We searched five databases (PubMed, Embase, the Institute of Electrical and Electronics Engineers [IEEE] Xplore Digital Library, the Association for Computing Machinery [ACM] Digital Library, and Web of Science) complemented with hand-searching in several prestigious computer science conference proceedings. We sought articles that reported deep learning methodologies on temporal data representation in structured EHR data from January 1, 2010, to August 30, 2020. We summarized and analyzed the selected articles from three perspectives: nature of time series, methodology, and model implementation. Results: We included 98 articles related to temporal data representation using deep learning. Four major challenges were identified, including data irregularity, heterogeneity, sparsity, and model opacity. We then studied how deep learning techniques were applied to address these challenges. Finally, we discuss some open challenges arising from deep learning. Conclusion: Temporal EHR data present several major challenges for clinical prediction modeling and data utilization. To some extent, current deep learning solutions can address these challenges. Future studies may consider designing comprehensive and integrated solutions. Moreover, researchers should incorporate clinical domain knowledge into study designs and enhance model interpretability to facilitate clinical implementation. © 2021 Elsevier Inc.},
	author_keywords = {Deep learning; Electronic health records; Representation; Systematic review; Temporal data},
	keywords = {Deep Learning; Electronic Health Records; PubMed; Deep learning; Digital libraries; Diseases; Domain Knowledge; E-learning; Machinery; Chronic disease management; Data representations; Deep learning; Event prediction; Novel methodology; Representation; Secondary use; Systematic Review; Temporal Data; Wealth of information; data base; data processing; deep learning; electronic health record; methodology; model; Review; systematic review; temporal data representation; time series analysis; Medline; Records management},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Douin2023,
	author = {Douin, Adèle and Poincloux, Samuel and Bruneton, Jean-Philippe and Lechenault, Frédéric},
	title = {Assessing seismic-like events prediction in model knits with unsupervised machine learning},
	year = {2023},
	journal = {Extreme Mechanics Letters},
	volume = {58},
	doi = {10.1016/j.eml.2022.101932},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143771002&doi=10.1016%2fj.eml.2022.101932&partnerID=40&md5=5eb91a504b25b4e785499d91bb72f298},
	abstract = {Knitted fabric exhibits avalanche-like events when deformed, which we are interested in predicting, by analogy with earthquakes. However, as in most analogous seismic models, the time intermittence and scale-invariance of these events severely jeopardize this endeavor. But more importantly, such predictions are hard to assess and not easily compared. Here we introduce a framework that allows not only to predict seismic-like, rebalanced time series, but to also evaluate and compare the relevance of competing predictions. It relies on a reinforcement learning environment that learns risk management in a model, seismically active city subjected to the crackling dynamics observed in the mechanical response of knitted fabric. Relying on extensive experimental data, we show that this mechanism allows to assess the finite predictability of seismic-like activity, and to compare the performance of different approaches in the operational usage of such predictions. © 2022 Elsevier Ltd},
	author_keywords = {Crackling noise; Knitted fabric; Machine learning; Seismicity},
	keywords = {Knit fabrics; Reinforcement learning; Risk management; Seismology; Crackling noise; Event prediction; Knitted fabric; Machine-learning; Reinforcement learnings; Scale invariance; Seismic model; Seismicity; Times series; Unsupervised machine learning; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lin20221024,
	author = {Lin, Yijun and Chiang, Yao-Yi},
	title = {A Semi-Supervised Learning Approach for Abnormal Event Prediction on Large Network Operation Time-Series Data},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Conference on Big Data, Big Data 2022},
	pages = {1024 – 1033},
	doi = {10.1109/BigData55660.2022.10020157},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147960828&doi=10.1109%2fBigData55660.2022.10020157&partnerID=40&md5=04d3873675dab9845a80e4fcd7478431},
	abstract = {Large network logs, recording multivariate time series generated from heterogeneous devices and sensors in a network, can reveal important information about abnormal activities, such as network intrusions and packet losses. Existing machine learning methods for anomaly detection on multiple multivariate time series typically assume that 1) infrequent behaviors beyond some inference threshold are anomalous for unsupervised models or 2) require a large set of labeled normal and abnormal sequences for supervised models. However, in practice, the reported abnormal events might be available but incomplete and sparse (i.e., much fewer than normal cases). This paper presents a novel semi-supervised approach, SNetAD, that takes advantage of the incomplete and imbalanced labels to effectively learn separable feature embeddings of network activities representing normal and abnormal events. Specifically, SNetAD first generates network representations by capturing relationships across time points and between network devices. Then SNetAD encourages the embeddings to form two clusters using contrastive center loss and improves the separability of the learned clusters using labeled and unlabeled samples in a semi-supervised manner. The experiments demonstrate that SNetAD significantly outperforms state-of-the-art approaches for abnormal event prediction on a large real-world network log. © 2022 IEEE.},
	author_keywords = {multivariate time series; network event prediction; semi-supervised},
	keywords = {Embeddings; Forecasting; Time series; Event prediction; Heterogeneous sensors; Larger networks; Multivariate time series; Network event prediction; Network operation time; Semi-supervised; Semi-supervised learning; Supervised learning approaches; Time-series data; Anomaly detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Fox2022,
	author = {Fox, Stephen and Zimmerman, Elizabeth and Daly, Tynan and O'Keeffe, Michael and Verleyen, Wim},
	title = {Providence-a Deep Learning Framework for Time-to-Event Prediction},
	year = {2022},
	journal = {IEEE Aerospace Conference Proceedings},
	volume = {2022-March},
	doi = {10.1109/AERO53065.2022.9843469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137546572&doi=10.1109%2fAERO53065.2022.9843469&partnerID=40&md5=3e6fdb25c5378689b52075ec6842fca6},
	abstract = {Prognostic Health Monitoring (PHM) and Condition Based Maintenance (CBM) are fields with robust bodies of research which have, in recent years, shown promise to be transformed by deep learning. A catalyst for the recent surge in time-to-event research has been the tandem advancement and widespread deployment of sensing technologies alongside maturation of deep learning techniques for time series. Consequently, deep learning for time-to-event modeling has gained in both popularity and effectiveness. Multivariate time series and sensor data have become a cornerstone of failure prognostics. Prior work has shown that traditional methods struggle to capture the complex nature of the underlying dynamical system, the relationships between sensor signals, the degradation of the system over time, multiple failure modes, and the often very rare event of failure. Recurrent Neural Networks (RNNs) have been used widely in remaining useful life (RUL) research, effectively modeling the temporal nature of the problem and complex relationships between sensor signals. Still, capturing the degradation of a dynamic system requires a domain-specific solution, as provided in the Weibull Time-to-Event RNN (WTTE-RNN). Building upon these advances, we introduce Providence, a neural network framework for generating Weibull time-to-event (TTE) estimates by solving a sequence-to-sequence learning problem. By learning a Weibull distribution, we translate the problem from one of forecasting to one of multivariate distribution fitting. We perform this task on a multi-device dataset and produce Weibull predictions per-device. By learning per-device, we avoid the issue of source distribution variance across multiple devices. With the Weibull distribution, we can predict a TTE for an arbitrary event; herein, we focus on device failures. We benchmark performance of the Providence framework with the publically available NASA Turbofan and Backblaze hard disk drive datasets. Additional experiments find that Transformers with temporal attention are able to learn distributions across an entire fleet. Finally, we demonstrate the efficacy of alternative approach to the RUL problem and champion it for its high interpretability. © 2022 IEEE.},
	keywords = {Benchmarking; Complex networks; Condition based maintenance; Dynamical systems; Learning systems; Recurrent neural networks; Time series; Weibull distribution; Condition based maintenance; Event prediction; Health condition; Health monitoring; Learning frameworks; Remaining useful lives; Sensor signals; Time to events; Weibull; ]+ catalyst; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schörgenhumer20199,
	author = {Schörgenhumer, Andreas and Kahlhofer, Mario and Grünbacher, Paul and Mössenböck, Hanspeter},
	title = {Can we Predict Performance Events with Time Series Data from Monitoring Multiple Systems?},
	year = {2019},
	journal = {ICPE 2019 - Companion of the 2019 ACM/SPEC International Conference on Performance Engineering},
	pages = {9 – 12},
	doi = {10.1145/3302541.3313101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064622633&doi=10.1145%2f3302541.3313101&partnerID=40&md5=825b67472d61c06ec8ec40b6cdb0fa84},
	abstract = {Predicting performance-related events is an important part of proactive fault management. As a result, many approaches exist for the context of single systems. Surprisingly, despite its potential benefits, multi-system event prediction, i.e., using data from multiple, independent systems, has received less attention. We present ongoing work towards an approach for multi-system event prediction that works with limited data and can predict events for new systems. We present initial results showing the feasibility of our approach. Our preliminary evaluation is based on 20 days of continuous, preprocessed monitoring time series data of 90 independent systems. We created five multi-system machine learning models and compared them to the performance of single-system machine learning models. The results show promising prediction capabilities with accuracies and F1-scores over 90% and false-positive-rates below 10%. © 2019 ACM.},
	author_keywords = {event prediction; infrastructure monitoring data; multivariate timeseries; supervised machine learning},
	keywords = {Continuous time systems; Forecasting; Machine learning; Supervised learning; Time series; Event prediction; False positive rates; Independent systems; Infrastructure monitoring; Machine learning models; Prediction capability; Proactive fault managements; Supervised machine learning; Monitoring},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Biswas2021809,
	author = {Biswas, Susmita and Sinha, Mourani},
	title = {Performances of deep learning models for Indian Ocean wind speed prediction},
	year = {2021},
	journal = {Modeling Earth Systems and Environment},
	volume = {7},
	number = {2},
	pages = {809 – 831},
	doi = {10.1007/s40808-020-00974-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091137036&doi=10.1007%2fs40808-020-00974-9&partnerID=40&md5=ff63ee5e58b9bb326554a40220d1f9bb},
	abstract = {A wind speed forecasting technique, using deep learning architectures based on long short-term memory (LSTM) model and bidirectional long short-term memory (BiLSTM) model is presented in this work. The coastal belts of the Indian peninsula are vulnerable to natural disasters like storm surges and inundations due to cyclones each year. The wind speed is a major parameter for analyzing extreme weather events. Prediction using numerical models is not efficient enough due to the irregular patterns in the data and, thus, deep neural network models involving many layers have been tested. The shallow feed-forward model has also been considered along with deep learning models to estimate future values from past data. The present work employs a comparison study of different models to forecast wind speed time series at two locations in the Bay of Bengal and the Arabian Sea, respectively, having different dynamics and randomness. For training the models, daily wind speed data are considered for the period 2006–2017 and an independent validation set is chosen comprising 2018 wind speed data to check the accuracy. To evaluate forecast efficiency among different network models fitted to given time series, mean square error (MSE) and root mean square error (RMSE) have been computed. Multiple experiments are conducted with different hidden unit values and epoch values to obtain the minimum error. Regression equations generated may be used for forecasting future time series. The BiLSTM model connecting hidden states of opposite directions proved to be most efficient for the wind speed forecasting in different regions. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Bidirectional LSTM model; Deep learning; Indian Ocean; Machine learning; Prediction; Wind speed},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@ARTICLE{Zhao202114,
	author = {Zhao, Zilin and Ding, Zhiming and Cao, Yang},
	title = {A Method of Emergency Prediction Based on Spatiotemporal Context Time Series},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12567 LNCS},
	pages = {14 – 28},
	doi = {10.1007/978-3-030-69873-7_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103304973&doi=10.1007%2f978-3-030-69873-7_2&partnerID=40&md5=d6e48ae03b718fc7d6296e19821c0dba},
	abstract = {How to detect and predict the critical situation in large-scale activities is a very important research issue. The existing researches of emergency prediction are mainly focus on the micro events in some specific fields. Applying existing results directly to predict the critical situation in large-scale activity is a big challenge. In this paper, we show a novel method to predict emergency based on historical data analysis. We integrate relevant research results into a unified spatiotemporal model. Firstly, constructing the historical spatiotemporal context time series based on historical activity data. Then, dividing the time series into time period and time window. Finally, exploiting the time series’ spatiotemporal patterns to predict the emergency of current activity. Experimental results show that the proposed method can achieve better prediction of large-scale activity emergencies in a specific venue. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Emergency; Event prediction; Spatiotemporal; Time series},
	keywords = {Time series; Historical data; Micro-events; Prediction-based; Research issues; Research results; Spatio-temporal models; Spatiotemporal patterns; Time-periods; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rostamian202217193,
	author = {Rostamian, Ahoora and O’Hara, John G.},
	title = {Event prediction within directional change framework using a CNN-LSTM model},
	year = {2022},
	journal = {Neural Computing and Applications},
	volume = {34},
	number = {20},
	pages = {17193 – 17205},
	doi = {10.1007/s00521-022-07687-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136213811&doi=10.1007%2fs00521-022-07687-3&partnerID=40&md5=1537e09db53430495f50adf9814343d0},
	abstract = {Financial forecasting has always been an intriguing research area in the field of finance. The widely accepted approach to forecast financial data is to perform predictions using time series data. In time series analysis, sampling the financial data with a predefined frequency (e.g. hourly, daily) leads to an uneven and discontinued data flow. Directional Change is a newly proposed approach that replaces physical time within the financial data and establishes an event-driven framework. With the emergence of the machine and deep learning-based methods, researchers have utilised them in financial time series. These techniques have shown to outperform conventional approaches. This paper aims to employ the CNN-LSTM model to investigate its predictive competence within the Directional Change (DC) framework to predict DC event prices. To obtain this objective, we first create the tick bars/candles of the GBPUSD, EURUSD, USDCHF, and USDCAD tick prices from January to August 2019. Then, the DC-based summaries of the selected tick bar/candle for each currency pair will be generated and fed to the CNN-LSTM model. The CNN-LSTM network architecture incorporates the robustness of Convolutional Neural Network (CNN) in feature extraction and Long Short-Term Memory (LSTM) in predicting sequential data. The results suggest that the performance of the CNN-LSTM model improves significantly within the DC framework. © 2022, The Author(s).},
	author_keywords = {CNN; Directional change framework; Event prediction; LSTM; Price prediction},
	keywords = {Convolutional neural networks; Costs; Data flow analysis; Forecasting; Network architecture; Time series analysis; Convolutional neural network; Directional change framework; Directional changes; Event prediction; Financial data; Financial forecasting; Memory modeling; Price prediction; Research areas; Time-series data; Long short-term memory},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Abilasha20221726,
	author = {Abilasha, S. and Bhadra, Sahely and Dadarkar, Ahmed Zaheer and Deepak, P.},
	title = {Deep Extreme Mixture Model for Time Series Forecasting},
	year = {2022},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {1726 – 1735},
	doi = {10.1145/3511808.3557282},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140851075&doi=10.1145%2f3511808.3557282&partnerID=40&md5=2f2f3df46d0e2eabb64ac06de51a93bf},
	abstract = {Time Series Forecasting (TSF) has been a topic of extensive research, which has many real world applications such as weather prediction, stock market value prediction, traffic control etc. Many machine learning models have been developed to address TSF, yet, predicting extreme values remains a challenge to be effectively addressed. Extreme events occur rarely, but tend to cause a huge impact, which makes extreme event prediction important. Assuming light tailed distributions, such as Gaussian distribution, on time series data does not do justice to the modeling of extreme points. To tackle this issue, we develop a novel approach towards improving attention to extreme event prediction. Within our work, we model time series data distribution, as a mixture of Gaussian distribution and Generalized Pareto distribution (GPD). In particular, we develop a novel Deep eXtreme Mixture Model (DXtreMM) for univariate time series forecasting, which addresses extreme events in time series. The model consists of two modules: 1) Variational Disentangled Auto-encoder (VD-AE) based classifier and 2) Multi Layer Perceptron (MLP) based forecaster units combined with Generalized Pareto Distribution (GPD) estimators for lower and upper extreme values separately. VD-AE Classifier model predicts the possibility of occurrence of an extreme event given a time segment, and forecaster module predicts the exact value. Through extensive set of experiments on real-world datasets we have shown that our model performs well for extreme events and is comparable with the existing baseline methods for normal time step forecasting. © 2022 ACM.},
	author_keywords = {extreme events; generalized pareto distribution; mixture models},
	keywords = {Mixtures; Pareto principle; Time series; Traffic control; Auto encoders; Event prediction; Extreme events; Extreme value; Generalized Pareto Distributions; Mixture modeling; Real-world; Time series forecasting; Time-series data; Weather prediction; Gaussian distribution},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Duan20202053,
	author = {Duan, Huilong and Sun, Zhoujian and Dong, Wei and He, Kunlun and Huang, Zhengxing},
	title = {On Clinical Event Prediction in Patient Treatment Trajectory Using Longitudinal Electronic Health Records},
	year = {2020},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	volume = {24},
	number = {7},
	pages = {2053 – 2063},
	doi = {10.1109/JBHI.2019.2962079},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077292172&doi=10.1109%2fJBHI.2019.2962079&partnerID=40&md5=aaa3176570704bcf5d7a636ddf3f94dc},
	abstract = {Healthcare process leaves patient treatment trajectory (PTT), described as a sequence of interdependent clinical events affiliated with a large volume of longitudinal therapy and treatment information. Predicting the future clinical event in PTT, as a vital and essential task for providing insights into the entire treatment trajectory, can serve as an efficient and proactive altering service for health service delivery. However, it is challenging because there are long-term dependencies between clinical events, which are irregularly distributed along the temporal axis with varying time intervals. This characteristic inevitably impedes the performance of clinical event prediction (CEP) using the existing approaches. To address this challenge, we propose a novel approach to learn representative and discriminative PTT features for CEP. In detail, multivariate Hawkes process (HP) is adopted to uncover the mutual excitation intensities between clinical event pairs in an interpretable manner. Thereafter, the captured spontaneous and interactional intensities of events are incorporated into recurrent neural networks (RNN) to encode PTT in latent representations, while jointly performing the CEP task based on the extracted trajectory representations. We evaluate the performance of the proposed approach on a real clinical dataset consisting of 13,545 visits of 2,102 heart failure patients. Compared to state-of-the-art methods, our best model achieves 6.4% and 4.1% AUC performance gains on three-months and one-year CEP tasks, respectively. The experimental results demonstrate that the proposed approach outperforms state-of-the-art models in CEP, and can be profitably exploited as a basis for PTT analysis and optimization. © 2013 IEEE.},
	author_keywords = {Clinical Event Prediction (CEP); Longitudinal Electronic Health Record; Multivariate Hawkes Process; Patient Treatment Trajectory (PTT); Recurrent Neural Network (RNN)},
	keywords = {Diagnosis; Electronic Health Records; Heart Failure; Humans; Medical Informatics Applications; Models, Statistical; Neural Networks, Computer; Treatment Outcome; Forecasting; Patient treatment; Records management; Trajectories; Electronic health record; Event prediction; Healthcare process; Long-term dependencies; Mutual excitation; Recurrent neural network (RNN); State of the art; State-of-the-art methods; accuracy; Article; body mass; clinical decision making; electronic health record; health care delivery; health service; hospital readmission; hospitalization; human; learning algorithm; machine learning; Markov chain; nerve cell network; pregnancy; support vector machine; time series analysis; diagnosis; electronic health record; heart failure; medical informatics; statistical model; treatment outcome; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@ARTICLE{Cho2021,
	author = {Cho, Insook and Jin, In sun and Park, Hyunchul and Dykes, Patricia C.},
	title = {Clinical impact of an analytic tool for predicting the fall risk in inpatients: Controlled interrupted time series},
	year = {2021},
	journal = {JMIR Medical Informatics},
	volume = {9},
	number = {11},
	doi = {10.2196/26456},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120156420&doi=10.2196%2f26456&partnerID=40&md5=cb5d76140192a86855a637efe2d9f296},
	abstract = {Background: Patient falls are a common cause of harm in acute-care hospitals worldwide. They are a difficult, complex, and common problem requiring a great deal of nurses' time, attention, and effort in practice. The recent rapid expansion of health care predictive analytic applications and the growing availability of electronic health record (EHR) data have resulted in the development of machine learning models that predict adverse events. However, the clinical impact of these models in terms of patient outcomes and clinicians' responses is undetermined. Objective: The purpose of this study was to determine the impact of an electronic analytic tool for predicting fall risk on patient outcomes and nurses' responses. Methods: A controlled interrupted time series (ITS) experiment was conducted in 12 medical-surgical nursing units at a public hospital between May 2017 and April 2019. In six of the units, the patients' fall risk was assessed using the St. Thomas' Risk Assessment Tool in Falling Elderly Inpatients (STRATIFY) system (control units), while in the other six, a predictive model for inpatient fall risks was implemented using routinely obtained data from the hospital's EHR system (intervention units). The primary outcome was the rate of patient falls; secondary outcomes included the rate of falls with injury and analysis of process metrics (nursing interventions that are designed to mitigate the risk of fall). Results: During the study period, there were 42,476 admissions, of which 707 were for falls and 134 for fall injuries. Allowing for differences in the patients' characteristics and baseline process metrics, the number of patients with falls differed between the control (n=382) and intervention (n=325) units. The mean fall rate increased from 1.95 to 2.11 in control units and decreased from 1.92 to 1.79 in intervention units. A separate ITS analysis revealed that the immediate reduction was 29.73% in the intervention group (z=-2.06, P=.039) and 16.58% in the control group (z=-1.28, P=.20), but there was no ongoing effect. The injury rate did not differ significantly between the two groups (0.42 vs 0.31, z=1.50, P=.134). Among the process metrics, the risk-targeted interventions increased significantly over time in the intervention group. Conclusions: This early-stage clinical evaluation revealed that implementation of an analytic tool for predicting fall risk may to contribute to an awareness of fall risk, leading to positive changes in nurses' interventions over time. © 2021 JMIR Publications Inc.. All rights reserved.},
	author_keywords = {Clinical effectiveness; Data analytics; Event prediction; Inpatient falls; Process metrics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Duan202312496,
	author = {Duan, Jingyuan and Tian, Ling and Li, Kaiyang},
	title = {Event Predictability: A Uniform Form for IoT-Based Nondeterministic Social Systems},
	year = {2023},
	journal = {IEEE Internet of Things Journal},
	volume = {10},
	number = {14},
	pages = {12496 – 12507},
	doi = {10.1109/JIOT.2023.3247726},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149360952&doi=10.1109%2fJIOT.2023.3247726&partnerID=40&md5=a54e30d82e3e80b4ebe1b6555400ce50},
	abstract = {Integrating massive social data with traditional social sciences, the computational social science (CSS) is crucial for understanding the Internet of Things (IoT)-based nondeterministic social systems. Event predictability is the fundamental premise of widespread societal event predictions with CSS. Due to data quality, model suitability, and the nondeterministic nature of IoT-based social systems, the event predictability is difficult to be characterized. Based on Turing computability and prediction error tolerability, this article posits a uniform event predictability theory. With discrepancy and Rademacher complexity, the generalization error bound is utilized to represent data quality and model suitability. Together with thresholds for the generalization error bound and confidence, the event predictability is modeled in a probabilistic manner to capture the nondeterminism within IoT-based social systems. The event predictability theory is theoretically proved and validated, and utilizing the proposed approximation algorithm for discriminating event predictability (AADEP), its applicability is further verified by experiments on a real-world data set for IoT-based nondeterministic social systems. © 2014 IEEE.},
	author_keywords = {Complex systems; computational social science (CSS); event predictability; event prediction; Internet of Things (IoT)-based systems},
	keywords = {Approximation algorithms; Behavioral research; Computational complexity; Errors; Forecasting; Internet of things; Complexity theory; Computational modelling; Computational social science; Event predictability; Event prediction; Internet of thing-based system; Model suitability; Predictive models; Social systems; Time-series analysis; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Alvarado2023,
	author = {Alvarado, Jorge and Velasco, J. Manuel and Chavez, Francisco and Fernández-de-Vega, Francisco and Hidalgo, J. Ignacio},
	title = {Combining wavelet transform with convolutional neural networks for hypoglycemia events prediction from CGM data},
	year = {2023},
	journal = {Chemometrics and Intelligent Laboratory Systems},
	volume = {243},
	doi = {10.1016/j.chemolab.2023.105017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175726274&doi=10.1016%2fj.chemolab.2023.105017&partnerID=40&md5=3e4e7b74b5eb24b22100e8f2ad721967},
	abstract = {Estimating future blood glucose levels is an essential and challenging task for people with diabetes. It must be carried out based on variables such as current glucose, carbohydrate intake, physical activity, and insulin dosing. Accurate estimation is essential to maintain glucose values in a healthy range and avoid dangerous events of low glucose levels (hypoglycemia) and extremely high glucose values (hyperglycemia). Those situations maintained in time can cause not only permanent long-term damage but also short-term complications and even the death of the person. This paper proposes a new method to predict and detect hypoglycemic events over a 24-h time horizon. The technique combines applying the wavelet transform to glucose time series and deep learning convolutional neural networks. We have experimented with real data collected from 20 different people with type 1 diabetes. Our technique can also be applied to predict hyperglycemia. We incorporate a data augmentation technique consisting of a rolling windows system that improves the accuracy of the prediction. The uncertainty of the data is considered by the addition of controlled noise. The results show that the predictions obtained are accurate (higher than 88% of accuracy, sensitivity, specificity, and precision), confirming the effectiveness of the proposed method. © 2023 The Authors},
	author_keywords = {Deep learning; Diabetes; Glucose prediction; Wavelet transform},
	keywords = {Convolution; Convolutional neural networks; Deep learning; Glucose; Insulin; Wavelet transforms; 'current; Blood glucose level; Convolutional neural network; Deep learning; Event prediction; Glucose prediction; Hyperglycaemia; Hypoglycaemia; Physical activity; Wavelets transform; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Labiad2023218,
	author = {Labiad, Badre and Berrado, Abdelaziz and Benabbou, Loubna},
	title = {Predicting extreme events in the stock market using generative adversarial networks},
	year = {2023},
	journal = {International Journal of Advances in Intelligent Informatics},
	volume = {9},
	number = {2},
	pages = {218 – 230},
	doi = {10.26555/ijain.v9i2.898},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167426159&doi=10.26555%2fijain.v9i2.898&partnerID=40&md5=b9b69c3040e0b503aa73657c367887d3},
	abstract = {Accurately predicting extreme stock market fluctuations at the right time will allow traders and investors to make better-informed investment decisions and practice more efficient financial risk management. However, extreme stock market events are particularly hard to model because of their scarce and erratic nature. Moreover, strong trading strategies, market stress tests, and portfolio optimization largely rely on sound data. While the application of generative adversarial networks (GANs) for stock forecasting has been an active area of research, there is still a gap in the literature on using GANs for extreme market movement prediction and simulation. In this study, we proposed a framework based on GANs to efficiently model stock prices’ extreme movements. By creating synthetic real-looking data, the framework simulated multiple possible market-evolution scenarios, which can be used to improve the forecasting quality of future market variations. The fidelity and predictive power of the generated data were tested by quantitative and qualitative metrics. Our experimental results on S&P 500 and five emerging market stock data show that the proposed framework is capable of producing a realistic time series by recovering important properties from real data. The results presented in this work suggest that the underlying dynamics of extreme stock market variations can be captured efficiently by some state-of-the-art GAN architectures. This conclusion has great practical implications for investors, traders, and corporations willing to anticipate the future trends of their financial assets. The proposed framework can be used as a simulation tool to mimic stock market behaviors. © 2023, Universitas Ahmad Dahlan. All rights reserved.},
	author_keywords = {Extreme events prediction; Generative adversarial networks; Long short-term memory; Stock markets simulation; Time series generation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Cornejo-Bueno2021,
	author = {Cornejo-Bueno, Sara and Casillas-Pérez, David and Cornejo-Bueno, Laura and Chidean, Mihaela I. and Caamaño, Antonio J. and Cerro-Prada, Elena and Casanova-Mateo, Carlos and Salcedo-Sanz, Sancho},
	title = {Statistical analysis and machine learning prediction of fog-caused low-visibility events at a-8 motor-road in spain},
	year = {2021},
	journal = {Atmosphere},
	volume = {12},
	number = {6},
	doi = {10.3390/atmos12060679},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109211069&doi=10.3390%2fatmos12060679&partnerID=40&md5=cd398cf12474402794efeca1b6ce365c},
	abstract = {This work presents a full statistical analysis and accurate prediction of low-visibility events due to fog, at the A-8 motor-road in Mondoñedo (Galicia, Spain). The present analysis covers two years of study, considering visibility time series and exogenous variables collected in the zone affected the most by extreme low-visibility events. This paper has then a two-fold objective: first, we carry out a statistical analysis for estimating the fittest probability distributions to the fog event duration, using the Maximum Likelihood method and an alternative method known as the L-moments method. This statistical study allows association of the low-visibility depth with the event duration, showing a clear relationship, which can be modeled with distributions for extremes such as Generalized Extreme Value and Generalized Pareto distributions. Second, we apply a neural network approach, trained by means of the ELM (Extreme Learning Machine) algorithm, to predict the occurrence of low-visibility events due to fog, from atmospheric predictive variables. This study provides a full characterization of fog events at this motor-road, in which orographic fog is predominant, causing important traffic problems during all year. We also show how the ELM approach is able to obtain highly accurate low-visibility events predictions, with a Pearson correlation coefficient of 0.8, within a half-hour time horizon, enough to initialize some protocols aiming at reducing the impact of these extreme events in the traffic of the A-8 motor road. © MDPI AG. All rights reserved.},
	author_keywords = {Extreme learning machines; Low-visibility events; Machine learning algorithms; Orographic and hill-fogs; Prediction problems},
	keywords = {Galicia [Spain]; Spain; Correlation methods; Fog; Forecasting; Maximum likelihood estimation; Pareto principle; Predictive analytics; Roads and streets; Time series analysis; Visibility; Accurate prediction; ELM (extreme learning machine); Exogenous variables; Generalized extreme value; Generalized Pareto Distributions; Maximum likelihood methods; Pearson correlation coefficients; Predictive variables; algorithm; fog; hill; machine learning; orography; prediction; road transport; statistical analysis; visibility; Machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access}
}

@CONFERENCE{Prouvost2020205,
	author = {Prouvost, Antoine and Lodi, Andrea and Rousseau, Louis-Martin and Vallee, Jonathan},
	title = {Adverse Event Prediction by Telemonitoring and Deep Learning},
	year = {2020},
	journal = {Springer Proceedings in Mathematics and Statistics},
	volume = {316},
	pages = {205 – 215},
	doi = {10.1007/978-3-030-39694-7_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083995182&doi=10.1007%2f978-3-030-39694-7_16&partnerID=40&md5=d9361bfbe7d3c01f0cbeef3f3303283c},
	abstract = {Home health care comes as a potential solution to increasing stress on health-care systems, as well as concerns for medical patients comfort. However, additional distance from the care workers to the patients lead to more challenges, some of which can be addressed with machine learning (ML) and operations research (OR) algorithms. In this paper, we focus on automating a risk assessment of remote patients. Namely, we describe a risk prediction framework for home telemonitoring patients and show that learning a risk from weak signals in the patient’s data outperforms simple risk threshold proposed by care workers to automate the task. We combine recurrent neural networks with a ranking objective from survival analysis to evaluate the risk of patient’s adverse events. Training and testing of our methodology is achieved on a retrospective dataset gathered by an Ontario home health care agency during the course of a multi-year pilot home telemonitoring program. Results are benchmarked against alerts that were manually engineered by registered nurses, and against a simple linear baseline. This is an additional step in the application of machine learning in health care for patient-centered personalized treatments. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Deep learning; Home health care; Telemonitoring; Time-series prediction},
	keywords = {Learning systems; Operations research; Recurrent neural networks; Risk assessment; Software testing; Statistical tests; Systems engineering; Adverse events; Health-care system; Home telemonitoring; Risk predictions; Risk threshold; Survival analysis; Tele-monitoring; Training and testing; Home health care},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zeng2020,
	author = {Zeng, Canying and Qi, Feng and Zhu, A-Xing and Liu, Feng},
	title = {Construction of land surface dynamic feedback for digital soil mapping considering the spatial heterogeneity of rainfall magnitude},
	year = {2020},
	journal = {Catena},
	volume = {191},
	doi = {10.1016/j.catena.2020.104576},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082431824&doi=10.1016%2fj.catena.2020.104576&partnerID=40&md5=b7ec49c217eeeaaac6e54ce95ccadb87},
	abstract = {The land surface dynamic feedback (LSDF) information captured by time-series remote sensing data during the soil-drying process after a rainfall event provides effective covariates for digital soil mapping over low-relief areas. However, current methods used to capture LSDF require a uniform rainfall magnitude in the geographic space; a condition that is not often met for large areas. Here, we propose a LSDF construction method considering the spatial heterogeneity of rainfall magnitudes by adjusting the evaporation variables in the LSDF. For this, the relationships between evaporation and rainfall magnitudes were first established. The LSDFs from various locations for rainfall events with different magnitudes were then adjusted based on these relationships. Using a case study, the adjusted LSDFs after two rainfall events were then used to predict soil texture over a low-relief area. The results showed that the cubic polynomial model performed best when constructing the relationship between evaporation adjustment and rainfall magnitude, giving the highest R2 value and a low Akaike information criterion. Adjustment to the LSDF decreases with increasing rainfall and the rate of change in the adjustment also decreases with increasing rainfall. For both rainfall events, prediction accuracies with the adjusted LSDFs were higher than those based on the original LSDFs. Furthermore, the greater the adjustment, the greater the improvement in the accuracy. We conclude that the proposed construction method for LSDF, accounting for the spatial heterogeneity of rainfall magnitudes, offers improved predictive power for digital soil mapping over large areas. © 2020 Elsevier B.V.},
	author_keywords = {Land surface dynamic feedback (LSDF); Low-relief areas; MODIS; Soil texture; Spatial heterogeneity of rainfall},
	keywords = {construction method; heterogeneity; land surface; mapping method; MODIS; rainfall; remote sensing; satellite data; soil texture},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Chen2020923,
	author = {Chen, Peng and Jatowt, Adam and Yoshikawa, Masatoshi},
	title = {Conflict or cooperation?: Predicting future tendency of international relations},
	year = {2020},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {923 – 930},
	doi = {10.1145/3341105.3373929},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083023398&doi=10.1145%2f3341105.3373929&partnerID=40&md5=05f8b017411d6f41f2783c9e885b3cbb},
	abstract = {International relations analysis is crucial to many stakeholders including policy makers, executives in international companies or social scientists. Generally, recent events between two countries define the international relations between them. We explore the possibilities of predicting future tendency of international relations by analyzing historical events between countries. Using auto-coded event database GDELT (Global Data on Events, Location, and Tone), which records what happened between various countries in the past few decades, we extract various types of events between two countries of interest and aggregate them into categories: conflict and cooperation. Then, according to a sequence of recent events, we predict the number of conflict events and cooperation events in the next time unit. We use MILSTM (Multi-input LSTM) considering diverse kinds of relations between different country pairs. We assume that relations between a specific pair of countries could be affected by other related country pairs. Based on this hypothesis we first select country pairs related to the target pair, and extract their multiple historical event sequences as additional input to train the model. The test results show that MILSTM performs better than vanilla LSTM, which confirms our initial hypothesis. © 2020 ACM.},
	author_keywords = {Event prediction; GDELT; Multi-input LSTM; News collections; Time series analysis},
	keywords = {Long short-term memory; Conflict and cooperation; Event sequence; Global data; Initial hypothesis; International company; International relations; Policy makers; Social scientists; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Li2023550,
	author = {Li, Lijie and Liu, Wenqiang and Xiong, Zuobin and Wang, Ye},
	title = {Sequence-Based Modeling for Temporal Knowledge Graph Link Prediction},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14257 LNCS},
	pages = {550 – 562},
	doi = {10.1007/978-3-031-44216-2_45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174630280&doi=10.1007%2f978-3-031-44216-2_45&partnerID=40&md5=745fd49b79a1cba07d1c41036028c7ab},
	abstract = {Currently, the majority of research in temporal knowledge graph link prediction focuses on completing missing facts. Nevertheless, the utilization of knowledge graphs to forecast future facts has garnered significant scholarly attention. The attainment of efficient future fact prediction for time-series data hinges primarily on an in-depth exploration of both past historical facts and concurrent facts in the present. Presently, the majority of research in this domain lacks an all-encompassing integration of temporal points and durations in factual features, thereby hindering the effective management of two distinct types of facts with varying chronologies and ultimately disregarding their latent influence on future facts. This paper introduces an advanced representation model - the Progressive Representation Graph Attention Network (PRGAN) - which harnesses the potential of Graph Convolutional Neural Network and Recurrent Neural Network. PRGAN aims to ameliorate the existing shortcomings and augment the efficacy of future event prediction through attention-based learning of progressive representations of entities and relations in time series. We evaluated our proposed method with five event datasets. Extensive experimentation revealed that, in comparison with other baseline models, the PRGAN model displayed remarkable performance and efficiency in temporal reasoning tasks, thereby demonstrating its outstanding superiority. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Event Prediction; Graph Representation Learning; Knowledge Representation; Temporal Knowledge Graph},
	keywords = {Forecasting; Graph neural networks; Recurrent neural networks; Time series; Based modelling; Event prediction; Graph representation; Graph representation learning; Knowledge graphs; Knowledge-representation; Link prediction; Temporal knowledge; Temporal knowledge graph; Time-series data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nidamanuri202264,
	author = {Nidamanuri, Jaswanth and Mukherjee, Prerana and Assfalg, Rolf and Venkataraman, Hrishikesh},
	title = {Auto-Alert: A Spatial and Temporal Architecture for Driving Assistance in Road Traffic Environments},
	year = {2022},
	journal = {International Journal of Intelligent Transportation Systems Research},
	volume = {20},
	number = {1},
	pages = {64 – 74},
	doi = {10.1007/s13177-021-00272-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114951824&doi=10.1007%2fs13177-021-00272-3&partnerID=40&md5=6740c83b5591edbb3ddb031b0c940b80},
	abstract = {Over the last decade, the Advanced Driver Assistance System (ADAS) concept has evolved prominently. ADAS involves several advanced approaches such as automotive electronics, vehicular communication, RADAR, LIDAR, computer vision, and its associated aspects such as machine learning and deep learning. Of these, computer vision and machine learning-based solutions have mainly been effective that have allowed real-time vehicle control, driver-aided systems, etc. However, most of the existing works deal with ADAS deployment and autonomous driving functionality in countries with well-disciplined lane traffic. These solutions and frameworks do not work in countries and cities with less-disciplined/ chaotic traffic. Hence, critical ADAS functionalities and even L2/ L3 autonomy levels in driving remain a major open challenge. In this regard, this work proposes a novel framework called Auto-Alert. Auto-Alert performs a two-stage spatial and temporal analysis based on external traffic environment and tri-axial sensor system for safe driving assistance. This work investigates time-series analysis with deep learning models for driving events prediction and assistance. Further, as a basic premise, various essential design considerations towards the ADAS are discussed. Significantly, the Convolutional Neural Network (CNN) and Long-Short-Term-Memory (LSTM) models are applied in the proposed Auto-Alert. It is shown that the LSTM outperforms the CNN with 99% for the considered window length. Importantly, this also involves developing and demonstrating an efficient traffic monitoring and density estimation system. Further, this work provides the benchmark results for Indian Driving Dataset (IDD), specifically for the object detection task. The findings of this proposed work demonstrate the significance of using CNN and LSTM networks to assist the driver in the holistic traffic environment. © 2021, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Auto-alert; Autonomous driving; CNN; Computer vision; IDD; LSTM},
	keywords = {Automobile drivers; Computer control systems; Computer vision; Control system synthesis; Convolutional neural networks; Deep learning; Learning systems; Long short-term memory; Object detection; Optical radar; Real time systems; Time series analysis; Traffic control; Autonomous driving; Density estimation; Design considerations; Road traffic environments; Safe-driving assistance; Spatial and temporal analysis; Traffic environment; Vehicular communications; Advanced driver assistance systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Schorgenhumer2019115,
	author = {Schorgenhumer, Andreas and Kahlhofer, Mario and Chalupar, Peter and Grunbacher, Paul and Mossenbock, Hanspeter},
	title = {A framework for preprocessing multivariate, topology-aware time series and event data in a multi-system environment},
	year = {2019},
	journal = {Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
	volume = {2019-January},
	pages = {115 – 122},
	doi = {10.1109/HASE.2019.00026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064005888&doi=10.1109%2fHASE.2019.00026&partnerID=40&md5=a1e8a8d6d95247125d94272c6a34bdee},
	abstract = {Monitoring and predicting quality properties of complex systems relies on collecting and analyzing huge amounts of data at run time. Machine learning is frequently adopted to analyze time series and event data, often coming from multiple systems. In such a context, extracting and preprocessing data is an essential but also highly tedious task. In this paper, we thus present an offline preprocessing framework that can handle multivariate time series and event data in a multisystem environment that also takes the system's topology into account. After a discussion of the key requirements, we present the architecture and implementation of our highly configurable and easy-to-use framework. We demonstrate how the framework allows to extract data and to yield output files for machine learning via configuration settings. In a two-step evaluation, we investigate the framework's usefulness and scalability. We demonstrate the usefulness in an event prediction case study of real-world multi-system time series data. Our results show the significant impact of different data preprocessing settings on machine learning. Our experiments further demonstrate that processing performance scales linearly with respect to the number of systems and time series. ©2019 IEEE.},
	keywords = {Machine learning; Systems engineering; Time series; Topology; Data preprocessing; Event prediction; Multiple systems; Multivariate time series; Processing performance; Quality properties; Time-series data; Topology aware; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Syafrudin2022151,
	author = {Syafrudin, Muhammad and Alfian, Ganjar and Fitriyani, Norma Latif and Hadibarata, Tony and Rhee, Jongtae and Anshari, Muhammad},
	title = {Future Glycemic Events Prediction Model Based On Artificial Neural Network},
	year = {2022},
	journal = {2022 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies, 3ICT 2022},
	pages = {151 – 155},
	doi = {10.1109/3ICT56508.2022.9990708},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146421403&doi=10.1109%2f3ICT56508.2022.9990708&partnerID=40&md5=c0fad85dee04325e5f1ba22540ecbb41},
	abstract = {Predicting future glycemic events such as hypoglycemia, hyperglycemia, and normal for type 1 diabetes (T1D) remains a significant and challenging issue. In this study, an artificial neural network (ANN)-based model is proposed to predict the future glycemic events of T1D patients. We utilized five T1D patient datasets to build the models and predict future glycemic events with a prediction horizon (PH) of 30 and 60 minutes ahead of time. We applied the data preprocessing method based on the sliding window approach by sliding the blood glucose time-series data from the past 60 minutes (the last 12 data points) as input and using the next 30 and 60 minutes (the next 6 and 12-th data points) as output. All the numeric blood glucose output data are then transformed into a multi-class classification label, such as hypoglycemia, hyperglycemia, and normal. Our proposed model is then used to learn and create the prediction model from the preprocessed blood glucose dataset. Four performance metrics such as accuracy, precision, recall, and f-1 score were utilized to measure the performance of the classification models used in this study, such as Naïve Bayes (NB), Decision Tree (DT), Support Vector Machine (SVM), and K-Nearest Neighbour (KNN). The results showed that our proposed ANN-based model performed better at predicting future glycemic events than other models, with an average accuracy, precision, recall, and f-1 score of 88.649%, 76.661%, 71.731%, 72.609%, and 83.364%, 60.437%, 61.345%, 60.62% for the PH of 30 and 60 minutes, respectively. As a result, knowing this future glycemic event sooner can help patients avoid potentially dangerous conditions and can eventually be used to improve diabetes management. © 2022 IEEE.},
	author_keywords = {artificial neural network; classification model; glycemic event; type 1 diabetes},
	keywords = {Blood; Classification (of information); Forecasting; Glucose; Insulin; Nearest neighbor search; Neural networks; Support vector machines; Artificial neural-network based modeling; Blood glucose; Classification models; Diabetes patients; Glycemic event; Hyperglycaemia; Hypoglycaemia; Prediction horizon; Prediction modelling; Type 1 diabetes; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Zhang20211760,
	author = {Zhang, Chi and Fanaee-T, Hadi and Thoresen, Magne},
	title = {Feature extraction from unequal length heterogeneous EHR time series via dynamic time warping and tensor decomposition},
	year = {2021},
	journal = {Data Mining and Knowledge Discovery},
	volume = {35},
	number = {4},
	pages = {1760 – 1784},
	doi = {10.1007/s10618-020-00724-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098651998&doi=10.1007%2fs10618-020-00724-6&partnerID=40&md5=830a000ff2e40b3ff2bb852242f37a64},
	abstract = {Electronic Health Records (EHR) data is routinely generated patient data that can provide useful information for analytical tasks such as disease detection and clinical event prediction. However, temporal EHR data such as physiological vital signs and lab test results are particularly challenging. Temporal EHR features typically have different sampling frequencies; such examples include heart rate (measured almost continuously) and blood test results (a few times during a patient’s entire stay). Different patients also have different length of stays. Existing approaches for temporal EHR sequence extraction either ignore the temporal pattern within features, or use a predefined window to select a section of the sequences without taking into account all the information. We propose a novel approach to tackle the issue of irregularly sampled, unequal length EHR time series using dynamic time warping and tensor decomposition. We use DTW to learn the pairwise distances for each temporal feature among the patient cohort and stack the distance matrices into a tensor. We then decompose the tensor to learn the latent structure, which is consequently used for patient representation. Finally, we use the patient representation for in-hospital mortality prediction. We illustrate our method on two cohorts from the MIMIC-III database: the sepsis and the acute kidney failure cohorts. We show that our method produces outstanding classification performance in terms of AUROC, AUPRC and accuracy compared with the baseline methods: LSTM and DTW-KNN. In the end we provide a detailed analysis on the feature importance for the interpretability of our method. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.},
	author_keywords = {Dynamic time warping; Electronic health records; Patient similarity; Tensor decomposition},
	keywords = {Extraction; Hospital data processing; Long short-term memory; Tensors; Time series; Classification performance; Dynamic time warping; Electronic health record; Hospital mortality; Latent structures; Pairwise distances; Sampling frequencies; Tensor decomposition; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@CONFERENCE{Lee202094,
	author = {Lee, Jeong Min and Hauskrecht, Milos},
	title = {Clinical event time-series modeling with periodic events},
	year = {2020},
	journal = {Proceedings of the 33rd International Florida Artificial Intelligence Research Society Conference, FLAIRS 2020},
	pages = {94 – 99},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102407983&partnerID=40&md5=8706da1bd955843362b395e55d61da62},
	abstract = {The focus of this work is on developing models that can accurately predict events in complex multivariate event-time series derived from electronic health records (EHRs). One common characteristic of many EHR-based event time series is that they are periodic and events are repeated at regular time intervals. Hence in order to define a high accuracy event prediction process, the periodicity of the event occurrence needs to be properly modeled. In this work, instead of trying to combine and model periodic patterns for many event time series in a common hidden space we propose multiple simple periodic mechanisms that help us to drive the expression of individual events in time. We show that these simple periodic mechanisms can be effectively combined with more complex neural architectures capable of modeling the dependencies among different types of events. We test our new model on the clinical event prediction problem that consists of hundreds of lab test events in EHRs derived from MIMIC-III database. We show that our model that relies on simple periodic mechanisms is able to outperform competing baseline models in the multivariate event prediction task. © FLAIRS 2020.All right reserved.},
	keywords = {Forecasting; Time series; Baseline models; Electronic health record (EHRs); Event prediction; High-accuracy; Neural architectures; Periodic pattern; Time interval; Time series modeling; Artificial intelligence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Wang201970253,
	author = {Wang, Lutong and Wang, Hong and Song, Yongqiang and Wang, Qian},
	title = {MCPL-Based FT-LSTM: Medical Representation Learning-Based Clinical Prediction Model for Time Series Events},
	year = {2019},
	journal = {IEEE Access},
	volume = {7},
	pages = {70253 – 70264},
	doi = {10.1109/ACCESS.2019.2919683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067234230&doi=10.1109%2fACCESS.2019.2919683&partnerID=40&md5=abf427ead08ced1da6745284ad96cf6b},
	abstract = {Large collections of electronic medical records (EMRs) provide us with a vast source of information on medical practice. However, the utilization of these data to support clinical decisions is still limited. Extracting useful patterns from such data is particularly challenging because the data are variable longitudinal, sparse, and heterogeneous. Therefore, in this paper, we propose the MCPL-based FT-LSTM, a clinical event prediction method based on medical concept representation learning. On one hand, inspired by FASTTEXT, we have developed an interpretative vector representation of medical events in EMRs, which enables us to capture the medical concept information effectively so that the patient's clinical data can be represented more reasonably. On the other hand, we propose a novel time-controlled long short-term memory (LSTM) prediction model, which adds time-control units to the original LSTM model. The model can describe the variable time intervals in EMRs, better capture long-term, and short-term information, and eliminate the strong dependence of clinical data on timestamps; thus, improving the model's prediction performance for clinical events. Through extensive experiments on the MIMICIII dataset, we demonstrate that the MCPL-based FT-LSTM achieves higher precision in the field of clinical event prediction, which is of great significance for the medical information research. © 2013 IEEE.},
	author_keywords = {Electronic medical records; FT-LSTM; medical concept; variable time interval; word vector representation},
	keywords = {Clinical research; Forecasting; Medical computing; Electronic medical record; FT-LSTM; Medical concepts; Time interval; Word vectors; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@ARTICLE{Ahmadzadeh2021,
	author = {Ahmadzadeh, Azim and Aydin, Berkay and Georgoulis, Manolis K. and Kempton, Dustin J. and Mahajan, Sushant S. and Angryk, Rafal A.},
	title = {How to train your flare prediction model: Revisiting robust sampling of rare events},
	year = {2021},
	journal = {Astrophysical Journal, Supplement Series},
	volume = {254},
	number = {2},
	doi = {10.3847/1538-4365/abec88},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106567382&doi=10.3847%2f1538-4365%2fabec88&partnerID=40&md5=4aba0d8ee73b800bea505e05a2fec675},
	abstract = {We present a case study of solar flare forecasting by means of metadata feature time series, by treating it as a prominent class-imbalance and temporally coherent problem. Taking full advantage of pre-flare time series in solar active regions is made possible via the Space Weather Analytics for Solar Flares (SWAN-SF) benchmark data set, a partitioned collection of multivariate time series of active region properties comprising 4075 regions and spanning over 9 yr of the Solar Dynamics Observatory period of operations. We showcase the general concept of temporal coherence triggered by the demand of continuity in time series forecasting and show that lack of proper understanding of this effect may spuriously enhance models’ performance. We further address another well-known challenge in rare-event prediction, namely, the class-imbalance issue. The SWAN-SF is an appropriate data set for this, with a 60:1 imbalance ratio for GOES M- and X-class flares and an 800:1 imbalance ratio for X-class flares against flare-quiet instances. We revisit the main remedies for these challenges and present several experiments to illustrate the exact impact that each of these remedies may have on performance. Moreover, we acknowledge that some basic data manipulation tasks such as data normalization and cross validation may also impact the performance; we discuss these problems as well. In this framework we also review the primary advantages and disadvantages of using true skill statistic and Heidke skill score, two widely used performance verification metrics for the flare-forecasting task. In conclusion, we show and advocate for the benefits of time series versus point-in-time forecasting, provided that the above challenges are measurably and quantitatively addressed. © 2021. The American Astronomical Society. All rights reserved.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Alhathloul2023,
	author = {Alhathloul, Saleh H. and Mishra, Ashok K. and Khan, Abdul A.},
	title = {Low visibility event prediction using random forest and K-nearest neighbor methods},
	year = {2023},
	journal = {Theoretical and Applied Climatology},
	doi = {10.1007/s00704-023-04697-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173744009&doi=10.1007%2fs00704-023-04697-6&partnerID=40&md5=5d910aa7b8636bd167eccce453a93224},
	abstract = {Low visibility events at King Khalid airport in Riyadh, Saudi Arabia, are investigated using hourly time series of meteorological and air pollution data from April 2015 to December 2017. The analysis of binary classification is based on two machine learning classifiers (random forest (RF) and K-nearest neighbors (KNN)). Six models based on the feature selection methods of RF feature importance and Pearson correlation matrix are presented. The classification tasks include two resampling approaches (random oversampling and random undersampling) to address the problem of an imbalanced dataset of the visibility event classes. An important finding is that oversampling outperforms undersampling for the evaluated classifiers and achieves higher scores in terms of accuracy and F1 score metrics. The RF classifier has a better performance compared to the KNN in both sampling approaches. The RF classifier with oversampling approach provides the best overall performance in terms of accuracy, F1 score, and area under the receiver operating characteristics (AUROC). The best model has scores above 0.95 based on all the evaluation metrics considered in the study. Air temperature and dewpoint temperature have minimal impact on the performance, whereas the particulate matter with aerodynamic diameter <10 μm (PM10) has a profound impact on the performance. It is found that the PM10 has the highest importance (52%) for the low visibility events based on the analysis of RF feature importance. Other pollutants and meteorological variables show relative importance between 5 and 10% for low visibility events. Overall, the best model is found when all variables, except temperature and dewpoint temperature, are employed to predict the visibility classes. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Arvin2021,
	author = {Arvin, Ramin and Khattak, Asad J. and Qi, Hairong},
	title = {Safety critical event prediction through unified analysis of driver and vehicle volatilities: Application of deep learning methods},
	year = {2021},
	journal = {Accident Analysis and Prevention},
	volume = {151},
	doi = {10.1016/j.aap.2020.105949},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097716387&doi=10.1016%2fj.aap.2020.105949&partnerID=40&md5=0c2edc34f05c20f6710e756ce5b9e3d7},
	abstract = {Transportation safety is highly correlated with driving behavior, especially human error playing a key role in a large portion of crashes. Modern instrumentation and computational resources allow for the monitorization of driver, vehicle, and roadway/environment to extract leading indicators of crashes from multi-dimensional data streams. To quantify variations that are beyond normal in driver behavior and vehicle kinematics, the concept of volatility is applied. The study measures driver-vehicle volatilities using the naturalistic driving data. By integrating and fusing multiple real-time streams of data, i.e., driver distraction, vehicular movements and kinematics, and instability in driving, this study aims to predict occurrence of safety critical events and generate appropriate feedback to drivers and surrounding vehicles. The naturalistic driving data is used which contains 7566 normal driving events, and 1315 severe events (i.e., crash and near-crash), vehicle kinematics, and driver behavior collected from more than 3500 drivers. In order to capture the local dependency and volatility in time-series data 1D-Convolutional Neural Network (1D-CNN), Long Short-Term Memory (LSTM), and 1DCNN-LSTM are applied. Vehicle kinematics, driving volatility, and impaired driving (in terms of distraction) are used as the input parameters. The results reveal that the 1DCNN-LSTM model provides the best performance, with 95.45% accuracy and prediction of 73.4% of crashes with a precision of 95.67%. Additional features are extracted with the CNN layers and temporal dependency between observations is addressed, which helps the network learn driving patterns and volatile behavior. The model can be used to monitor driving behavior in real-time and provide warnings and alerts to drivers in low-level automated vehicles, reducing their crash risk. © 2020 Elsevier Ltd},
	author_keywords = {Big Data; CNN; Crash prediction; Deep Learning; LSTM; Naturalistic driving study; Neural Network; SHRP2; Volatility},
	keywords = {Accidents, Traffic; Automobile Driving; Deep Learning; Distracted Driving; Humans; car driving; distracted driving; human; prevention and control; traffic accident},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Bronze Open Access}
}

@ARTICLE{Allen202036,
	author = {Allen, K.J. and Hope, P. and Lam, D. and Brown, J.R. and Wasson, R.J.},
	title = {Improving Australia’s flood record for planning purposes–can we do better?},
	year = {2020},
	journal = {Australian Journal of Water Resources},
	volume = {24},
	number = {1},
	pages = {36 – 45},
	doi = {10.1080/13241583.2020.1745735},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083550656&doi=10.1080%2f13241583.2020.1745735&partnerID=40&md5=31aaa8343dfd40e646d35a1382d5aa22},
	abstract = {Extreme rainfall is projected to increase with climate change, but the impact of climate change on floods is uncertain. Infrastructure design based on information available from short gauged time series (typically ~30–80 years) may not take account of the full range of possible flood events, or be suitable for identifying non-stationarity. Australian palaeoflood and palaeo-hydroclimate records drawn from a wide variety of natural archives and documentary sources suggest that Australia has been subjected to larger flood events in the past; a pluvial period for eastern Australia in the eighteenth Century is particularly note-worthy. If the current infrastructure is inadequate for past floods, it is unlikely it will adequately mitigate future floods. We discuss how improved awareness, and incorporation, of palaeoflood records in risk estimates could help guide infrastructure planning and design, flood event prediction and inform flood mitigation policy. This is particularly relevant for Australia with its notoriously variable hydroclimate. © 2020, © 2020 Engineers Australia.},
	author_keywords = {Floods; infrastructure design risk; palaeofloods},
	keywords = {Australia; Climate change; Flood control; Documentary sources; Eastern Australia; Extreme rainfall; Flood mitigation; Infrastructure design; Infrastructure planning; Non-stationarities; Risk estimates; climate variation; design method; extreme event; flooding; hydrometeorology; infrastructure planning; paleoflood; precipitation intensity; time series analysis; Floods},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Theunissen2021,
	author = {Theunissen, Carl Daniel and Bradshaw, Steven Martin and Auret, Lidia and Louw, Tobias Muller},
	title = {One-dimensional convolutional auto-encoder for predicting furnace blowback events from multivariate time series process data—a case study},
	year = {2021},
	journal = {Minerals},
	volume = {11},
	number = {10},
	doi = {10.3390/min11101106},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116830991&doi=10.3390%2fmin11101106&partnerID=40&md5=85cca07efcedbb833bff491c22187e4a},
	abstract = {Modern industrial mining and mineral processing applications are characterized by large volumes of historical process data. Hazardous events occurring in these processes compromise process safety and therefore overall viability. These events are recorded in historical data and are often preceded by characteristic patterns. Reconstruction-based data-driven models are trained to reconstruct the characteristic patterns of hazardous event-preceding process data with minimal residuals, facilitating effective event prediction based on reconstruction residuals. This investigation evaluated one-dimensional convolutional auto-encoders as reconstruction-based data-driven models for predicting positive pressure events in industrial furnaces. A simple furnace model was used to generate dynamic multivariate process data with simulated positive pressure events to use as a case study. A one-dimensional convolutional auto-encoder was trained as a reconstruction-based model to recognize the data preceding the hazardous events, and its performance was evaluated by comparing it to a fully-connected auto-encoder as well as a principal component analysis reconstruction model. This investigation found that one-dimensional convolutional auto-encoders recognized event-preceding patterns with lower detection delays, higher specificities, and lower missed alarm rates, suggesting that the one-dimensional convolutional auto-encoder layout is superior to the fully connected auto-encoder layout for use as a reconstruction-based event prediction model. This investigation also found that the nonlinear auto-encoder models outperformed the linear principal component model investigated. While the one-dimensional auto-encoder was evaluated comparatively on a simulated furnace case study, the methodology used in this evaluation can be applied to industrial furnaces and other mineral processing applications. Further investigation using industrial data will allow for a view of the convolutional auto-encoder’s absolute performance as a reconstruction-based hazardous event prediction model. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Failure prediction; One-dimensional convolutional network; Process monitoring; Reconstruction-based model; Semi-supervised model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Zin2020143,
	author = {Zin, Thi Thi and Sumi, Kosuke and Tin, Pyke},
	title = {Time to Dairy Cow Calving Event Prediction by Using Time Series Analysis},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {143 – 146},
	doi = {10.1145/3408066.3408104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092003757&doi=10.1145%2f3408066.3408104&partnerID=40&md5=04385b9e90895df76264e4746a6c1b61},
	abstract = {In these days the precision dairy farming which is utilization of the Information and Communication Technologies (ICT) has become one of front line research topics in dairy science as well as in data science leading to Agriculture 4.0. An increase in on-farm mortality due to the occurrence calving difficulties with late assistance can cause possible problems not only for animal welfare but also economic losses to the farmers. In this aspect, calving is an extremely important event in the life of a dairy cow. On the other hand, the time around calving is also a critical period since clinical disorders, and calving problems can occur. Calving difficulties are also becoming increasingly common with many dairy cows requiring assistance at the time of calving. To maximize welfare and minimize losses due to calving difficulties, all animals need to be individually monitored to identify any calving difficulties or health problems as early as possible. In addition, it is important to know the exact time of calving event occur so that timely assistance can be made. In this paper, we propose a continuous video monitoring system for time-to calving event investigation based on time series analysis to achieve an accurate calving time prediction. In doing so we have employed three time series models of autoregressive, moving average smoothing. At the same time, we have confirmed the validity of the proposed method by using the real life data experimented on the University Dairy Farm and one of large dairy farms in Japan. The experimental results show that the proposed time series method is promising and can lead to a new prospect in modern precision dairy farming.  © 2020 ACM.},
	author_keywords = {Autoregressive Model; Calving Event; Time Series Analysis; Timely Assistance; Welfare Management},
	keywords = {Agricultural robots; Animals; Dairies; Data Science; Farms; Harmonic analysis; Intelligent computing; Losses; Autoregressive , moving averages; Clinical disorders; Critical periods; Event prediction; Information and Communication Technologies; Time series method; Time series models; Video monitoring systems; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Hu2022722,
	author = {Hu, Meng and Bai, Lu and Yang, Mei},
	title = {Script event prediction method based on self-attention mechanism and graph representation learning},
	year = {2022},
	journal = {IEEE Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)},
	volume = {2022-October},
	pages = {722 – 726},
	doi = {10.1109/IAEAC54830.2022.9929851},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142270403&doi=10.1109%2fIAEAC54830.2022.9929851&partnerID=40&md5=2eb6ea30c072e1d7bd126c23d10b1d96},
	abstract = {Script event prediction usually refers to giving a sequence of contextual events and then selecting the most likely subsequent event from multiple candidate events. Usually, script event prediction methods are based on event pairs or event chain methods to build prediction models, but these methods can not fully capture the complex relationship between context events and candidate events. Aiming at the two difficulties of how to fully mine the meaning of events in text data to accurately represent events and how to make full use of the potential information between event nodes in narrative event graph to improve the accuracy of prediction tasks, this paper proposes a script event prediction model Bert-SatGNN, which combines Bert pre-training model, structural self-attention mechanism and narrative event graph. Our model introduces Bert pre-training mechanism into script event prediction for the first time so that it can more accurately represent the event nodes input into the prediction model. And use the multi-head structure self-attention module to learn the structural information of the event nodes in the narrative event graph, so as to capture the potential information of evolutionary events with causal logic, and finally combine the structural information and time series information to predict the final events. In this paper, experiments are carried out on the widely used New York Times data set, and the experimental results show that our models are better than the most advanced methods.  © 2022 IEEE.},
	author_keywords = {attention mechanism; graph representation learning; GRU; pre-training model; Script event prediction},
	keywords = {Computation theory; Graph theory; Learning systems; Attention mechanisms; Event prediction; Graph representation; Graph representation learning; GRU; Pre-training; Pre-training model; Prediction modelling; Script event prediction; Training model; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Karaahmetoglu20233097,
	author = {Karaahmetoglu, Oguzhan and Kozat, Suleyman Serdar},
	title = {Spatiotemporal Sequence Prediction With Point Processes and Self-Organizing Decision Trees},
	year = {2023},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	volume = {34},
	number = {6},
	pages = {3097 – 3110},
	doi = {10.1109/TNNLS.2021.3111817},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115731120&doi=10.1109%2fTNNLS.2021.3111817&partnerID=40&md5=f7a912f00e827134ea4b179752f0aba2},
	abstract = {We study the spatiotemporal prediction problem and introduce a novel point-process-based prediction algorithm. Spatiotemporal prediction is extensively studied in machine learning literature due to its critical real-life applications, such as crime, earthquake, and social event prediction. Despite these thorough studies, specific problems inherent to the application domain are not yet fully explored. Here, we address the nonstationary spatiotemporal prediction problem on both densely and sparsely distributed sequences. We introduce a probabilistic approach that partitions the spatial domain into subregions and models the event arrivals in each region with interacting point processes. Our algorithm can jointly learn the spatial partitioning and the interaction between these regions through a gradient-based optimization procedure. Finally, we demonstrate the performance of our algorithm on both simulated data and two real-life datasets. We compare our approach with baseline and state-of-the-art deep learning-based approaches, where we achieve significant performance improvements. Moreover, we also show the effect of using different parameters on the overall performance through empirical results and explain the procedure for choosing the parameters.  © 2012 IEEE.},
	author_keywords = {Adaptive decision trees; crime prediction; earthquake prediction; Hawkes process; nonstationary time-series data; online learning; spatiotemporal point process},
	keywords = {Crime; Decision trees; Deep learning; Earthquakes; Forecasting; Forestry; Adaptation models; Adaptive decision tree; Crime prediction; Earthquake prediction; Hawkes process; Non-stationary time series; Nonstationary time-series data; Online learning; Optimisations; Partitioning algorithms; Point process; Predictive models; Spatiotemporal phenomenon; Spatiotemporal point process.; Time-series data; algorithm; article; crime; decision tree; deep learning; earthquake; human; prediction; simulation; Optimization},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Ma2023386,
	author = {Ma, Yibing and Guo, Hongyu and Sun, Yuqi and Liu, Fang},
	title = {Real-time prediction algorithm and simulation of sports results based on internet of things and machine learning},
	year = {2023},
	journal = {International Journal of Information Technology and Management},
	volume = {22},
	number = {3-4},
	pages = {386 – 406},
	doi = {10.1504/IJITM.2023.131845},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166388246&doi=10.1504%2fIJITM.2023.131845&partnerID=40&md5=3acc6db45b819a92fc8cf11922379b43},
	abstract = {Machine learning is an intelligent technology that plays an important role in classification and prediction. In the field of sports prediction, the prediction results must be processed, because many events in large-scale sports events are linked to funds. Through inquiries on the internet, more and more sports-related data can be obtained. Using these data, people continue to develop intelligent models and prediction systems, optimise and innovate these models and systems, and then more accurately predict the results of the game. Sports event prediction can capture various attributes, including team game video, game results, and player data. Different stakeholders use different methods to predict the outcome of the game. This article is mainly based on basketball technical time series statistics, using a three-layer feedforward back-propagation neural network, and adopting a rotation prediction method to predict the most important technical and statistical indicators of the team. According to the team’s forecast data, the average field goal percentage is 46.03%, the 3-point field goal percentage is 37.48%, the assists are 12.95, and the backcourt rebounds are 25.4. Copyright © 2023 Inderscience Enterprises Ltd.},
	author_keywords = {exercise results; internet of things; IoT; machine learning; real-time prediction},
	keywords = {Backpropagation; Forecasting; Internet of things; Multilayer neural networks; Time series; Exercise result; Intelligent models; Intelligent technology; IoT; Large-scales; Machine-learning; Prediction algorithms; Real-time prediction; Sports events; Sports prediction; Sports},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2019,
	title = {12th IAPR-TC15 Workshop on Graph-Based Representations in Pattern Recognition, GbRPR 2019},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11510 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069541241&partnerID=40&md5=1b9f61f206103b3760c791c9003081d7},
	abstract = {The proceedings contain 23 papers. The special focus in this conference is on Graph-Based Representations in Pattern Recognition. The topics include: Network Time Series Analysis Using Transfer Entropy; GEDLIB: A C++ Library for Graph Edit Distance Computation; reconstructing Objects from Noisy Images at Low Resolution; network Embedding by Walking on the Line Graph; discriminant Manifold Learning with Graph Convolution Based Regression for Image Classification; graph-Based Representations for Supporting Genome Data Analysis and Visualization: Opportunities and Challenges; learning the Graph Edit Costs: What Do We Want to Optimise?; sub-optimal Graph Matching by Node-to-Node Assignment Classification; cross-Evaluation of Graph-Based Keyword Spotting in Handwritten Historical Documents; graph Edge Entropy in Maxwell-Boltzmann Statistics for Alzheimer’s Disease Analysis; solving the Graph Edit Distance Problem with Variable Partitioning Local Search; A Database and Evaluation for Classification of RNA Molecules Using Graph Methods; event Prediction Based on Unsupervised Graph-Based Rank-Fusion Models; preface; experimental Evaluation of Subgraph Isomorphism Solvers; generalized Median Graph via Iterative Alternate Minimizations; an Hypergraph Data Model for Expert Finding in Multimedia Social Networks; on-Line Learning the Edit Costs Based on an Embedded Model; congratulations! Dual Graphs Are Now Orientated!; a Parallel Algorithm for Subgraph Isomorphism; local Binary Pattern Based Graph Construction for Hyperspectral Image Segmentation.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sangeetha20201079,
	author = {Sangeetha, K. and Vishnu Raja, P. and Naveen Kumar, A. and Naveen Kumar, K.K. and Ragul, V. and Rudresh, D.},
	title = {Prediction of adverse glycemic events from continuous glucose monitoring signals by gradient boosting algorithm},
	year = {2020},
	journal = {International Journal of Advanced Science and Technology},
	volume = {29},
	number = {3 Special Issue},
	pages = {1079 – 1085},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081995255&partnerID=40&md5=99a64741b0db422f5b5dd36fbc5cde1a},
	abstract = {In Diabetes therapy,the most important step includes maintaining the glucose level in the proper euglycemic range.CGM devices have been introduced which helps to see the glucose levels and helps in maintaining in the desired range. The challenge here is detecting the glucose level and predicting the critical levels in the glucose levels with the collected data.This study aims to fill this gap, by carrying out a comparative analysis among the most common methods for glucose event prediction. Both regression and classification algorithms have been implemented and analyzed, including static and dynamic training approaches. The dataset consists of 89 CGM time series measuring India diabetic subjects for 7 subsequent days. Performance metrics, specifically defined to assess and compare the event prediction capabilities of the methods, have been introduced and analyzed. The numerical results show that a static training approach exhibits better performance, in particular when regression methods are considered. However, classifiers show some improvement when trained for a specific event category, such as hyperglycemia, achieving performance comparable to the regressors, with the advantage of predicting the events sooner. ⓒ 2020 SERSC.},
	author_keywords = {Blood Glucose (BG); Continuous Glucose Monitoring(CGM); Glycemic Range},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@ARTICLE{2017,
	title = {3rd International Conference on Soft Computing in Data Science, SCDS 2017},
	year = {2017},
	journal = {Communications in Computer and Information Science},
	volume = {788},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036540570&partnerID=40&md5=186a4a150f2b473328876bafc044f316},
	abstract = {The proceedings contain 26 papers. The special focus in this conference is on Soft Computing in Data Science. The topics include: Time series machine learning: Implementing ARIMA and hybrid ARIMA-ANN for electricity forecasting modeling; a design of a reminiscence system for tacit knowledge recall and transfer; pattern search based on particle swarm optimization technique for block matching motion estimation algorithm; enhancing parallel self-organizing map on heterogeneous system architecture; geovisualization using hexagonal tessellation for spatiotemporal earthquake data analysis in Indonesia; Incremental filtering visualization of jobstreet Malaysia ICT jobs; software application for analyzing photovoltaic module panel temperature in relation to climate factors; budget visual: Malaysia budget visualization; fuzzy arithmetical modeling of pressurizer in a nuclear power plant; road lane segmentation using deconvolutional neural network; nitrogen fertilizer recommender for paddy fields; Ranking performance of modified fuzzy TOPSIS variants based on different similarity measures; prediction of new bioactive molecules of chemical compound using boosting ensemble methods; Pragmatic miner to risk analysis for intrusion detection (PMRA-ID); intelligent system E-learning modeling according to learning styles and level of ability of students; mining textual terms for stock market prediction analysis using financial news; content quality of latent dirichlet allocation summaries constituted using unique significant words; rare event prediction using similarity majority under-sampling technique; Pattern recognition of balinese carving motif using learning vector quantization (LVQ); Feature extraction for image content retrieval in thai traditional painting with SIFT algorithms; modeling of the gaussian-based component analysis on the kernel space to extract face image.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gmati2018796,
	author = {Gmati, Fatma Ezzahra and Chakhar, Salem and Lajoued Chaari, Wided and Chen, Huijing},
	title = {A rough set approach to events prediction in multiple time series},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10868 LNAI},
	pages = {796 – 807},
	doi = {10.1007/978-3-319-92058-0_77},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049017677&doi=10.1007%2f978-3-319-92058-0_77&partnerID=40&md5=e1c0d716bcacc1d98e5c90d55975ce8d},
	abstract = {This paper introduces and illustrates a rough-set based approach to event prediction in multiple time series. The proposed approach uses two different versions of rough set theory to predict events occurrences and intensities. First, classical Indiscernibility relation-based Rough Set Approach (IRSA) is used to predict event classes and occurrences. Then, the Dominance-based Rough Set Approach (DRSA) is employed to predict the intensity of events. This paper presents the fundamental of the proposed approach and the conceptual architecture of a framework implementing this approach. © 2018, Springer International Publishing AG, part of Springer Nature.},
	author_keywords = {Dominance-based Rough Set Approach; Event prediction; Multiple time series; Rough sets},
	keywords = {Forecasting; Intelligent systems; Time series; Conceptual architecture; Dominance-based rough set approach; Dominance-based rough set approach (DRSA); Event class; Event prediction; Indiscernibility relation; Multiple time series; Rough-set based; Rough set theory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{20151,
	title = {European Conference on Data Analysis, ECDA 2013},
	year = {2015},
	journal = {Studies in Classification, Data Analysis, and Knowledge Organization},
	volume = {48},
	pages = {1 – 556},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945535820&partnerID=40&md5=864615a45e46b043d6e2e8c09f76226a},
	abstract = {The proceedings contain 48 papers. The special focus in this conference is on Data Science and Clustering. The topics include: A new supervised classification of credit approval data via the hybridized RBF neural network model using information complexity; finding the number of disparate clusters with background contamination; clustering of solar irradiance; factor analysis of local formalism; recent progress in complex network analysis; recent progress in complex network analysis; similarity measures of concept lattices; shortest path, commute time, max-flow and free energy; on-line clustering of functional boxplots for monitoring multiple streaming time series; smooth tests of fit for Gaussian mixtures; selecting a multi-label classification method for an interactive system; visual analysis of topics in twitter based on co-evolution of terms; incremental weighted naive bays classifiers for data stream; SVM ensembles are better when different kernel types are combined; ratings-/rankings-based versus choice-based conjoint analysis for predicting choices; a statistical software package for image data analysis in marketing; the bass model as integrative diffusion model; preference measurement in complex product development; combination of distances and image features for clustering image data bases; a game theoretic product design approach considering stochastic partworth functions; key success-determinants of crowd funded projects; preferences interdependence among family members; evaluation of cell line suitability for disease specific perturbation experiments; effect of hundreds sequenced genomes on the classification of human papilloma viruses; donor limited hot deck imputation; ensembles of representative prototype sets for classification and data set analysis and event prediction in pharyngeal high-resolution manometry. },
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tan2015210,
	author = {Tan, Terence K. and Darken, Christian J.},
	title = {Learning and prediction of relational time series},
	year = {2015},
	journal = {Computational and Mathematical Organization Theory},
	volume = {21},
	number = {2},
	pages = {210 – 241},
	doi = {10.1007/s10588-015-9182-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937765231&doi=10.1007%2fs10588-015-9182-0&partnerID=40&md5=a92a2a4b3aad7a55ddd04879dc091f4f},
	abstract = {Learning to predict events in the near future is fundamental to human and artificial agents. Many prediction techniques are unable to learn and predict a stream of relational data online when the environments are unknown, non-stationary, and no prior training examples are available. This paper addresses the online prediction problem by introducing a low complexity learning technique called Situation Learning and several prediction techniques that use the information from Situation Learning to predict the next likely event. The prediction techniques include two variants of a Bayesian inference technique, a variable order Markov model prediction technique and situation matching techniques. We compared their prediction accuracies quantitatively for three domains: a role-playing game, computer network intrusion system alerts, and event prediction of maritime paths in a discrete-event simulator. © 2015, Springer Science+Business Media New York.},
	author_keywords = {Prediction; Relational time series; Sequence learning},
	keywords = {Bayesian networks; Complex networks; Computer games; Inference engines; Markov processes; Social networking (online); Time series; Discrete-event simulators; Learning techniques; Matching techniques; Network intrusion systems; Prediction techniques; Relational Time Series; Sequence learning; Variable Order Markov Models; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Charalampidis2010,
	author = {Charalampidis, Dimitrios and Kattekola, Sravanthi},
	title = {Computationally efficient radar image based forecasting using RBF neural networks},
	year = {2010},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {7701},
	doi = {10.1117/12.851305},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958030070&doi=10.1117%2f12.851305&partnerID=40&md5=e0c361074b66a82058a6dceb0c0b7be3},
	abstract = {Radial Basis Function neural networks (RBFNN) have been used for tracking precipitation in weather imagery. Techniques presented in the literature used RBFNN to model precipitation as a combination of localized envelopes which evolve over time. A separate RBFNN was used to predict future values of the evolving envelope parameters considering each parameter as a time series. Prediction of envelope parameters is equivalent to forecasting the associated weather events. Recently, the authors proposed an alternative RBFNN-based approach for modeling precipitation in weather imagery in a computationally efficient manner. However, the event prediction stage was not investigated, and thus any possible trade-off between efficiency and forecasting effectiveness was not examined. In order to facilitate such a test, an appropriate prediction technique is needed. In this work, an RBFNN series prediction scheme explores the dependence of envelope parameters on each other. Although different approaches can be employed for training the RBFNN predictor, a computationally efficient subset selection method is adopted from past work, and adjusted to support parameter dependence. Simulations are presented to illustrate that simultaneous prediction of the precipitation event parameters may be advantageous. © 2010 SPIE.},
	author_keywords = {Radial Basis Functions; Series prediction; Weather radars},
	keywords = {Computational efficiency; Data processing; Image segmentation; Meteorological radar; Neural networks; Radial basis function networks; Time series; Computationally efficient; Event prediction; Parameter dependence; Precipitation events; Prediction schemes; Prediction techniques; Radar image; Radial basis function neural networks; Radial basis functions; RBF Neural Network; Series prediction; Subset selection; Weather events; Weather imagery; Weather radars; Weather forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rahman2015382,
	author = {Rahman, Ashfaqur and McCulloch, John and Mamun, Quazi},
	title = {Prediction with uncertainty: A novel framework for analyzing sensor data streams},
	year = {2015},
	journal = {IEEE Sensors Journal},
	volume = {15},
	number = {1},
	pages = {382 – 386},
	doi = {10.1109/JSEN.2014.2344683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910633357&doi=10.1109%2fJSEN.2014.2344683&partnerID=40&md5=8353b72bc94ff3b0fc659703b9f28edc},
	abstract = {In this paper, we present a novel framework to predict events through time-series analysis of sensor data streams. The framework is capable of producing and visualizing event prediction probabilities, uncertainties around the predictions, and the actual decision being taken based on the prediction. We have tested the analytical framework on predicting closure events in shellfish farms in Tasmania. Reasonably high prediction accuracy is achieved. The visualization was able to capture prediction, uncertainty, and actual decision being taken (i.e., three-in-one). © 2001-2012 IEEE.},
	author_keywords = {prediction with uncertainty; Sensor data analytics; time series prediction},
	keywords = {Data communication systems; Time series analysis; Uncertainty analysis; Event prediction; Prediction accuracy; Sensor data; Time series prediction; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Ali201079,
	author = {Ali, Azad and Khelil, Abdelmajid and Shaikh, Faisal Karim and Suri, Neeraj},
	title = {MPM: Map based Predictive Monitoring for Wireless Sensor Networks},
	year = {2010},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering},
	volume = {23 LNICST},
	pages = {79 – 95},
	doi = {10.1007/978-3-642-11482-3_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885890045&doi=10.1007%2f978-3-642-11482-3_6&partnerID=40&md5=f13a82d2f8cc4b826db7c02952f0e3a5},
	abstract = {We present the design of a Wireless Sensor Networks (WSN) level event prediction framework to monitor the network and its operational environment to support proactive self* actions. For example, by monitoring and subsequently predicting trends on network load or sensor nodes energy levels, theWSN can proactively initiate self-reconfiguration. We propose a Map based Predictive Monitoring (MPM) approach where a selected WSN attribute is first profiled as WSN maps, and based on the maps history, predicts future maps using time series modeling. The "attribute" maps are created using a gridding technique and predicted maps are used to detect events using our regioning algorithm. The proposed approach is also a general framework to cover multiple application domains. For proof of concept, we show MPM's enhanced ability to also accurately "predict" the network partitioning, accommodating parameters such as shape and location of the partition with a very high accuracy and efficiency. © Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering 2010.},
	author_keywords = {Event prediction; Predicitve Monitoring; Time series analysis; Wireless Sensor Networks},
	keywords = {Forecasting; Sensor nodes; Sensors; Telecommunication equipment; Time series; Time series analysis; Event prediction; Gridding; Multiple applications; Network load; Network partitioning; Operational environments; Predicitve Monitoring; Predictive monitoring; Proof of concept; Self reconfiguration; Time series modeling; Wireless networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Ruta2015485,
	author = {Ruta, Dymitr and Cen, Ling},
	title = {Self-organized predictor of methane concentration warnings in coal mines},
	year = {2015},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9437},
	pages = {485 – 493},
	doi = {10.1007/978-3-319-25783-9_43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952684607&doi=10.1007%2f978-3-319-25783-9_43&partnerID=40&md5=d973690303fdb1842ad223532af53387},
	abstract = {Coal mining operation continuously balances the trade-off between the mining productivity and the risk of hazards like methane explosion. Dangerous methane concentration is normally a result of increased cutter loader workload and leads to a costly operation shutdown until the increased concentrations abate. We propose a simple yet very robust methane warning prediction model that can forecast imminent high methane concentrations at least 3 minutes in advance, thereby giving enough notice to slow the mining operation, prevent methane warning and avoid costly shutdowns. Our model is in fact an instance of the generic prediction framework able to rapidly compose a predictor of any future events upon the aligned time series big data. The model uses fast greedy backward-forward search applied subsequently upon the design choices of the machine learning model from the data granularity, feature selection, filtering and transformation up to the selection of the predictor, its configuration and complexity. We have applied such framework to the methane concentration warning prediction in real coal mines as a part of the IJCRS’2015 data mining competition and scored 3rd place with the performance just under 85%. Our top model emerged as a result of the rapid filtering through the large amount of sensors time series and eventually used only the latest 1 minute of aggregated data from just few sensors and the logistic regression predictor. Many other model setups harnessing multiple linear regression, decision trees, naive Bayes or support vector machine predictors on slightly altered feature sets returned nearly equally good performance. © Springer International Publishing Switzerland 2015.},
	author_keywords = {Big data; Classification; Events prediction; Feature selection; Regression; Time series forecasting},
	keywords = {Artificial intelligence; Classification (of information); Coal; Coal mines; Cutter loaders; Data mining; Decision trees; Economic and social effects; Feature extraction; Forecasting; Fuzzy sets; Granular computing; Learning systems; Linear regression; Metadata; Methanation; Methane; Regression analysis; Rough set theory; Time series; Coalmining operations; Logistic regressions; Machine learning models; Methane concentrations; Methane explosions; Multiple linear regressions; Regression; Time series forecasting; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{2015,
	title = {Procedia Computer Science},
	year = {2015},
	journal = {Procedia Computer Science},
	volume = {48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939217949&partnerID=40&md5=51a3eee4287a0e9dfcead57c114c5e4c},
	abstract = {The proceedings contain 112 papers. The topics discussed include: a model ranking based selective ensemble approach for time series forecasting; differential search algorithm for multiobjective problems; an enhancement in adaptive median filter for edge preservation; fractional order control and comparative analysis of a hybrid system; influence of lexical, syntactic and structural features and their combination on authorship attribution for Telugu text; multiple information hiding using circular random grids; decision support model for automated railway level crossing system using fuzzy logic control; subtractive clustering fuzzy expert system for engineering applications; temporal sentiment analysis and causal rules extraction from tweets for event prediction; and a comparative study of solution of economic load dispatch problem in power systems in the environmental perspective.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Herron20092689,
	author = {Herron, Natasha and Croke, Barry},
	title = {Including the influence of groundwater exchanges in a lumped rainfall-runoff model},
	year = {2009},
	journal = {Mathematics and Computers in Simulation},
	volume = {79},
	number = {9},
	pages = {2689 – 2700},
	doi = {10.1016/j.matcom.2008.08.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349165062&doi=10.1016%2fj.matcom.2008.08.007&partnerID=40&md5=6a2bdd88419220b52c5c2d8e3bf84ec9},
	abstract = {The growing realisation that groundwater and surface water systems are components of connected hydrologic system has in recent years sparked the development of integrated surface-ground water models. In this paper, a version of the IHACRES rainfall-runoff model is presented, in which the CMD module for calculating effective rainfall is coupled to a streamflow-groundwater module, and applied to the Coxs Creek catchment, a variably gaining-losing stream system in Australia. The aim is to determine the capacity for the coupled model to capture the switching off-on behaviour evident in the observed flow record. Model performance can be improved in terms of event prediction, volume of baseflow and the percentile of flow cessation, through manipulation of CMD parameters, however, improvements in some performance criteria come at the expense of performance in others. An analysis of the input rainfall time-series, generated using a standard weighted Thiessen polygon approach, reveals mismatches between observed streamflow events and the occurrence of rainfall, which impose major limits on model performance. The challenge is to develop a simple lumped rainfall-runoff model that has the potential to improve system understanding and allow for meaningful exploration of alternate climate, groundwater extraction and land use change scenarios, given a situation of data poor catchments in many parts of Australia. © 2008 IMACS.},
	author_keywords = {Baseflow; Groundwater-surface water interactions; IHACRES; Rainfall-runoff},
	keywords = {Catchments; Climate change; Groundwater; Hydrogeology; Land use; Stream flow; Time series analysis; Water wells; Australia; Baseflow; Coupled models; Effective rainfall; Event prediction; Flow cessation; Groundwater extraction; Groundwater models; Groundwater-surface water interactions; Hydrologic systems; IHACRES; Land-use change; Model performance; Performance criterion; Polygon approach; Rainfall-runoff; Rainfall-runoff models; Stream-flow events; Runoff},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@ARTICLE{Liu2011531,
	author = {Liu, Ke-Feng and Zhang, Jun and Chen, Yi-De and Li, Xiang-Jun},
	title = {Compositive prediction of ENSO based on wavelet decomposition and support vector machine},
	year = {2011},
	journal = {Jiefangjun Ligong Daxue Xuebao/Journal of PLA University of Science and Technology (Natural Science Edition)},
	volume = {12},
	number = {5},
	pages = {531 – 535},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80855153756&partnerID=40&md5=53c74ae54849b4db1e45cc65d8cb494b},
	abstract = {To improve the predictive effect of the EI Nino/La Nine and the Southern Oscillation(ENSO), based on the sea surface temperature anomaly time series of Nino integrated area, the method of the wavelet decomposition and the least squares support vector machine combined with multi-step delivery forecast idea was introduced to establish ENSO prediction model. The analysis shows that the compositive multi-step forecasting method based on the wavelet decomposition and the least squares support vector machine is efficient with much advantages in El Nino/La Nina events prediction, and that the forecasting results provide reference to the ENSO forecast.},
	author_keywords = {ENSO; Least squares support vector machines; Multi-step delivery forecast; Wavelet decomposition},
	keywords = {Atmospheric pressure; Atmospheric temperature; Forecasting; Least squares approximations; Mathematical models; Support vector machines; Time series; Vectors; Compositive; EI Nino; EL Nino; ENSO; ENSO forecast; ENSO prediction models; Integrated areas; Least squares support vector machines; Multi-step; Multi-step forecasting; Sea surface temperature anomalies; Southern Oscillation; Wavelet decomposition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Lajevardi2008533,
	author = {Lajevardi, Seyed Behzad and Minaei-Bidgoli, Behrouz},
	title = {Comparison between ANN and decision tree in aerology event prediction},
	year = {2008},
	journal = {Proceedings - 2008 International Conference on Advanced Computer Theory and Engineering, ICACTE 2008},
	pages = {533 – 537},
	doi = {10.1109/ICACTE.2008.121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949210669&doi=10.1109%2fICACTE.2008.121&partnerID=40&md5=f3b6ebd68196e20bee66df3126526baa},
	abstract = {Predictive systems use historical and other available data to predict an event. In this paper we tries to compare the power of Artificial Neural Network (ANN) and Decision Tree (DT) in prediction of aerology events with time series streams and events stream using combination of K-means clustering algorithm and Decision Tree C5 algorithm and ANN. We try to find the effective parameters on events occurrences. Firstly, we find the closest time series record for any events; therefore, we have gathered different parameters value when an event is occurring. Using K-means we add a field to dataset which determines the cluster of each record and after that we predict the events using C5 algorithm and ANN. This framework and time series model can predict future events efficiently. We gathered 1961 until 2005 data of aerology organization for Tehran Mehrabad Station. This data contains some fields such as wet bulb, relative humidity, amount of cloud, wind speed and etc. This dataset includes 17 types of events. Using this framework the closest event can be predicted. The C5 method is able to predict events with 79.55% accuracy and ANN with 72.87% accuracy. Applying K-means clustering algorithm the prediction increase to 94.59% for C5 and 92.66% accuracies for ANN. We use 10fold cross validation to evaluate our prediction rate. This framework is the first estimation in the area of event prediction for a huge dataset of aerology and can be extended in many different datasets in any other environments. © 2008 IEEE.},
	keywords = {Atmospheric humidity; Backpropagation; Decision trees; Meteorology; Neural networks; Time series; Water supply systems; 10 fold cross validations; Artificial neural networks; Data sets; Effective parameters; Event predictions; K-Means; K-means clustering algorithms; Prediction rates; Predictive systems; Relative humidities; Time-series models; Wet bulbs; Wind speed; Clustering algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Prakash20162133,
	author = {Prakash, B. Aditya and Ramakrishnan, Naren},
	title = {Leveraging propagation for data mining: Models, algorithms and applications},
	year = {2016},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	volume = {13-17-August-2016},
	pages = {2133 – 2134},
	doi = {10.1145/2939672.2945390},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985036729&doi=10.1145%2f2939672.2945390&partnerID=40&md5=d02aac1018fe86e2446ef5e54f0b6d98},
	abstract = {Can we infer if a user is sick from her tweet? How do opinions get formed in online forums? Which people should we immunize to prevent an epidemic as fast as possible? How do we quickly zoom out of a graph? Graphs|also known as networks|are powerful tools for modeling processes and situations of interest in real life domains of social systems, cyber-security, epidemiology, and biology. They are ubiquitous, from online social networks, gene-regulatory networks, to router graphs. This tutorial will cover recent and state-of-the-art research on how propagation-like processes can help big-data mining specifically involving large networks and time-series, algorithms behind network problems, and their practical applications in various diverse settings. Topics include diffusion and virus propagation in networks, anomaly and outbreak detection, event prediction and connections with work in public health, the web and online media, social sciences, humanities, and cyber-security. © 2016 Copyright held by the owner/author(s).},
	author_keywords = {Cyber security; Diffusion; Dynamical processes; Graph mining; Propagation; Public health; Social media},
	keywords = {Algorithms; Big data; Computer viruses; Diffusion; Network security; Public health; Social networking (online); Viruses; Wave propagation; Cyber security; Dynamical process; Gene regulatory networks; Graph mining; On-line social networks; Outbreak detection; Social media; Virus propagation; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Huang20131376,
	author = {Huang, Guangyan and He, Jing and Cao, Jie and Qiao, Zhi and Steyn, Michael and Taraporewalla, Kersi},
	title = {A real-time abnormality detection system for intensive care management},
	year = {2013},
	journal = {Proceedings - International Conference on Data Engineering},
	pages = {1376 – 1379},
	doi = {10.1109/ICDE.2013.6544948},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881360423&doi=10.1109%2fICDE.2013.6544948&partnerID=40&md5=76de9c17da7d0636508f9d9ed5b37927},
	abstract = {Detecting abnormalities from multiple correlated time series is valuable to those applications where a credible realtime event prediction system will minimize economic losses (e.g. stock market crash) and save lives (e.g. medical surveillance in the operating theatre). For example, in an intensive care scenario, anesthetists perform a vital role in monitoring the patient and adjusting the flow and type of anesthetics to the patient during an operation. An early awareness of possible complications is vital for an anesthetist to correctly react to a given situation. In this demonstration, we provide a comprehensive medical surveillance system to effectively detect abnormalities from multiple physiological data streams for assisting online intensive care management. Particularly, a novel online support vector regression (OSVR) algorithm is developed to approach the problem of discovering the abnormalities from multiple correlated time series for accuracy and real-time efficiency. We also utilize historical data streams to optimize the precision of the OSVR algorithm. Moreover, this system comprises a friendly user interface by integrating multiple physiological data streams and visualizing alarms of abnormalities. © 2013 IEEE.},
	keywords = {Algorithms; Losses; Physiology; Time series; User interfaces; Abnormality detection; Early awareness; Event prediction; Historical data; Medical surveillance; Operating theatre; Physiological data; Stock market crashes; Data communication systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Molaei2015,
	author = {Molaei, Soheila Mehr and Keyvanpour, Mohammad Reza},
	title = {An analytical review for event prediction system on time series},
	year = {2015},
	journal = {2015 2nd International Conference on Pattern Recognition and Image Analysis, IPRIA 2015},
	doi = {10.1109/PRIA.2015.7161635},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947969323&doi=10.1109%2fPRIA.2015.7161635&partnerID=40&md5=d7d5597609e28f28acb26220bc8c04c8},
	abstract = {This Time series mining is a new area of research in temporal databases and has been an active area of research with its notable recent progress. Event prediction is one of the main goals of time series mining which have important roles for appropriate decision making in different application area. So far, different studies have been presented in the field of time series mining for meaningful events prediction, which have ample challenges. Lack of systematic identification of challenges causes some obstacles for the development of methods. In this paper, due to the abundance and diversity of challenges in event prediction system on time series, lack of a perfect platform for their systematic identification and removing barriers for the development of methods, a classification is proposed for challenging problems of event prediction system on time series. Also, reviewed and analyzed the application of data mining techniques for solving different challenges in event prediction system on time series. For this goal, the article tries to closely study and categorize related researches for better understanding and to reach a comparison structure that can map data mining techniques into the event prediction challenges. The proposed classification of this paper by introducing systematic challenges can help create different research pivots for the elimination of challenges in different areas of applying and developing methods. We think that this paper can help researchers in event prediction systems on time series for the future activities. © 2015 IEEE.},
	author_keywords = {challenges; event prediction; time series; time series mining},
	keywords = {Decision making; Forecasting; Image analysis; Pattern recognition; Time series; Analytical reviews; Application area; challenges; Event prediction; Map data minings; Systematic identification; Temporal Database; Time-series mining; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@CONFERENCE{Amodeo20111981,
	author = {Amodeo, Giuseppe and Blanco, Roi and Brefeld, Ulf},
	title = {Hybrid models for future event prediction},
	year = {2011},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {1981 – 1984},
	doi = {10.1145/2063576.2063870},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83055161561&doi=10.1145%2f2063576.2063870&partnerID=40&md5=374e1e0dfb87dfea46a5b92cabf6c4af},
	abstract = {We present a hybrid method to turn off-the-shelf information retrieval (IR) systems into future event predictors. Given a query, a time series model is trained on the publication dates of the retrieved documents to capture trends and periodicity of the associated events. The periodicity of historic data is used to estimate a probabilistic model to predict future bursts. Finally, a hybrid model is obtained by intertwining the probabilistic and the time-series model. Our empirical results on the New York Times corpus show that autocorrelation functions of time-series suffice to classify queries accurately and that our hybrid models lead to more accurate future event predictions than baseline competitors. © 2011 ACM.},
	author_keywords = {arima; arma; event prediction; future prediction; information retrieval; sarima; time series; web search},
	keywords = {Forecasting; Information retrieval; Knowledge management; Regression analysis; Time series; World Wide Web; arima; arma; Event prediction; sarima; Web searches; Search engines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Green Open Access}
}

@CONFERENCE{Rocha20116037,
	author = {Rocha, T. and Paredes, S. and Carvalho, P. and Henriques, J.},
	title = {A wavelet-based approach for time series pattern detection and events prediction applied to telemonitoring data},
	year = {2011},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	pages = {6037 – 6040},
	doi = {10.1109/IEMBS.2011.6091492},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84055192099&doi=10.1109%2fIEMBS.2011.6091492&partnerID=40&md5=d96cb03e7c24c3eab2c5dae0873b1325},
	abstract = {This work aims the development of a predictive strategy able to estimate future events with relevant impact in the cardiovascular status. Based on wavelet transform, a new time series similarity metric is introduced, which is capable to detect a pre-defined pattern in time series data. In addition, a methodology combining a wavelet scheme with state space multi-models is proposed to achieve the prediction of future signal values. Blood pressure signals, collected by a telemonitoring platform (TEN-HMS), are used to detect the occurrence of future hypertension events. © 2011 IEEE.},
	keywords = {Blood Pressure Determination; Diagnosis, Computer-Assisted; Humans; Hypertension; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Telemedicine; Wavelet Analysis; Blood pressure; Telecommunication services; Time series; Wavelet transforms; Blood pressure signals; Signal value; Similarity metrics; State space; Tele-monitoring; Time series patterns; Time-series data; Wavelet-based approach; article; automated pattern recognition; blood pressure measurement; computer assisted diagnosis; human; hypertension; methodology; reproducibility; sensitivity and specificity; telemedicine; wavelet analysis; Signal detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Zhou2017386,
	author = {Zhou, Yuqian},
	title = {Pro-ISIS fanboys network analysis and attack detection through Twitter data},
	year = {2017},
	journal = {2017 IEEE 2nd International Conference on Big Data Analysis, ICBDA 2017},
	pages = {386 – 390},
	doi = {10.1109/ICBDA.2017.8078846},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040020193&doi=10.1109%2fICBDA.2017.8078846&partnerID=40&md5=2ef531b1e79fd44c898319dcb20aac1c},
	abstract = {Terrorism becomes more severe these days, especially the attacks sponsored by Islamic State of Iraq and Syria (ISIS) or Daesh. They are experts of using social network for propaganda and recruitment, thus predicting their activities through big social network data will help to predict and avoid more serious attacks. In this paper, we analyze over 17k Twitter records of pro-ISIS fanboys over a year. Based on those tweets, we want to dig out: 1. Who is the most important and active member in the social network? 2. What are the hashtags they frequently used for propaganda? 3. According to the twitting peak time and information on-hand, will it be able to predict the next attack? Our results reveal the leader in this propaganda network, and achieve a satisfactory attack prediction via time-series neural network through very limited attack history. © 2017 IEEE.},
	author_keywords = {event prediction; social network; terrorism; time-series neural network},
	keywords = {Data handling; Forecasting; Information analysis; Social networking (online); Terrorism; Time series; Active member; Attack detection; Attack prediction; Event prediction; Hashtags; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Rahman201442,
	author = {Rahman, Ashfaqur and Shahriar, Md Sumon and D'Este, Claire and Smith, Greg and McCulloch, John and Timms, Greg},
	title = {Time-series prediction of shellfish farm closure: A comparison of alternatives},
	year = {2014},
	journal = {Information Processing in Agriculture},
	volume = {1},
	number = {1},
	pages = {42 – 50},
	doi = {10.1016/j.inpa.2014.05.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016737220&doi=10.1016%2fj.inpa.2014.05.001&partnerID=40&md5=0c14a8f5067d7231fe15c412d9f5504b},
	abstract = {Shellfish farms are closed for harvest when microbial pollutants are present. Such pollutants are typically present in rainfall runoff from various land uses in catchments. Experts currently use a number of observable parameters (river flow, rainfall, salinity) as proxies to determine when to close farms. We have proposed using the short term historical rainfall data as a time-series prediction problem where we aim to predict the closure of shellfish farms based only on rainfall. Time-series event prediction consists of two steps: (i) feature extraction, and (ii) prediction. A number of data mining challenges exist for these scenarios: (i) which feature extraction method best captures the rainfall pattern over successive days that leads to opening or closure of the farms?, (ii) The farm closure events occur infrequently and this leads to a class imbalance problem; the question is what is the best way to deal with this problem? In this paper we have analysed and compared different combinations of balancing methods (under-sampling and over-sampling), feature extraction methods (cluster profile, curve fitting, Fourier Transform, Piecewise Aggregate Approximation, and Wavelet Transform) and learning algorithms (neural network, support vector machine, k-nearest neighbour, decision tree, and Bayesian Network) to predict closure events accurately considering the above data mining challenges. We have identified the best combination of techniques to accurately predict shellfish farm closure from rainfall, given the above data mining challenges. © 2014},
	author_keywords = {Aquaculture; Data mining; Shellfish farm closure; Time series data},
	keywords = {Approximation algorithms; Aquaculture; Bayesian networks; Catchments; Curve fitting; Decision trees; Extraction; Feature extraction; Forecasting; Land use; Nearest neighbor search; Pollution; Rain; Runoff; Shellfish; Time series; Trees (mathematics); Wavelet transforms; Class imbalance problems; Feature extraction methods; K-nearest neighbours; Observable parameters; Piecewise aggregate approximation; Time series prediction; Time-series data; Time-series events; Data mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Antunes2003631,
	author = {Antunes, M. and Amaral Turkman, M.A. and Turkman, K.F.},
	title = {A Bayesian approach to event prediction},
	year = {2003},
	journal = {Journal of Time Series Analysis},
	volume = {24},
	number = {6},
	pages = {631 – 646},
	doi = {10.1111/j.1467-9892.2003.00326.x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346265982&doi=10.1111%2fj.1467-9892.2003.00326.x&partnerID=40&md5=f6020af42cb13f1528d02d4d9c13d58d},
	abstract = {In a series of papers, Lindgren (1975a, 1985) and de Maré (1980) set the principles of optimal alarm systems and obtained the basic results. Application of these ideas to linear discrete time-series models was carried out by Svensson et al. (1996). In this paper, we suggest a Bayesian predictive approach to event prediction and optimal alarm systems for discrete time series. There are two novelties in this approach: first, the variation in the model parameters is incorporated in the analysis; second, this method allows 'on-line prediction' in the sense that, as we observe the process, our posterior probabilities and predictions are updated at each time point.},
	author_keywords = {Autoregressive processes; Optimal alarm systems; Predictive distributions},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@ARTICLE{Janusz201783,
	author = {Janusz, Andrzej and Grzegorowski, Marek and Michalak, Marcin and Wróbel, Łukasz and Sikora, Marek and Ślęzak, Dominik},
	title = {Predicting seismic events in coal mines based on underground sensor measurements},
	year = {2017},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {64},
	pages = {83 – 94},
	doi = {10.1016/j.engappai.2017.06.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021052337&doi=10.1016%2fj.engappai.2017.06.002&partnerID=40&md5=8a9bcc6541754c78d1ef10d62e4c4f39},
	abstract = {In this paper, we address the problem of safety monitoring in underground coal mines. In particular, we investigate and compare practical methods for the assessment of seismic hazards using analytical models constructed based on sensory data and domain knowledge. For our case study, we use a rich data set collected during a period of over five years from several active Polish coal mines. We focus on comparing the prediction quality between expert methods which serve as a standard in the coal mining industry and state-of-the-art machine learning methods for mining high-dimensional time series data. We describe an international data mining challenge organized to facilitate our study. We also demonstrate a technique which we employed to construct an ensemble of regression models able to outperform other approaches used by participants of the challenge. Finally, we explain how we utilized the data obtained during the competition for the purpose of research on the cold start problem in deploying decision support systems at new mining sites. © 2017 Elsevier Ltd},
	author_keywords = {Cold-start problem; Decision support systems; Feature engineering; Predictive analytics; Seismic events prediction; Time series data},
	keywords = {Artificial intelligence; Coal; Coal industry; Decision support systems; Forecasting; Ignition; Learning systems; Predictive analytics; Regression analysis; Seismology; Starting; Time series; Coal mining industry; Cold start problems; Feature engineerings; Seismic event; Sensor measurements; State-of-the-art machine learning methods; Time-series data; Underground coal mine; Coal mines},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30}
}

@ARTICLE{20161,
	title = {20th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2016},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9794},
	pages = {1 – 280},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978811061&partnerID=40&md5=ff2bdff345faefb88ab7ed1f95e2b77b},
	abstract = {The proceedings contain 23 papers. The special focus in this conference is on Biologically Inspired Data Mining Techniques. The topics include: Towards a new evolutionary subsampling technique for heuristic optimisation of load disaggregators; neural choice by elimination via highway networks; attribute selection and classification of prostate cancer gene expression data using artificial neural networks; an improved self-structuring neural network; multiple seeds based evolutionary algorithm for mining boolean association rules; predicting phone usage behaviors with sensory data using a hierarchical generative model; rigidly self-expressive sparse subspace clustering; joint recognition and segmentation of actions via probabilistic integration of spatio-temporal fisher vectors; learning multi-faceted activities from heterogeneous data with the product space hierarchical dirichlet processes; phishing detection on twitter streams; image segmentation with superpixel based covariance descriptor; normalized cross-match; event prediction in healthcare analytics; a music recommendation system based on acoustic features and user personalities; a social spam detection framework via semi-supervised learning; a hierarchical beta process approach for financial time series trend prediction; efficient iris image segmentation for ATM based approach through fuzzy entropy and graph cut; matching product offers of E-shops; keystroke biometric recognition on Chinese long text input and recommendation algorithm design in a land exchange platform.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ali2012233,
	author = {Ali, Azad and Khelil, Abdelmajid and Shaikh, Faisal Karim and Suri, Neeraj},
	title = {Efficient predictive monitoring of wireless sensor networks},
	year = {2012},
	journal = {International Journal of Autonomous and Adaptive Communications Systems},
	volume = {5},
	number = {3},
	pages = {233 – 254},
	doi = {10.1504/IJAACS.2012.047657},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863641242&doi=10.1504%2fIJAACS.2012.047657&partnerID=40&md5=30fd5df3325c81e1cf07de3203656896},
	abstract = {Wireless sensor networks (WSNs) are deployed to monitor physical events such as fire, or the state of physical objects such as bridges in order to support appropriate reaction to avoid potential damages. However, many situations require immediate attention or long-reaction plan. Therefore, the classical approach of just detecting the physical events may not suffice in many cases. We present a generic WSN level event prediction framework to forecast the physical events, such as network partitioning, well in advance to support proactive self-actions. The framework collects the state of a specified attribute on the sink using an efficient spatio-temporal compression technique. The future state of the targeted attributes is then predicted using time series modelling. We propose a generic event prediction algorithm, which is adaptable to multiple application domains. Using simulations we show our framework's enhanced ability to accurately predict the network partitioning with very high accuracy and efficiency. Copyright © 2012 Inderscience Enterprises Ltd.},
	author_keywords = {Event detection and prediction; Predictive monitoring; Spatio-temporal compression; Time series analysis; Wireless sensor networks; WSNs},
	keywords = {Forecasting; Time series analysis; Event detection and predictions; Multiple applications; Network partitioning; Predictive monitoring; Spatio-temporal compressions; Time-series modelling; Wireless sensor network (WSNs); WSNs; Wireless sensor networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Takahashi2013727,
	author = {Takahashi, Rikiya and Mizuta, Hideyuki and Abe, Naoki and Kennedy, Ruby L. and Jeffs, Vincent J. and Shah, Ravi and Crites, Robert H.},
	title = {Collective response spike prediction for mutually interacting consumers},
	year = {2013},
	journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
	pages = {727 – 736},
	doi = {10.1109/ICDM.2013.84},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894676217&doi=10.1109%2fICDM.2013.84&partnerID=40&md5=64d4efc5fb36341b8a2b6bb007774267},
	abstract = {Modeling how marketing actions in various channels influence or cause consumer purchase decisions is crucial for marketing decision-making. Marketing campaigns stimulate consumer awareness, interest and help drive interactions such as the browsing of product web pages, ultimately impacting an individual's purchase decision. In addition, some successful campaigns stimulate word-of-mouth and social trends among consumers, and such collective behavior of consumers result in concurrent and correlated responses over a short term. Though each consumer's response should be attributed with both the same individual's experiences and the collective factors, unobservability of most word-of-mouth events makes the estimation challenging. The authors propose a new continuous-time predictive model for time-dependent response rates of each consumer, which can incorporate both the individual and the collective factors without explicit word-of-mouth observations. The individual factor is modeled as staircase functions associated with the experienced events by each consumer, and provides a clear psychological interpretation about how marketing advertising communications impact short-term and mid-term memories of consumers. The collective factor is modeled with aggregate response frequencies for mutually-interacting groups that are automatically estimated from data. The key idea to mine the mutually-interacting groups exists in a three-step estimator, which initially performs a Poisson regression without the collective factor, then does clustering of the residual time-series in the initial regression, and finally performs another Poisson regression involving the collective factor. The proposed collective factor robustly incorporates the underlying trends even when causality from one consumer's event spikes to another consumer's response is weak. High predictive accuracy of the proposed approach is empirically validated using real-world data provided by an online retailer in Europe. © 2013 IEEE.},
	author_keywords = {Continuous-time event prediction; Poisson regression; residual clustering; time-decaying curves},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Wang201878,
	author = {Wang, Wenzhi and Lv, Weifeng and Lang, Xianmei},
	title = {Impact of traffic event prediction based on time series prediction},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	volume = {Part F137704},
	pages = {78 – 82},
	doi = {10.1145/3219788.3219798},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053698613&doi=10.1145%2f3219788.3219798&partnerID=40&md5=d30c69c4bccb214625874a579ffea151},
	abstract = {In this paper, we predict the impact of traffic event on urban roads in Xi'an, including the range and the total time of the influence. The author creatively proposes to use Recurrent Neural Network (RNN) algorithm to predict the change of road traffic index by calculating the basic information of road、the basic information of event and weather data, combining with the road traffic index and time series forecasting. Among them, RNN algorithm uses deep recurrent neural network and long-short term memory (LSTM) to achieve. Finally, the predicted change sequence is compared with the historical road condition index of the road section to determine whether the road is affected and the total time of the influence. © 2018 Association for Computing Machinery.},
	author_keywords = {Influence range; Influence time; Prediction; RNN; Traffic event},
	keywords = {Long short-term memory; Roads and streets; Time series; Influence range; Influence time; Recurrent neural network (RNN); Road condition; Time series forecasting; Time series prediction; Traffic event; Weather data; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Bae1994355,
	author = {Bae, Deg-Hyo and Georgakakos, Konstantine P.},
	title = {Climatic variability of soil water in the American Midwest: Part 1. Hydrologic modeling},
	year = {1994},
	journal = {Journal of Hydrology},
	volume = {162},
	number = {3-4},
	pages = {355 – 377},
	doi = {10.1016/0022-1694(94)90236-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028669311&doi=10.1016%2f0022-1694%2894%2990236-4&partnerID=40&md5=4d88db3cc4487910262d34125e22038a},
	abstract = {A conceptual hydrologic rainfall-runoff model that is an adaptation of the operational US National Weather Service hydrologic model is used to simulate the hydrologic processes in large basins of the US upper Mississippi region. In particular, the conceptual rainfall-runoff model is used to produce daily streamflow from daily rainfall, temperature and potential evapotranspiration input over three neighboring headwater basins that span 2° longitude by 2° latitude. When used for simulation of historical flows, the model provides a means of inference of the 40 year time series of unrecorded mesoscale soil water and actual evapo-transpiration for climate studies. In this paper we discuss issues associated with parameter estimation, the reliability and stability of parameter estimates, and the interpretation of soil water estimates. It is concluded that the conceptual hydrologic model may be used to estimate the variability of aggregate soil water over large areas of the Midwestern US provided that: (a) all significant basin inflows and outflows are accounted for; (b) model verification yields good agreement between observed and simulated flows on a daily basis. Parameter sensitivity studies showed that estimating the soil's capacity to hold water is most important for flood event prediction and flow simulation, and, for such parameters, underestimation is more critical than overestimation. Also, uncertainty associated with the parametrization of evapo-transpiration may introduce local errors in the time series of soil water estimates produced by the model. In a companion paper we present a spatio-temporal analysis of the estimated time series of soil water. © 1994.},
	keywords = {USA, (Midwest); Climate; Hydrology; Modelling; Soils; Variability; Water; climate variability; evapotranspiration; hydrological model; mesoscale; precipitation; soil water content; temperature},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{Yuan2016,
	author = {Yuan, Kun and Wu, Junjie and Zhao, Zhonghua},
	title = {Burst prediction from Weibo: A crowd-sensing and tweet-centric method},
	year = {2016},
	journal = {2016 13th International Conference on Service Systems and Service Management, ICSSSM  2016},
	doi = {10.1109/ICSSSM.2016.7538627},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986558126&doi=10.1109%2fICSSSM.2016.7538627&partnerID=40&md5=7f31bc4e0b3358952b293dd4297266a5},
	abstract = {Online social media such as Weibo generates copious and to-The-minute information about real-world events of all kinds. How to effectively and efficiently detect emergent events from massive tweet streams is now drawing attention from various sources of every interest. Despite the wealth of previous research work, bursty topic detection (or burst prediction) remains a huge challenge because of certain qualities in the data such as sparseness of useable information and an enormous amount of noise in each data set. In particular, the conventional term-frequency-based approaches may not be appropriate in this context, since the propagation of Weibo events is typically driven by a few influential posts, which are often buried among irrelevant noisy tweets with frequent but trivial terms. Other commonly used methods, such as topic models, may also fail to detect bursty events due to the high sparseness of tweets and high computational complexity. In light of this, this paper proposes a crowd-sensing, tweet-centric method for burst prediction. That is, we first select influential users on Weibo as social sensors to perceive bursty events via their posts or reposts. This is indeed crucial for excluding the interference of unimportant tweets and reducing computational costs. All the tweets are then subject to the filtering of uninteresting topics and the remainder is then monitored for possible bursts according to the modeling of the time-series of retweeted occurrences. Extensive experiments on real-life huge Weibo datasets show both the efficiency and effectiveness of our approach. In particular, the tweet-centric philosophy of our method provides rich semantics to the detected bursts and thus is of great value in practice. © 2016 IEEE.},
	author_keywords = {bursty events prediction; crowd-sensing; tweet stram; tweet-centric},
	keywords = {Forecasting; Semantics; Computational costs; crowd-sensing; Influential users; Online social medias; Social sensors; Term Frequency; tweet stram; tweet-centric; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Damle2007305,
	author = {Damle, Chaitanya and Yalcin, Ali},
	title = {Flood prediction using Time Series Data Mining},
	year = {2007},
	journal = {Journal of Hydrology},
	volume = {333},
	number = {2-4},
	pages = {305 – 316},
	doi = {10.1016/j.jhydrol.2006.09.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845971941&doi=10.1016%2fj.jhydrol.2006.09.001&partnerID=40&md5=a02af6d8e1b1b176b291904390f4d364},
	abstract = {This paper describes a novel approach to river flood prediction using Time Series Data Mining which combines chaos theory and data mining to characterize and predict events in complex, nonperiodic and chaotic time series. Geophysical phenomena, including earthquakes, floods and rainfall, represent a class of nonlinear systems termed chaotic, in which the relationships between variables in a system are dynamic and disproportionate, however completely deterministic. Chaos theory provides a structured explanation for irregular behavior and anomalies in systems that are not inherently stochastic. While nonlinear approaches such as Artificial Neural Networks, Hidden Markov Models and Nonlinear Prediction are useful in forecasting of daily discharge values in a river, the focus of these approaches is on forecasting magnitudes of future discharge values rather than the prediction of floods. The described Time Series Data Mining methodology focuses on the prediction of events where floods constitute the events in a river daily discharge time series. The methodology is demonstrated using data collected at the St. Louis gauging station located on the Mississippi River in the USA. Results associated with the impact of earliness of prediction and the acceptable risk-level vs. prediction accuracy are presented. © 2006 Elsevier B.V. All rights reserved.},
	author_keywords = {Chaotic systems; Event prediction; River flood forecasting; Time Series Data Mining},
	keywords = {Mississippi River; Missouri; North America; Saint Louis; United States; Chaos theory; Data mining; Floods; Mathematical models; Rivers; Time series analysis; Chaos theory; Data mining; Mathematical models; Rivers; Time series analysis; artificial neural network; chaos theory; data mining; flood forecasting; numerical model; prediction; risk assessment; river discharge; time series analysis; Chaotic systems; Event prediction; River flood forecasting; Time Series Data Mining; Floods},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55}
}

@CONFERENCE{Zhang20175970,
	author = {Zhang, Shengdong and Bahrampour, Soheil and Ramakrishnan, Naveen and Schott, Lukas and Shah, Mohak},
	title = {Deep learning on symbolic representations for large-scale heterogeneous time-series event prediction},
	year = {2017},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	pages = {5970 – 5974},
	doi = {10.1109/ICASSP.2017.7953302},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023769197&doi=10.1109%2fICASSP.2017.7953302&partnerID=40&md5=4e59ed887fd24bac427558de26f8cc94},
	abstract = {In this paper, we consider the problem of event prediction with multi-variate time series data consisting of heterogeneous (continuous and categorical) variables. The complex dependencies between the variables combined with asynchronicity and sparsity of the data makes the event prediction problem particularly challenging. Most state-of-art approaches address this either by designing hand-engineered features or breaking up the problem over homogeneous variates. In this work, we formulate the (rare) event prediction task as a classification problem with a novel asymmetric loss function and propose an end-to-end deep learning algorithm over symbolic representations of time-series. Symbolic representations are fed into an embedding layer and a Long Short Term Memory Neural Network (LSTM) layer which are trained to learn discriminative features. We also propose a simple sequence chopping technique to speed-up the training of LSTM for long temporal sequences. Experiments on real-world industrial datasets demonstrate the effectiveness of the proposed approach. © 2017 IEEE.},
	author_keywords = {Event Prediction; Feature Discovery; Recurrent Networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Yan200629,
	author = {Yan, Xiangbin and Li, Yijun and Cui, Guangbin},
	title = {Event prediction based on time series data mining},
	year = {2006},
	journal = {Jisuanji Gongcheng/Computer Engineering},
	volume = {32},
	number = {5},
	pages = {29 – 31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645771263&partnerID=40&md5=91a19636d51a2b4ce3db0e9038b32aed},
	abstract = {A research on event prediction in time series based on data mining method is undertaken. A significant feature extraction algorithm and a corresponding feature similar measure are proposed. Time series is transformed into feature sequence by application of the clustering algorithm. Prediction pattern for event is extracted in prediction period through using frequent feature pattern searching algorithm and prediction pattern generating algorithm. Experimental results indicate that the proposed method is effective in event prediction.},
	author_keywords = {Clustering; Data mining; Event; Feature; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Vilalta2002474,
	author = {Vilalta, Ricardo and Sheng, Ma.},
	title = {Predicting rare events in temporal domains},
	year = {2002},
	journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
	pages = {474 – 481},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149354391&partnerID=40&md5=774a69dce6458d73faf9a09803fc950b},
	abstract = {Temporal data mining aims at finding patterns in historical data. Our work proposes an approach to extract temporal patterns from data to predict the occurrence of target events, such as computer attacks on host networks, or fraudulent transactions in financial institutions. Our problem formulation exhibits two major challenges: 1) we assume events being characterized by categorical features and displaying uneven inter-arrival times; such an assumption falls outside the scope of classical time-series analysis, 2) we assume target events are highly infrequent; predictive techniques must deal with the class-imbalance problem. We propose an efficient algorithm that tackles the challenges above by transforming the event prediction problem into a search for all frequent eventsets preceding target events. The class imbalance problem is overcome by a search for patterns on the minority class exclusively; the discrimination power of patterns is then validated against other classes. Patterns are then combined into a rule-based model for prediction. Our experimental analysis indicates the types of event sequences where target events can be accurately predicted. © 2002 IEEE.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 123}
}

@CONFERENCE{2017,
	title = {CEUR Workshop Proceedings},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {2086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046030399&partnerID=40&md5=3fe0177b322d1d87d2d81ffecdcd1803},
	abstract = {The proceedings contain 26 papers. The topics discussed include: approaches and techniques for analysing WiFi location data; assessing the usefulness of different feature sets for predicting the comprehension difficulty of text; finding niche topics using semisupervised topic modeling via word embeddings; running with cases: a CBR approach to running your best marathon; pinyin as subword unit for Chinese-sourced neural machine translation; how short is a piece of string?: the impact of text length and text augmentation on short-text classification; semi-supervised overlapping community finding with pairwise constraints; how do distance runners experience inner speech? an empirical investigation; a cognitive learning model that combines feature formation and event prediction; inferring waypoints in the absence of knowledge of driving style; on the relationship between sampling rate and hidden Markov models accuracy in nonintrusive load monitoring; multi-resolution forecast aggregation for time series in agri datasets; multilevel attention-based neural networks for distant supervised relation extraction; adoption, architecture and technology of enterprise IoT systems – towards a framework of concerns in IoT environments; and a computational lymph tissue model for long term HIV infection progression and immune fitness.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Henriques2015678,
	author = {Henriques, Jorge and Carvalho, Paulo and Rocha, Teresa and Paredes, Simão and Morais, João},
	title = {Multi-parametric trends analysis and events prediction in the context of a cardiac rehabilitation system},
	year = {2015},
	journal = {IFMBE Proceedings},
	volume = {45},
	pages = {678 – 681},
	doi = {10.1007/978-3-319-11128-5_169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937810428&doi=10.1007%2f978-3-319-11128-5_169&partnerID=40&md5=8dfa9ab7eeb6b3ac24cbac38acc633a7},
	abstract = {The final goal of this work is the development of methodologies for time series prediction. The aim is to support the forecast of biosignals collected by telemonitoring systems, as well as the early detection of critical events (such as hypertension episodes, based on the evolution of blood pressure). The main hypothesis is that the estimation of biosignals future evolution can be supported on current and past measurements taken from historical data. To this end, two main stages are considered: similarity analysis, to find a set of similar patterns in the historical dataset followed by a prediction mechanism, based on the obtained patterns. Two approaches are proposed based on this principle: singleparametric and multi-parametric ones. The validation and comparison of both single and multiparametric approaches is performed using blood pressure, heart rate and body weight signals collected during the myHeart telemonitoring study. © Springer International Publishing Switzerland 2015.},
	author_keywords = {Biosignals prediction; Early diagnosis; Similarity measures; Wavelets},
	keywords = {Biochemical engineering; Biology; Blood pressure; Diagnosis; Biosignals; Cardiac rehabilitations; Early diagnosis; Prediction mechanisms; Similarity measure; Telemonitoring systems; Time series prediction; Wavelets; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Yan20042874,
	author = {Yan, Xiang-Bin and Tao, Lu and Li, Yi-Jun and Cui, Guang-Bin},
	title = {Research on event prediction in time-series data},
	year = {2004},
	journal = {Proceedings of 2004 International Conference on Machine Learning and Cybernetics},
	volume = {5},
	pages = {2874 – 2878},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-6344229871&partnerID=40&md5=0fe0d7bf2b661e456573e3f105079f46},
	abstract = {Event prediction in time series is an important problem with many real world applications. Existing statistical and machine learning methods are not suitable for the problem. This paper describes a neural network system that predicts events by identifying features extracted from time-series data. A new. feature extraction method is proposed and a corresponding clustering method is given. The method is applied to real time series and the resulting generalization performance of the trained feed-forward neural network predictors is analyzed. It show that the method is effective in event prediction.},
	author_keywords = {Event prediction; Feature; Neural network; Similarity; Time-series},
	keywords = {Feature extraction; Genetic algorithms; Neural networks; Precision balances; Problem solving; Time series analysis; Event prediction; Features; Similarity; Data acquisition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{2014,
	title = {Hybrid Artificial Intelligence Systems - 9th International Conference, HAIS 2014, Proceedings},
	year = {2014},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8480 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902436773&partnerID=40&md5=d8229028176439cafb66f51e154b85c2},
	abstract = {The proceedings contain 61 papers. The topics discussed include: a variable neighborhood search approach for solving the generalized vehicle routing problem; a framework to develop adaptive multimodal dialog systems for android-based mobile devices; wind power ramp event prediction with support vector machines; an ontology for human-machine computation workflow specification; time series segmentation and statistical characterization of the Spanish stock market ibex-35 index; an approach of steel plates fault diagnosis in multiple classes decision making; developing adaptive agents situated in intelligent virtual environments; concurrence among imbalanced labels and its influence on multi-label re-sampling algorithms; constraint and preference modeling for spatial decision making with use of possibility theory; and evaluation of bounding box level fusion of single target video object trackers.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ilhan20151509,
	author = {Ilhan, Nagehan and Öǧüdücü, Şule Gündüz},
	title = {Predicting community evolution based on time series modeling},
	year = {2015},
	journal = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2015},
	pages = {1509 – 1516},
	doi = {10.1145/2808797.2808913},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962525490&doi=10.1145%2f2808797.2808913&partnerID=40&md5=4472f68839b40b4974f8043118c1f11a},
	abstract = {Communities in real life are usually dynamic and community structures evolve over time. Detecting community evolution provides insight into the underlying behavior of the network. A growing body of study is devoted in studying the dynamics of communities in evolving social networks. Most of them provide an event-based framework to characterize and track the community evolution. A part of these studies take a step further and provide a predictive model of the events by exploiting community features. However, the proposed models require the community extraction and computing the community features relevant to the time point to be predicted. In this paper, we proposed a new approach for predicting events by estimating feature values related to the communities in a given network. An event-based framework is used to characterize community behavior patterns. Then, a time series ARIMA model is used to predict how particular community features will change in the following time period. Distinct time windows are examined in constituting and analyzing time series. Our proposed approach efficiently tracks similar communities and identifies events over time. Furthermore, community feature values are forecasted with an acceptable error rate. Event prediction using forecasted feature values substantially match up with actual events. © 2015 ACM.},
	keywords = {Software architecture; Time series; Behavior patterns; Community evolution; Community extractions; Community structures; Event prediction; Growing bodies; Predictive modeling; Time series modeling; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27}
}

@ARTICLE{Gholami2008646,
	author = {Gholami, Ehsanollah and Borujerdi, Mohammadreza Matash},
	title = {Fuzzy knowledge discovery from time series data for events prediction},
	year = {2008},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {5351 LNAI},
	pages = {646 – 657},
	doi = {10.1007/978-3-540-89197-0_59},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58349103606&doi=10.1007%2f978-3-540-89197-0_59&partnerID=40&md5=45383c89051add20655df5742a8907ec},
	abstract = {When the time dimension is added to datasets, time series data are obtained. Extracting knowledge from time series data requires special attention to the timing aspects of the data. An interesting activity in the field of knowledge discovery from time series data is predicting the timing of upcoming events. In this paper we present a method for mining fuzzy knowledge from time series data. In contrast to traditional time series analysis methods which largely focus on global models, our method is about the discovery of local patterns in time series. The extracted knowledge will be in the form of fuzzy association rules and it aims at predicting the approximate timing of upcoming events. The proposed method includes cleaning and filtering of time series data, segmenting time series, extracting important features for prediction, further cleaning on feature values, fuzzifying feature values, extracting fuzzy association rules, and pruning the discovered rules. We will show the efficiency of our approach on a stock market dataset. © 2008 Springer Berlin Heidelberg.},
	author_keywords = {Fuzzy association Rules; Knowledge discovery; Post-processing; Preprocessing; Time series},
	keywords = {Artificial intelligence; Association rules; Associative processing; Bionics; Feature extraction; Forecasting; Fuzzy rules; Knowledge based systems; Time measurement; Fuzzy association Rules; Knowledge discovery; Post-processing; Preprocessing; Time series; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Lin201013,
	author = {Lin, Jessica and Li, Yuan},
	title = {Finding approximate frequent patterns in streaming medical data},
	year = {2010},
	journal = {Proceedings - IEEE Symposium on Computer-Based Medical Systems},
	pages = {13 – 18},
	doi = {10.1109/CBMS.2010.6042675},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80055071907&doi=10.1109%2fCBMS.2010.6042675&partnerID=40&md5=f9e30b542d520ee70f52241c4fc49b91},
	abstract = {Time series data is ubiquitous and plays an important role in virtually every domain. For example, in medicine, the advancement of computer technology has enabled more sophisticated patients monitoring, either on-site or remotely. Such monitoring produces massive amount of time series data, which contain valuable information for pattern learning and knowledge discovery. In this paper, we explore the problem of identifying frequently occurring patterns, or motifs, in streaming medical data. The problem of frequent patterns mining has many potential applications, including compression, summarization, and event prediction. We propose a novel approach based on grammar induction that allows the discovery of approximate, variable-length motifs in streaming data. The preliminary results show that the grammar-based approach is able to find some important motifs in some medical data, and suggest that using grammar-based algorithms for time series pattern discovery might be worth exploring. © 2010 IEEE.},
	author_keywords = {Frequent Patterns; Grammar Induction; Time Series},
	keywords = {Computational grammars; Time series; Computer technology; Event prediction; Frequent patterns; Grammar induction; Medical data; Pattern Learning; Potential applications; Streaming data; Time series patterns; Time-series data; Medical computing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@ARTICLE{Kovalev2016142,
	author = {Kovalev, Sergey and Sukhanov, Andrey},
	title = {Reconstructed phase space method for event prediction based on Sugeno-type fuzzy inference},
	year = {2016},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {281},
	pages = {142 – 148},
	doi = {10.3233/978-1-61499-619-4-142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964575255&doi=10.3233%2f978-1-61499-619-4-142&partnerID=40&md5=fcc3e0ca38c9c91ecce247c89b4d41c7},
	abstract = {This paper proposes the modified time series data mining framework applying Reconstructed Phase Space to construct clusters from the temporal patterns, which are predictive of interesting events. Cluster objective function used in the presented technique is defined not only by cluster internal predictive patterns but also by estimation of the efficacy of cluster to characterize the predictive clusters. For prediction stage, framework uses initial both information about predictive clusters and expert knowledges by applying Sugeno-type fuzzy inference. Experimental results demonstrate presented framework can reach more effective results than existed algorithms, which utilize reconstructed phase space. © 2016 The authors and IOS Press. All rights reserved.},
	author_keywords = {Anomaly detection; Cluster analysis; Interesting event identification; Reconstructed phase space; Time-series prediction},
	keywords = {Cluster analysis; Data mining; Forecasting; Fuzzy inference; Fuzzy systems; Time series; Time series analysis; Anomaly detection; Event identification; Event prediction; Objective functions; Reconstructed phase space; Temporal pattern; Time series data mining; Time series prediction; Phase space methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Peddemors2010401,
	author = {Peddemors, Arjan and Eertink, Henk and Niemegeers, Ignas},
	title = {Predicting mobility events on personal devices},
	year = {2010},
	journal = {Pervasive and Mobile Computing},
	volume = {6},
	number = {4},
	pages = {401 – 423},
	doi = {10.1016/j.pmcj.2009.11.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956408100&doi=10.1016%2fj.pmcj.2009.11.001&partnerID=40&md5=c98ae1be6a09dab02a414b69ef07d03c},
	abstract = {High-end mobile phones are quickly becoming versatile sensing platforms, capable of continuously capturing the dynamic context of their owners through various sensors. A change in this context is often caused by the fact that ownersand therefore the devices they carryare moving from one place to another. In this paper, we model the sensed environment as a stream of events, and assume, given that people are creatures of habit, that time correlations exists between successive events. We propose a method for the prediction in time of the next occurrence of an event of interest, such as 'arriving at a certain location' or 'meeting with another person', with a focus on the prediction of network visibility events as observed through the wireless network interfaces of the device. Our approach is based on using other events in the stream as predictors for the event we are interested in, and, in the case of multiple predictors, applying different strategies for the selection of the best predictor. Using two real-world data sets, we found that including predictors of infrequently occurring events results in better predictions using the best selection strategy. Also, we found that cross-sensor (cross-interface) information in most cases improves the prediction performance. © 2010 Elsevier B.V. All rights reserved.},
	author_keywords = {Context-awareness; Event prediction; Kernel density estimation; Mobility modeling; Personalization; Time series},
	keywords = {Computer science; Mobile computing; Time series; Context- awareness; Event prediction; Kernel Density Estimation; Mobility model; Personalizations; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Kim2016783,
	author = {Kim, Yongwook Bryce and O'Reilly, Una-May},
	title = {Analysis of locality-sensitive hashing for fast critical event prediction on physiological time series},
	year = {2016},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	volume = {2016-October},
	pages = {783 – 787},
	doi = {10.1109/EMBC.2016.7590818},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009100506&doi=10.1109%2fEMBC.2016.7590818&partnerID=40&md5=1fbce41581a34c4ea295d6205f885846},
	abstract = {We apply the sublinear time, scalable locality-sensitive hashing (LSH) and majority discrimination to the problem of predicting critical events based on physiological waveform time series. Compared to using the linear exhaustive k-nearest neighbor search, our proposed method vastly speeds up prediction time up to 25 times while sacrificing only 1% of accuracy when demonstrated on an arterial blood pressure dataset extracted from the MIMIC2 database. We compare two widely used variants of LSH, the bit sampling based (L1LSH) and the random projection based (E2LSH) methods to measure their direct impact on retrieval and prediction accuracy. We experimentally show that the more sophisticated E2LSH performs worse than L1LSH in terms of accuracy, correlation, and the ability to detect false negatives. We attribute this to E2LSH's simultaneous integration of all dimensions when hashing the data, which actually makes it more impotent against common noise sources such as data misalignment. We also demonstrate that the deterioration of accuracy due to approximation at the retrieval step of LSH has a diminishing impact on the prediction accuracy as the speed up gain accelerates. © 2016 IEEE.},
	keywords = {Acute Disease; Algorithms; Blood Pressure; Databases, Factual; Early Diagnosis; Humans; Intensive Care Units; Models, Theoretical; Sensitivity and Specificity; acute disease; algorithm; blood pressure; early diagnosis; factual database; human; intensive care unit; physiology; sensitivity and specificity; theoretical model},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Sharov200665,
	author = {Sharov, S.A. and Dolenko, S.A. and Persiantsev, I.G.},
	title = {The applicability of wavelet transform to the extraction of informative features from the images of the Sun},
	year = {2006},
	journal = {Pattern Recognition and Image Analysis},
	volume = {16},
	number = {1},
	pages = {65 – 67},
	doi = {10.1134/S1054661806010202},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746098884&doi=10.1134%2fS1054661806010202&partnerID=40&md5=a1fd9a684d0735d722a2f1b1d567a247},
	abstract = {The potentialities of wavelet analysis for extracting informative features from the images of complicated objects existing on the Sun's surface and in the solar corona are investigated. Images being analyzed are derived from the solar imagery obtained by the SOHO satellite, a joint ESA/NASA project. The extracted features may be used to form multidimensional time series of data, which are important for subsequent analysis and solar event prediction. © Pleiades Publishing, Inc., 2006.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cortez2018315,
	author = {Cortez, Bitzel and Carrera, Berny and Kim, Young-Jin and Jung, Jae-Yoon},
	title = {An architecture for emergency event prediction using LSTM recurrent neural networks},
	year = {2018},
	journal = {Expert Systems with Applications},
	volume = {97},
	pages = {315 – 324},
	doi = {10.1016/j.eswa.2017.12.037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039755181&doi=10.1016%2fj.eswa.2017.12.037&partnerID=40&md5=f8cb3751f916fdab57c5b89707bc1a9d},
	abstract = {Emergency event prediction is a crucial topic since the events could involve human injuries or even deaths. Many countries record a considerable number of emergency events (EVs) that are caused by a variety of incidents such as murder and robbery. Emergency response systems based on more accurate EV prediction can help to allocate the required resources and resolve the emergencies through more rapid and effective risk management. Most real-time EV prediction systems are based on traditional time series analysis techniques such as moving average or autoregressive integrated moving average (ARIMA) models. To improve the accuracy of EV prediction, we propose a new architecture for EV prediction based on recurrent neural networks (RNN), specifically a long short-term memory (LSTM) architecture. A comparative analysis is presented to show the effectiveness of the proposed architecture compared to traditional time series analysis and machine learning methods through the evaluation of historical EV data provided by the national police of Guatemala. © 2017 Elsevier Ltd},
	author_keywords = {Emergency events; Emergency prediction system; Long short-term memory; Recurrent neural network},
	keywords = {Brain; Crime; Forecasting; Harmonic analysis; Learning systems; Long short-term memory; Memory architecture; Network architecture; Real time systems; Risk management; Time series analysis; Autoregressive integrated moving average models; Comparative analysis; Emergency events; Emergency response systems; Machine learning methods; Prediction systems; Proposed architectures; Recurrent neural network (RNN); Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 127}
}

@ARTICLE{Hajihashemi2016953,
	author = {Hajihashemi, Zahra and Popescu, Mihail},
	title = {A Multidimensional Time-Series Similarity Measure with Applications to Eldercare Monitoring},
	year = {2016},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	volume = {20},
	number = {3},
	pages = {953 – 962},
	doi = {10.1109/JBHI.2015.2424711},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969802861&doi=10.1109%2fJBHI.2015.2424711&partnerID=40&md5=e61cc359fe8883c6f481d8d551ca368d},
	abstract = {In the last decade, data mining techniques have been applied to sensor data in a wide range of application domains, such as healthcare monitoring systems, manufacturing processes, intrusion detection, database management, and others. Many data mining techniques are based on computing the similarity between two sensor data patterns. A variety of representations and similarity measures for multiattribute time series have been proposed in the literature. In this paper, we describe a novel method for computing the similarity of two multiattribute time series based on a temporal version of Smith-Waterman (SW), a well-known bioinformatics algorithm. We then apply our method to sensor data from an eldercare application for early illness detection. Our method mitigates difficulties related to data uncertainty and aggregation that often arise when processing sensor data. The experiments take place at an aging-in-place facility, TigerPlace, located in Columbia, MO, USA. To validate our method, we used data from nonwearable sensor networks placed in TigerPlace apartments, combined with information from an electronic health record. We provide a set of experiments that investigate temporal version of SW properties, together with experiments on TigerPlace datasets. On a pilot sensor dataset from nine residents, with a total of 1902 days and around 2.1 million sensor hits of collected data, we obtained an average abnormal events prediction F-measure of 0.75. © 2015 IEEE.},
	author_keywords = {Genetic algorithm; multiattribute time series; Smith-Waterman (SW) algorithm; time-series data mining},
	keywords = {Activities of Daily Living; Algorithms; Data Mining; Humans; Independent Living; Monitoring, Ambulatory; Signal Processing, Computer-Assisted; Time Factors; Genetic algorithms; Information management; Intrusion detection; Sensor networks; Time series; Database management; Electronic health record; Healthcare monitoring; Manufacturing process; Multi-attributes; Multidimensional time series; Smith-Waterman; Time series data mining; algorithm; ambulatory monitoring; classification; daily life activity; data mining; human; independent living; procedures; signal processing; time factor; Data mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Boubrahimi20172533,
	author = {Boubrahimi, Soukaina Filali and Aydin, Berkay and Martens, Petrus and Angryk, Rafal},
	title = {On the prediction of >100 MeV solar energetic particle events using GOES satellite data},
	year = {2017},
	journal = {Proceedings - 2017 IEEE International Conference on Big Data, Big Data 2017},
	volume = {2018-January},
	pages = {2533 – 2542},
	doi = {10.1109/BigData.2017.8258212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047854620&doi=10.1109%2fBigData.2017.8258212&partnerID=40&md5=99befe95c192c858e0500c165cc2cc8b},
	abstract = {Solar energetic particles are a result of intense solar events such as solar flares and Coronal Mass Ejections (CMEs). These latter events all together can cause major disruptions to spacecraft that are in Earth's orbit and outside of the magnetosphere. In this work we are interested in establishing the necessary conditions for a major geo-effective solar particle storm immediately after a major flare, namely the existence of a direct magnetic connection. To our knowledge, this is the first work that explores not only the correlations of GOES X-ray and proton channels, but also the correlations that happen across all the proton channels. We found that proton channels autocorrelations and cross-correlations may also be precursors to the occurrence of an SEP event. In this paper, we tackle the problem of predicting >100 MeV SEP events from a multivariate time series perspective using easily interpretable decision tree models. © 2017 IEEE.},
	author_keywords = {100 MeV SEP; CART decision tree; GOES X-ray and Proton correlation; SEP Events Prediction; Vector autoregression},
	keywords = {Big data; Decision trees; Elementary particles; Forecasting; Magnetosphere; Regression analysis; X rays; 100 MeV SEP; Coronal mass ejection; Cross correlations; Decision tree models; Multivariate time series; Solar energetic particle events; Solar energetic particles; Vector autoregressions; Orbits},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{Hürriyetoʇlu201320,
	author = {Hürriyetoʇlu, Ali and Kunneman, Florian and Van Den Bosch, Antal},
	title = {Estimating the time between twitter messages and future events},
	year = {2013},
	journal = {CEUR Workshop Proceedings},
	volume = {986},
	pages = {20 – 23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921902139&partnerID=40&md5=71ac49dcdb5b9aa35d7c0d170fc0551d},
	abstract = {We describe and test three methods to estimate the remain-ing time between a series of microtexts (tweets) and the future event they refer to via a hashtag. Our system gener-ates hourly forecasts. A linear and a local regression-based approach are applied to map hourly clusters of tweets directly onto time-to-event. To take changes over time into account, we develop a novel time series analysis approach that first derives word frequency time series from sets of tweets and then performs local regression to predict time- to-event from nearest-neighbor time series. We train and test on a single type of event, Dutch premier league foot- ball matches. Our results indicate that in an 'early' stage, four days or more before the event, the time series analysis produces time-to-event predictions that are about one day off; closer to the event, local regression attains a similar ac-curacy. Local regression also outperforms both mean and median-based baselines, but on average none of the tested system has a consistently strong performance through time.},
	author_keywords = {Event prediction; Time series analysis; Twitter},
	keywords = {Forecasting; Harmonic analysis; Information retrieval; Regression analysis; Social networking (online); Event prediction; Local regression; Nearest neighbors; Time to events; Twitter; Word frequencies; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Gupta2011243,
	author = {Gupta, Dhawal and Shahani, D.T.},
	title = {Estimation of radon as an earthquake precursor: A neural network approach},
	year = {2011},
	journal = {Journal of the Geological Society of India},
	volume = {78},
	number = {3},
	pages = {243 – 248},
	doi = {10.1007/s12594-011-0090-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80855156369&doi=10.1007%2fs12594-011-0090-8&partnerID=40&md5=ea5678b31f45de66b7483e608f3a89f5},
	abstract = {An artificial neural networks (ANN) approach combined with Fourier Transform based selection of time period in the time series Radon Emission Data has been presented and shown to improve event prediction rates and reduce false alarms in Earthquake Event Identification over the traditional multiple linear regression techniques. The paper presents a neural networks system using radial basis function (RBF) network as an alternative to traditional statistical regression technique in isolating Radon Emission Anomaly caused by seismic activities. The RBF model has been developed to accept and predict earthquakes events based on a known data set of Radon Emanation, Metrological parameters and actual earthquake events. Subsequently, the model was tested and evaluated on a future data set and a prediction rate of 87.8%, if a reduced false alarm was achieved, the results obtained are better than the traditional techniques. © 2011 Geological Society of India.},
	author_keywords = {Modeling; Neural Network; Prediction; Radon precursor},
	keywords = {artificial neural network; earthquake precursor; earthquake prediction; estimation method; Fourier transform; identification method; numerical model; parameterization; radon; regression analysis; seismicity},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Sahoo2003426,
	author = {Sahoo, R.K. and Oliner, A.J. and Rish, I. and Gupta, M. and Moreira, J.E. and Ma, S. and Vilalta, R. and Sivasubramaniam, A.},
	title = {Critical event prediction for proactive management in large-scale computer clusters},
	year = {2003},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {426 – 435},
	doi = {10.1145/956750.956799},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952378080&doi=10.1145%2f956750.956799&partnerID=40&md5=3d71b04dec9f1ff11e4f77091e0ef0f5},
	abstract = {As the complexity of distributed computing systems increases, systems management tasks require significantly higher levels of automation; examples include diagnosis and prediction based on real-time streams of computer events, setting alarms, and performing continuous monitoring. The core of autonomic computing, a recently proposed initiative towards next-generation IT-systems capable of 'self-healing', is the ability to analyze data in real-time and to predict potential problems. The goal is to avoid catastrophic failures through prompt execution of remedial actions.This paper describes an attempt to build a proactive prediction and control system for large clusters. We collected event logs containing various system reliability, availability and serviceability (RAS) events, and system activity reports (SARs) from a 350-node cluster system for a period of one year. The 'raw' system health measurements contain a great deal of redundant event data, which is either repetitive in nature or misaligned with respect to time. We applied a filtering technique and modeled the data into a set of primary and derived variables. These variables used probabilistic networks for establishing event correlations through prediction algorithms. We also evaluated the role of time-series methods, rule-based classification algorithms and Bayesian network models in event prediction.Based on historical data, our results suggest that it is feasible to predict system performance parameters (SARs) with a high degree of accuracy using time-series models. Rule-based classification techniques can be used to extract machine-event signatures to predict critical events with up to 70% accuracy. Copyright 2003 ACM.},
	author_keywords = {Critical event prediction; Large-scale clusters; System event log},
	keywords = {Algorithms; Bayesian networks; Cluster computing; Computer hardware description languages; Continuous time systems; Data mining; Forecasting; Inference engines; Security of data; Activity report; Autonomic Computing; Availability and serviceability; Bayesian network models; Catastrophic failures; Cluster systems; Computer clusters; Continuous monitoring; Critical events; Distributed computing systems; Event correlation; Filtering technique; Health measurement; High degree of accuracy; Historical data; Large clusters; Large-scale clusters; Levels of automation; Potential problems; Prediction algorithms; Prediction and control; Proactive management; Probabilistic network; Redundant event; Rule-based classification; Self-healing; System performance parameters; System reliability; Systems management; Time series models; Real time systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 204}
}

@ARTICLE{20171,
	title = {17th Industrial Conference on Advances in Data Mining, ICDM 2017},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10357 LNAI},
	pages = {1 – 344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025156774&partnerID=40&md5=469aa52e8aef5f792be328c2f784e650},
	abstract = {The proceedings contain 26 papers. The special focus in this conference is on Advances in Data Mining. The topics include: Incorporating positional information into deep belief networks for sentiment classification; tracking multiple social media for stock market event prediction; ensemble sales forecasting study in semiconductor industry; association rule-based classifier using artificial missing values; mining location-based service data for feature construction in retail store recommendation; constraint-based clustering algorithm for multi-density data and arbitrary shapes; towards a large scale practical churn model for prepaid mobile markets; multivariate time series representation and similarity search using PCA; fast GPU-based influence maximization within finite deadlines via node-level parallelism; visual scenes mining for agent awareness module; predicting hospital re-admissions from nursing care data of hospitalized patients; activity prediction in process management using the woman framework; collaborative filtering fusing label features based on SDAE; interestingness classification of association rules for master data; mapreduce and spark-based analytic framework using social media data for earlier flu outbreak detection; using the results of capstone analysis to predict a weather outcome; classification of network traffic using fuzzy clustering for network security; machine learning and pattern recognition techniques for information extraction to improve production control and design decisions; real-time prediction of styrene production volume based on machine learning algorithms; a graph-based ranking model for automatic keyphrases extraction from arabic documents; mining frequent subgraph pattern over a collection of attributed-graphs and construction of a relation hierarchy for result reporting.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lajevardi2008111,
	author = {Lajevardi, Seyed Behzad and Minaei-Bidgoli, Behrouz},
	title = {Combination of time series, Decision Tree and clustering: A case study in Aerology event prediction},
	year = {2008},
	journal = {Proceedings of the 2008 International Conference on Computer and Electrical Engineering, ICCEE 2008},
	pages = {111 – 115},
	doi = {10.1109/ICCEE.2008.110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949181227&doi=10.1109%2fICCEE.2008.110&partnerID=40&md5=f84246bbb32644fe3892d30f59837092},
	abstract = {Predictive systems use historical and other available data to predict an event. In this paper we propose a general framework to predict the Aerology events with time series streams and events stream using combination of K-means clustering algorithm and Decision Tree C5 algorithm. Firstly, we find the closest time series record for any events; therefore, we have gathered different parameters value when an event is occurring. Using K-means we add a field to data set which determines the cluster of each record after that by using C5 algorithm we predict events. C5 Decision Tree Algorithm is one of the well-known Decision Tree Algorithms. This framework and time series model can predict future events efficiently. We gathered 1961 until 2005 data of aerology organization for Tehran Mehrabad Station. This data contains some fields such as wet bulb, relative humidity, amount of cloud, wind speed and etc. This data set includes 17 types of events. Time series models can predict next time series parameters value and by using this Framework the closest event can be predicted. The C5 method is able to predict Events with Correct 74.11 percent and Wrong 25.89 percent. But with the aims of K-means clustering algorithm the prediction increase to 85 percent and wrong to 15 percent. 90 percent of data was used for training set and 10 percent for test set. We use 10-fold cross validation to evaluate our prediction rate. This framework is the first estimation in the area of event prediction for a huge data set of aerology and can be extended in many different data sets in any other environments. © 2008 IEEE.},
	keywords = {Atmospheric humidity; Clustering algorithms; Decision trees; Electrical engineering; Meteorology; Water supply systems; Cross validations; Data sets; Decision-tree algorithms; Event predictions; K-Means; K-means clustering algorithms; Prediction rates; Predictive systems; Relative humidities; Test sets; Time-series models; Training sets; Wet bulbs; Wind speed; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Stolze2018858,
	author = {Stolze, David and McConky, Katie and Kuhl, Michael and Yang, Shanchieh Jay},
	title = {Feature engineering of time-series data to extract discriminative features},
	year = {2018},
	journal = {IISE Annual Conference and Expo 2018},
	pages = {858 – 864},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054010450&partnerID=40&md5=169e9cc0ff35e3091ed418971b5faa2d},
	abstract = {Time-series data streams often contain predictive value in the form of unique patterns. While these patterns may be used as leading indicators for event prediction, a lack of prior knowledge of pattern shape and irregularities can render traditional forecasting methods ineffective. This research tests an automated means of predetermining the most effective combination of transformations to be applied to time-series data when training a classification algorithm. This method relies on using meta-features of a provided data set such as coefficient of variation and length to determine optimal transformations to test based on past trials. The transformations applied include converting values of the time-series data stream into a binary data set, with each anomalous value being labeled as a “1”. The number of binary points to be used for training is varied to determine an optimal length. The training set is then aggregated into bins containing a set number of data points, with each bin represented by the summation of the contained binary values. Application of these transformations creates a simplified set of values with which a classifier is trained. By comparing the performance of multiple trained classifiers generated using different transformation parameters, an optimal combination may be determined. © 2018 Institute of Industrial Engineers (IIE). All rights reserved.},
	author_keywords = {Feature Engineering; Machine Learning; Predictive Analytics},
	keywords = {Learning systems; Predictive analytics; Statistical tests; Time series; Classification algorithm; Coefficient of variation; Discriminative features; Feature engineerings; Forecasting methods; Optimal combination; Optimal transformation; Transformation parameters; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mehrmolaei2015235,
	author = {Mehrmolaei, Soheila and Keyvanpourr, Mohammad Reza},
	title = {A brief survey on event prediction methods in time series},
	year = {2015},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {347},
	pages = {235 – 246},
	doi = {10.1007/978-3-319-18476-0_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940910088&doi=10.1007%2f978-3-319-18476-0_24&partnerID=40&md5=c1d38bb3d7862a0b39ae6bea6d04b76e},
	abstract = {Time series mining is a new area of research in temporal data bases. Hitherto various methods have been presented for time series mining which the most of an existing works in different applied areas have been focused on event prediction. Event prediction is one of the main goals of time series mining which can play an effective role for appropriate decision making in different applied areas. Due to the variety and plenty of event prediction methods in time series and lack of a proper context for their systematic introduction, in this paper, a classification is proposed for event prediction methods in time series. Also, event prediction methods in time series are evaluated based on the proposed classification by some proposed measures. Using the proposed classification can be beneficial in selecting the appropriate method and can play an effective role in the analysis of event prediction methods in different application domains © Springer International Publishing Switzerland 2015.},
	author_keywords = {Event prediction; Methods; Time series; Time series mining},
	keywords = {Artificial intelligence; Decision making; Forecasting; Social networking (online); Event prediction; Methods; Temporal Data; Time-series mining; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Singh2012165,
	author = {Singh, Raj Mohan},
	title = {Wavelet-ANN model for flood events},
	year = {2012},
	journal = {Advances in Intelligent and Soft Computing},
	volume = {131 AISC},
	number = {VOL. 2},
	pages = {165 – 175},
	doi = {10.1007/978-81-322-0491-6_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861211172&doi=10.1007%2f978-81-322-0491-6_16&partnerID=40&md5=1269d73ca3e99887eb5f0f07f81f7155},
	abstract = {The observation of peak flows into river or stream system is not straight forward but complex function of hydrology and geology of the region. There are well established statistical approach to predict the flood events with their magnitude and frequency. Development of models based on temporal observations may improve understanding the underlying hydrological processes in such complex phenomena. Present work utilized temporal patterns extracted from temporal observations of annual peak series using wavelet theory. These patterns are then utilized by an artificial neural network (ANN). The wavelet-ANN conjunction model is then able to predict the flood event comparable to statistical approach. The application of the proposed methodology is illustrated with real data. The limited performance evaluation of the methodology show potential application of the developed methodology. © 2012 Springer India Pvt. Ltd.},
	author_keywords = {ANN; Flood event prediction; Time series modeling; Wavelet analysis; Wavelet-ANN},
	keywords = {Forecasting; Neural networks; Problem solving; Soft computing; Wavelet analysis; ANN; Complex functions; Flood event; Hydrological process; Peak flows; Performance evaluation; Potential applications; Statistical approach; Temporal pattern; Time series modeling; Wavelet theory; Wavelet-ANN; Floods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@ARTICLE{20151,
	title = {4th Computer Science On-line Conference, CSOC 2015},
	year = {2015},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {347},
	pages = {1 – 363},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940914892&partnerID=40&md5=8ff15c68fe2789966e6b12255c0808f4},
	abstract = {The proceedings contain 35 papers. The special focus in this conference is on Artificial Intelligence Perspectives and Applications. The topics include: A multiagent-based approach to scheduling of multi-component applications in distributed systems; a cellular automaton based approach for real time embedded systems scheduling problem resolution; ways of increasing of the effectiveness of the making decisions by intelligent systems using fuzzy inference; a hybrid model based on mutual information and support vector machine for automatic image annotation; the bioinspired algorithm of electronic computing equipment schemes elements placement; combined method of analyzing anaphoric pronouns and inter-sentential relationships between transitive verbs for enhancing pairs of sentences summarization; pre-processing, repairing and transfer functions can help binary electromagnetism-like algorithms; heuristic feasibility and preprocessing for a set covering solver based on firefly optimization; on the performance of ensemble learning for automated diagnosis of breast cancer; predicting financial distress of banks using random subspace ensembles of support vector machines; interdependence of text mining quality and the input data preprocessing; WSM tuning in autonomous search via gravitational search algorithms; enumeration strategies for solving constraint satisfaction problems; evaluation of the accuracy of numerical weather prediction models; design of fuzzy controller for hexacopter position control; an artificial intelligence approach to nutritional meal planning for cancer patients; energy efficient time synchronization technique in large scale wireless sensor network and a brief survey on event prediction methods in time series.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zaourar20131693,
	author = {Zaourar, Naïma and Hamoudi, Mohamed and Holschneider, Matthias and Mandea, Mioara},
	title = {Fractal dynamics of geomagnetic storms},
	year = {2013},
	journal = {Arabian Journal of Geosciences},
	volume = {6},
	number = {6},
	pages = {1693 – 1702},
	doi = {10.1007/s12517-011-0487-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878332289&doi=10.1007%2fs12517-011-0487-0&partnerID=40&md5=0421b19e394783b14a4ad7e2daeb8633},
	abstract = {We explore fluctuations of the horizontal component of the Earth's magnetic field to identify scaling behaviour of the temporal variability in geomagnetic data recorded by the Intermagnet observatories during the solar cycle 23 (years 1996 to 2005). In this work, we use the remarkable ability of scaling wavelet exponents to highlight the singularities associated with discontinuities present in the magnetograms obtained at two magnetic observatories for six intense magnetic storms, including the sudden storm commencements of 14 July 2000, 29-31 October and 20-21 November 2003. In the active intervals that occurred during geomagnetic storms, we observe a rapid and unidirectional change in the spectral scaling exponent at the time of storm onset. The corresponding fractal features suggest that the dynamics of the whole time series is similar to that of a fractional Brownian motion. Our findings point to an evident relatively sudden change related to the emergence of persistency of the fractal power exponent fluctuations precedes an intense magnetic storm. These first results could be useful in the framework of extreme events prediction studies. © 2011 Saudi Society for Geosciences.},
	author_keywords = {Geomagnetic field; Geomagnetic storm; Magnetosphere; Multiscale analysis; Spectral exponent},
	keywords = {atmospheric electricity; Brownian motion; discontinuity; fractal analysis; geomagnetic field; geomagnetic storm; magnetosphere; time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Wang2018369,
	author = {Wang, Xiuling and Chen, Hao and Li, Zhoujun and Zhao, Zhonghua},
	title = {Unrest news amount prediction with context-aware attention LSTM},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11013 LNAI},
	pages = {369 – 377},
	doi = {10.1007/978-3-319-97310-4_42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051939421&doi=10.1007%2f978-3-319-97310-4_42&partnerID=40&md5=ece618b9c7ca3f7e2e4cae6d118c5a80},
	abstract = {Accurately predicting social unrest events is crucial to improve public security. Currently, with the large scale news event datasets available such as GDELT, we can use the amount of unrest news to estimate the risk of instability which is particularly helpful in resource allocation and policy making. Thus in this paper we propose a context-aware attention based long short-term memory (LSTM) prediction framework named CA-LSTM to accurately predict the amount of unrest news of each country or state in the future. Specifically, we first use LSTM to learn the hidden representation from the raw time series data, and then we employ a temporal attention mechanism to learn the importance weight of each time slot. Finally, a fully connected layer is adopted to predict the future unrest news amount by combining the context information and the time series embedding vectors. We conduct extensive experiments on the GDELT data of the United States, and the results demonstrate the effectiveness of the proposed framework. © Springer International Publishing AG, part of Springer Nature 2018.},
	author_keywords = {Attention LSTM; Context-aware; Unrest event prediction},
	keywords = {Long short-term memory; Risk perception; Time series; Attention LSTM; Attention mechanisms; Context information; Context-Aware; Event prediction; Fully-connected layers; Importance weights; Time-series data; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Singh20131,
	author = {Singh, Raj Mohan},
	title = {Wavelet-ANN model for river sedimentation predictions},
	year = {2013},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {202 AISC},
	number = {VOL. 2},
	pages = {1 – 13},
	doi = {10.1007/978-81-322-1041-2_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875085169&doi=10.1007%2f978-81-322-1041-2_1&partnerID=40&md5=a5cd7f19ada7648bc748526ae35c38be},
	abstract = {The observation of peak flows into river or stream system is not straight forward but complex function of hydrology and geology. Accurate suspended sediment prediction in rivers is an integral component of sustainable water resources and environmental systems modeling. Agricultural fields' fertility decays, rivers capacity decreases and reservoirs are filled due to sedimentation. The observation of suspended sediment flows into river or stream system is not straight forward but complex function of hydrology and geology of the region. There are statistical approaches to predict the suspended sediments in rivers. Development of models based on temporal observations may improve understanding the underlying hydrological processes complex phenomena of river sedimentation. Present work utilized temporal patterns extracted from temporal observations of annual peak series using wavelet theory. These patterns are then utilized by an artificial neural network (ANN). The wavelet-ANN conjunction model is then able to predict the daily sediment load. The application of the proposed methodology is illustrated with real data. © 2013 Springer.},
	author_keywords = {ANN; Suspended sediment event prediction; Time series modeling; Wavelet analysis; Wavelet-ANN},
	keywords = {Computation theory; Forecasting; Geology; Hydrology; Neural networks; Reservoirs (water); Suspended sediments; Water conservation; Water resources; Wavelet analysis; ANN; Environmental systems modeling; Event prediction; Hydrological process; Statistical approach; Sustainable water resources; Time series modeling; Wavelet-ANN; Rivers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dorado-Moreno2017428,
	author = {Dorado-Moreno, M. and Cornejo-Bueno, L. and Gutiérrez, P.A. and Prieto, L. and Hervás-Martínez, C. and Salcedo-Sanz, S.},
	title = {Robust estimation of wind power ramp events with reservoir computing},
	year = {2017},
	journal = {Renewable Energy},
	volume = {111},
	pages = {428 – 437},
	doi = {10.1016/j.renene.2017.04.016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018536096&doi=10.1016%2fj.renene.2017.04.016&partnerID=40&md5=0ee315ec582556328608ac56f7a6e49a},
	abstract = {Wind power ramp events are sudden increases or decreases of wind speed within a short period of time. Their prediction is nowadays one of the most important research trends in wind energy production because they can potentially damage wind turbines, causing an increase in wind farms management costs. In this paper, 6-h and 24-h binary (ramp/non-ramp) prediction based on reservoir computing methodology is proposed. This forecasting may be used to avoid damages in the turbines. Reservoir computing models are used because they are able to exploit the temporal structure of data. We focus on echo state networks, which are one of the most successfully applied reservoir computing models. The variables considered include past values of the ramp function and a set of meteorological variables, obtained from reanalysis data. Simulations of the system are performed in data from three wind farms located in Spain. The results show that our algorithm proposal is able to correctly predict about 60% of ramp events in both 6-h and 24-h prediction cases and 75% of the non-ramp events in the next 24-h case. These results are compared against state of the art models, obtaining in all cases significant improvements in favour of the proposed algorithm. © 2017 Elsevier Ltd},
	author_keywords = {Echo state networks; Reanalysis data; Recurrent neural networks; Reservoir computing; Time series; Wind power ramp events prediction},
	keywords = {Spain; Electric utilities; Forecasting; Recurrent neural networks; Time series; Wind; Wind effects; Wind turbines; Echo state networks; Meteorological variables; Ramp events; Reanalysis; Reservoir Computing; Robust estimation; Temporal structures; Wind energy production; algorithm; artificial neural network; computer simulation; cost analysis; data set; estimation method; management practice; network analysis; prediction; reservoir; time series; wind farm; wind power; wind velocity; Wind power},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}