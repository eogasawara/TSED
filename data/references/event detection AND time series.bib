Scopus
EXPORT DATE: 14 November 2023

@ARTICLE{Haufe2023,
	author = {Haufe, Stefan and Isaias, Ioannis U. and Pellegrini, Franziska and Palmisano, Chiara},
	title = {Gait Event Prediction Using Surface Electromyography in Parkinsonian Patients},
	year = {2023},
	journal = {Bioengineering},
	volume = {10},
	number = {2},
	doi = {10.3390/bioengineering10020212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149068728&doi=10.3390%2fbioengineering10020212&partnerID=40&md5=ce65a98dd3af63fea2ae69110a53dce6},
	abstract = {Gait disturbances are common manifestations of Parkinson’s disease (PD), with unmet therapeutic needs. Inertial measurement units (IMUs) are capable of monitoring gait, but they lack neurophysiological information that may be crucial for studying gait disturbances in these patients. Here, we present a machine learning approach to approximate IMU angular velocity profiles and subsequently gait events using electromyographic (EMG) channels during overground walking in patients with PD. We recorded six parkinsonian patients while they walked for at least three minutes. Patient-agnostic regression models were trained on temporally embedded EMG time series of different combinations of up to five leg muscles bilaterally (i.e., tibialis anterior, soleus, gastrocnemius medialis, gastrocnemius lateralis, and vastus lateralis). Gait events could be detected with high temporal precision (median displacement of <50 ms), low numbers of missed events (<2%), and next to no false-positive event detections (<0.1%). Swing and stance phases could thus be determined with high fidelity (median F1-score of ~0.9). Interestingly, the best performance was obtained using as few as two EMG probes placed on the left and right vastus lateralis. Our results demonstrate the practical utility of the proposed EMG-based system for gait event prediction, which allows the simultaneous acquisition of an electromyographic signal to be performed. This gait analysis approach has the potential to make additional measurement devices such as IMUs and force plates less essential, thereby reducing financial and preparation overheads and discomfort factors in gait studies. © 2023 by the authors.},
	author_keywords = {electromyography; gait-phase prediction; inertial measurement units; machine learning; Parkinson’s disease},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Lockhart2021,
	author = {Lockhart, Thurmon E. and Soangra, Rahul and Yoon, Hyunsoo and Wu, Teresa and Frames, Christopher W. and Weaver, Raven and Roberto, Karen A.},
	title = {Prediction of fall risk among community-dwelling older adults using a wearable system},
	year = {2021},
	journal = {Scientific Reports},
	volume = {11},
	number = {1},
	doi = {10.1038/s41598-021-00458-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117949603&doi=10.1038%2fs41598-021-00458-5&partnerID=40&md5=ca8d76a42f876dc21b446b63ab008cf0},
	abstract = {Falls are among the most common cause of decreased mobility and independence in older adults and rank as one of the most severe public health problems with frequent fatal consequences. In the present study, gait characteristics from 171 community-dwelling older adults were evaluated to determine their predictive ability for future falls using a wearable system. Participants wore a wearable sensor (inertial measurement unit, IMU) affixed to the sternum and performed a 10-m walking test. Measures of gait variability, complexity, and smoothness were extracted from each participant, and prospective fall incidence was evaluated over the following 6-months. Gait parameters were refined to better represent features for a random forest classifier for the fall-risk classification utilizing three experiments. The results show that the best-trained model for faller classification used both linear and nonlinear gait parameters and achieved an overall 81.6 ± 0.7% accuracy, 86.7 ± 0.5% sensitivity, 80.3 ± 0.2% specificity in the blind test. These findings augment the wearable sensor's potential as an ambulatory fall risk identification tool in community-dwelling settings. Furthermore, they highlight the importance of gait features that rely less on event detection methods, and more on time series analysis techniques. Fall prevention is a critical component in older individuals’ healthcare, and simple models based on gait-related tasks and a wearable IMU sensor can determine the risk of future falls. © 2021, The Author(s).},
	keywords = {Accidental Falls; Aged; Aged, 80 and over; Gait; Gait Analysis; Humans; Incidence; Independent Living; Machine Learning; Prospective Studies; Risk Factors; Sensitivity and Specificity; Wearable Electronic Devices; aged; devices; electronic device; falling; gait; human; incidence; independent living; machine learning; physiology; prevention and control; prospective study; risk factor; sensitivity and specificity; very elderly},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zamee2023,
	author = {Zamee, Muhammad Ahsan and Han, Dongjun and Cha, Heejune and Won, Dongjun},
	title = {Self-supervised online learning algorithm for electric vehicle charging station demand and event prediction},
	year = {2023},
	journal = {Journal of Energy Storage},
	volume = {71},
	doi = {10.1016/j.est.2023.108189},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164219833&doi=10.1016%2fj.est.2023.108189&partnerID=40&md5=79aff76d1d0a5d62d994dca681164545},
	abstract = {With the increasing popularity of electric vehicles (EVs), countries are setting up new charging stations to meet up the rising demand. Therefore, accurately forecasting charging demand and charging events is highly significant. Historical data are crucial for developing a quality forecasting model, but countries or locations with recently installed EV stations suffer from data inadequacy. Delayed data accumulation for forecasting model creation impedes EV's optimal operation, and an offline or fixed-sized data-based learning model may not perform optimally due to the future uncertainties of input variables. Therefore, it is required to create an online forecasting model that can learn right from the beginning of the operation of charging stations, forecast, and relearn, when necessary, by considering the impact of input/external variables. For optimal model development, impactful input variables should be chosen online using appropriate feature engineering. In this research, a unique feature engineering considering multi-level correlation with multicollinearity and simultaneous online learning General Regression Neural Network (GRNN) based on has been suggested. Also due to the discrete and asynchronous nature of the charging event a detailed data handling method has been developed to create meaningful time series data. It is interestingly realized that the proposed model outperforms general Artificial Neural Networks (ANN), various sophisticated models, such as Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Bi-LSTM, Gated Recurrent Unit (GRU), and the Deep Neural Network (DNN) model when the appropriate inputs and their delayed variables are used. © 2023 Elsevier Ltd},
	author_keywords = {Charging demand forecasting; Electric vehicle; Event detection forecasting; General Regression Neural Network; Long short term memory; Online learning},
	keywords = {Brain; Charging (batteries); Data handling; Deep neural networks; E-learning; Electric vehicles; Forecasting; Learning algorithms; Learning systems; Regression analysis; Charging demand forecasting; Charging demands; Charging station; Demand forecasting; Event detection forecasting; Events detection; Forecasting models; General regression neural network; Online learning; Regression neural networks; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{García2022231,
	author = {García, Enol and Villar, Mario and Fáñez, Mirko and Villar, José R. and de la Cal, Enrique and Cho, Sung-Bae},
	title = {Towards effective detection of elderly falls with CNN-LSTM neural networks},
	year = {2022},
	journal = {Neurocomputing},
	volume = {500},
	pages = {231 – 240},
	doi = {10.1016/j.neucom.2021.06.102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131037373&doi=10.1016%2fj.neucom.2021.06.102&partnerID=40&md5=3830731de830093f01a68b4b8efa690f},
	abstract = {Fall detection is a very challenging task that has a clear impact in the autonomous living of the elderly individuals: suffering a fall with no support increases the fears of the elderly population to continue living by themselves. This study proposes the use of a non-invasive tri-axial accelerometer device placed on a wrist to measure the movements of the participant. The novelty of this study is two fold: on the one hand, the use of a Long-Short Term Memory Neural Network (LSTM) for classification of the Time Series and, on the other hand, the proposal of a novel data augmentation stage that introduces variability in the training by merging the Time Series gathered from both human activities of daily living. The experimentation shows that the combination of a LSTM model together with the data augmentation produces more robust and accurate models that perfectly cope with the validation stage; the high impact fall event detection can be considered solved. © 2022 The Author(s)},
	author_keywords = {Data augmentation; Fall detection; Recurrent neural networks},
	keywords = {Fall detection; Time series; 4 aminobutyric acid; Activities of Daily Living; Data augmentation; Elderly falls; Elderly populations; Fall detection; Human activities; Neural network model; Neural-networks; Times series; Triaxial accelerometer; Article; artificial neural network; daily life activity; discriminant analysis; electroencephalography; electromyography; human; long short term memory network; machine learning; nerve cell network; random forest; recurrent neural network; support vector machine; time series analysis; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Gatteschi202253,
	author = {Gatteschi, Valentina and Cannavo, Alberto and Lamberti, Fabrizio and Morra, Lia and Montuschi, Paolo},
	title = {Comparing Algorithms for Aggressive Driving Event Detection Based on Vehicle Motion Data},
	year = {2022},
	journal = {IEEE Transactions on Vehicular Technology},
	volume = {71},
	number = {1},
	pages = {53 – 68},
	doi = {10.1109/TVT.2021.3122197},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118589484&doi=10.1109%2fTVT.2021.3122197&partnerID=40&md5=8688311caeba45a1b8b473ec86b529b9},
	abstract = {Aggressive driving is one of the main causes of fatal crashes. Correctly identifying aggressive driving events still represents a challenge in the literature. Furthermore, datasets available for testing the proposed approaches have some limitations since they generally (a) include only a few types of events, (b) contain data collected with only one device, and (c) are generated in drives that did not fully consider the variety of road characteristics and/or driving conditions. The main objective of this work is to compare the performance of several state-of-The-Art algorithms for aggressive driving event detection (belonging to anomaly detection-, threshold-and machine learning-based categories) on multiple datasets containing sensors data collected with different devices (black-boxes and smartphones), on different vehicles and in different locations. A secondary objective is to verify whether smartphones could replace black-boxes in aggressive/non-Aggressive classification tasks. To this aim, we propose the AD$^2$ (Aggressive Driving Detection) dataset, which contains (i) data collected using multiple devices to evaluate their influence on the algorithm performance, (ii) geographical data useful to analyze the context in which the events occurred, (iii) events recorded in different situations, and (iv) events generated by traveling the same path with aggressive and non-Aggressive driving styles, in order to possibly separate the effects of driving style from those of road characteristics. Our experimental results highlighted the superiority of machine learning-based approaches and underlined the ability of smartphones to ensure a level of performance similar to that of black-boxes.  © 1967-2012 IEEE.},
	author_keywords = {anomaly detection; black-box; classification; Driving behavior; machine learning; smartphone; threshold},
	keywords = {Accidents; Digital storage; Feature extraction; Learning systems; Roads and streets; Time series analysis; Vehicles; Anomaly detection; Black boxes; Driving behaviour; Features extraction; Performances evaluation; Sensor phenomenon and characterizations; Smart phones; Threshold; Time-series analysis; Smartphones},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Satme2022,
	author = {Satme, Joud and Coble, Daniel and Priddy, Braden and Downey, Austin R.J. and Bakos, Jason D. and Comert, Gurcan},
	title = {PROGRESS TOWARDS DATA-DRIVEN HIGH-RATE STRUCTURAL STATE ESTIMATION ON EDGE COMPUTING DEVICES},
	year = {2022},
	journal = {Proceedings of the ASME Design Engineering Technical Conference},
	volume = {10},
	doi = {10.1115/DETC2022-90118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142635641&doi=10.1115%2fDETC2022-90118&partnerID=40&md5=7059b12bea00cd732d69b03c5506974d},
	abstract = {Structures operating in high-rate dynamic environments, such as hypersonic vehicles, orbital space infrastructure, and blast mitigation systems, require microsecond (µs) decision-making. Advances in real-time sensing, edge-computing, and high-bandwidth computer memory are enabling emerging technologies such as High-rate structural health monitoring (HR-SHM) to become more feasible. Due to the time restrictions such systems operate under, a target of 1 millisecond (ms) from event detection to decision-making is set at the goal to enable HR-SHM. With minimizing latency in mind, a data-driven method that relies on time-series measurements processed in real-time to infer the state of the structure is investigated in this preliminary work. A methodology for deploying LSTM-based state estimators for structures using subsampled time-series vibration data is presented. The proposed estimator is deployed to an embedded real-time device and the achieved accuracy along with system timing are discussed. The proposed approach has shown potential for high-rate state estimation as it provides sufficient accuracy for the considered structure while a time-step of 2.5 ms is achieved. The Contributions of this work are twofold: 1) a framework for deploying LSTM models in real-time for high-rate state estimation, 2) an experimental validation of LSTMs running on a real-time computing system. © 2022 by ASME.},
	keywords = {Decision making; Edge computing; Hypersonic vehicles; Interface states; Long short-term memory; Structural health monitoring; Time series; Computing devices; Data driven; Decisions makings; Dynamic environments; Edge computing; High rate; Orbital space; Real- time; Structural state; Times series; State estimation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fayad202289,
	author = {Fayad, Moustafa and Hachani, Mohamed-Yacine and Mostefaoui, Ahmed and Chouali, Samir and Yahiaoui, Réda},
	title = {Elderly Fall Detection: A Lightweight Kinect Based Deep Learning Approach},
	year = {2022},
	journal = {MobiWac 2022 - Proceedings of the 20th ACM International Symposium on Mobility Management and Wireless Access},
	pages = {89 – 95},
	doi = {10.1145/3551660.3560911},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141731915&doi=10.1145%2f3551660.3560911&partnerID=40&md5=af678fcacab7b9a3e7818a0e2553bb4b},
	abstract = {Fall detection is one of the main issues for the elder's health care systems because of its economic and social impact. Whereas the primary metric of such a system remains its accuracy in terms of good detection of falls and avoiding either false detection or missing detection, its deployment raises many issues in terms of the number of devices, their nature (scalar, multimedia, Lidar, etc.) and the technique used. Generally, techniques based on multimedia processing provide better results but at the expense of a high CPU processing and consequently need appropriate devices. This paper explores an approach that uses less-powerful affordable devices (i.e., Raspberry Pi like) with multimedia sensors (i.e., Kinect) and a Deep Learning-based processing mechanism. More precisely, we applied LSTM (Long Short-Term Memory) on features extracted from the time series data acquired from the Kinect. Experimental results we obtained from our lightweight LSTM model on the Raspberry pi show that geometric features are more relevant for fall event detection. Our model achieves advanced performance with metrics that are usually considered (accuracy, precision, sensitivity, and specificity). Furthermore, our lightweight model is very promising for deployment on machines considered "low-cost." © 2022 ACM.},
	author_keywords = {elderly; fall detection; kinect; lstm; raspberry pi},
	keywords = {Long short-term memory; Economic impacts; Elderly; Elderly falls; Fall detection; Healthcare systems; Kinect; Learning approach; Lstm; Raspberry pi; Social impact; Fall detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Riskalla Leal2021,
	author = {Riskalla Leal, Philipe and de Paula Souza e Guimarães, Ricardo José and Dall Cortivo, Fábio and Santos Araújo Palharini, Rayana and Kampel, Milton},
	title = {A new approach to detect extreme events: a case study using remotely-sensed precipitation time-series data},
	year = {2021},
	journal = {Remote Sensing Applications: Society and Environment},
	volume = {24},
	doi = {10.1016/j.rsase.2021.100618},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122769021&doi=10.1016%2fj.rsase.2021.100618&partnerID=40&md5=81acd37ff62db06487ccb1af3fb56855},
	abstract = {Detecting and predicting extreme events are of major importance for socioeconomic, healthcare and ecological purposes. This study proposes an alternative model to detect extreme events based on analyses of probability distribution functionffns s (f(X)), called Optimum Probability Distribution Function Searcher Model (Opt.PDF-model). The Opt.PDF-model involves the optimization of a fitness function between an histogram and a set of theoretical f(X), and the subsequent evaluation of the Probability Point Function (PPF) of the fittest theoretical (f(X)) to assess threshold values for the classification of extreme events. Any occurrence in the dataset with a PPF value equal to or greater than 90% was considered an extreme event candidate. A satellite-derived precipitation time-series (Climate Hazards Group InfraRed Precipitation with Station data) was used to calibrate and validate the proposed model, with data on accumulated precipitation from more than 30 years (Jan.1981 to Dec.2018) of the Brazilian Amazon region. The proposed method was pairwise cross-validated with two other extreme event models based on Gamma and Gaussian distributions, as applied by the European Drought Observatory of the European Environment Agency. Aditionally, all three extreme event classification models were cross-validated relative to the El Niño Southern Oscillation (ENSO). By means of the Opt.PDF-model, it was possible to evidence two positive temporal trends for the area of study: one for more intense precipitation events, and another for less intense events. The pairwise cross-validation analysis returned specific Kappa's similarity indices, and the highest similarity was observed between the Gamma and the Opt.PDF models (48% for PPF(97.7%)). This analysis indicated that extreme event detection models are highly sensitive to distribution family priors and to threshold definitions. The proposed approach and the results obtained here are potentially useful for climate change warnings, and can be extended to other scientific areas that involve time-series analyses. © 2021 Elsevier B.V.},
	author_keywords = {Brazilian Amazon region; Climate change; Extreme event detection; Precipitation time-series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Paixão2021623,
	author = {Paixão, Balthazar and Baroni, Lais and Pedroso, Marcel and Salles, Rebecca and Escobar, Luciana and de Sousa, Carlos and de Freitas Saldanha, Raphael and Soares, Jorge and Coutinho, Rafaelli and Porto, Fabio and Ogasawara, Eduardo},
	title = {Estimation of COVID-19 Under-Reporting in the Brazilian States Through SARI},
	year = {2021},
	journal = {New Generation Computing},
	volume = {39},
	number = {3-4},
	pages = {623 – 645},
	doi = {10.1007/s00354-021-00125-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102564236&doi=10.1007%2fs00354-021-00125-3&partnerID=40&md5=95f6b2b7b7bf7ed1cf0dd943a5a3a401},
	abstract = {Due to its impact, COVID-19 has been stressing the academy to search for curing, mitigating, or controlling it. It is believed that under-reporting is a relevant factor in determining the actual mortality rate and, if not considered, can cause significant misinformation. Therefore, this work aims to estimate the under-reporting of cases and deaths of COVID-19 in Brazilian states using data from the InfoGripe. InfoGripe targets notifications of Severe Acute Respiratory Infection (SARI). The methodology is based on the combination of data analytics (event detection methods) and time series modeling (inertia and novelty concepts) over hospitalized SARI cases. The estimate of real cases of the disease, called novelty, is calculated by comparing the difference in SARI cases in 2020 (after COVID-19) with the total expected cases in recent years (2016–2019). The expected cases are derived from a seasonal exponential moving average. The results show that under-reporting rates vary significantly between states and that there are no general patterns for states in the same region in Brazil. The states of Minas Gerais and Mato Grosso have the highest rates of under-reporting of cases. The rate of under-reporting of deaths is high in the Rio Grande do Sul and the Minas Gerais. This work can be highlighted for the combination of data analytics and time series modeling. Our calculation of under-reporting rates based on SARI is conservative and better characterized by deaths than for cases. © 2021, Ohmsha, Ltd. and Springer Japan KK, part of Springer Nature.},
	author_keywords = {COVID-19; Data analytics; SARI; Time series modeling; Under-reporting},
	keywords = {Data Analytics; Time series; Event detection; Exponential moving averages; General patterns; Mato Grosso; Minas Gerais; Mortality rate; Rio Grande do Sul; Time series modeling; Population statistics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Lima2022,
	author = {Lima, Janio and Salles, Rebecca and Porto, Fabio and Coutinho, Rafaelli and Alpis, Pedro and Escobar, Luciana and Pacitti, Esther and Ogasawara, Eduardo},
	title = {Forward and Backward Inertial Anomaly Detector: A Novel Time Series Event Detection Method},
	year = {2022},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	volume = {2022-July},
	doi = {10.1109/IJCNN55064.2022.9892088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140743257&doi=10.1109%2fIJCNN55064.2022.9892088&partnerID=40&md5=fb6c1207790813975324c58f485e8dd9},
	abstract = {Time series event detection is related to studying methods for detecting observations in a series with special meaning. These observations differ from the expected behavior of the data set. In data streaming scenarios, it is possible to observe an increase in the speed of data generation in time series. Therefore, adapting to time series changes becomes crucial. Thus, identifying events associated with these changes is essential for timely and correct decision-making. Although there are many methods to detect events, it is still possible to have difficulties detecting them correctly, particularly those associated with concept drift. In order to fill the gap in the literature, this work proposes a new method, named Forward and Backward Inertial Anomaly Detector (FBIAD), for detecting events in time series. It contributes by analyzing surrounding inertia around observations. FBIAD outperformed other methods both in accuracy and elapsed time. © 2022 IEEE.},
	keywords = {Decision making; Anomaly detector; Data generation; Data set; Data streaming; Detection methods; Events detection; Forward-and-backward; Inertial anomalies; Time-series events; Times series; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Da Silva2022,
	author = {Da Silva, Sérgio Luiz E. F. and Corso, Gilberto},
	title = {Microseismic event detection in noisy environments with instantaneous spectral Shannon entropy},
	year = {2022},
	journal = {Physical Review E},
	volume = {106},
	number = {1},
	doi = {10.1103/PhysRevE.106.014133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135973802&doi=10.1103%2fPhysRevE.106.014133&partnerID=40&md5=a4bc7830ced315b4496b7779537dd259},
	abstract = {The detection of information-bearing signals in a time series is very important for describing and analyzing a wide variety of complex physical systems. However, identifying events in low signal-to-noise ratio circumstances remains a challenge once heavy data preprocessing is usually required. In this work, we propose a robust methodology based on the instantaneous-spectral Shannon entropy for capturing microseismic events in noisy environments without the requirement of data preprocessing. We call our proposal the instantaneous spectral entropy detection (ISED) method. We tested the ISED in a couple of real empirical seismic records to detect microseismic events. Our methodology detects microseismic patterns even without any preprocessing, in contrast to usual methods in the literature which need appreciable data preprocessing.  © 2022 American Physical Society.},
	keywords = {Seismology; Complex physical systems; Data preprocessing; Events detection; Information-bearing signals; Low signal-to-noise ratio; Microseismic events; Noisy environment; Shannon's entropy; Spectral entropy; Times series; article; entropy; noise; Signal to noise ratio},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{D'Antoni20239074,
	author = {D'Antoni, Federico and Petrosino, Lorenzo and Marchetti, Alessandro and Bacco, Luca and Pieralice, Silvia and Vollero, Luca and Pozzilli, Paolo and Piemonte, Vincenzo and Merone, Mario},
	title = {Layered Meta-Learning Algorithm for Predicting Adverse Events in Type 1 Diabetes},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {9074 – 9094},
	doi = {10.1109/ACCESS.2023.3237992},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147270477&doi=10.1109%2fACCESS.2023.3237992&partnerID=40&md5=be3e3c182780d77e8b4ad8d97271c39b},
	abstract = {Type 1 diabetes mellitus (T1D) is a chronic disease that, if not treated properly, can lead to serious complications. We propose a layered meta-learning approach based on multi-expert systems to predict adverse events in T1D. The base learner is composed of three deep neural networks and exploits only continuous glucose monitoring data as an input feature. Each network specializes in predicting whether the patient is about to experience hypoglycemia, hyperglycemia, or euglycemia. The output of the experts is passed to a meta-learner to provide the final model classification. In addition, we formally introduce a novel parameter, α , to evaluate the advance by which a prediction is performed. We evaluate the proposed approach on both a public and a private dataset and implement it on an edge device to test its feasibility in real life. On average, on the Ohio T1DM dataset, our system was able to predict hypoglycemia events with a time gain of 22.8 minutes, hyperglycemia ones with an advance of 24.0 minutes. Our model not only outperforms presented models in the literature in terms of events predicted with sufficient advance, but also with regard to the number of false positives, achieving on average 0.45 and 0.46 hypo- and hyperglycemic false alarms per day, respectively. Furthermore, the meta-learning approach effectively improves performance in a new cohort of patients by training only the meta-learner with a limited amount of data. We believe our approach would be an essential ally for the patients to control the glycemic fluctuations and adjust their insulin therapy and dietary intakes, enabling them to speed up decision-making and improve personal self-management, resulting in a reduced risk of acute and chronic complications. As our last contribution, we assessed the validity of the approach by exploiting only blood glucose variations as well as in combination with the information of the insulin boluses, the skin temperature, and the galvanic skin response. In general, we have observed that providing other information but CGM leads to slightly lower performances with respect to considering CGM alone.  © 2013 IEEE.},
	author_keywords = {diabetes; event detection; Meta learning; time series analysis},
	keywords = {Blood; Decision making; Deep neural networks; Electrophysiology; Expert systems; Forecasting; Insulin; Learning algorithms; Patient treatment; Statistical tests; Time series analysis; Adverse events; Biomedical monitoring; Blood; Events detection; Metalearning; Performances evaluation; Predictive models; Time-series analysis; Glucose},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Tasci2023876,
	author = {Tasci, Kutay and Akal, Fuat},
	title = {Transforming temporal-dynamic graphs into time-series data for solving event detection problems},
	year = {2023},
	journal = {Turkish Journal of Electrical Engineering and Computer Sciences},
	volume = {31},
	number = {5},
	pages = {876 – 891},
	doi = {10.55730/1300-0632.4023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174619102&doi=10.55730%2f1300-0632.4023&partnerID=40&md5=9d048acbeb369df142f77d0edf7d62da},
	abstract = {Event detection on temporal-dynamic graphs aims at detecting significant events based on deviations from the normal behavior of the graphs. With the widespread use of social media, many real-world events manifest as social media interactions, making them suitable for modeling as temporal-dynamic graphs. This paper presents a workflow for event detection on temporal-dynamic graphs using graph representation learning. Our workflow leverages generated embeddings of a temporal-dynamic graph to reframe the problem as an unsupervised time-series anomaly detection task. We evaluated our workflow on four distinct real-world social media datasets and compared our results with the related work. The results show that the performance depends on how anomalies deviate from normal. These include changes in both size and topology. Our results are similar to the related work for the graphs where the deviation from a normal state of the temporal-dynamic graph is apparent, e.g., Reddit. On the other hand, we achieved a 3-fold improvement in precision for the graphs where deviations exist on size and topology, e.g., Twitter. Also, our results are 20% to 5-fold better even if we introduced some delay factor. That is, we beat our competition while detecting events that occurred some time ago. As a result, our study proves that graph embeddings as time-series data can be used for event detection tasks. © 2023 Turkiye Klinikleri. All rights reserved.},
	author_keywords = {anomaly detection; Event detection; graph representation learning; Temporal-dynamic graphs},
	keywords = {Graph embeddings; Graphic methods; Metadata; Social networking (online); Time series; Topology; Anomaly detection; Dynamic graph; Events detection; Graph representation; Graph representation learning; Social media; Temporal dynamics; Temporal-dynamic graph; Time-series data; Work-flows; Anomaly detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Maraj2023,
	author = {Maraj, Joshua J. and Haughn, Kevin P.T. and Inman, Daniel J. and Sarles, Stephen A.},
	title = {Sensory Adaptation in Biomolecular Memristors Improves Reservoir Computing Performance},
	year = {2023},
	journal = {Advanced Intelligent Systems},
	volume = {5},
	number = {8},
	doi = {10.1002/aisy.202300049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168371301&doi=10.1002%2faisy.202300049&partnerID=40&md5=275f52c26417f4fd7a1bb670eea2f061},
	abstract = {Despite its prevalence in neurosensory systems for pattern recognition, event detection, and learning, the effects of sensory adaptation (SA) are not explored in reservoir computing (RC). Monazomycin-based biomolecular synapse (MzBS) devices that exhibit volatile memristance and short-term plasticity with two strength-dependent modes of response are studied: facilitation and facilitation-then-depression (i.e., SA). Their ability to perform RC tasks including digit recognition, nonlinear function learning, and aerodynamic gust classification via combination of model-based device simulations and physical experiments where SA presence is controlled is studied. Simulations exhibiting moderate SA achieve significantly higher accuracy classifying a custom 5 × 5 binary digit set, with experimental validation achieving maximum testing accuracies of 90%. Classifications of the Modified National Institute of Standards and Technology (MNIST) handwritten digit dataset achieve a maximum testing accuracy of 94.34% in devices with SA. Fitting error of the Mackey–Glass time series is also significantly reduced by SA. Experimentally obtained pressure distributions representing gusts on an airfoil in a wind tunnel are classified by MzBS reservoirs. Reservoirs exhibiting SA achieve 100% accuracy, unlike MzBS reservoirs without SA and comparable static neural networks. © 2023 The Authors. Advanced Intelligent Systems published by Wiley-VCH GmbH.},
	author_keywords = {artificial intelligence; autonomous systems; machine learning; neuromorphic computing; reservoir computing; sensory adaptation; volatile memristor},
	keywords = {Character recognition; Classification (of information); Intelligent systems; Learning systems; Machine learning; Statistical tests; Wind tunnels; Autonomous system; Bio-molecular; Computing performance; Machine-learning; Memristor; Neuromorphic computing; Reservoir Computing; Sensory adaptation; Testing accuracy; Volatile memristor; Memristors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Ghaemi2022,
	author = {Ghaemi, Elham and Tabesh, Massoud and Nazif, Sara},
	title = {Improving the ARIMA Model Prediction for Water Quality Parameters of Urban Water Distribution Networks (Case Study: CANARY Dataset)},
	year = {2022},
	journal = {International Journal of Environmental Research},
	volume = {16},
	number = {6},
	doi = {10.1007/s41742-022-00482-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139952074&doi=10.1007%2fs41742-022-00482-x&partnerID=40&md5=5781b033fba8c61040f1345086dc0ce9},
	abstract = {Water distribution networks are susceptible to pollutants entering the system. Continuous monitoring of water quality parameters in distribution networks improves the network performance and warns of pollution in the water distribution network. This research proposes an ARIMA model for water quality parameters (Cl, TOC, and pH) prediction by analyzing the time series dataset available in CANARY event detection software. Predictions are made by two different methods, Static and Rolling Samples. The model performance is evaluated by statistical indicators like RMSE, MAE, MAPE, SMAPE, and the Theil coefficient. The presented statistical indicator values showed that using ARIMA for predicting water quality variables is associated with small errors. The results showed that these low error values can be reduced with a proper prediction method according to the characteristics of the dataset. For Cl and pH, the Rolling method and for TOC, the Static method performed better for predicting. © 2022, University of Tehran.},
	author_keywords = {ARIMA; Time series analysis; Water distribution network; Water quality parameters},
	keywords = {data set; hydrological modeling; prediction; software; time series analysis; urban area; water quality; water supply},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Li2021,
	author = {Li, Chen and Liang, Gaoqi and Zhao, Huan and Chen, Guo},
	title = {A Demand-Side Load Event Detection Algorithm Based on Wide-Deep Neural Networks and Randomized Sparse Backpropagation},
	year = {2021},
	journal = {Frontiers in Energy Research},
	volume = {9},
	doi = {10.3389/fenrg.2021.720831},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122128364&doi=10.3389%2ffenrg.2021.720831&partnerID=40&md5=c6d8f53fc1820f3f3dd070382e26df6f},
	abstract = {Event detection is an important application in demand-side management. Precise event detection algorithms can improve the accuracy of non-intrusive load monitoring (NILM) and energy disaggregation models. Existing event detection algorithms can be divided into four categories: rule-based, statistics-based, conventional machine learning, and deep learning. The rule-based approach entails hand-crafted feature engineering and carefully calibrated thresholds; the accuracies of statistics-based and conventional machine learning methods are inferior to the deep learning algorithms due to their limited ability to extract complex features. Deep learning models require a long training time and are hard to interpret. This paper proposes a novel algorithm for load event detection in smart homes based on wide and deep learning that combines the convolutional neural network (CNN) and the soft-max regression (SMR). The deep model extracts the power time series patterns and the wide model utilizes the percentile information of the power time series. A randomized sparse backpropagation (RSB) algorithm for weight filters is proposed to improve the robustness of the standard wide-deep model. Compared to the standard wide-deep, pure CNN, and SMR models, the hybrid wide-deep model powered by RSB demonstrates its superiority in terms of accuracy, convergence speed, and robustness. Copyright © 2021 Li, Liang, Zhao and Chen.},
	author_keywords = {backpropagation; convolutional neural network; event classification; index terms-event detection; non-intrusive load monitoring (NILM); smart home; soft-max regression; wide and deep learning},
	keywords = {Backpropagation; Convolution; Convolutional neural networks; Deep neural networks; Electric load management; Electric utilities; Intelligent buildings; Signal detection; Time series; Convolutional neural network; Events classification; Events detection; Index term-event detection; Index terms; Non-intrusive load monitoring; Nonintrusive load monitoring; Smart homes; Soft-max regression; Wide and deep learning; Automation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Komisarenko2022,
	author = {Komisarenko, Viacheslav and Voormansik, Kaupo and Elshawi, Radwa and Sakr, Sherif},
	title = {Exploiting time series of Sentinel-1 and Sentinel-2 to detect grassland mowing events using deep learning with reject region},
	year = {2022},
	journal = {Scientific Reports},
	volume = {12},
	number = {1},
	doi = {10.1038/s41598-022-04932-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123064145&doi=10.1038%2fs41598-022-04932-6&partnerID=40&md5=a8aa310d21bbf0d2223dd27b61e358ac},
	abstract = {Governments pay agencies to control the activities of farmers who receive governmental support. Field visits are costly and highly time-consuming; hence remote sensing is widely used for monitoring farmers’ activities. Nowadays, a vast amount of available data from the Sentinel mission significantly boosted research in agriculture. Estonia is among the first countries to take advantage of this data source to automate mowing and ploughing events detection across the country. Although techniques that rely on optical data for monitoring agriculture events are favourable, the availability of such data during the growing season is limited. Thus, alternative data sources have to be evaluated. In this paper, we developed a deep learning model with an integrated reject option for detecting grassland mowing events using time series of Sentinel-1 and Sentinel-2 optical images acquired from 2000 fields in Estonia in 2018 during the vegetative season. The rejection mechanism is based on a threshold over the prediction confidence of the proposed model. The proposed model significantly outperforms the state-of-the-art technique and achieves event accuracy of 73.3% and end of season accuracy of 94.8%. © 2022, The Author(s).},
	keywords = {article; deep learning; Estonia; grassland; growing season; human; plowing; prediction; time series analysis; agriculture},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Reinermann2022,
	author = {Reinermann, Sophie and Gessner, Ursula and Asam, Sarah and Ullmann, Tobias and Schucknecht, Anne and Kuenzer, Claudia},
	title = {Detection of Grassland Mowing Events for Germany by Combining Sentinel-1 and Sentinel-2 Time Series},
	year = {2022},
	journal = {Remote Sensing},
	volume = {14},
	number = {7},
	doi = {10.3390/rs14071647},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128025911&doi=10.3390%2frs14071647&partnerID=40&md5=8e9bf644f25f4649388b827a278c7dba},
	abstract = {Grasslands cover one-third of the agricultural area in Germany and play an important economic role by providing fodder for livestock. In addition, they fulfill important ecosystem services, such as carbon storage, water purification, and the provision of habitats. These ecosystem services usually depend on the grassland management. In central Europe, grasslands are grazed and/or mown, whereby the management type and intensity vary in space and time. Spatial information on the mowing timing and frequency on larger scales are usually not available but would be required in order to assess the ecosystem services, species composition, and grassland yields. Time series of high-resolution satellite remote sensing data can be used to analyze the temporal and spatial dynamics of grasslands. Within this study, we aim to overcome the drawbacks identified by previous studies, such as optical data availability and the lack of comprehensive reference data, by testing the time series of various Sentinel-2 (S2) and Sentinal-1 (S1) parameters and combinations of them in order to detect mowing events in Germany in 2019. We developed a threshold-based algorithm by using information from a comprehensive reference dataset of heterogeneously managed grassland parcels in Germany, obtained by RGB cameras. The developed approach using the enhanced vegetation index (EVI) derived from S2 led to a successful mowing event detection in Germany (60.3% of mowing events detected, F1-Score = 0.64). However, events shortly before, during, or shortly after cloud gaps were missed and in regions with lower S2 orbit coverage fewer mowing events were detected. Therefore, S1-based backscatter, InSAR, and PolSAR features were investigated during S2 data gaps. From these, the PolSAR entropy detected mowing events most reliably. For a focus region, we tested an integrated approach by combining S2 and S1 parameters. This approach detected additional mowing events, but also led to many false positive events, resulting in a reduction in the F1-Score (from 0.65 of S2 to 0.61 of S2 + S1 for the focus region). According to our analysis, a majority of grasslands in Germany are only mown zero to two times (around 84%) and are probably additionally used for grazing. A small proportion is mown more often than four times (3%). Regions with a generally higher grassland mowing frequency are located in southern, south-eastern, and northern Germany. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {cutting events; earth observation; grazing; harvests; InSAR; meadow; optical; pasture; PolSAR; remote sensing; SAR},
	keywords = {Agriculture; Digital storage; Ecosystems; Observatories; Orbits; Space optics; Time series; Vegetation; Cutting event; Earth observations; Grazing; Harvest; InSAR; Meadow; Optical-; PolSAR; Remote-sensing; SAR; Remote sensing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Bento2022156,
	author = {Bento, Fábio R. O. and Vassallo, Raquel F. and Samatelo, Jorge L. A.},
	title = {Anomaly Detection on Public Streets Using Spatial Features and a Bidirectional Sequential Classifier},
	year = {2022},
	journal = {Journal of Control, Automation and Electrical Systems},
	volume = {33},
	number = {1},
	pages = {156 – 166},
	doi = {10.1007/s40313-021-00817-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116494414&doi=10.1007%2fs40313-021-00817-7&partnerID=40&md5=bbe9dad1e4edce025c78fd51d5c25e16},
	abstract = {The anomaly detection problem consists in identifying the events that do not conform to an expected behavior pattern. In law enforcement and security, detection of anomalous events has application in the identification of suspicious behaviors. This paper addresses such problem in public areas by monitoring surveillance videos. Our approach involves a convolutional neural network for spatial features extraction, followed by a time series classifier with a one-dimensional convolutional layer and an ensemble of stacked bidirectional recurrent networks. The proposed methodology selects a pre-trained convolutional architecture for the spatial feature and applies transfer learning to specialize this architecture in anomaly detection in surveillance videos. We performed the experiments on the UCSD Anomaly Detection Dataset and the CUHK Avenue Dataset for Abnormal Event Detection to compare our approach with other works. Our evaluation protocol uses the Area Under the Receiver Operating Characteristic Curve—AUC, the Equal Error Rate—EER, and the Area Under the Precision vs. Recall Curve—AUPRC. During the experiments, the model obtained AUC above 92 % and EER below 15 % , which are compatible with the current literature. © 2021, Brazilian Society for Automatics--SBA.},
	author_keywords = {Anomaly detection; Computer vision; Deep learning; Smart cities},
	keywords = {Computer vision; Convolution; Feature extraction; Multilayer neural networks; Network architecture; Recurrent neural networks; Security systems; Smart city; Anomalous events; Anomaly detection; Behaviour patterns; Deep learning; Detection problems; Public streets; Security detection; Sequential classifier; Spatial features; Surveillance video; Anomaly detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Chen20215323,
	author = {Chen, Huan and Hsu, Jyh-Yih and Hsieh, Jia-You and Hsu, Hsin-Yao and Chang, Chia-Hao and Lin, Yu-Ju},
	title = {Predictive maintenance of abnormal wind turbine events by using machine learning based on condition monitoring for anomaly detection},
	year = {2021},
	journal = {Journal of Mechanical Science and Technology},
	volume = {35},
	number = {12},
	pages = {5323 – 5333},
	doi = {10.1007/s12206-021-1105-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120811093&doi=10.1007%2fs12206-021-1105-z&partnerID=40&md5=037644afb45a06efab20e8d765ca2a1d},
	abstract = {The predictive maintenance of wind turbines has become a critical issue with the rapid development of wind power generation. The early detection of abnormal operation conditions can prevent failure status, which takes a long time to recover. Energy waste can also be reduced while maintenance efficiency can be improved by using a supervisory control and data acquisition (SCADA) system to monitor the operation status of wind turbines. Massive data are generated from different sensors during wind turbine operation, and SCADA can be used to gather reports about hundreds of possible abnormal conditions. The popular maintenance methods have been mostly designed on the basis of statistical analysis and data mining. However, such schemes need not only big data but also sophisticated processing techniques. This study addresses the aforementioned challenges by proposing a deep learning model with comprehensive data preprocessing and hyperparameter tuning on batch size to achieve abnormal early detection. The necessary data preprocessing is initially conducted besides the conventional data cleaning and normalization steps, and time-series data windowing and label settings are also performed. Then, the imbalanced classes in the records are addressed by adopting an augmentation scheme called the synthetic minority oversampling technique. Principal component analysis is also used to enhance the training. Finally, the proposed deep learning method with fine-tuning is compared with three machine learning models for early anomaly event detection. Experimental results show that the proposed scheme can identify potential faults 72 hours before they occur, and the precision rate exceeds 90 %. © 2021, The Korean Society of Mechanical Engineers and Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {Anomaly detection; Data argumentation; Machine learning; Predictive maintenance; Wind turbine},
	keywords = {Anomaly detection; Condition monitoring; Data acquisition; Data mining; Deep learning; Electric power generation; Maintenance; Principal component analysis; Wind power; Abnormal operation; Anomaly detection; Critical issues; Data argumentation; Data preprocessing; Energy wastes; On condition monitoring; Operation conditions; Predictive maintenance; Wind power generation; Wind turbines},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Marullo2023,
	author = {Marullo, Giorgia and Tanzi, Leonardo and Ulrich, Luca and Porpiglia, Francesco and Vezzetti, Enrico},
	title = {A Multi-Task Convolutional Neural Network for Semantic Segmentation and Event Detection in Laparoscopic Surgery},
	year = {2023},
	journal = {Journal of Personalized Medicine},
	volume = {13},
	number = {3},
	doi = {10.3390/jpm13030413},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151614867&doi=10.3390%2fjpm13030413&partnerID=40&md5=2160f31320a841af2d4e2c8498b9fe0e},
	abstract = {The current study presents a multi-task end-to-end deep learning model for real-time blood accumulation detection and tools semantic segmentation from a laparoscopic surgery video. Intraoperative bleeding is one of the most problematic aspects of laparoscopic surgery. It is challenging to control and limits the visibility of the surgical site. Consequently, prompt treatment is required to avoid undesirable outcomes. This system exploits a shared backbone based on the encoder of the U-Net architecture and two separate branches to classify the blood accumulation event and output the segmentation map, respectively. Our main contribution is an efficient multi-task approach that achieved satisfactory results during the test on surgical videos, although trained with only RGB images and no other additional information. The proposed multi-tasking convolutional neural network did not employ any pre- or postprocessing step. It achieved a Dice Score equal to 81.89% for the semantic segmentation task and an accuracy of 90.63% for the event detection task. The results demonstrated that the concurrent tasks were properly combined since the common backbone extracted features proved beneficial for tool segmentation and event detection. Indeed, active bleeding usually happens when one of the instruments closes or interacts with anatomical tissues, and it decreases when the aspirator begins to remove the accumulated blood. Even if different aspects of the presented methodology could be improved, this work represents a preliminary attempt toward an end-to-end multi-task deep learning model for real-time video understanding. © 2023 by the authors.},
	author_keywords = {bleeding detection; CNN; laparoscopic surgery; multi-task convolutional neural network; semantic segmentation},
	keywords = {Article; artificial intelligence; brain depth stimulation; convolutional neural network; deep learning; human; laparoscopic surgery; learning algorithm; machine learning; operative blood loss; reliability; segmentation algorithm; semantic segmentation; three-dimensional imaging; time series analysis; videorecording; visibility; visual feedback},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{AlDhanhani20231395,
	author = {AlDhanhani, Ahmed and Damiani, Ernesto and Mizouni, Rabeb and Wang, Di and Al-Rubaie, Ahmad},
	title = {Multi-modal traffic event detection using shapelets},
	year = {2023},
	journal = {Neural Computing and Applications},
	volume = {35},
	number = {2},
	pages = {1395 – 1408},
	doi = {10.1007/s00521-022-07837-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138816734&doi=10.1007%2fs00521-022-07837-7&partnerID=40&md5=c012935770a8880aadd3488df9d39b9b},
	abstract = {Traffic management continues to be one of the most critical challenges facing smart cities. Timely detection of incidents plays an important role in reducing fatality rates, avoiding congestion and improving traffic conditions. Currently, traditional traffic event detection approaches often rely on one source of data, such as road sensor readings or social media posts. However, there is a need for new approaches that can combine these channels and benefit from the diversity of the collected data for better event detection performance. This paper presents a new framework for near real-time event detection based on the fusion of sensor readings and social media data. The shapelets technique, used for sensor readings, generates sub-sequences of the time series representing distinctive patterns. Each pattern is called a shapelet and is selected based on the maximal differentiation achieved between the different classes of a time series set. In traffic events, shapelets can represent patterns of incidents/congestion as well as normal traffic situations that the framework utilizes to detect the occurrence of events. Similarly, social media posts can be featured as shapelets to enable the combination of both media channels creating a multi-modal solution. In the proposed framework, two pipelines are defined : sensor readings detection pipeline and social media detection pipeline. In addition, two multi-modal fusion techniques based on Shapelet Transform are suggested and compared, namely early fusion and late fusion. They help in combining the two pipelines either at the data level or at the decision level. Validation using the M25 London Circular road data shows that early fusion of both sources has better detection rate and better performance over late fusion. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Automatic incident detection; Event detection; Multi-modal; Shapelet transform; Time series classification; Traffic},
	keywords = {Roads and streets; Sensor data fusion; Social networking (online); Time series; Traffic congestion; Automatic incident detection; Events detection; Multi-modal; Sensor readings; Shapelet transform; Shapelets; Social media; Time series classifications; Traffic; Traffic event; Pipelines},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {2nd International Conference on Emerging Technologies and Intelligent Systems, ICETIS 2022},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {584 LNNS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150968459&partnerID=40&md5=f2eb5b7576ee34d1e25c8bcf9b2c9198},
	abstract = {The proceedings contain 61 papers. The special focus in this conference is on Emerging Technologies and Intelligent Systems. The topics include: Predictive Analytics for Oil and Gas Asset Maintenance Using XGBoost Algorithm; Event Detection and Information Extraction Strategies from Text: A Preliminary Study Using GENIA Corpus; human Evacuation Movement Simulation Model: Concepts and Techniques; A Data Mining Approach to Determine Prospective Debtor of Unsecured Credit (Case Study: Bank XYZ in Indonesia); date Palm Leaves Discoloration Detection System Using Deep Transfer Learning; solving Drinking-Water Challenges: Supply and Temperature in a Smart Poultry Monitoring System Using IoT System; offline Marker-Less Augmented Reality Application for Exploring Threatened Historical Places; a Robust Tuned K-Nearest Neighbours Classifier for Software Defect Prediction; Smart Virtual Robot Automation (SVRA)-Improving Supplier Transactional Processes in Enterprise Resource Planning (ERP) System: A Conceptual Framework; a Review of Long Short-Term Memory Approach for Time Series Analysis and Forecasting; design and Implementation of Modified Vedic Multiplier Using Modified Decoder-Based Adder; Design and FPGA Implementation of Matrix Multiplier Using DEMUX-RCA-Based Vedic Multiplier; Analysis and Modeling of Brushless DC Motor PWM Control Technique Using PSIM Software; single-Bit Architecture for Low Power IoT Applications; hybrid Fuzzy Logic Active Force Control for Trajectory Tracking of a Quadrotor System; semantic Analysis of Moving Objects in Video Sequences; Improved Automatic License Plate Recognition System in Iraq for Surveillance System Using OCR; do We Use the Right Elements for Assurance Case Development?; development of a Mobile Application for Scheduling Electric Vehicle Charging in Wind Energy Powered Facility.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Singh2022429,
	author = {Singh, Shubhr and Phan, Huy and Benetos, Emmanouil},
	title = {HYPERNETWORKS FOR SOUND EVENT DETECTION: A PROOF-OF-CONCEPT},
	year = {2022},
	journal = {European Signal Processing Conference},
	volume = {2022-August},
	pages = {429 – 433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141012217&partnerID=40&md5=b3f6e90e3c2e2847fd312ffb265f6c29},
	abstract = {Polyphonic sound event detection (SED) involves the prediction of sound events present in an audio recording along with their onset and offset times. Recently, Deep Neural Networks, specifically convolutional recurrent neural networks (CRNN) have achieved impressive results for this task. The convolution part of the architecture is used to extract translational invariant features from the input and the recurrent part learns the underlying temporal relationship between audio frames. Recent studies showed that the weight sharing paradigm of recurrent networks might be a hindering factor in certain kinds of time series data, specifically where there is a temporal conditional shift, i.e. the conditional distribution of a label changes across the temporal scale. This warrants a relevant question - is there a similar phenomenon in polyphonic sound events due to dynamic polyphony level across the temporal axis? In this work, we explore this question and inquire if relaxed weight sharing improves performance of a CRNN for polyphonic SED. We propose to use hypernetworks to relax weight sharing in the recurrent part and show that the CRNN's performance is improved by ˜ 3% across two datasets, thus paving the way for further exploration of the existence of temporal conditional shift for polyphonic SED. © 2022 European Signal Processing Conference, EUSIPCO. All rights reserved.},
	author_keywords = {hypernetworks; recurrent networks; sound event detection; weight sharing},
	keywords = {Audio acoustics; Convolution; Deep neural networks; Signal processing; Hypernetwork; Invariant features; Offset time; Onset-time; Polyphonic sounds; Proof of concept; Recurrent networks; Sound event detection; Sound events; Weight sharing; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wolf202223912,
	author = {Wolf, Lukas and Kastrati, Ard and Płomecka, Martyna Beata and Li, Jie-Ming and Klebe, Dustin and Veicht, Alexander and Wattenhofer, Roger and Langer, Nicolas},
	title = {A Deep Learning Approach for the Segmentation of Electroencephalography Data in Eye Tracking Applications},
	year = {2022},
	journal = {Proceedings of Machine Learning Research},
	volume = {162},
	pages = {23912 – 23932},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163127251&partnerID=40&md5=35c4f17fc75d00d20907aaefbbd33b4a},
	abstract = {The collection of eye gaze information provides a window into many critical aspects of human cognition, health and behaviour. Additionally, many neuroscientific studies complement the behavioural information gained from eye tracking with the high temporal resolution and neurophysiological markers provided by electroencephalography (EEG). One of the essential eye-tracking software processing steps is the segmentation of the continuous data stream into events relevant to eye-tracking applications, such as saccades, fixations, and blinks. Here, we introduce DETRtime, a novel framework for time-series segmentation that creates ocular event detectors that do not require additionally recorded eye-tracking modality and rely solely on EEG data. Our end-to-end deep-learning-based framework brings recent advances in Computer Vision to the forefront of the times series segmentation of EEG data. DETRtime achieves state-of-the-art performance in ocular event detection across diverse eye-tracking experiment paradigms. In addition to that, we provide evidence that our model generalizes well in the task of EEG sleep stage segmentation. Copyright © 2022 by the author(s)},
	keywords = {Application programs; Behavioral research; Deep learning; Electroencephalography; Electrophysiology; Eye movements; Eye-gaze; Eye-tracking; High temporal resolution; Human behaviors; Human cognition; Human health; Learning approach; Software processing; Time-series segmentation; Tracking application; Eye tracking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Blaise2022,
	author = {Blaise, Agathe and Bouet, Mathieu and Conan, Vania and Secci, Stefano},
	title = {Group anomaly detection in mobile app usages: A spatiotemporal convex hull methodology},
	year = {2022},
	journal = {Computer Networks},
	volume = {216},
	doi = {10.1016/j.comnet.2022.109277},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136297177&doi=10.1016%2fj.comnet.2022.109277&partnerID=40&md5=0bf371f3ebbb54244e7c7b6ff8226dfe},
	abstract = {Analysing mobile apps communications can unleash significant information on both the communication infrastructure state and the operations of mobile computing services. A wide variety of events can engender unusual mobile communication patterns possibly interesting for pervasive computing applications, e.g., in smart cities. For instance, local events, national events, and network outages can produce spatiotemporal load anomalies that could be taken into consideration by both mobile applications and infrastructure providers, especially with the emergence of edge computing frameworks where the two environments merge. Being able to detect and timely treat these anomalies is therefore a desirable feature for next-generation cellular and edge computing networks, with regards to security, network and application performance, and public safety. We focus on the detection of mobile access spatiotemporal anomalies by decomposing, aggregating and grouping cellular data usage features time series. We propose a methodology to detect first raw anomalies, and group them in a spatiotemporal convex hull, further refining the anomaly detection logic, with a novel algorithmic framework. We show how with the proposed framework we can unveil details about broad-category mobile events timeline, their spatiotemporal spreading, and their impacted apps. We apply our technique to extensive real-world data and open source our code. By linkage with ground-truth special events that happened in the observed period, we show how our methodology is able to detect them. We also evidence the existence of five main categories of anomalies, finely characterising them. Finally, we identify global patterns in the anomalies and assess their level of unpredictability, based on the nature of the impacted mobile applications. © 2022 Elsevier B.V.},
	author_keywords = {Group anomaly detection; Mobile data analytics; Special events detection},
	keywords = {Computation theory; Computational geometry; Data Analytics; Feature extraction; Mobile computing; Mobile edge computing; Open source software; Open systems; Ubiquitous computing; Anomaly detection; Convex hull; Data analytics; Events detection; Group anomaly detection; Mobile app; Mobile applications; Mobile data; Mobile data analytic; Special event detection; Anomaly detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Saragih2022,
	author = {Saragih, Agung Shamsuddin and Basyiri, Hadyan Nasran and Raihan, Muhammad Yusuf},
	title = {Analysis of Motor Imagery Data from EEG Device to Move Prosthetic Hands by using Deep Learning Classification},
	year = {2022},
	journal = {AIP Conference Proceedings},
	volume = {2537},
	doi = {10.1063/5.0098178},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138276708&doi=10.1063%2f5.0098178&partnerID=40&md5=8e4cdd13f2fa97fb12c24b48a38c696f},
	abstract = {Controlling the artificial hand using the mind is a dream for many people who had lost their limbs. Brain-Computer Interface (BCI) technology is hoped in making these things happen by connecting commands and responses to the brain as information in the control system. However, the complexity of the EEG signal becomes a challenge in realizing. The use of a deep learning-based classification model is expected to be a solution for classifying the hand movements imagined by the user as an input to the electric artificial hand control system. The main aim of this study is to classify EEG signals from the human brain in real-time using a non-invasive EEG headset for two different hand operations: rest and grip. OpenBCI Ultracortex Mark IV Headset was used in this study. This study proposes a solution for the classification of rest and grip hand movement by exploiting a Long Short-Term Memory (LSTM) network and Convolutional Neural Network (CNN) to learn the electroencephalogram (EEG) time-series information. EEG signals were recorded from 1 healthy subject via brain waves at specific locations on the scalp, at points F3, Fz, F4, FC1, FC2, C3, CZ, C3. A wide range of time-domain features are extracted from the EEG signals and used to train an LSTM and CNN to perform the classification task. This headset can capture brain waves that include artefacts such as limb movement, heartbeat, blink, and many more. Raw EEG from the headset was processed for event detection. Raw EEG from the headset was filtered using Butterworth bandpass filtering to separate the signal data into a new dataset containing alpha, beta, and both ranges. The results of this study indicate that the classification model using the CNN technique for the classification of two types of hand movements is able to achieve an accuracy of 95.45% at the highest, while the LSTM technique can achieve an accuracy of 93.64 %. Detected events were then used to trigger control signals to a prosthetic hand controlled by microcontroller. © 2022 American Institute of Physics Inc.. All rights reserved.},
	author_keywords = {Brain-Computer Interface (BCI); Convolutional Neural Network (CNN); electroencephalography (EEG); Long Short-Term Memory (LSTM); prosthetic hand control},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Wang2022,
	author = {Wang, Jiangeng and Zhu, Linglong and Zhang, Yonghong and Huang, Wei and Song, Kaida and Tian, Feng},
	title = {Characterizing Spatiotemporal Patterns of Snowfall in the Kaidu River Basin from 2000–2020 Using MODIS Observations},
	year = {2022},
	journal = {Remote Sensing},
	volume = {14},
	number = {22},
	doi = {10.3390/rs14225885},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142713196&doi=10.3390%2frs14225885&partnerID=40&md5=b2e37e7af33d484e4afad743bb68744b},
	abstract = {Characterizing spatiotemporal patterns of snowfall is essential for understanding cryosphere responses to warming climate stress. The changes in snowfall and topographic controls in mountain regions still need to be clarified. This study proposes a general parsimonious methodology to obtain the frequency of snowfall in mountainous areas. The methodology employed is easily transferable to any other mountain region. Utilizing daily MODIS observations from June 2000 to May 2020 and the snowfall event detection algorithm, we monitored the frequency of snowfall in a long time series in the Kaidu river basin. The results are as follows: (1) The method for detecting the frequency of snowfall has high accuracy. The annual detected results agreed with surface observations, with an R2 of 0.65 and RMSE of 3.39. (2) The frequency of snowfall events increased monotonically with elevation. The influence of slope angle on snowfall gradually decreased with increasing elevation. (3) The frequency of snowfall events in the Kaidu river basin was dominated by an increasing trend. The trends showed a pronounced topographic dependence. This study reveals the distribution characteristics and changing snowfall trends in mountain regions. The results provide a reference for snowfall research in mountainous areas. © 2022 by the authors.},
	author_keywords = {Kaidu river basin; MODIS; mountain regions; snow grain size; snowfall; spatial-temporal pattern},
	keywords = {Landforms; Radiometers; Rivers; Watersheds; Kaidu river basin; MODIS; Mountain regions; Mountainous area; River basins; Snow grain size; Spatial temporals; Spatial-temporal pattern; Spatiotemporal patterns; Temporal pattern; Snow},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Otsuka2023,
	author = {Otsuka, Hideto and Ohta, Yusaku and Hino, Ryota and Kubota, Tatsuya and Inazu, Daisuke and Inoue, Tomohiro and Takahashi, Narumi},
	title = {Reduction of non-tidal oceanographic fluctuations in ocean-bottom pressure records of DONET using principal component analysis to enhance transient tectonic detectability},
	year = {2023},
	journal = {Earth, Planets and Space},
	volume = {75},
	number = {1},
	doi = {10.1186/s40623-023-01862-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165282042&doi=10.1186%2fs40623-023-01862-z&partnerID=40&md5=dbc5dc433237543b1c36718a492e6ddf},
	abstract = {Ocean bottom pressure-gauge (OBP) records play an essential role in seafloor geodesy. Oceanographic fluctuations in OBP data, however, pose as a significant noise source in seafloor transient crustal deformation observations, including slow slip events (SSEs), making it crucial to evaluate them quantitatively. To extract the significant fluctuation phenomena common to multiple observation networks, including oceanographic fluctuations and tectonic signals, we applied principal component analysis (PCA) to the 3-year Dense Oceanfloor Network System for Earthquakes and Tsunamis (DONET) OBP time series for 40 stations during 2016–2019. PCA could separate several oceanographic signals based on the characteristics of their spatial distributions, although evident transient tectonic signals could not be confirmed from the observed pressure records during this observed period. The spatial distribution of the first four principal components (PCs) reflected the common component, inclined component along sea depth, longitude component, and parabola-like pattern, respectively. By subtracting each PC (in particular, PC-2 and PC-4) from the time series, we could significantly reduce the sea depth dependence of OBP records, which has been highlighted in several previous studies and is also evident in this region. We interpreted PCs 2–4 as the reflection of the strength and meandering of ocean geostrophic currents based on a comparison with the PC spatial distribution of the numerical oceanographic models. In addition, to evaluate the ability of PCA to separate transient tectonic signal from OBP time series, including oceanographic fluctuations, we conducted a synthetic ramp assuming an SSE by rectangular fault and then applied PCA. The assumed synthetic tectonic signal could be separated from the oceanographic signals and included in the principal component independently depending on its amplitude, suggesting that the spatial distribution of each PC would change if the amplitude of the synthetic signal were sufficiently large. We propose a transient event-detection method based on the spatial distribution difference of a specific PC with or without a tectonic signal. We used the normalized inner product (NIP) between these PCs as the indicator of their similarities. This method can detect transient tectonic signals more significantly than the moment-magnitude scale of 5.9 from OBP records. Graphical Abstract: [Figure not available: see fulltext.]. © 2023, The Author(s).},
	author_keywords = {DONET; Nankai trough; Ocean bottom pressure-gauge; Oceanographic fluctuations; Principal component analysis; Seafloor crustal deformation; Slow slip events},
	keywords = {Nankai Trough; Pacific Ocean; bottom pressure; crustal deformation; fault slip; principal component analysis; seafloor; tectonics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Yang20231,
	author = {Yang, Jie and Tang, Diyin and Yu, Jinsong and Zhang, Jian and Liu, Haigang},
	title = {Explaining Anomalous Events in Flight Data of UAV With Deep Attention-Based Multi-Instance Learning},
	year = {2023},
	journal = {IEEE Transactions on Vehicular Technology},
	pages = {1–14},
	doi = {10.1109/TVT.2023.3301678},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166776184&doi=10.1109%2fTVT.2023.3301678&partnerID=40&md5=8cc2466ef9b7920f8ab115e10edcfa02},
	abstract = {Ensuring the safety and reliability of unmanned aerial vehicles (UAVs) has become a critical issue as they continue to advance. Analyzing anomalous events using event-based explanations is an effective approach to identifying key anomalous behaviors and mitigating potential risks. However, this task is challenging because anomalous events in flight data lack time-step labels in real-world UAV flight scenarios. To address this challenge, we propose a dual attention-based multi-instance learning (DA-DI-MIL) for pinpointing anomaly instances and automatically explaining anomalous events. Our MIL-based framework, from a weakly supervised learning perspective, treats a segment of flight data as a &#x2018;bag&#x2019; with an available label, and its time steps as &#x2018;instances&#x2019; without labels. The dual attention mechanism in DA-DI-MIL combines a temporal pseudo-label, predicted by temporal attention, and sensor variable importance obtained from delta feature attention to better pinpoint anomalies from instance-level labels. We use these labels in our proposed MIL-based framework to establish the relationships between anomalous events and anomalous behaviors. We conducted extensive experiments on real UAV flight data with engine failures to demonstrate the effectiveness and robustness of our proposed method compared to existing state-of-the-art methods. DA-DI-MIL achieves near 90&#x0025; in evaluation metrics with less than 5 time steps&#x0027; delay of anomalous event detection and around 85&#x0025; in temporal anomaly detection. Additionally, we present an illustration of both global and local interpretations in the time domain and feature space, providing comprehensive insights into anomalous events. Our proposed method has efficiently and automatically explained anomalous events in UAV flight data, contributing to high-level aviation safety and reliability. IEEE},
	author_keywords = {anomalous events; Anomaly detection; Anomaly detection; attention mechanism; Autonomous aerial vehicles; aviation safety; Behavioral sciences; Data models; deep learning; multiple instance learning; Sensors; Time series analysis; Training; unmanned aerial vehicle},
	keywords = {Aircraft detection; Antennas; Behavioral research; Deep learning; Drones; Reliability analysis; Time domain analysis; Time series analysis; Aerial vehicle; Anomalous events; Anomaly detection; Attention mechanisms; Aviation safety; Behavioral science; Deep learning; Multiple-instance learning; Time-series analysis; Unmanned aerial vehicle; Anomaly detection},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Stržinar2023,
	author = {Stržinar, Žiga and Pregelj, Boštjan and Škrjanc, Igor},
	title = {Soft sensor for non-invasive detection of process events based on Eigenresponse Fuzzy Clustering},
	year = {2023},
	journal = {Applied Soft Computing},
	volume = {132},
	doi = {10.1016/j.asoc.2022.109859},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149824842&doi=10.1016%2fj.asoc.2022.109859&partnerID=40&md5=eca683df47a996488af00d183e89fec4},
	abstract = {Changes in process states and properties can be observed through measured variables. In this way, by classifying time series segments of measured data, changes in model parameters can be detected and the system state can be inferred. Time series classification methods are used in many fields, but the work presented here focuses mainly on the field of manufacturing. In the category of whole-series time series classifiers, the Nearest Neighbor classifier is often used. The aim of this work is to introduce an alternative supervised method for time series classification — Eigenresponse Fuzzy Clustering (EFC). We introduce class eigenresponses, which are time series prototypes of a class. We propose the learning eigenresponses for each class using a fuzzy clustering technique. Unlike some existing methods, we propose the use of multiple prototypes per class to better describe a wider range of values for each class. Moreover, the presented method is evaluated on several datasets. Using a dataset obtained on an industrial test bench on an e-bike drive assembly line, the method correctly classifies all time series. To further validate the performance, a set of publicly available datasets (UCR Archive) is used. For the category of datasets most similar to the target industrial application, an improvement over the benchmark approach is obtained. © 2022 The Author(s)},
	author_keywords = {Classification algorithms; Event detection; Fuzzy classification; Manufacturing; Time series analysis},
	keywords = {Benchmarking; Classification (of information); Digital storage; Fuzzy clustering; Statistical tests; Classification algorithm; Event-based; Events detection; Fuzzy classification; Manufacturing; Non-invasive detection; Soft sensors; Time series classifications; Time-series analysis; Times series; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Bazzi2022,
	author = {Bazzi, Hassan and Baghdadi, Nicolas and Najem, Sami and Jaafar, Hadi and Le Page, Michel and Zribi, Mehrez and Faraslis, Ioannis and Spiliotopoulos, Marios},
	title = {Detecting Irrigation Events over Semi-Arid and Temperate Climatic Areas Using Sentinel-1 Data: Case of Several Summer Crops},
	year = {2022},
	journal = {Agronomy},
	volume = {12},
	number = {11},
	doi = {10.3390/agronomy12112725},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141840250&doi=10.3390%2fagronomy12112725&partnerID=40&md5=c8b8686627f61d7a235683b9eafdf04d},
	abstract = {Irrigation monitoring is of great importance in agricultural water management to guarantee better water use efficiency, especially under changing climatic conditions and water scarcity. This study presents a detailed assessment of the potential of the Sentinel-1 (S1) Synthetic Aperture Radar (SAR) data to detect irrigation events at the plot scale. The potential of the S1 data to detect the irrigation events was carried out using the Irrigation Event Detection Model (IEDM) over semi-arid and temperate oceanic climates in five study sites in south Europe and the Middle East. The IEDM is a decision tree model initially developed to detect irrigation events using the change detection algorithm applied to the S1 time series data. For each study site and at each agricultural plot, all available S1 images during the period of irrigation were used to construct an S1 time series and apply the IEDM. Different types of major summer irrigated crops were analyzed in this study, including Maize, Soybean, Sorghum and Potato, mainly with the sprinkler irrigation technique. The irrigation detection accuracy was evaluated using S1 images and the IEDM against the climatic condition of the studied area, the vegetation development (by means of the normalized difference vegetation index, NDVI) and the revisit time of the S1 sensor. The main results showed generally good overall accuracy for irrigation detection using the S1 data, reaching 67% for all studied sites together. This accuracy varied according to the climatic conditions of the studied area, with the highest accuracy for semi-arid areas and lowest for temperate areas. The analysis of the irrigation detection as a function of the crop type showed that the accuracy of irrigation detection decreases as the vegetation becomes well developed. The main findings demonstrated that the density of the available S1 images in the S1 time series over a given area affects the irrigation detection accuracy, especially for temperate areas. In temperate areas the irrigation detection accuracy decreased from 70% when 15 to 20 S1 images were available per month to reach less than 56% when less than 10 S1 images per month were available over the study sites. © 2022 by the authors.},
	author_keywords = {climate change; precision agriculture; remote sensing; sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sanderson20231684,
	author = {Sanderson, Richard W and Matoza, Robin S and Fee, David and Haney, Matthew M and Lyons, John J},
	title = {Infrasound single-channel noise reduction: application to detection and localization of explosive volcanism in Alaska using backprojection and array processing},
	year = {2023},
	journal = {Geophysical Journal International},
	volume = {232},
	number = {3},
	pages = {1684 – 1712},
	doi = {10.1093/gji/ggac182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144610421&doi=10.1093%2fgji%2fggac182&partnerID=40&md5=cea0b8817b879f09e220e5772f8341c8},
	abstract = {Infrasound sensors are deployed in a variety of spatial configurations and scales for geophysical monitoring, including networks of single sensors and networks of multisensor infrasound arrays. Infrasound signal detection strategies exploiting these data commonly make use of intersensor correlation and coherence (array processing, multichannel correlation); network-based tracking of signal features (e.g. reverse time migration); or a combination of these such as backazimuth cross-bearings for multiple arrays. Single-sensor trace-based denoising techniques offer significant potential to improve all of these various infrasound data processing strategies, but have not previously been investigated in detail. Single-sensor denoising represents a pre-processing step that could reduce the effects of ambient infrasound and wind noise in infrasound signal association and location workflows. We systematically investigate the utility of a range of single-sensor denoising methods for infrasound data processing, including noise gating, non-negative matrix factorization, and data-adaptive Wiener filtering. For the data testbed, we use the relatively dense regional infrasound network in Alaska, which records a high rate of volcanic eruptions with signals varying in power, duration, and waveform and spectral character. We primarily use data from the 2016-2017 Bogoslof volcanic eruption, which included multiple explosions, and synthetics. The Bogoslof volcanic sequence provides an opportunity to investigate regional infrasound detection, association, and location for a set of real sources with varying source spectra subject to anisotropic atmospheric propagation and varying noise levels (both incoherent wind noise and coherent ambient infrasound, primarily microbaroms). We illustrate the advantages and disadvantages of the different denoising methods in categories such as event detection, waveform distortion, the need for manual data labelling, and computational cost. For all approaches, denoising generally performs better for signals with higher signal-to-noise ratios and with less spectral and temporal overlap between signals and noise. Microbaroms are the most globally pervasive and repetitive coherent ambient infrasound noise source, with such noise often referred to as clutter or interference. We find that denoising offers significant potential for microbarom clutter reduction. Single-channel denoising of microbaroms prior to standard array processing enhances both the quantity and bandwidth of detectable volcanic events. We find that reduction of incoherent wind noise is more challenging using the denoising methods we investigate; thus, station hardware (wind noise reduction systems) and site selection remain critical and cannot be replaced by currently available digital denoising methodologies. Overall, we find that adding single-channel denoising as a component in the processing workflow can benefit a variety of infrasound signal detection, association, and location schemes. The denoising methods can also isolate the noise itself, with utility in statistically characterizing ambient infrasound noise.  © 2022 The Author(s). Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Explosive volcanism; Statistical methods; Time-series analysis; Volcano monitoring; Volcano seismology},
	keywords = {Alaska; United States; Array processing; Clutter (information theory); Data handling; Explosives; Explosives detection; Matrix algebra; Non-negative matrix factorization; Signal to noise ratio; Volcanoes; Ambients; De-noising; Denoising methods; Explosive volcanism; Infra sound; Single sensor; Time-series analysis; Volcano monitoring; Volcano seismology; Wind noise; detection method; explosive volcanism; infrasonics; monitoring; seismic noise; signal processing; time series analysis; volcano; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Berger2023,
	author = {Berger, Christian and Birkemeyer, Lukas},
	title = {ZEBRA: Z-order Curve-based Event Retrieval Approach to Efficiently Explore Automotive Data},
	year = {2023},
	journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
	volume = {2023-June},
	doi = {10.1109/IV55152.2023.10186770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167963810&doi=10.1109%2fIV55152.2023.10186770&partnerID=40&md5=61d39db95c29285c2a535eaa4be647df},
	abstract = {Evaluating the performance of software for automated vehicles is predominantly driven by data collected from the real world. While professional test drivers are supported with technical means to semi-automatically annotate driving maneuvers to allow better event identification, simple data loggers in large vehicle fleets typically lack automatic and detailed event classification and hence, extra effort is needed when post-processing such data. Yet, the data quality from professional test drivers is apparently higher than the one from large fleets where labels are missing, but the non-annotated data set from large vehicle fleets is much more representative for typical, realistic driving scenarios to be handled by automated vehicles. However, while growing the data from large fleets is relatively simple, adding valuable annotations during post-processing has become increasingly expensive. In this paper, we leverage Z-order space-filling curves to systematically reduce data dimensionality while preserving domain-specific data properties, which allows us to explore even large-scale field data sets to spot interesting events orders of magnitude faster than processing time-series data directly. Furthermore, the proposed concept is based on an analytical approach, which preserves explainability for the identified events. © 2023 IEEE.},
	author_keywords = {event detection; Morton-order; space-filling curve; Z-order curve},
	keywords = {Data handling; Intelligent systems; Intelligent vehicle highway systems; Vehicles; Automated vehicles; Events detection; Large vehicles; Morton order; Post-processing; Simple++; Space-filling curve; Test drivers; Vehicle fleets; Z-order curve; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Balenzano2022,
	author = {Balenzano, Anna and Satalino, Giuseppe and Lovergine, Francesco Paolo and D’Addabbo, Annarita and Palmisano, Davide and Grassi, Riccardo and Ozalp, Ozlem and Mattia, Francesco and Nafría García, David and Paredes Gómez, Vanessa},
	title = {Sentinel-1 and Sentinel-2 Data to Detect Irrigation Events: Riaza Irrigation District (Spain) Case Study},
	year = {2022},
	journal = {Water (Switzerland)},
	volume = {14},
	number = {19},
	doi = {10.3390/w14193046},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139864281&doi=10.3390%2fw14193046&partnerID=40&md5=27557ff8787de58f1a78fe16706d5d60},
	abstract = {This paper investigates the use of high resolution (~100 m) surface soil moisture (SSM) maps to detect irrigation occurrences, in time and space. The SSM maps have been derived from time series of Copernicus Sentinel-1 (S-1) and Sentinel-2 (S-2) observations. The analysis focused on the Riaza irrigation district in the Castilla y León region (Spain), where detailed information on land use, irrigation scheduling, water withdrawal, meteorology and parcel borders is available from 2017 to 2021. The well-documented data basis has supported a solid characterization of the sources of uncertainties affecting the use of SSM to map and monitor irrigation events. The main factors affecting the irrigation detection are meteo-climatic condition, crop type, water supply and spatial and temporal resolution of Earth observation data. Results indicate that approximately three-quarters of the fields irrigated within three days of the S-1 acquisition can be detected. The specific contribution of SSM to irrigation monitoring consists of (i) an early detection, well before vegetation indexes can even detect the presence of a crop, and (ii) the identification of the irrigation event in time, which remains unfeasible for vegetation indexes. Therefore, SSM can integrate vegetation indexes to resolve the irrigation occurrences in time and space. © 2022 by the authors.},
	author_keywords = {high resolution soil moisture; irrigation event detection; Sentinel-1; Sentinel-2; uncertainties},
	keywords = {Castile; Crops; Land use; Soil moisture; Vegetation; Water supply; Events detection; High resolution; High resolution soil moisture; Irrigation districts; Irrigation event detection; Sentinel-1; Sentinel-2; Surface soil moisture; Uncertainty; Vegetation index; detection method; irrigation system; meteorology; observational method; satellite data; Sentinel; soil moisture; uncertainty analysis; Irrigation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Xiaowei20231011,
	author = {Xiaowei, Wang},
	title = {Research on the Application of Deep Reinforcement Learning Algorithm for Sensor Networks in Intelligent Environment Control},
	year = {2023},
	journal = {2023 IEEE International Conference on Control, Electronics and Computer Technology, ICCECT 2023},
	pages = {1011 – 1015},
	doi = {10.1109/ICCECT57938.2023.10140795},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162865605&doi=10.1109%2fICCECT57938.2023.10140795&partnerID=40&md5=9ee45e82721555b70a705325938e1588},
	abstract = {Real-time search of objects, data, and services has grown to be a crucial and practical problem in the IoT world in recent years due to the fast deployment of numerous Internet of Things (IoT) sensors. In addition to offering solutions for real-time sensor data collecting in the IoT, IoT data prediction models also provide more useful applications than conventional IoT event detection models. Using complicated time series created by several types of sensors, we have developed an enhanced neural network model in this research for multi-dimensional feature selection and outlier identification. Comparing our approach to conventional data prediction methods, we can see an improvement in the stability and accuracy of long-term forecasts for IoT sensor data. Finally, we compare the training capabilities of traditional neural network models with random forest models to assess the efficacy of our prediction model using sensor data from the Intel Berkeley Research Laboratory. Our model achieves an accuracy rate that is respectively more than 12% and 68% higher than the two comparison models, while the corresponding loss values are less than 0.325 and 0.595, respectively.  © 2023 IEEE.},
	author_keywords = {complex time series; intelligent environmental control; IoT sensor data prediction; multi-dimensional feature selection; outlier detection},
	keywords = {Anomaly detection; Deep learning; Environmental management; Feature extraction; Forecasting; Reinforcement learning; Research laboratories; Sensor networks; Time series; Complex time series; Data prediction; Environmental control; Features selection; Intelligent environmental control; Internet of thing sensor data prediction; Multi dimensional; Multi-dimensional feature selection; Outlier Detection; Sensors data; Internet of things},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Peng2021,
	author = {Peng, Yun and Wang, Jianmei},
	title = {Rumor detection based on attention cnn and time series of context information},
	year = {2021},
	journal = {Future Internet},
	volume = {13},
	number = {11},
	doi = {10.3390/fi13110267},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118864582&doi=10.3390%2ffi13110267&partnerID=40&md5=e1d3dfa553f4457556f13b5a333fe07e},
	abstract = {This study aims to explore the time series context and sentiment polarity features of rumors’ life cycles, and how to use them to optimize the CNN model parameters and improve the classification effect. The proposed model is a convolutional neural network embedded with an attention mechanism of sentiment polarity and time series information. Firstly, the whole life cycle of rumors is divided into 20 groups by the time series algorithm and each group of texts is trained by Doc2Vec to obtain the text vector. Secondly, the SVM algorithm is used to obtain the sentiment polarity features of each group. Lastly, the CNN model with the spatial attention mechanism is used to obtain the rumors’ classification. The experiment results show that the proposed model introduced with features of time series and sentiment polarity is very effective for rumor detection, and can greatly reduce the number of iterations for model training as well. The accuracy, precision, recall and F1 of the attention CNN are better than the latest benchmark model. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Attention CNN; Rumor event detection; Sentiment polarity; Time series algorithm},
	keywords = {Convolutional neural networks; Life cycle; Support vector machines; Attention CNN; Attention mechanisms; CNN models; Context information; Events detection; Modeling parameters; Rumor event detection; Sentiment polarity; Time series algorithms; Times series; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Labella20221570,
	author = {Labella, Aidan P. and Karns, Joshua A. and Akhbardeh, Farhad and Desell, Travis and Walton, Andrew J. and Morgan, Zechariah and Wild, Brandon and Dusenbury, Mark},
	title = {Optimized flight safety event detection in the national general aviation flight information database},
	year = {2022},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {1570 – 1579},
	doi = {10.1145/3477314.3507115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130365468&doi=10.1145%2f3477314.3507115&partnerID=40&md5=44dc5a10d995ac107bf1f61bf784a711},
	abstract = {This work presents a redesign of the National General Aviation Flight Information Database (NGAFID) to allow swift ingestion of flight data and calculation of flight safety events, as it is rapidly growing and currently housing over 750,000 hours of flight data. This redesign reduced memory and storage usage by a factor of 5, as well as reducing flight data import and event calculation time from over 3 minutes to 0.3 seconds by using a per-parameter compressed data representation in the database and a new pipelined data ingestion strategy. In addition to this, four new advanced flight safety event calculations were developed for proximity, self-defined glide path deviation, stall and loss of control in flight (LOC-I). A time and location bounded flight matching strategy was used to calculate proximity events for flights in on average 3.2 seconds per flight in the full 660,000 flight database. The stall and LOC-I event calculations show strong improvements upon prior work in the area on both a test flight flown for accurate stall time measurements and a historical sample of data independently annotated by two subject matter experts. The enhancements to the stall and LOC-I event calculations resulted in an increase in stall event detection from 23.1% to 83.1% in the historical data while reducing false negatives by a factor of 3. As the leading cause of aviation accidents worldwide is LOC-I, it is an especially important issue for flight safety monitoring programs, especially as other existing flight data monitoring (FDM) software lacks these new stall, LOC-I and proximity event detection capabilities. © 2022 ACM.},
	author_keywords = {big geospatial temporal data; computational aviation safety; hazard detection; time series analysis},
	keywords = {Civil aviation; Data reduction; Database systems; Safety factor; Time series analysis; Aviation safety; Big geospatial temporal data; Computational aviation safety; Events detection; Flight data; Flight safety; Geo-spatial; Hazard detection; Temporal Data; Time-series analysis; Digital storage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Rizzo202219655,
	author = {Rizzo, Antonino Maria and Magri, Luca and Rutigliano, Davide and Invernizzi, Pietro and Sozio, Enrico and Alippi, Cesare and Binetti, Stefano and Boracchi, Giacomo},
	title = {Known and unknown event detection in OTDR traces by deep learning networks},
	year = {2022},
	journal = {Neural Computing and Applications},
	volume = {34},
	number = {22},
	pages = {19655 – 19673},
	doi = {10.1007/s00521-022-07634-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136798000&doi=10.1007%2fs00521-022-07634-2&partnerID=40&md5=0c37c2be1e7da6c1654b4f77d5c8365d},
	abstract = {Optical fiber links are customarily monitored by Optical Time Domain Reflectometer (OTDR), an optoelectronic instrument that measures the scattered or reflected light along the fiber and returns a signal, namely the OTDR trace. OTDR traces are typically analyzed by experts in laboratories or by hand-crafted algorithms running in embedded systems to localize critical events occurring along the fiber. In this work, we address the problem of automatically detecting optical events in OTDR traces through a deep learning model that can be deployed in embedded systems. In particular, we take inspiration from Faster R-CNN and present the first 1D object-detection neural network for OTDR traces. Thanks to an ad-hoc preprocessing pipeline for OTDR traces, we can also identify unknown events, namely events that are not represented in training data but that might indicate rare and unforeseen situations that need to be reported. The resulting network brings several advantages with respect to existing solutions, as these typically classify fixed-size windows of OTDR traces, thus are less accurate in the localization. Moreover, existing solutions do not report events that cannot be safely associated to any label in the training set. Our experiments, performed on real OTDR traces, show very promising performance, and can be directly executed on embedded OTDR devices. © 2022, The Author(s).},
	author_keywords = {Detection Network; Open-Set; OTDR Events; Recognition; Time Series},
	keywords = {Deep learning; Embedded systems; Learning systems; Optical fibers; Reflectometers; Detection networks; Embedded-system; Events detection; Learning network; Open-set; Optical time domain reflectometer; Optical time domain reflectometer event; Optical-fiber links; Recognition; Times series; Object detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{El Mokhtari2022,
	author = {El Mokhtari, Karim and Panushev, Ivan and McArthur, J.J.},
	title = {Development of a Cognitive Digital Twin for Building Management and Operations},
	year = {2022},
	journal = {Frontiers in Built Environment},
	volume = {8},
	doi = {10.3389/fbuil.2022.856873},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139394134&doi=10.3389%2ffbuil.2022.856873&partnerID=40&md5=e14857ed95c47e14fb60c45ee76d070c},
	abstract = {Cognitive Digital Twins (CDTs) are defined as capable of achieving some elements of cognition, notably memory (encoding and retrieval), perception (creating useful data representations), and reasoning (outlier and event detection). This paper presents the development of a CDT, populated by construction information, facility management data, and data streamed from the Building Automation System (BAS). Advanced machine learning was enabled by access to both real-time and historical data coupled with scalable cloud-based computational resources. Streaming data to the cloud has been implemented in existing architectures; to address security concerns from exposing building equipment to undesirable access, a secure streaming architecture from BACnet equipment to our research cloud is presented. Real-time data is uploaded to a high-performance scalable time-series database, while the ontology is stored on a relational database. Both data sources are integrated with Building Information Models (BIM) to aggregate, explore, and visualize information on demand. This paper presents a case study of a Digital Twin (DT) of an academic building where various capabilities of CDTs are demonstrated through a series of proof-of-concept examples. Drawing from our experience enhancing this implementation with elements of cognition, we present a development framework and reference architecture to guide future whole-building CDT research. Copyright © 2022 El Mokhtari, Panushev and McArthur.},
	author_keywords = {cognitive digital twin; data streaming; data visualization; IoT; smart building},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Chen20231,
	author = {Chen, Li-Chin and Hung, Kuo-Hsuan and Tseng, Yi-Ju and Wang, Hsin-Yao and Lu, Tse-Min and Huang, Wei-Chieh and Tsao, Yu},
	title = {Self-supervised based general laboratory progress pretrained model for cardiovascular event detection},
	year = {2023},
	journal = {IEEE Journal of Translational Engineering in Health and Medicine},
	pages = {1–1},
	doi = {10.1109/JTEHM.2023.3307794},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168727728&doi=10.1109%2fJTEHM.2023.3307794&partnerID=40&md5=48dc3ced4b9da674278ad27b19519937},
	abstract = {Objective: Leveraging patient data through machine learning techniques in disease care offers a multitude of substantial benefits. Nonetheless, the inherent nature of patient data poses several challenges. Prevalent cases amass substantial longitudinal data owing to their patient volume and consistent follow-ups, however, longitudinal laboratory data are renowned for their irregularity, temporality, absenteeism, and sparsity; In contrast, recruitment for rare or specific cases is often constrained due to their limited patient size and episodic observations. This study employed self-supervised learning (SSL) to pretrain a generalized laboratory progress (GLP) model that captures the overall progression of common laboratory markers in prevalent cardiovascular cases, with the intention of transferring this knowledge to aid in the detection of specific cardiovascular event. Methods and procedures: GLP implemented a two-stage training approach, leveraging the information embedded within interpolated data and amplify the performance of SSL. After GLP pretraining, it is transferred for TVR detection. Results: The proposed two-stage training improved the performance of pure SSL, and the transferability of GLP exhibited distinctiveness. After GLP processing, the classification exhibited a notable enhancement, with averaged accuracy rising from 0.63 to 0.90. All evaluated metrics demonstrated substantial superiority (<italic>p</italic> &#x003C; 0.01) compared to prior GLP processing. Conclusion: Our study effectively engages in translational engineering by transferring patient progression of cardiovascular laboratory parameters from one patient group to another, transcending the limitations of data availability. The transferability of disease progression optimized the strategies of examinations and treatments, and improves patient prognosis while using commonly available laboratory parameters. The potential for expanding this approach to encompass other diseases holds great promise. Clinical impact: Our study effectively transposes patient progression from one cohort to another, surpassing the constraints of episodic observation. The transferability of disease progression contributed to cardiovascular event assessment. Author},
	author_keywords = {cardiometabolic disease; Cardiovascular diseases; Cardiovascular diseases; disease progression; Electrocardiography; Glucose; Interpolation; laboratory examinations; pre-train model; representation learning; self-supervised learning; Statistics; Task analysis; time-series data; Training; transfer learning},
	keywords = {Cardiology; Diagnosis; Hospital data processing; Job analysis; Supervised learning; Time series analysis; Cardiometabolic disease; Cardiovascular disease; Disease progression; Laboratory examination; Pre-train model; Representation learning; Self-supervised learning; Task analysis; Time-series data; Train model; Transfer learning; Diseases},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Mishra2022,
	author = {Mishra, Kakuli and Basu, Srinka and Maulik, Ujjwal},
	title = {Graft: A graph based time series data mining framework},
	year = {2022},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {110},
	doi = {10.1016/j.engappai.2022.104695},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124612112&doi=10.1016%2fj.engappai.2022.104695&partnerID=40&md5=b502909492f4e8ee41cca9043ea7b6d1},
	abstract = {Rapid technology integration causes a high dimensional time series data accumulation in multiple domains and applying the classical data mining tools and techniques becomes a challenging task. Hence, the time series data representation have gained popularity over the years, which ease the task of mining, analysis and visualization. Graph based representation is one such emerging tool in which the time series data is represented as nodes and edges of graph. The current graph based representation is designed either to mine the motif or discords from a single time series or cluster the time series where each node represents a time series sample. Such representation technique causes information loss and also no further analysis could be performed other than clustering. To address these challenges, we propose a unique graph representation for time series dataset that works on multiple domains. Novelty of the graph representation is that it is unique for multiple time series and it acts as a framework for whole time series clustering, temporal pattern extraction from each cluster and temporally dependent rare event discovery. A new research direction for the proposed graph based framework is shown. Comparative analysis reveal the superiority of the proposed framework particularly as a clustering technique. The key contributions of the paper are: (i) transformation strategy of time series database from time domain to graph structure in topological domain (ii) time series clustering using path level analysis (iii) identification of temporally dependent co-occurring patterns (iv) rare event detection using component level analysis © 2022 Elsevier Ltd},
	author_keywords = {Clustering; Directed and undirected graphs; Eigen values; Graph based networks; Time series similarity},
	keywords = {Data mining; Data visualization; Directed graphs; Graphic methods; Time domain analysis; Time series analysis; Undirected graphs; Clusterings; Eigen-value; Graph based network; Graph-based; Graph-based representations; Multiple domains; Time series similarity; Time-series data; Times series; Undirected graph; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Bono2023308,
	author = {Bono, Carlo A. and Mülâyim, Mehmet Oğuz and Pernici, Barbara},
	title = {Learning Early Detection of Emergencies from Word Usage Patterns on Social Media},
	year = {2023},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {672 LNBIP},
	pages = {308 – 323},
	doi = {10.1007/978-3-031-34207-3_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173570889&doi=10.1007%2f978-3-031-34207-3_20&partnerID=40&md5=9db004fbd49ad5f6a3e3ee8a1ba3711a},
	abstract = {In the early stages of an emergency, information extracted from social media can support crisis response with evidence-based content. In order to capture this evidence, the events of interest must be first promptly detected. An automated detection system is able to activate other tasks, such as preemptive data processing for extracting event-related information. In this paper, we extend the human-in-the-loop approach in our previous work, TriggerCit, with a machine-learning-based event detection system trained on word count time series and coupled with an automated lexicon building algorithm. We design this framework in a language-agnostic fashion. In this way, the system can be deployed to any language without substantial effort. We evaluate the capacity of the proposed work against authoritative flood data for Nepal recorded over two years. © 2023, IFIP International Federation for Information Processing.},
	author_keywords = {Disaster Management; Early Alerting; Social Media},
	keywords = {Data handling; Disaster prevention; Disasters; Social networking (online); Automated detection; Crisis response; Detection system; Disaster management; Early alerting; Emergency information; Evidence-based; Human-in-the-loop; Social media; Usage patterns; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Sharma202135081,
	author = {Sharma, Anshul and Singh, Sanjay Kumar},
	title = {Early classification of multivariate data by learning optimal decision rules},
	year = {2021},
	journal = {Multimedia Tools and Applications},
	volume = {80},
	number = {28-29},
	pages = {35081 – 35104},
	doi = {10.1007/s11042-020-09366-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088822880&doi=10.1007%2fs11042-020-09366-8&partnerID=40&md5=b6b84392c7f27f3b0d2877571dc42a36},
	abstract = {Early classification on time series has emerged as an active research area in the field of machine learning. It covers a wide range of applications in agriculture, medical and multimedia systems, including drought prediction, health monitoring, event detection, and many more. The early classification aims to predict the class label of a time series as soon as possible without waiting for the complete series. A critical issue in early classification is the learning of decision policy that determines the adequacy of the collected data required for reliable class prediction. It is more challenging for Multivariate Time Series (MTS) data, where the decision depends on multiple variables to achieve a trade-off between earliness and accuracy. Therefore, this work proposes an optimization-based early classification model for MTS data based on optimal decision rule learning. The proposed model adopts a two-layered approach. The first layer employs the Gaussian process probabilistic classifiers for each variable in MTS that provides the class probabilities at the successive time steps in the series. The second layer defines Early Stopping Rule (ESR) that performs the class prediction task. The ESR learns its parameters through the particle swarm optimization by simultaneously minimizing the misclassification cost and delaying the decision cost. This work has utilized publicly available MTS datasets to validate the proposed early classification model. The experimental results show that the proposed model achieves promising results in terms of accuracy and earliness compared to existing methods. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Cost optimization; Early classification; Multimedia data; Multivariate data analysis; Time series},
	keywords = {Agricultural robots; Economic and social effects; Forecasting; Learning systems; Multimedia systems; Particle swarm optimization (PSO); Time series; Class probabilities; Classification models; Gaussian Processes; Layered approaches; Misclassification costs; Multivariate time series; Optimal decision-rule; Probabilistic classifiers; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Krakowczyk2023,
	author = {Krakowczyk, Daniel G. and Prasse, Paul and Reich, David R. and Lapuschkin, Sebastian and Scheffer, Tobias and Jäger, Lena A.},
	title = {Bridging the Gap: Gaze Events as Interpretable Concepts to Explain Deep Neural Sequence Models},
	year = {2023},
	journal = {Eye Tracking Research and Applications Symposium (ETRA)},
	doi = {10.1145/3588015.3588412},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161180193&doi=10.1145%2f3588015.3588412&partnerID=40&md5=ab5110d47380a5aa0802657d4cae154a},
	abstract = {Recent work in XAI for eye tracking data has evaluated the suitability of feature attribution methods to explain the output of deep neural sequence models for the task of oculomotric biometric identification. These methods provide saliency maps to highlight important input features of a specific eye gaze sequence. However, to date, its localization analysis has been lacking a quantitative approach across entire datasets. In this work, we employ established gaze event detection algorithms for fixations and saccades and quantitatively evaluate the impact of these events by determining their concept influence. Input features that belong to saccades are shown to be substantially more important than features that belong to fixations. By dissecting saccade events into sub-events, we are able to show that gaze samples that are close to the saccadic peak velocity are most influential. We further investigate the effect of event properties like saccadic amplitude or fixational dispersion on the resulting concept influence.  © 2023 Owner/Author.},
	author_keywords = {concept influence; explainability; eye movements; time-series; xai},
	keywords = {Computer vision; Eye tracking; Biometric identifications; Concept influence; Explainability; Eye-tracking; Input features; Saliency map; Sequence models; Times series; Tracking data; Xai; Eye movements},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Dey20224338,
	author = {Dey, Sharmita and Fan, David and Schmid, Robin and Dixit, Anushri and Otsu, Kyohei and Touma, Thomas and Schilling, Arndt F. and Agha-Mohammadi, Ali-Akbar},
	title = {PrePARE: Predictive Proprioception for Agile Failure Event Detection in Robotic Exploration of Extreme Terrains},
	year = {2022},
	journal = {IEEE International Conference on Intelligent Robots and Systems},
	volume = {2022-October},
	pages = {4338 – 4343},
	doi = {10.1109/IROS47612.2022.9981660},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146309494&doi=10.1109%2fIROS47612.2022.9981660&partnerID=40&md5=fe22794fb568cf06da1468731fe40ccf},
	abstract = {Legged robots can traverse a wide variety of terrains, some of which may be challenging for wheeled robots, such as stairs or highly uneven surfaces. However, quadruped robots face stability challenges on slippery surfaces. This can be resolved by adjusting the robot's locomotion by switching to more conservative and stable locomotion modes, such as crawl mode (where three feet are in contact with the ground always) or amble mode (where one foot touches down at a time) to prevent potential falls. To tackle these challenges, we propose an approach to learn a model from past robot experience for predictive detection of potential failures. Accordingly, we trigger gait switching merely based on proprioceptive sensory information. To learn this predictive model, we propose a semi-supervised process for detecting and annotating ground truth slip events in two stages: We first detect abnormal occurrences in the time series sequences of the gait data using an unsupervised anomaly detector, and then, the anomalies are verified with expert human knowledge in a replay simulation to assert the event of a slip. These annotated slip events are then used as ground truth examples to train an ensemble decision learner for predicting slip probabilities across terrains for traversability. We analyze our model on data recorded by a legged robot on multiple sites with slippery terrain. We demonstrate that a potential slip event can be predicted up to 720 ms ahead of a potential fall with an average precision greater than 0.95 and an average F-score of 0.82. Finally, we validate our approach in real-time by deploying it on a legged robot and switching its gait mode based on slip event detection. © 2022 IEEE.},
	keywords = {Events detection; Failure events; Ground truth; Learn+; Legged robots; Quadruped Robots; Robot face; Robotic explorations; Uneven surfaces; Wheeled robot; Multipurpose robots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Akhavan20228,
	author = {Akhavan, Zeinab and Esmaeili, Mona and Devetsikiotis, Michael and Zarkesh-Ha, Payman},
	title = {Cross-Correlation for Streaming Seismic Time Series to Detect Events using Parallel and Real-time Methods},
	year = {2022},
	journal = {2022 IEEE 13th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2022},
	pages = {8 – 13},
	doi = {10.1109/UEMCON54665.2022.9965662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144050998&doi=10.1109%2fUEMCON54665.2022.9965662&partnerID=40&md5=f32dabcfe45c95f348eb4d0cd17ec003},
	abstract = {The design of real-time systems is becoming increasingly important. Such systems must process the input and provide the output in a timely fashion. Therefore, the tasks must be carefully scheduled and executed on the processor(s). A good example of a system that requires real-time action is the earthquake warning system because it is critical that the system instantly examines the events happening. In such case, no disaster will happen if the system's response is in real-time. This paper describes real-time methods of seismic event detection and how to identify the correlation between seismic time-series in order to find the events' source and study the seismicity in New Mexico, USA using Spark Streaming framework. © 2022 IEEE.},
	author_keywords = {Big Data; Data Stream Processing; Large-scale visualization; Parallel Computing},
	keywords = {Data handling; Data visualization; Interactive computer systems; Real time systems; Seismology; Time series; Cross-correlations; Data streams processing; Large-scale visualization; Parallel com- puting; Real - Time system; Real time methods; Real- time; Seismic event; System response; Times series; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Barama20223514,
	author = {Barama, Louisa and Peng, Zhigang and Newman, Andrew V. and Williams, Jesse},
	title = {GTUNE: An Assembled Global Seismic Dataset of Underground Nuclear Test Blasts},
	year = {2022},
	journal = {Seismological Research Letters},
	volume = {93},
	number = {6},
	pages = {3514 – 3523},
	doi = {10.1785/0220220036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142290270&doi=10.1785%2f0220220036&partnerID=40&md5=fede8231134a458b72198833cb7d55b3},
	abstract = {From catalogs of available declassified underground nuclear explosions, we compiled a comprehensive seismic waveform and event catalog termed GTUNE (Georgia Tech Underground Nuclear Explosions). Nuclear blast seismic records are sourced from previously prepared published datasets and openly available waveforms from online sources. All seismic traces were assembled into a user-friendly format compatible with most python-based machine learning (ML) packages. The GTUNE dataset includes the raw seismogram time series, event coordinates and origin time, sampling rate, station metadata, channel, epicentral distance, and P-wave arrival time from the origin dataset when available and otherwise identified using a tuned automated picker. This is the first openly available comprehensive global underground nuclear blast seismic dataset and consists of 28,123 vertical-component waveforms from 774 nuclear test blasts between 1961 and 2017 recorded between 0 and 90 epicentral degrees. For stations where data are not directly included due to data-sharing restrictions, the mechanisms to acquire and process these data are included. In this article, we describe various steps involved in data collection and quality control to ensure accurate labels, and present summary properties of the catalog and data set. The catalog was initially developed for applications with ML methods but can be used for a wide range of studies such as source physics, earth structure, and event detection methodological development. © Seismological Society of America.},
	keywords = {Nuclear explosions; Seismic waves; Seismology; Statistical tests; Georgia; Nuclear blasts; Nuclear tests; Online sources; Seismic event; Seismic records; Seismic traces; Seismic waveforms; Underground nuclear explosions; Waveforms; data set; machine learning; nuclear explosion; seismic data; seismic source; seismic wave; Python},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Lu20223031,
	author = {Lu, Beichen and Chang, Zixing and Jin, Tao and Wang, Jianmin},
	title = {Time series event detection method based on wavelet analysis; [基于小波分析的时间序列事件检测方法]},
	year = {2022},
	journal = {Jisuanji Jicheng Zhizao Xitong/Computer Integrated Manufacturing Systems, CIMS},
	volume = {28},
	number = {10},
	pages = {3031 – 3038},
	doi = {10.13196/j.cims.2022.10.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151435333&doi=10.13196%2fj.cims.2022.10.001&partnerID=40&md5=9df7dfbe6d0735affd09b5bbc53321e9},
	abstract = {Time series event detection is an important task in the field of time series data mining which starts from time series data,and the event information in the data is detected by data mining method. Event is the basis of process mining,which can be used to discover,analyze and optimize processes. Two abstract methods were used to complete the event detection. The time series was divided into state intervals according to the given label, then the frequent time patterns were found in the state interval sequence,and the possible event points were obtained by screening the frequent patterns through association rules. The feasibility and efficiency of the algorithm were verified by experiments on simulated data sets and real data sets. © 2022 CIMS. All rights reserved.},
	author_keywords = {data mining; event detection; multi-resolution analysis; time series; wavelet analysis},
	keywords = {Multiresolution analysis; Time series; Time series analysis; Data mining methods; Detection methods; Events detection; Multi-resolution analysis; Process mining; Time series data mining; Time-series data; Time-series events; Times series; Wavelet-analysis; Data mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Morsa2023148,
	author = {Morsa, Nathan},
	title = {EDGAR: Embedded Detection of Gunshots by AI in Real-time},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13812 LNAI},
	pages = {148 – 166},
	doi = {10.1007/978-3-031-24378-3_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151062158&doi=10.1007%2f978-3-031-24378-3_10&partnerID=40&md5=d81fd6911d7e6d817d7641f70ad4f632},
	abstract = {Electronic shot counters allow armourers to perform preventive and predictive maintenance based on quantitative measurements, improving reliability, reducing the frequency of accidents, and reducing maintenance costs. To answer a market pressure for both low lead time to market and increased customisation, we aim to solve the shot detection and shot counting problem in a generic way through machine learning. In this study, we describe a method allowing one to construct a dataset with minimal labelling effort by only requiring the total number of shots fired in a time series. To our knowledge, this is the first study to propose a technique, based on learning from label proportions, that is able to exploit these weak labels to derive an instance-level classifier able to solve the counting problem and the more general discrimination problem. We also show that this technique can be deployed in heavily constrained microcontrollers while still providing hard real-time (&lt;100 ms) inference. We evaluate our technique against a state-of-the-art unsupervised algorithm and show a sizeable improvement, suggesting that the information from the weak labels is successfully leveraged. Finally, we evaluate our technique against human-generated state-of-the-art algorithms and show that it provides comparable performance and significantly outperforms them in some offline and real-world benchmarks. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Deep learning; Event detection; Label proportions; Preventive maintenance; Resource-constrained devices; Time series classification; Weak labels},
	keywords = {Benchmarking; Chemical detection; Commerce; Deep learning; Time series; Counting problems; Deep learning; Events detection; Label proportion; Predictive maintenance; Quantitative measurement; Real- time; Resourceconstrained devices; Time series classifications; Weak labels; Preventive maintenance},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Reinermann2023,
	author = {Reinermann, Sophie and Asam, Sarah and Gessner, Ursula and Ullmann, Tobias and Kuenzer, Claudia},
	title = {Multi-annual grassland mowing dynamics in Germany: spatio-temporal patterns and the influence of climate, topographic and socio-political conditions},
	year = {2023},
	journal = {Frontiers in Environmental Science},
	volume = {11},
	doi = {10.3389/fenvs.2023.1040551},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164521252&doi=10.3389%2ffenvs.2023.1040551&partnerID=40&md5=5c0965c57efce21acf673196aa22c785},
	abstract = {Introduction: Grasslands cover one third of the agricultural area in Germany and are mainly used for fodder production. However, grasslands fulfill many other ecosystem functions, like carbon storage, water filtration and the provision of habitats. In Germany, grasslands are mown and/or grazed multiple times during the year. The type and timing of management activities and the use intensity vary strongly, however co-determine grassland functions. Large-scale spatial information on grassland activities and use intensity in Germany is limited and not openly provided. In addition, the cause for patterns of varying mowing intensity are usually not known on a spatial scale as data on the incentives of farmers behind grassland management decisions is not available. Methods: We applied an algorithm based on a thresholding approach utilizing Sentinel-2 time series to detect grassland mowing events to investigate mowing dynamics in Germany in 2018–2021. The detected mowing events were validated with an independent dataset based on the examination of public webcam images. We analyzed spatial and temporal patterns of the mowing dynamics and relationships to climatic, topographic, soil or socio-political conditions. Results: We found that most intensively used grasslands can be found in southern/south-eastern Germany, followed by areas in northern Germany. This pattern stays the same among the investigated years, but we found variations on smaller scales. The mowing event detection shows higher accuracies in 2019 and 2020 (F1 = 0.64 and 0.63) compared to 2018 and 2021 (F1 = 0.52 and 0.50). We found a significant but weak (R2 of 0–0.13) relationship for a spatial correlation of mowing frequency and climate as well as topographic variables for the grassland areas in Germany. Further results indicate a clear value range of topographic and climatic conditions, characteristic for intensive grassland use. Extensive grassland use takes place everywhere in Germany and on the entire spectrum of topographic and climatic conditions in Germany. Natura 2000 grasslands are used less intensive but this pattern is not consistent among all sites. Discussion: Our findings on mowing dynamics and relationships to abiotic and socio-political conditions in Germany reveal important aspects of grassland management, including incentives of farmers. Copyright © 2023 Reinermann, Asam, Gessner, Ullmann and Kuenzer.},
	author_keywords = {cutting; Earth observation; management; meadow; pasture; remote sensing; Sentinel-2; time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Liu20221648,
	author = {Liu, Xinlong and Sun, Zepeng and Liu, Wei and Qiao, Feng and Cui, Li and Yang, Jing and Sha, Jingjie and Li, Jian and Xu, Li-Qun},
	title = {Multi-level translocation events analysis in solid-state nanopore current traces},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2022},
	pages = {1648 – 1653},
	doi = {10.1109/BIBM55620.2022.9995453},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146724728&doi=10.1109%2fBIBM55620.2022.9995453&partnerID=40&md5=1e97a9fb110ebc41388c7362e7a51513},
	abstract = {Solid-state nanopores have shown impressive performances in several sequencing research scenarios, such as biomolecule conformation detection, biomarker identification, and protein fingerprinting. In all these scenarios, accurate event detection is the fundamental step toward data analysis. Most existing event detection methods use either user-defined thresholds or adaptive thresholds determined automatically by the data. The former class depends heavily on human expertise, which is labor-intensive; the latter appears to be more advanced, however, the setting of threshold parameters is somewhat tricky. Hence, the results are usually inconsistent among different methods. In this paper, we develop a novel event detection method, where the selection threshold is computed following the principle governed by an analytical expression. Unlike other methods, each event's starting and ending points are located based on the slope rather than picking the first point whose current value goes across the baseline. Moreover, we add a method to determine whether multiple levels are present within each event. We then evaluate the method on two groups of current traces generated by short ssDNA and 48.5kb λ-DNA samples, respectively. The results show that our method performs well on detecting challenging translocation events with relatively low amplitudes, and is also able to accurately locate the starting/end points of each level of the events.  © 2022 IEEE.},
	author_keywords = {Event detection; Multilevel event fitting; Solid-state nanopores; Time-series analysis},
	keywords = {Biomolecules; Nanopores; Conformation detection; Current traces; Detection methods; Event analysis; Events detection; Multilevel event fitting; Multilevels; Performance; Solid-state nanopore; Time-series analysis; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tselentis2023254,
	author = {Tselentis, Dimitrios I. and Papadimitriou, Eleonora},
	title = {Time-series clustering for pattern recognition of speed and heart rate while driving: A magnifying lens on the seconds around harsh events},
	year = {2023},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	volume = {98},
	pages = {254 – 268},
	doi = {10.1016/j.trf.2023.09.010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173485063&doi=10.1016%2fj.trf.2023.09.010&partnerID=40&md5=4d456436d97c189eaedfcf29d85c4315},
	abstract = {Driving pattern recognition has been applied for the purposes of driving styles identification and harsh driving events detection. However, the evolution of driving behavior around and especially before such events has not been investigated at a microscopic level. The objective of this research is to reveal existing driving patterns around harsh events at the driving ‘pulse’ level i.e. a few seconds before and after the event. For that purpose, a time-series clustering approach is applied on speed and heart rate metrics of individual drivers using data collected from a large naturalistic driving study. Results show that there are distinct speed patterns before harsh braking, harsh acceleration, and harsh cornering events. A deceleration is identified shortly before most harsh acceleration and cornering events, which possibly indicates reckless behavior, i.e. drivers not dedicating enough time to smoothly brake before cornering, or of a brief ‘decision-making’ moment before the harsh manoeuvre. On the contrary, speed seems to be steady before harsh braking events. Regarding heart rate, the analysis revealed certain patterns only after raw data were cleansed and filtered. These patterns may show increasing, decreasing or variable heart rate trends, which may correspond to different stress patterns of drivers around harsh events. Finally, we introduce the concept of driving pattern consistency, which can reveal the share of individual drivers that follow the same harsh event pattern. It is indicated that more than half of the drivers are not consistent, suggesting that driving patterns around harsh events may be more context-related than driver personality-related. © 2023 The Author(s)},
	author_keywords = {Driving Pattern Recognition; Driving pulse; Heart-Rate patterns; Speed Patterns; Time-series Clustering; Unsupervised Learning},
	keywords = {Behavioral research; Heart; Pattern recognition; Time series; Unsupervised learning; Driving pattern; Driving pattern recognition; Driving pulse; Driving styles; Heart-rate; Heart-rate pattern; Magnifying lens; Speed patterns; Speed rates; Time series clustering; Decision making},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Huck20236299,
	author = {Huck, Rosemary and Bryant, Robert G. and King, James},
	title = {The (mis)identification of high-latitude dust events using remote sensing methods in the Yukon, Canada: a sub-daily variability analysis},
	year = {2023},
	journal = {Atmospheric Chemistry and Physics},
	volume = {23},
	number = {11},
	pages = {6299 – 6318},
	doi = {10.5194/acp-23-6299-2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163570532&doi=10.5194%2facp-23-6299-2023&partnerID=40&md5=e96aead35c2e0bf57efbd8bff0be2679},
	abstract = {The observation and quantification of mineral dust fluxes from high-latitude sources remains difficult due to a known paucity of year-round in situ observations and known limitations of satellite remote sensing data (e.g. cloud cover and dust detection). Here we explore the chronology of dust emissions at a known and instrumented high-latitude dust source: Lhù'ààn Mân (Kluane Lake) in Yukon, Canada. At this location we use oblique time-lapse (RC) cameras as a baseline for analysis of aerosol retrievals from in situ metrological data, AERONET, and co-incident MODIS MAIAC to (i) investigate the daily to annual chronology of dust emissions recorded by these instrumental and remote sensing methods (at timescales ranging from minutes to years) and (ii) use data intercomparisons to comment on the principal factors that control the detection of dust in each case. Lhù'ààn Mân is a prolific mineral dust source; on 24 May 2018 the RC captured dust in motion throughout the entire day, with the longest dust-free period lasting only 30min. When compared with time series of RC data, optimized AERONET data only manage an overall 26% detection rate for events (sub-day) but 100% detection rate for dust event days (DEDs) when dust was within the field of view. In this instance, RC and remote sensing data were able to suggest that the low event detection rate was attributed to fundamental variations in dust advection trajectory, dust plume height, and inherent restrictions in sun angle at high latitudes. Working with a time series of optimized aerosol optical depth (AOD) data (covering 2018/2019), we were able to investigate the gross impacts of data quality (DQ) choice on DED detection at the month or year scale. Relative to ground observations, AERONET's DQ2.0 cloud-screening algorithm may remove as much as 97% of known dust events (3% detection). Finally, when undertaking an AOD comparison for DED and non-DED retrievals, we find that cloud screening of MODIS/AERONET lead to a combined low sample of co-incident dust events and weak correlations between retrievals. Our results quantify and explain the extent of under-representation of dust in both ground and space remote sensing methods; this is a factor that impacts on the effective calibration and validation of global climate and dust models. © 2023 Rosemary Huck et al.},
	keywords = {Canada; Kluane Lake; Yukon Territory; AERONET; aerosol property; chronology; diel variation; mineral dust; MODIS; optical depth; remote sensing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Askari2022297,
	author = {Askari, Mohammad Reza and Rashid, Mudassir and Sun, Xiaoyu and Sevil, Mert and Shahidehpour, Andrew and Kawaji, Keigo and Cinar, Ali},
	title = {Meal and Physical Activity Detection from Free-Living Data for Discovering Disturbance Patterns of Glucose Levels in People with Diabetes},
	year = {2022},
	journal = {BioMedInformatics},
	volume = {2},
	number = {2},
	pages = {297 – 317},
	doi = {10.3390/biomedinformatics2020019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138478266&doi=10.3390%2fbiomedinformatics2020019&partnerID=40&md5=810d260dec640fcecc355522ec32fd01},
	abstract = {Objective: The interpretation of time series data collected in free-living has gained importance in chronic disease management. Some data are collected objectively from sensors and some are estimated and entered by the individual. In type 1 diabetes (T1D), blood glucose concentration (BGC) data measured by continuous glucose monitoring (CGM) systems and insulin doses administered can be used to detect the occurrences of meals and physical activities and generate the personal daily living patterns for use in automated insulin delivery (AID). Methods: Two challenges in time-series data collected in daily living are addressed: data quality improvement and the detection of unannounced disturbances of BGC. CGM data have missing values for varying periods of time and outliers. People may neglect reporting their meal and physical activity information. In this work, novel methods for preprocessing real-world data collected from people with T1D and the detection of meal and exercise events are presented. Four recurrent neural network (RNN) models are investigated to detect the occurrences of meals and physical activities disjointly or concurrently. Results: RNNs with long short-term memory (LSTM) with 1D convolution layers and bidirectional LSTM with 1D convolution layers have average accuracy scores of 92.32% and 92.29%, and outperform other RNN models. The F1 scores for each individual range from 96.06% to 91.41% for these two RNNs. Conclusions: RNNs with LSTM and 1D convolution layers and bidirectional LSTM with 1D convolution layers provide accurate personalized information about the daily routines of individuals. Significance: Capturing daily behavior patterns enables more accurate future BGC predictions in AID systems and improves BGC regulation. © 2022 by the authors.},
	author_keywords = {data preprocessing; event detection; outlier removal; recurrent neural networks; type 1 diabetes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhu2022141,
	author = {Zhu, Hengmin and Mei, Yanshuang and Wei, Jing and Shen, Chao},
	title = {Prediction of online topics’ popularity patterns},
	year = {2022},
	journal = {Journal of Information Science},
	volume = {48},
	number = {2},
	pages = {141 – 151},
	doi = {10.1177/0165551520961026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091301701&doi=10.1177%2f0165551520961026&partnerID=40&md5=2c03dafae194910fa8efa5e97ccb5e81},
	abstract = {Popularity prediction of online contents is always a tool of emergency management, business decision-making, and public opinion monitoring. Most previous work has made efforts to predict the volumes or levels of popularity, but patterns of popularity evolution are remaining largely unexplored. Actually, topic popularity patterns can offer more detailed information for event detection and early warning. In this article, we proposed an effective method to discover and predict the popularity patterns of topics on the Internet which combined clustering and classification models. This method does not rely on the early time data of topic propagation, so it can predict the future popularity pattern at the initial stage of topic releasing. First, we chose a time series clustering algorithm K-SC to obtain basic types of topic popularity patterns. Then, through acquiring and evaluating multiple features related to the topics including publisher features, outward characteristics of content and textual ones, we built the prediction model of topic popularity patterns based on machine learning methods. The experimental results show that it is suitable to cluster four basic patterns of topic popularity from the experimental data. What’s more, making use of certain initial characteristics, Decision Tree model can effectively predict the popularity pattern of a newly released topic, with an accuracy of 89.4%. © The Author(s) 2020.},
	author_keywords = {Information diffusion; online topics; popularity pattern; prediction},
	keywords = {Clustering algorithms; Decision trees; Forecasting; Learning systems; Predictive analytics; Risk management; Social aspects; Business decisions; Classification models; Decision tree modeling; Emergency management; Multiple features; Popularity predictions; Prediction model; Time series clustering; Decision making},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Khamphilung202317,
	author = {Khamphilung, P. and Konyai, S. and Slack, D. and Chaibandit, K. and Prasertsri, N.},
	title = {Flood Event Detection and Assessment using Sentinel-1 SAR-C Time Series and Machine Learning Classifiers Impacted on Agricultural Area, Northeastern, Thailand},
	year = {2023},
	journal = {International Journal of Geoinformatics},
	volume = {19},
	number = {6},
	pages = {17 – 29},
	doi = {10.52939/ijg.v19i6.2691},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164397247&doi=10.52939%2fijg.v19i6.2691&partnerID=40&md5=41c99a71ce7d67812a88283176667156},
	abstract = {This study presents image classification techniques using Sentinel-1A microwave SAR-C imagery to detect agricultural vulnerability area resulting from a massive flood in Ubon Ratchathani province, Thailand, which occurred in 2019. Two time series of selected images were used in analytical processes: namely S1A_IW_GRDH acquired on August 10th, 2019, representing the pre-flood event, and S1A_IW_GRDH acquired on 9th September 2019 represents the massive flood in this area. Prior to the classification, these data were preformed pre-processing processes, such as calibration, speckle filtering and terrain correction. The preprocessed data were then classified using 3 machine learning classifier algorithms, namely, Random Forest (RF), K-Dimensional Tree (KDTree KNN), and Maximum Likelihood for comparing classification accuracy derived from each classifier. There are 4 land use/land cover (LULC) classes derived from the dataset, i.e., (1) paddy rice, (2) water body, (3) residential area, and (4) vegetation, respectively. The second map was used to determine the extent of flooding and non-water area based on backscattering coefficient derived from Sigma0_VV polarization using band math calculation obtained from the histogram. The extracted flooded area aimed at creating the flooded water mask for overlaying with the classified LULC maps derived from each classifier. Finally, the LULC maps were overlaid with flooded event map that occurred on September 9, 2019, for quantifying affected area. The results indicated that paddy rice was damaged by flooded with the area of 98 km2 classified by RF achieving the overall accuracy of 94.60%. The KDTree KNN classifier identified the affected area of 85 km2 with the overall accuracy of 93%, while the Maximum Likelihood classifier detected the flooded area of 91 km2 with the overall accuracy of 93.36%, respectively. © Geoinformatics International.},
	author_keywords = {Flood Detection; Machine Learning Classifiers; Microwave Remote Sensing; Random Forest},
	keywords = {Northeastern Region; Thailand; Ubon Ratchathani; flood; hazard assessment; machine learning; remote sensing; risk assessment; Sentinel; synthetic aperture radar; vulnerability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zhu20215472,
	author = {Zhu, Lipeng and Hill, David J.},
	title = {Spatialoral Data Analysis-Based Event Detection in Weakly Damped Power Systems},
	year = {2021},
	journal = {IEEE Transactions on Smart Grid},
	volume = {12},
	number = {6},
	pages = {5472 – 5474},
	doi = {10.1109/TSG.2021.3084459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107227523&doi=10.1109%2fTSG.2021.3084459&partnerID=40&md5=8aa3d7cf29beea4ad17cc24cfd20b218},
	abstract = {Focusing on tackling the challenging issue of detecting events in weakly damped power systems, this letter proposes a novel event detection approach via spatialoral data analysis. Based on the intrinsic spatialoral correlations in regional PMU measurements, it efficiently profiles spatialoral nearest neighbors (STNNs) of multiple buses' featured time series. With such discriminative STNN profiles, it is able to detect the occurrence of various events even in the presence of significant frequency oscillations. Numerical test results on the Nordic test system as well as several IEEE test systems demonstrate the efficacy of the proposed approach.  © 2010-2012 IEEE.},
	author_keywords = {Data analysis; event detection; spatialoral correlation; synchrophasor measurements; time series},
	keywords = {Data handling; Information analysis; Event detection; Frequency oscillations; IEEE test systems; Nearest neighbors; PMU measurements; Spatial temporals; Spatial-temporal correlation; Spatial-temporal data; Spatial variables measurement},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Sidarta2023,
	author = {Sidarta, Djoni Eka and Auburtin, Erwan and Ledoux, Alain and Lim, Ho-Joon and Leridon, Aurelien and Tcherniguin, Nicolas},
	title = {Mooring Line Failure Detection Using Artificial Neural Networks: An Application to Field Data Including Artificial Failure Cases},
	year = {2023},
	journal = {Proceedings of the Annual Offshore Technology Conference},
	volume = {2023-May},
	doi = {10.4043/32181-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156140365&doi=10.4043%2f32181-MS&partnerID=40&md5=c13d10ec6dac071f6162f728918a9c09},
	abstract = {Alternative methods to using physical sensors for monitoring the integrity of mooring lines on floating offshore platforms are of great interest in the Offshore O&G industry. These alternative methods can be used in parallel with the physical sensors at the start of the service life of the asset, measurements from the physical sensors can be used to validate these methods, and the validated methods can be vital tools when the physical sensors are no longer working. Technip Energies has presented ALANN (Anchor Lines monitoring using Artificial Neural Networks) system in a 2021 OTC paper to detect mooring line failure using a dry monitoring system. The system requires only monitoring the positions and headings of the vessel, and it requires information on the draft of the vessel for an FPSO. The system combines status-based detection and event detection to determine mooring line condition, whether they are intact or there is mooring line failure. Artificial Neural Networks (ANN) play a very important role in the status detection with the ability to detect subtle shifts in patterns of vessel motions from intact lines condition to a mooring line failure condition. Numerical algorithms are used for status detection that complements ANN for benign environmental conditions and for event detection. An ALANN system has been developed, including training ANN models using numerical simulations, for a spread moored FPSO in West Africa. The system has been tested using field data that include time series of easting and northing positions of the vessel, vessel headings and vessel drafts. In addition, field data have been modified to include artificial mooring line failure cases, and these altered field data are used to further test the system. ALANN system performs very well for measured data in good quality independently from the FPSO loading condition, and it is able to detect all the artificial failure cases. The tests confirm and demonstrate how components of the ALANN system contribute to and improve the robustness of the overall solution. Important lessons learned, including challenges that have been encountered due to typical real-life sensor and communication issues (leading to gaps, drift, spikes and/or varying sampling within the data), along with comparison of measured and simulated data are presented in this paper. © 2023, Offshore Technology Conference.},
	author_keywords = {Anchor Lines; Artificial Intelligence; Artificial Neural Networks; DGPS; Dry Sensors; Failure Detection; Field Data; FPSO; GNSS; Monitoring; Mooring; Mooring Lines},
	keywords = {Mooring cables; Neural networks; Offshore oil well production; Offshore technology; 'Dry' [; Anchor line; DGPS; Dry sensor; Failure detection; Field data; GNSS; Line monitoring; Mooring line; Physical sensors; Mooring},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Zheng2022,
	author = {Zheng, Zhiqiang},
	title = {The Classification of Music and Art Genres under the Visual Threshold of Deep Learning},
	year = {2022},
	journal = {Computational Intelligence and Neuroscience},
	volume = {2022},
	doi = {10.1155/2022/4439738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131219886&doi=10.1155%2f2022%2f4439738&partnerID=40&md5=7eee4070f2ff875c79de850779b69e1d},
	abstract = {Wireless networks are commonly employed for ambient assisted living applications, and artificial intelligence-enabled event detection and classification processes have become familiar. However, music is a kind of time-series data, and it is challenging to design an effective music genre classification (MGC) system due to a large quantity of music data. Robust MGC techniques necessitate a massive amount of data, which is time-consuming, laborious, and requires expert knowledge. Few studies have focused on the design of music representations extracted directly from input waveforms. In recent times, deep learning (DL) models have been widely used due to their characteristics of automatic extracting advanced features and contextual representation from actual music or processed data. This paper aims to develop a novel deep learning-enabled music genre classification (DLE-MGC) technique. The proposed DLE-MGC technique effectively classifies the music genres into multiple classes by using three subprocesses, namely preprocessing, classification, and hyperparameter optimization. At the initial stage, the Pitch to Vector (Pitch2vec) approach is applied as a preprocessing step where the pitches in the input musical instrument digital interface (MIDI) files are transformed into the vector sequences. Besides, the DLE-MGC technique involves the design of a cat swarm optimization (CSO) with bidirectional long-term memory (BiLSTM) model for the classification process. The DBTMPE technique has gained a moderately increased accuracy of 94.27%, and the DLE-MGC technique has accomplished a better accuracy of 95.87%. The performance validation of the DLE-MGC technique was carried out using the Lakh MIDI music dataset, and the comparative results verified the promising performance of the DLE-MGC technique over current methods.  © 2022 Zhiqiang Zheng.},
	keywords = {Artificial Intelligence; Deep Learning; Music; Neural Networks, Computer; Assisted living; Deep learning; Ambient assisted living; Classification process; Classification technique; Detection process; Events classification; Events detection; Music genre classification; Musical instrument digital interfaces; Time-series data; Visual threshold; artificial intelligence; music; Music},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gashi2022,
	author = {Gashi, Milot and Gursch, Heimo and Hinterbichler, Hannes and Pichler, Stefan and Lindstaedt, Stefanie and Thalmann, Stefan},
	title = {MEDEP: Maintenance Event Detection for Multivariate Time Series Based on the PELT Approach},
	year = {2022},
	journal = {Sensors},
	volume = {22},
	number = {8},
	doi = {10.3390/s22082837},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127648545&doi=10.3390%2fs22082837&partnerID=40&md5=730a02331f5ea45c9153a9f082868a17},
	abstract = {Predictive Maintenance (PdM) is one of the most important applications of advanced data science in Industry 4.0, aiming to facilitate manufacturing processes. To build PdM models, sufficient data, such as condition monitoring and maintenance data of the industrial application, are required. However, collecting maintenance data is complex and challenging as it requires human involvement and expertise. Due to time constrains, motivating workers to provide comprehensive labeled data is very challenging, and thus maintenance data are mostly incomplete or even completely missing. In addition to these aspects, a lot of condition monitoring data-sets exist, but only very few labeled small maintenance data-sets can be found. Hence, our proposed solution can provide additional labels and offer new research possibilities for these data-sets. To address this challenge, we introduce MEDEP, a novel maintenance event detection framework based on the Pruned Exact Linear Time (PELT) approach, promising a low false-positive (FP) rate and high accuracy results in general. MEDEP could help to automatically detect performed maintenance events from the deviations in the condition monitoring data. A heuristic method is proposed as an extension to the PELT approach consisting of the following two steps: (1) mean threshold for multivariate time series and (2) distribution threshold analysis based on the complexity-invariant metric. We validate and compare MEDEP on the Microsoft Azure Predictive Maintenance data-set and data from a real-world use case in the welding industry. The experimental outcomes of the proposed approach resulted in a superior performance with an FP rate of around 10% on average and high sensitivity and accuracy results. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {change point detection; event detection; maintenance event detection; predictive maintenance; welding industry},
	keywords = {Condition monitoring; Heuristic methods; Maintenance; Time series; Welding; Windows operating system; Change point detection; Condition-monitoring data; Data set; Events detection; Linear time; Maintenance event detection; Multivariate time series; Predictive maintenance; Welding industry; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Lobert2021,
	author = {Lobert, Felix and Holtgrave, Ann-Kathrin and Schwieder, Marcel and Pause, Marion and Vogt, Juliane and Gocht, Alexander and Erasmi, Stefan},
	title = {Mowing event detection in permanent grasslands: Systematic evaluation of input features from Sentinel-1, Sentinel-2, and Landsat 8 time series},
	year = {2021},
	journal = {Remote Sensing of Environment},
	volume = {267},
	doi = {10.1016/j.rse.2021.112751},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117601951&doi=10.1016%2fj.rse.2021.112751&partnerID=40&md5=96511a9f9b95b6b8994b2f54a3784e8f},
	abstract = {The intensity of land use and management in permanent grasslands affects both biodiversity and important ecosystem services. Comprehensive knowledge about these intensities is a crucial factor for sustainable decision-making in landscape policy. For meadows, the management intensity can be described by proxies such as the mowing frequency, usually, a higher number of cuts indicate higher intensities. Dense time series of medium resolution (10–30 m) remote sensing data are suitable for the detection of mowing events. However, existing studies revealed a general lack of consensus about the most appropriate input data set for a consistent and reliable mowing detection. We systematically evaluated the synergistic use of acquisitions from Sentinel-1, Sentinel-2, and Landsat 8 to detect the occurrence, frequency, and date of mowing events as an indicator of grassland management intensity. Dense time series of NDVI (Sentinel-2 and Landsat 8), γ0 backscatter, backscatter cross-ratio, backscatter second-order texture metrics as well as 6-day interferometric coherence (Sentinel-1) were used as input features. All possible combinations of input features were tested to train a one-dimensional convolutional neural network, which enables enhanced exploitation of the temporal domain of the data. The evaluation was conducted on 64 meadows for an overall of 257 mowing events from 2017 to 2019 in Germany. Our results revealed that the combination of input features improves the detection performance. The highest overall accuracy was reached by a combination of NDVI, backscatter cross-ratio, and interferometric coherence with an F1-Score of 0.84. The mowing frequency was predicted with a mean absolute error of 0.38 events per year, while the date of the events was missed by 3.79 days on average. NDVI time series alone mostly underperformed in comparison to optical/SAR combinations but clearly outperformed input-sets that were solely based on SAR features. The proposed model performed well for meadows with low to medium management intensities but further testing is recommended for highly intensive managed parcels. The results clearly demonstrate the additional value of fusing time series of the three present Earth observation systems that deliver a freely available global coverage of the land surface at medium resolution. © 2021 The Authors},
	author_keywords = {Agriculture; Backscatter coefficient; Convolutional neural networks; Deep learning; GLCM; Grassland management intensity; Interferometric coherence; Land use intensity; Moving window; NDVI; SAR; Sequential classification},
	keywords = {Germany; Indicator indicator; Backscattering; Biodiversity; Convolution; Convolutional neural networks; Decision making; Deep learning; Ecosystems; Feature extraction; Interferometry; Land use; Remote sensing; Synthetic aperture radar; Textures; Backscatter coefficients; Convolutional neural network; Deep learning; GLCM; Grassland management intensity; Interferometric coherence; Land use intensity; Moving window; NDVI; SAR; Sequential classification; backscatter; decision making; detection method; ecosystem service; grassland; Landsat; mowing; remote sensing; Sentinel; time series analysis; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Wang2021,
	author = {Wang, Meng-Die and Lin, Ting-Han and Jhan, Kai-Chun and Wu, Shun-Chi},
	title = {Abnormal event detection, identification and isolation in nuclear power plants using LSTM networks},
	year = {2021},
	journal = {Progress in Nuclear Energy},
	volume = {140},
	doi = {10.1016/j.pnucene.2021.103928},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112486729&doi=10.1016%2fj.pnucene.2021.103928&partnerID=40&md5=7dd889dd10e7402bd01568fb0f198db2},
	abstract = {Increases in concerns regarding system safety and reliability challenge nuclear energy's attractiveness among the public. To alleviate such concerns, being able to prevent a developing event from escalating into a severe accident is indispensable, which requires an abnormal event to be identified in its early stage. In this study, several long short-term memory (LSTM)-based networks for abnormal event detection, identification, and isolation are proposed to help maintain the safe operations of nuclear power plants (NPPs). With the proposed model for predicting normal operation sensing readings, an abnormal event is detected if the discrepancies between the acquired and predicted readings exceed a preset threshold. Through LSTM's superior capability in time series analysis, the process information for sensing reading generation and the interrelations among the sensors in the event recordings can be extracted to enable valid event identification. Via the proposed autoencoders for sensing reading reconstruction, the plausible type for the ongoing event can be further verified to prevent an unseen event from being wrongly linked to any class in the event set. Results from experiments utilizing data of 13 event classes generated by a Maanshan NPP simulator illustrate the efficacy of the proposed models. © 2021 Elsevier Ltd},
	author_keywords = {Deep learning; Event detection; Event identification; Long short-term memory (LSTM); Unseen event isolation},
	keywords = {Brain; Long short-term memory; Nuclear energy; Nuclear fuels; Nuclear reactor accidents; Time series analysis; Abnormal event detections; Deep learning; Detection/identification; Event identification; Events detection; Long short-term memory; Memory network; Power; Short term memory; Unseen event isolation; Nuclear power plants},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Jin2022146,
	author = {Jin, Wangkai and Liu, Junyu and Feng, Meili and Ren, Jianfeng},
	title = {Polyphonic Sound Event Detection Using Capsule Neural Network on Multi-Type-Multi-Scale Time-Frequency Representation},
	year = {2022},
	journal = {2022 2nd IEEE International Conference on Software Engineering and Artificial Intelligence, SEAI 2022},
	pages = {146 – 150},
	doi = {10.1109/SEAI55746.2022.9832286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136329114&doi=10.1109%2fSEAI55746.2022.9832286&partnerID=40&md5=a243f77e4a19970873c22d1c2654b499},
	abstract = {The challenges of polyphonic sound event detection (PSED) stem from the detection of multiple overlapping events in a time series. Recent efforts exploit Deep Neural Networks (DNNs) on Time-Frequency Representations (TFRs) of audio clips as model inputs to mitigate such issues. However, existing solutions often rely on a single type of TFR, which causes under-utilization of input features. To this end, we propose a novel PSED framework, which incorporates Multi-Type-Multi-Scale TFRs. Our key insight is that: TFRs, which are of different types or in different scales, can reveal acoustics patterns in a complementary manner, so that the overlapped events can be best extracted by combining different TFRs. Moreover, our framework design applies a novel approach, to adaptively fuse different models and TFRs symbiotically. Hence, the overall performance can be significantly improved. We quantitatively examine the benefits of our framework by using Capsule Neural Networks, a state-of-the-art approach for PSED. The experimental results show that our method achieves a 7% reduction in error rate compared with the state-of-the-art solutions on the TUT-SED 2016 dataset.  © 2022 IEEE.},
	author_keywords = {capsule neural network; polyphonic sound event detection; time-frequency representation},
	keywords = {Computer vision; Audio clips; Capsule neural network; Model inputs; Multi-scales; Neural-networks; Polyphonic sound event detection; Polyphonic sounds; Sound event detection; Time-frequency representations; Times series; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Nalepa2022689,
	author = {Nalepa, Jakub and Myller, Michal and Andrzejewski, Jacek and Benecki, Pawel and Piechaczek, Szymon and Kostrzewa, Daniel},
	title = {Evaluating algorithms for anomaly detection in satellite telemetry data},
	year = {2022},
	journal = {Acta Astronautica},
	volume = {198},
	pages = {689 – 701},
	doi = {10.1016/j.actaastro.2022.06.026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133306740&doi=10.1016%2fj.actaastro.2022.06.026&partnerID=40&md5=70c7b3477b8e0f32a0478dadfbfbef63},
	abstract = {Detecting anomalies in telemetry data captured on-board a spacecraft is critical to ensure its safe operation. Although there exist various techniques for automatically detecting point, contextual, and collective anomalies from time-series data, quantifying their performance remains under-researched. In this paper, we thoroughly validate our approach for the task of anomalous event detection that is built upon a two-stage technique, in which the telemetry signal is predicted using a long short-term memory network based on the historical data, and then the prediction is compared with the actual (captured) data. If the difference between those two is sufficiently large, we can infer that an anomalous event has happened. To evaluate the capabilities of such detection techniques over the simulated and benchmark time-series data, we investigate a set of commonly used metrics obtained for a range of anomaly detection approaches, and present their shortcomings, especially related to their inability of capturing the temporal aspects of the detectors. We tackle this issue by introducing new quality metrics which enable us to objectively verify if the detectors can timely spot the anomalies in sequential data. The experimental study showed that inferring the conclusions based on a subset of metrics can lead to biased observations, as the best algorithms determined based on the overlap metrics, including the Dice coefficient, do not necessarily correspond to the algorithms that offer the fastest detection. Finally, we discuss the Antelope Toolbox—our software tool for simulating nominal telemetry data of given characteristics, alongside well-defined anomalous events, and to perform the quantitative and qualitative analysis of anomaly detection algorithms over such simulated events. © 2022 IAA},
	author_keywords = {Anomaly detection; Deep learning; Evaluation; LSTM; Quantitative and qualitative analysis; Recurrent neural network},
	keywords = {Chemical detection; Long short-term memory; Telemetering equipment; Time series; Anomalous events; Anomaly detection; Deep learning; Evaluating algorithms; Evaluation; LSTM; Quantitative and qualitative analysis; Satellite telemetry data; Telemetry data; Time-series data; Anomaly detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Alqudah20237283,
	author = {Alqudah, Mohammad and Kezunovic, Mladen and Obradovic, Zoran},
	title = {Automated Power System Fault Prediction and Precursor Discovery Using Multi-Modal Data},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {7283 – 7296},
	doi = {10.1109/ACCESS.2022.3233219},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148219943&doi=10.1109%2fACCESS.2022.3233219&partnerID=40&md5=468066fa2e546313ef99d583107503d8},
	abstract = {Electric power system operators monitor large multi-modal data streams from wide service areas. The current data setups stand to get more complex as utilities add more smart-grid sensors to collect additional data from power system substations and other in-situ locations. We propose a methodology to utilize multi-modal data for automated power system fault prediction, and precursor discovery that takes advantage of not only the utility owned measurements but also an abundance of data from other related databases such as weather observation systems. The process is automated to help operators analyze multi-modal data that may be impossible to process manually due to the size and variety. We automatically preprocess multi-source data and learn a joint latent representation from collocated streamed, sparse, and high-dimensional data collected from Phasor Measurement Units and external weather data. Then we utilize multi-instance learning to predict events and discover precursors simultaneously without relying on post-mortem studies of fault signatures. We apply the proposed methodology to provide early predictions of faults in the U.S. Western Interconnection. AU-ROC of 0.94 is achieved in predicting events by utilizing information 5 hours before event time using season-specific models. We show how precursors can be extracted from multi-modal data and interpreted for predicted events.  © 2013 IEEE.},
	author_keywords = {Big data; event detection; event precursors; machine learning; phasor measurement units; power system faults; smart grids; time series analysis; weather},
	keywords = {Automation; Big data; Clustering algorithms; Data mining; Electric power system interconnection; Electric substations; Machine learning; Modal analysis; Phasor measurement units; Smart power grids; Event precursor; Events detection; Fault prediction; Machine-learning; Multi-modal data; Power system fault; Power system operators; Smart grid; Time-series analysis; Weather; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Krysiński20221142,
	author = {Krysiński, Mateusz and Gawlikowski, Maciej and Biełka, Agnieszka and Krysińska, Małgorzata and Małyszek-Tumidajewicz, Justyna and Copik, Izabela and Pacholewicz, Jerzy and Zembala, Marian and Zembala, Michał},
	title = {Early detection of HVAD pump thrombosis based on technical analysis and power consumption measurements},
	year = {2022},
	journal = {Artificial Organs},
	volume = {46},
	number = {6},
	pages = {1142 – 1148},
	doi = {10.1111/aor.14163},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122760261&doi=10.1111%2faor.14163&partnerID=40&md5=70ed4b9ead146e533caffb7aaec25e48},
	abstract = {Background: Continuous-flow left ventricular assist devices (LVADs) have been extensively used in a strategy of bridge to orthotopic heart transplant and destination therapy. The usage of LVAD, however, is not free from limitations such as device-related adverse events, including pump thrombosis (PT). We aimed to develop an algorithm of early PT detection based on the maintenance parameters monitored by the implanted device. Methods: We analyzed log files of 101 patients implanted with HeartWare pump (HVAD) with 18 PT events among them. For signal processing, we used the open-high-low-close format transformation and typical price (TP) technical analysis indicator. Model parameters were tuned with 5-fold cross-validation, and the final performance was measured on a separate group of patients. Results: Our algorithm achieved 100% sensitivity and 100% specificity of indications. In the final evaluation, alarms preceded the clinical acknowledgement of events by 2 days and 20 h on average. In the worst-case scenario, an alarm was raised 1 day and 8 h prior to the event. Conclusions: The proposed algorithm could be installed to work directly with the device controller and provide clinicians with automatic readings analysis, raising an alarm when there is a high probability of thromboembolism. Early event detection could enable better thrombosis management and improve prognosis in patients implanted with HVAD. © 2022 International Center for Artificial Organs and Transplantation and Wiley Periodicals LLC.},
	author_keywords = {early detection; early event detection; HVAD pump; left ventricular assisting device; pump thrombosis},
	keywords = {Heart Failure; Heart Transplantation; Heart-Assist Devices; Humans; Retrospective Studies; Thromboembolism; Thrombosis; Alarm systems; Blood vessels; Diagnosis; Electric power utilization; Left ventricular assist devices; Pumps; Signal processing; Adverse events; Consumption measurement; Continuous-flow; Destination therapy; Heart transplant; Implanted device; Logfile; Maintenance parameters; Orthotopic; Technical analysis; adult; alarm monitoring; Article; cross validation; data analysis; detection algorithm; diagnostic test accuracy study; early diagnosis; electrical parameters; human; major clinical study; male; measurement; power consumption; pump thrombosis; sensitivity and specificity; signal processing; time series analysis; adverse device effect; heart assist device; heart failure; heart transplantation; retrospective study; thromboembolism; thrombosis; Diseases},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2022,
	title = {6th International Conference on Computational Intelligence in Data Mining, ICCIDM 2021},
	year = {2022},
	journal = {Smart Innovation, Systems and Technologies},
	volume = {281},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130406871&partnerID=40&md5=3745a37e4fbe7fc5d5b2924fb6ca6aab},
	abstract = {The proceedings contain 56 papers. The special focus in this conference is on Computational Intelligence in Data Mining. The topics include: Topic Evolution Model for Interactive Information Search; A Novel Automated Human Face Recognition and Temperature Detection System Using Deep Neural Networks—FRTDS; A Novel BFS and CCDS-Based Efficient Sleep Scheduling Algorithm for WSN; face Recognition: A Review and Analysis; COVID-19 Time Series Prediction and Lockdown Effectiveness; Performance Evaluation of Electrogastrogram (EGG) Signal Compression for Telemedicine Using Various Wavelet Transform; The Impact of UV-C Treatment on Fruits and Vegetables for Quality and Shelf Life Improvement Using Internet of Things; modeling and Forecasting Stock Closing Prices with Hybrid Functional Link Artificial Neural Network; sentiment Analysis: A Recent Survey with Applications and a Proposed Ensemble Algorithm; whale Optimization Algorithm Based Optimal Power Flow to Reduce Generation Cost; an Artificial Electric Field Algorithm and Artificial Neural Network-Based Hybrid Model for Software Reliability Prediction; disaster Event Detection from Text: A Survey; context-Adaptive Content-Based Filtering Recommender System Based on Weighted Implicit Rating Approach; a Deep Learning-Based Classifier for Remote Sensing Images; performance Evaluation of Machine Learning Algorithms to Predict Breast Cancer; topology Dependent Ant Colony-Based Routing Scheme for Software-Defined Networking in Cloud; on Computational Complexity of Transfer Learning Approaches in Facial Analysis; adaptive Classifier Using Extreme Learning Machine for Classifying Twitter Data Streams; decision Making on Covid-19 Containment Zones’ Lockdown Exit Process Using Fuzzy Soft Set Model; An Automated System for Facial Mask Detection and Social Distancing during COVID-19 Pandemic; Investigating the Impact of COVID-19 on Important Economic Indicators.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Corrêa2022,
	author = {Corrêa, Débora and Polpo, Adriano and Small, Michael and Srikanth, Shreyas and Hollins, Kylie and Hodkiewicz, Melinda},
	title = {Data-driven approach for labelling process plant event data},
	year = {2022},
	journal = {International Journal of Prognostics and Health Management},
	volume = {13},
	number = {1},
	doi = {10.36001/ijphm.2022.v13i1.3045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125769074&doi=10.36001%2fijphm.2022.v13i1.3045&partnerID=40&md5=44c7fd1b590bcbe9f9e58f7c848139de},
	abstract = {An essential requirement in any data analysis is to have a response variable representing the aim of the analysis. Much academic work is based on laboratory or simulated data, where the experiment is controlled, and the ground truth clearly defined. This is seldom the reality for equipment performance in an industrial environment and it is common to find issues with the response variable in industry situations. We discuss this matter using a case study where the problem is to detect an asset event (failure) using data available but for which no ground truth is available from historical records. Our data frame contains measurements of 14 sensors recorded every minute from a process control system and 4 current motors on the asset of interest over a three year period. In this situation the ``how to'' label the event of interest is of fundamental importance. Different labelling strategies will generate different models with direct impact on the in-service fault detection efficacy of the resulting model. We discuss a data-driven approach to label a binary response variable (fault/anomaly detection) and compare it to a rule-based approach. Labelling of the time series was performed using dynamic time warping followed by agglomerative hierarchical clustering to group events with similar event dynamics. Both data sets have significant imbalance with 1,200,000 non-event data but only 150 events in the rule-based data set and 64 events in the data-driven data set. We study the performance of the models based on these two different labelling strategies, treating each data set independently. We describe decisions made in window-size selection, managing imbalance, hyper-parameter tuning, training and test selection, and use two models, logistic regression and random forest for event detection. We estimate useful models for both data sets. By useful, we understand that we could detect events for the first four months in the test set. However as the months progressed the performance of both models deteriorated, with an increasing number of false positives, reflecting possible changes in dynamics of the system. This work raises questions such as ``what are we detecting?'' and ``is there a right way to label?'' and presents a data driven approach to support labelling of historical events in process plant data for event detection in the absence of ground truth data. © 2022, Prognostics and Health Management Society. All rights reserved.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Holtgrave2023,
	author = {Holtgrave, Ann-Kathrin and Lobert, Felix and Erasmi, Stefan and Röder, Norbert and Kleinschmit, Birgit},
	title = {Grassland mowing event detection using combined optical, SAR, and weather time series},
	year = {2023},
	journal = {Remote Sensing of Environment},
	volume = {295},
	doi = {10.1016/j.rse.2023.113680},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162931943&doi=10.1016%2fj.rse.2023.113680&partnerID=40&md5=034e1abdc71d8c3982f82e8ad475f7ea},
	abstract = {The European Union's Common Agricultural Policy (CAP) and the Habitats Directive aim to improve biodiversity in agricultural landscapes. Both policies require enormous monitoring, which can be facilitated by remote sensing. Use intensity, measured by mowing frequency is an important indicator of biodiversity in permanent grasslands. The frequency and timing of mowing can be determined using satellite remote sensing because photosynthetically active biomass changes rapidly in response to mowing. However, the rapid regrowth of grasses requires very dense satellite time series for reliable detection. Radar time series can complement optical time series and fill in cloud-related gaps to overcome this problem. Additional weather data can support the detection of grassland mowing events, as mowing events are associated with specific meteorological conditions. However, previous studies have not fully exploited both potentials or different machine learning approaches for mowing event detection. This study presents a new transferable two-step approach to detect grassland mowing events using combined optical and SAR data and additional weather data. First, we filled cloud-related gaps in optical time series using a supervised machine learning regression with optical and SAR data. We then classified time series sequences of optical, SAR and weather data into mown and unmown using four different machine learning algorithms. We used time series of NDVI and EVI (combined Sentinel-2 and Landsat 8), SAR backscatter, six-day interferometric coherence, backscatter radar vegetation index, backscatter cross-ratio (Sentinel-1), and temperature and precipitation sums. Our test sites are distributed across Germany and cover the entire gradient of grassland use intensities. Mowing events could be detected with F1 values of up to 89%, first cut with up to 94%. Our results show no structural advantage of infilling time series with machine learning over linearly interpolated time series. The combined Sentinel-2 and Landsat-8 time series provided dense time series with mostly median gaps less than 20 days, which proved sufficient to reliably detect mowing events. SAR data were not essential for mowing event detection in our study, but weather data improved classification results for models trained on all areas and years. However, when the model was transferred to unknown years or areas that were not used for training, SAR data improved detection accuracy, whereas weather data degrade it. Models trained on all years but not all study sites detected mowing events with an accuracy of up to F1 = 76%. Models trained with all regions but not all years detected mowing events in untrained years with F1 up to 80%. © 2023 The Authors},
	author_keywords = {Backscatter; CAP; CNN; Interferomic coherence; Landsat 8; LSTM; Random forest; Sentinel-1; Sentinel-2; SVM},
	keywords = {Germany; Backscattering; Biodiversity; Forestry; Interferometry; Learning systems; Optical remote sensing; Random forests; Space-based radar; Supervised learning; Synthetic aperture radar; Time series; Vegetation; Backscatter; Common agricultural policy; Interferomic coherence; LANDSAT; Landsat 8; LSTM; Random forests; Sentinel-1; Sentinel-2; SVM; agricultural land; algorithm; biodiversity; grassland; Landsat; machine learning; NDVI; remote sensing; satellite data; Sentinel; support vector machine; synthetic aperture radar; Landsat},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zainab2023130,
	author = {Zainab, Tayyaba and Karstens, Jens and Landsiedel, Olaf},
	title = {LightEQ: On-Device Earthquake Detection with Embedded Machine Learning},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {130 – 143},
	doi = {10.1145/3576842.3582387},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159711264&doi=10.1145%2f3576842.3582387&partnerID=40&md5=2b6c41260dae5772c7f77f0472ff17be},
	abstract = {The detection of earthquakes in seismological time series is central to observational seismology. Generally, seismic sensors passively record data and transmit it to the cloud or edge for integration, storage, and processing. However, transmitting raw data through the network is not an option for sensors deployed in harsh environments like underwater, underground, or in rural areas with limited connectivity. This paper introduces an efficient data processing pipeline and a set of lightweight deep-learning models for seismic event detection deployable on tiny devices such as microcontrollers. We conduct an extensive hyperparameter search and devise three lightweight models. We evaluate our models using the Stanford Earthquake Dataset and compare them with a basic STA/LTA detection algorithm and the state-of-the-art machine learning models, i.e., CRED, EQtransformer, and LCANet. For example, our smallest model consumes 193 kB of RAM and has an F1 score of 0.99 with just 29k parameters. Compared to CRED, which has an F1 score of 0.98 and 293k parameters, we reduce the number of parameters by a factor of 10. Deployed on Cortex M4 microcontrollers, the smallest version of LightEQ-NN has an inference time of 932 ms for 1 minute of raw data, an energy consumption of 5.86 mJ, and a flash requirement of 593 kB. Our results show that resource-efficient, on-device machine learning for seismological time series data is feasible and enables new approaches to seismic monitoring and early warning applications.  © 2023 ACM.},
	author_keywords = {Deep Neural Networks; Earthquake detection; Edge AI; Internet of Things; Low-Power; On-device; Seismological data analysis},
	keywords = {Data handling; Earthquakes; Energy utilization; Internet of things; Learning systems; Low power electronics; Microcontrollers; Pipeline processing systems; Random access storage; Time series; Earthquake detection; Edge AI; Embedded machines; F1 scores; Low Power; Machine-learning; On-device; Seismological data; Seismological data analyse; Times series; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Montoya2022,
	author = {Montoya, A. and Habtour, E. and Moreu, F.},
	title = {Detecting hidden transient events in noisy nonlinear time-series},
	year = {2022},
	journal = {Chaos},
	volume = {32},
	number = {7},
	doi = {10.1063/5.0097973},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135215641&doi=10.1063%2f5.0097973&partnerID=40&md5=8192a70d585dd7fa8b1278fe933bace6},
	abstract = {The information impulse function (IIF), running Variance, and local Hölder Exponent are three conceptually different time-series evaluation techniques. These techniques examine time-series for local changes in information content, statistical variation, and point-wise smoothness, respectively. Using simulated data emulating a randomly excited nonlinear dynamical system, this study interrogates the utility of each method to correctly differentiate a transient event from the background while simultaneously locating it in time. Computational experiments are designed and conducted to evaluate the efficacy of each technique by varying pulse size, time location, and noise level in time-series. Our findings reveal that, in most cases, the first instance of a transient event is more easily observed with the information-based approach of IIF than with the Variance and local Hölder Exponent methods. While our study highlights the unique strengths of each technique, the results suggest that very robust and reliable event detection for nonlinear systems producing noisy time-series data can be obtained by incorporating the IIF into the analysis. © 2022 Author(s).},
	keywords = {Heart Rate; Noise; Nonlinear Dynamics; Time Factors; heart rate; noise; nonlinear system; time factor},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Sadoughi2022,
	author = {Sadoughi, Azadeh and Shamsollahi, Mohammad Bagher and Fatemizadeh, Emad},
	title = {Automatic detection of respiratory events during sleep from Polysomnography data using Layered Hidden Markov Model},
	year = {2022},
	journal = {Physiological Measurement},
	volume = {43},
	number = {1},
	doi = {10.1088/1361-6579/ac45e1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123968753&doi=10.1088%2f1361-6579%2fac45e1&partnerID=40&md5=7f44d6a6506b926b754c3457e21809ba},
	abstract = {Objective. Sleep apnea is a serious respiratory disorder, which is associated with increased risk factors for cardiovascular disease. Many studies in recent years have been focused on automatic detection of sleep apnea from polysomnography (PSG) recordings, however, detection of subtle respiratory events named Respiratory Event Related Arousals (RERAs) that do not meet the criteria for apnea or hypopnea is still challenging. The objective of this study was to develop automatic detection of sleep apnea based on Hidden Markov Models (HMMs) which are probabilistic models with the ability to learn different dynamics of the real time-series such as clinical recordings. Approach. In this study, a hierarchy of HMMs named Layered HMM was presented to detect respiratory events from PSG recordings. The recordings of 210 PSGs from Massachusetts General Hospital's database were used for this study. To develop detection algorithms, extracted feature signals from airflow, movements over the chest and abdomen, and oxygen saturation in blood (SaO2) were chosen as observations. The respiratory disturbance index (RDI) was estimated as the number of apneas, hypopneas, and RERAs per hour of sleep. Main results. The best F1 score of the event by event detection algorithm was between 0.22 ± 0.16 and 0.70 ± 0.08 for different groups of sleep apnea severity. There was a strong correlation between the estimated and the PSG-derived RDI (R 2 = 0.91, p < 0.0001). The best recall of RERA detection was achieved 0.45 ± 0.27. Significance. The results showed that the layered structure can improve the performance of the detection of respiratory events during sleep.  © 2022 Institute of Physics and Engineering in Medicine.},
	author_keywords = {Event detection; Hidden Markov Model; Polysomnography; Respiratory Disturbance Index; Respiratory Event Related Arousals; Sleep apnea},
	keywords = {Arousal; Humans; Polysomnography; Sleep; Sleep Apnea Syndromes; Sleep Apnea, Obstructive; Signal detection; Sleep research; Automatic Detection; Disturbance index; Events detection; Hidden-Markov models; Layered hidden markov models; Polysomnography; Respiratory disturbance index; Respiratory disturbances; Respiratory event related arousal; Sleep apnea; arousal; human; polysomnography; sleep; sleep disordered breathing; Hidden Markov models},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Arul2022,
	author = {Arul, Monica and Kareem, Ahsan and Burlando, Massimiliano and Solari, Giovanni},
	title = {Machine learning based automated identification of thunderstorms from anemometric records using shapelet transform},
	year = {2022},
	journal = {Journal of Wind Engineering and Industrial Aerodynamics},
	volume = {220},
	doi = {10.1016/j.jweia.2021.104856},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120303888&doi=10.1016%2fj.jweia.2021.104856&partnerID=40&md5=1ae97bfac2dab58119766ce140bbe298},
	abstract = {Detection of thunderstorms is important to the wind hazard community to better understand extreme wind field characteristics and associated wind-induced load effects on structures. This paper contributes to this effort by proposing an innovative course of research that uses machine learning techniques, independent of wind statistics-based parameters, to autonomously identify thunderstorms from large databases containing high-frequency sampled continuous wind speed data. In this context, the use of Shapelet transform is proposed to identify key individual attributes distinctive to extreme wind events based on similarity of the shape of their time series signature. This shape-based representation, when combined with machine learning algorithms, yields a practical event detection procedure with minimal domain expertise. In this paper, the shapelet transform along with Random Forest classifier is employed for the identification of thunderstorms from 1-year of data from 14 ultrasonic anemometers that are a part of an extensive in-situ wind monitoring network in the Northern Mediterranean ports. A collective total of 240 non-stationary records associated with thunderstorms were identified using this method. The results lead to enhancing the pool of thunderstorm data for a more comprehensive understanding of a wide variety of thunderstorms that have not been previously detected using conventional gust factor-based methods. © 2021},
	author_keywords = {Machine learning; Shapelet transform; Thunderstorm detection; Time series shapelets; Wind monitoring network},
	keywords = {Decision trees; Learning algorithms; Machine learning; Thunderstorms; Ultrasonic applications; Wind; Extreme winds; Monitoring network; Shapelet transform; Shapelets; Thunderstorm detection; Time series shapelet; Times series; Wind monitoring; Wind monitoring network; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Dittmann2022,
	author = {Dittmann, T. and Liu, Y. and Morton, Y. and Mencin, D.},
	title = {Supervised Machine Learning of High Rate GNSS Velocities for Earthquake Strong Motion Signals},
	year = {2022},
	journal = {Journal of Geophysical Research: Solid Earth},
	volume = {127},
	number = {11},
	doi = {10.1029/2022JB024854},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142889471&doi=10.1029%2f2022JB024854&partnerID=40&md5=7f14bb254745ed345aac618545c6c9e3},
	abstract = {High rate Global Navigation Satellite System (GNSS) processed time series capture a broad spectrum of earthquake strong motion signals, but experience regular sporadic noise that can be difficult to distinguish from true seismic signals. The range of possible seismic signal frequencies amidst a high, location-varying noise floor makes filtering difficult to generalize. Existing methods for automatic detection rely on external inputs to mitigate false alerts, which limit their usefulness. For these reasons, geodetic seismic signal detection makes for a compelling candidate for data-driven machine learning classification. In this study we generated high rate GNSS time differenced carrier phase (TDCP) velocity time series concurrent in space and time with expected signals from 77 earthquakes occurring over nearly 20 years. TDCP velocity processing has increased sensitivity relative to traditional geodetic displacement processing without requiring sophisticated corrections. We trained, validated and tested a random forest classifier to differentiate seismic events from noise. We find our supervised random forest classifier outperforms the existing detection methods in stand-alone mode by combining frequency and time domain features into decision criteria. The classifier achieves a 90% true positive rate of seismic event detection within the data set of events ranging from MW4.8–8.2, with typical detection latencies seconds behind S-wave arrivals. We conclude the performance of this model provides sufficient confidence to enable these valuable ground motion measurements to run in stand-alone mode for development of edge processing, geodetic infrastructure monitoring and inclusion in operational ground motion observations and models. © 2022. The Authors.},
	author_keywords = {earthquake early warning; GNSS; machine learning; random forest},
	keywords = {early warning system; earthquake; GNSS; S-wave; strong motion; supervised learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Dokic2022,
	author = {Dokic, Tatjana and Baembitov, Rashid and Hai, Ameen Abdel and Cheng, Zheyuan and Hu, Yi and Kezunovic, Mladen and Obradovic, Zoran},
	title = {Machine Learning Using a Simple Feature for Detecting Multiple Types of Events From PMU Data},
	year = {2022},
	journal = {2022 International Conference on Smart Grid Synchronized Measurements and Analytics, SGSMA 2022 - Proceedings},
	doi = {10.1109/SGSMA51733.2022.9806000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134250695&doi=10.1109%2fSGSMA51733.2022.9806000&partnerID=40&md5=99facb7f027018b1fe6627a26242bfc7},
	abstract = {This paper describes simple and efficient machine learning (ML) methods for efficiently detecting multiple types of power system events captured by PMUs scarcely placed in a large power grid. It uses a single feature from each PMU based on a rectangle area enclosing the event in a given data window. This single feature is sufficient to enable commonly used ML models to detect different types of events quickly and accurately. The feature is used by five ML models on four different data-window sizes. The results indicated a tradeoff between the execution speed and detection accuracy in variety of data-window size choices. The proposed method is insensitive to most data quality issues typical for data from field PMUs, and thus it does not require major data cleansing efforts prior to feature extraction.  © 2022 IEEE.},
	author_keywords = {Big data; Event detection; Machine learning; Phasor measurement units; Power system faults; Time series analysis},
	keywords = {Big data; Electric power transmission networks; Feature extraction; Smart power grids; Time series analysis; Data windows; Events detection; Machine learning methods; Machine learning models; Machine-learning; Power system fault; Simple++; Time-series analysis; Types of power; Window Size; Phasor measurement units},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Pavithra2023299,
	author = {Pavithra, G. and Pavithra, L. and Preethi, B. and Sujasre, J.R. and Vanniyammai, R.},
	title = {Anomaly Detection for Bank Security Against Theft—A Survey},
	year = {2023},
	journal = {Smart Innovation, Systems and Technologies},
	volume = {312},
	pages = {299 – 310},
	doi = {10.1007/978-981-19-3575-6_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140754600&doi=10.1007%2f978-981-19-3575-6_31&partnerID=40&md5=664f47b3350422f87132901cfd753cbc},
	abstract = {Abnormal event detection is one of the most huge objectives in analysis sector and viable applications of motion picture intelligence.To improve public safety, reconnaissance cameras are progressively being used in broad daylight spaces like streets, junction, banks, and shopping centers.One most critical limit in video structure is perceiving uncommon activity, for instance, car accidents, bad behaviors, or other illegal exercises.Generally, odd events are only sometimes happened when diverged from standard activities.By and large, atypical occasions seldom happen when contrasted with typical exercises.The target of an irregularity revelation structure is to advantageous sign a development that veers off from customary examples and to recognize the time window of the inconsistency happening in the framework.Once an abnormal activity has been identified, classification techniques are utilized to segregate it into distinct activities.This paper provides an overview of anomaly detection, with an emphasis on the approach of detecting odd actions in banking operations.Banking operation includes daily, weekly, and a periodic activities and transactions performed by or affecting variety of stakeholders such as employees, clients, and external entities.Events may open out over time, and early discovery can considerably mitigate potential negative consequences, and in some cases actively prevent the same.Inconsistency recognition dependent on time series is utilized to recognize individuals during badly designed occasions.In this work AI based oddity recognition strategy carried out to perceive the typical and unusual occasions. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Alert notification; Face recognition; Gaussian mixture model; HAAR cascade algorithm; Video surveillance},
	keywords = {Accidents; Anomaly detection; Crime; Gaussian distribution; Security systems; Abnormal event detections; Alert notification; Anomaly detection; Banking operations; Cascade algorithm; Critical limit; Gaussian Mixture Model; HAAR cascade algorithm; Public safety; Video surveillance; Face recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Alqudah20223434,
	author = {Alqudah, Mohammad and Pavlovski, Martin and Dokic, Tatjana and Kezunovic, Mladen and Hu, Yi and Obradovic, Zoran},
	title = {Fault Detection Utilizing Convolution Neural Network on Timeseries Synchrophasor Data From Phasor Measurement Units},
	year = {2022},
	journal = {IEEE Transactions on Power Systems},
	volume = {37},
	number = {5},
	pages = {3434 – 3442},
	doi = {10.1109/TPWRS.2021.3135336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121764535&doi=10.1109%2fTPWRS.2021.3135336&partnerID=40&md5=c4d9a4aa0fc397904b6a80840e054bdd},
	abstract = {An end-to-end supervised learning method is proposed for fault detection in the electric grid using Big Data from multiple Phasor Measurement Units (PMUs). The approach consists of preprocessing steps aimed at reducing data noise and dimensionality, followed by utilization of six classification models considered for detecting faults. Three of the models were variants of Convolutional Neural Network (CNN) architectures that consider a single type of measurement (voltage, current or frequency) at all PMUs or all types together also at all PMUs. CNN based models were compared to traditional methods of Logistic Regression (LR), Multi-layer Perceptron (MLP) and Support Vector Machine (SVM). Evaluation was conducted on two-year data measured by PMUs at 37 locations in a large electric grid. The response variable for classification were extracted from the grid-wide outage event log. Experiments show that CNN-based models outperformed traditional methods on one year out-of-sample outage detection over the entire grid.  © 1969-2012 IEEE.},
	author_keywords = {Big data applications; convolutional neural networks; dimensionality reduction; event detection; machine learning; neural networks; phasor measurement units; power system faults; smart grids; time series analysis},
	keywords = {Big data; Convolution; Data reduction; Electric power transmission networks; Fault detection; Neural networks; Outages; Phasor measurement units; Smart power grids; Support vector machines; Time series analysis; Big data applications; Convolutional neural network; Dimensionality reduction; Events detection; Faults detection; Features extraction; Frequency measurements; Neural-networks; Power system fault; Smart grid; Support vectors machine; Time-series analysis; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@ARTICLE{De Paepe2021,
	author = {De Paepe, Dieter and Hautte, Sander Vanden and Steenwinckel, Bram and Moens, Pieter and Vaneessen, Jasper and Vandekerckhove, Steven and Volckaert, Bruno and Ongenae, Femke and Van Hoecke, Sofie},
	title = {A complete software stack for IoT time-series analysis that combines semantics and machine learning—lessons learned from the dyversify project},
	year = {2021},
	journal = {Applied Sciences (Switzerland)},
	volume = {11},
	number = {24},
	doi = {10.3390/app112411932},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118734561&doi=10.3390%2fapp112411932&partnerID=40&md5=4433c49453713af26da02a0278cebfa1},
	abstract = {Companies are increasingly gathering and analyzing time-series data, driven by the rising number of IoT devices. Many works in literature describe analysis systems built using either data-driven or semantic (knowledge-driven) techniques. However, little to no works describe hybrid combinations of these two. Dyversify, a collaborative project between industry and academia, investigated how event and anomaly detection can be performed on time-series data in such a hybrid setting. We built a proof-of-concept analysis platform, using a microservice architecture to ensure scalability and fault-tolerance. The platform comprises time-series ingestion, long term storage, data semantification, event detection using data-driven and semantic techniques, dynamic visualization, and user feedback. In this work, we describe the system architecture of this hybrid analysis platform and give an overview of the different components and their interactions. As such, the main contribution of this work is an experience report with challenges faced and lessons learned. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Data analytics; Machine learning; Microservice architecture; Reasoning; Semantic web; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{2023,
	title = {2nd International Conference on Emerging Technologies and Intelligent Systems, ICETIS 2022},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {573 LNNS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144946248&partnerID=40&md5=209fa1e6dbf375d8353c5538600ba506},
	abstract = {The proceedings contain 61 papers. The special focus in this conference is on Emerging Technologies and Intelligent Systems. The topics include: Predictive Analytics for Oil and Gas Asset Maintenance Using XGBoost Algorithm; Event Detection and Information Extraction Strategies from Text: A Preliminary Study Using GENIA Corpus; human Evacuation Movement Simulation Model: Concepts and Techniques; A Data Mining Approach to Determine Prospective Debtor of Unsecured Credit (Case Study: Bank XYZ in Indonesia); date Palm Leaves Discoloration Detection System Using Deep Transfer Learning; solving Drinking-Water Challenges: Supply and Temperature in a Smart Poultry Monitoring System Using IoT System; offline Marker-Less Augmented Reality Application for Exploring Threatened Historical Places; a Robust Tuned K-Nearest Neighbours Classifier for Software Defect Prediction; Smart Virtual Robot Automation (SVRA)-Improving Supplier Transactional Processes in Enterprise Resource Planning (ERP) System: A Conceptual Framework; a Review of Long Short-Term Memory Approach for Time Series Analysis and Forecasting; design and Implementation of Modified Vedic Multiplier Using Modified Decoder-Based Adder; Design and FPGA Implementation of Matrix Multiplier Using DEMUX-RCA-Based Vedic Multiplier; Analysis and Modeling of Brushless DC Motor PWM Control Technique Using PSIM Software; single-Bit Architecture for Low Power IoT Applications; hybrid Fuzzy Logic Active Force Control for Trajectory Tracking of a Quadrotor System; semantic Analysis of Moving Objects in Video Sequences; Improved Automatic License Plate Recognition System in Iraq for Surveillance System Using OCR; do We Use the Right Elements for Assurance Case Development?; development of a Mobile Application for Scheduling Electric Vehicle Charging in Wind Energy Powered Facility.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Izadi20222170,
	author = {Izadi, Milad and Mohsenian-Rad, Hamed},
	title = {A Synchronized Lissajous-Based Method to Detect and Classify Events in Synchro-Waveform Measurements in Power Distribution Networks},
	year = {2022},
	journal = {IEEE Transactions on Smart Grid},
	volume = {13},
	number = {3},
	pages = {2170 – 2184},
	doi = {10.1109/TSG.2022.3148757},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124213145&doi=10.1109%2fTSG.2022.3148757&partnerID=40&md5=d3e603aa5a9780ba8f0890cf7505732e},
	abstract = {Waveform measurement units (WMUs) are a new class of smart grid sensors. They capture synchro-waveforms, i.e., time-synchronized high-resolution voltage waveform and current waveform measurements. In this paper, we propose new methods to detect and classify power quality events in power distribution systems by using synchro-waveform measurements. The methods are built upon a novel graphical concept, called synchronized Lissajous curve. The proposed event detection and event classification methods work by analyzing the shape of the synchronized Lissajous curves during disturbances and events. The impact of challenging factors, such as the angle, the location, and other parameters of the event are discussed. We show that these challenges can be addressed if we treat the synchronized Lissajous curves as images, instead of as time series as in the raw synchronized waveform measurements. Hence, we can take advantage of the recent advancements in the field of image processing so as to capture the overall characterizing patterns in the shapes of the synchronized Lissajous curves. We develop a Convolutional Neural Network (CNN) method to classify the events, where the input is the synchronized Lissajous images. The effectiveness of the proposed event detection and classification methods is demonstrated through computer simulations, including hardware-in-the-loop simulations, and real-world field data. Multiple case studies verify the performance of the proposed methods. The proposed event detection method can accurately detect events, and identify the start time and the end time of each event. The proposed event classification method can classify power quality events with high accuracy. The proposed detection and classification methods do not require any prior knowledge about the network. They use data from as few as only two WMUs.  © 2010-2012 IEEE.},
	author_keywords = {classification; convolutional neural network; data-driven method; detection; hardware-in-the-loop simulations; image classification; power quality event; Synchro-waveform; synchronized Lissajous curves; waveform measurement unit},
	keywords = {Classification (of information); Convolution; Electric power transmission networks; Hardware-in-the-loop simulation; Image classification; Neural networks; Power quality; Smart power grids; Synthetic apertures; Waveform analysis; Convolutional neural network; Data-driven methods; Detection; Events detection; Hardware-in-the-loop simulation.; Hardwarein-the-loop simulations (HIL); Images classification; Lissajous curves; Power; Power measurement; Power quality event; Shape; Synchro-waveform; Synchronized lissajous curve; Waveform measurement; Waveform measurement unit; Waveforms; Synchronization},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Green Open Access}
}

@ARTICLE{2023,
	title = {7th International Conference on Data Management, Analytics and Innovation, ICDMAI 2023},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {662 LNNS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163347999&partnerID=40&md5=38159e8130e2559e667fc8adaa1cb2dd},
	abstract = {The proceedings contain 71 papers. The special focus in this conference is on Data Management, Analytics and Innovation. The topics include: Graphology-Based Behavior Prediction: Case Study Analysis; Statistics-Driven Suspicious Event Detection of Fishing Vessels Based on AIS Data; landslide Susceptibility Mapping Using J48 Decision Tree and Its Ensemble Methods for Rishikesh to Gangotri Axis; distributed Reduced Alphabet Representation for Predicting Proinflammatory Peptides; predicting Injury Severity in Construction Using Logistic Regression; prakruti Nishchitikaran of Human Body Using Supervised Machine Learning Approach; Time Series AutoML; Hierarchical Factor Based Forecasting; Economic Growth Prediction and Performance Analysis of Developed and Developing Countries Using ARIMA, PCA, and k-Means Clustering; optimized Feature Representation for Odia Document Clustering; A Smart System to Classify Walking and Sitting Activities Based on EEG Signal; paris Olympic (2024) Medal Tally Prediction; crop Recommendation Using Hybrid Ensembles Model by Extracting Statistical Measures; aspect-Based Product Recommendation System by Sentiment Analysis of User Reviews; X-ABI: Toward Parameter-Efficient Multilingual Adapter-Based Inference for Cross-Lingual Transfer; comparative Study of Depth Estimation for 2D Scene Using Deep Learning Model; Product Recommendation System Using Deep Learning Techniques: CNN and NLP; modified Long Short-Term Memory Algorithm for Faulty Node Detection Using node’s Raw Data Pattern; DCNN-Based Transfer Learning Approaches for Gender Recognition; fetal Brain Component Segmentation Using 2-Way Ensemble U-Net; morbidity Detection from Clinical Text Data Using Artificial Intelligence Technique; forest Fire Detection and Classification Using Deep Learning Concepts; investigating the Application of Multi-lingual Transformer in Graph-Based Extractive Text Summarization for Hindi Text; real-Time Learning Toward Asset Allocation.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2023,
	author = {Zhang, Tianhao and Jia, Qianqian and Guo, Chao and Huang, Xiaojin},
	title = {Abnormal Event Detection in Nuclear Power Plants via Attention Networks},
	year = {2023},
	journal = {Energies},
	volume = {16},
	number = {18},
	doi = {10.3390/en16186745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172734343&doi=10.3390%2fen16186745&partnerID=40&md5=deff7432c6edf4549d48b45327ebb205},
	abstract = {Ensuring the safety of nuclear energy necessitates proactive measures to prevent the escalation of severe operational conditions. This article presents an efficient and interpretable framework for the swift identification of abnormal events in nuclear power plants (NPPs), equipping operators with timely insights for effective decision-making. A novel neural network architecture, combining Long Short-Term Memory (LSTM) and attention mechanisms, is proposed to address the challenge of signal coupling. The derivative dynamic time warping (DDTW) method enhances interpretability by comparing time series operating parameters during abnormal and normal states. Experimental validation demonstrates high real-time accuracy, underscoring the broader applicability of the approach across NPPs. © 2023 by the authors.},
	author_keywords = {abnormal event detection; attention mechanism; interpretation; neural network; nuclear energy},
	keywords = {Decision making; Long short-term memory; Memory architecture; Network architecture; Nuclear fuels; Nuclear power plants; Abnormal event detections; Attention mechanisms; Decisions makings; Interpretation; Memory mechanism; Neural network architecture; Neural-networks; Novel neural network; Operational conditions; Proactive measures; Nuclear energy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Liu2023,
	author = {Liu, Bo and Hou, Yufan and Luan, Wenpeng and Liu, Zishuai and Chen, Sheng and Yu, Yixin},
	title = {A divide-and-conquer method for compression and reconstruction of smart meter data},
	year = {2023},
	journal = {Applied Energy},
	volume = {336},
	doi = {10.1016/j.apenergy.2023.120851},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148375523&doi=10.1016%2fj.apenergy.2023.120851&partnerID=40&md5=6c5d77b77268b71d750574ba6329ead1},
	abstract = {As smart grid sensors, smart meters generate abundant valuable data, laying the foundation for data-driven applications. However, the data collection brings huge communication pressure to electric utilities. In this context, considering that different types of devices have different power consumption patterns, and different types of data compression methods have their own applicable scenarios, we propose a divide-and-conquer method for compression and reconstruction of smart meter data. First, based on algorithm of voice activity detection (VAD), a load power fluctuation segment location method is proposed, which is combined with load event detection method to divide the load data into the event segments, fluctuation segments, and steady-state segments. Then, for the fluctuation segments, a cloud-device collaboration adaptive strategy based on the compressive sensing (CS) theory is designed, in which the sparse basis and measurement matrix are updated accordingly to ensure the high reconstruction accuracy in different scenarios. For the steady-state segments, a data compression method based on the improved symbolic aggregation approximation (SAX) is established, in which the dividing rectangle (DIRECT) algorithm and the irregular time partitioning method are combined to reduce the data volume for transmission without losing important information. For the event segments, the original data values are retained since the event power curves are relatively more complex and short duration. Finally, the received compressed data are reconstructed into the original power time series data in the master station on cloud to support advanced data analytics. Comparative experiments are conducted on the private and public datasets of 12 households in North America and China. The results show that our method has higher data reconstruction accuracy and compression efficiency compared to the existing methods. © 2023 Elsevier Ltd},
	author_keywords = {Cloud-device collaboration; Compressive sensing; Data compression; Fluctuation Segment Detection; Symbolic aggregation approximation},
	keywords = {China; North America; Approximation algorithms; Compressed sensing; Data Analytics; Data compression; Electric loads; Electric utilities; Cloud-device collaboration; Compression methods; Compressive sensing; Device collaboration; Divide and conquer methods; Fluctuation segment detection; Reconstruction accuracy; Smart grid; Steady state; Symbolic aggregation approximation; algorithm; compression; data set; detection method; efficiency measurement; reconstruction; smart grid; Smart meters},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sun2023522,
	author = {Sun, Guohao and Yan, Kehuan and Fan, Chengbin},
	title = {Deep learning-based vehicle tracking and traffic event detection},
	year = {2023},
	journal = {2023 4th International Conference on Computer Vision, Image and Deep Learning, CVIDL 2023},
	pages = {522 – 526},
	doi = {10.1109/CVIDL58838.2023.10166470},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166296314&doi=10.1109%2fCVIDL58838.2023.10166470&partnerID=40&md5=854e9fccb4b309a3ad62bc45fb393ed7},
	abstract = {Time-series data mining plays an important role in big data decision making because it can reveal the development pattern of things. Similar concatenation of temporal data is a fundamental prerequisite for data twinning., whose core objective is to find all similar temporal data pairs according to a given similarity metric. Dynamic temporal regularization (DTW) has been widely used in many fields., such as target detection., trend prediction and fault identification., as the best data alignment method on temporal data. We use deep learning to extract vehicle trajectories and perform behavioral pattern learning., and finally use an improved DTW algorithm to pre-process the trajectory data and solve the distance function to achieve matching between the trajectories of the event sequence to be measured and the typical trajectory data patterns. By comparing the indicators with the unimproved DTW algorithm., the research results show that this traffic condition recognition method is stable and reliable., and can maintain high matching accuracy with significantly reduced computation., high success rate and good real-time performance.  © 2023 IEEE.},
	author_keywords = {Data Mining; Deep Learning; Digital Twins; DTW algorithm; Traffic Event; Trajectory Tracking},
	keywords = {Decision making; Deep learning; E-learning; Intelligent vehicle highway systems; Trajectories; Data decision; Deep learning; DTW algorithm; Events detection; Matchings; Temporal Data; Time series data mining; Traffic event; Trajectories datum; Trajectory-tracking; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Levasseur2022,
	author = {Levasseur, Guillaume and Bersini, Hugues},
	title = {Time Series Representation for Real-World Applications of Deep Neural Networks},
	year = {2022},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	volume = {2022-July},
	doi = {10.1109/IJCNN55064.2022.9892244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140776961&doi=10.1109%2fIJCNN55064.2022.9892244&partnerID=40&md5=6e6b9b4d39adaf8007b6acd4867e1404},
	abstract = {Neural networks have a proven usefulness at predicting, denoising or classifying time series. However, the performance of deep learning models is bound to the size of the input window. Yet, no common method has emerged to determine the optimal window size. In this paper, we compare two heuristics and three event detection algorithms to find the best time representation for three different tasks, using one simulated and two real-world datasets. The two real-world applications are the electricity disaggregation for energy efficiency in buildings and the detection of fibrillation for diagnosis in cardiology. We compare the obtained window sizes with the experimental values from previous research and we experimentally validate the relevance of the results using both convolutional and recurrent deep neural networks. Results confirm the impact of the sequence length on model performance and show that window sizes cannot be simply transferred to another dataset, even for the same problem. We also find that the false nearest neighbors method can reliably estimate the window size and can help with the tedious work of finding the right time representation. © 2022 IEEE.},
	keywords = {Convolutional neural networks; Deep neural networks; Energy efficiency; Recurrent neural networks; De-noising; Event detection algorithm; Learning models; Neural-networks; Optimal window size; Performance; Real-world; Series representations; Times series; Window Size; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Lim20224702,
	author = {Lim, Min Hyuk and Cho, Young Min and Kim, Sungwan},
	title = {Multi-Task Disentangled Autoencoder for Time-Series Data in Glucose Dynamics},
	year = {2022},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	volume = {26},
	number = {9},
	pages = {4702 – 4713},
	doi = {10.1109/JBHI.2022.3175928},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130471807&doi=10.1109%2fJBHI.2022.3175928&partnerID=40&md5=c7071885dade6839af06376b8b87a667},
	abstract = {The objective of this study is to propose MD-VAE: a multi-task disentangled variational autoencoders (VAE) for exploring characteristics of latent representations (LR) and exploiting LR for diverse tasks including glucose forecasting, event detection, and temporal clustering. We applied MD-VAE to one virtual continuous glucose monitoring (CGM) data from an FDA-approved Type 1 Diabetes Mellitus simulator (T1DMS) and one publicly available CGM data of real patients for glucose dynamics of Type 1 Diabetes Mellitus. LR captured meaningful information to be exploited for diverse tasks, and was able to differentiate characteristics of sequences with clinical parameters. LR and generative models have received relatively little attention for analyzing CGM data so far. However, as proposed in our study, VAE has the potential to integrate not only current but also future information on glucose dynamics and unexpected events including interactions of devices in the data-driven manner. We expect that our model can provide complementary views on the analysis of CGM data. © 2013 IEEE.},
	author_keywords = {Continuous glucose monitoring; disentanglement; generative model; latent representation; Type 1 diabetes mellitus},
	keywords = {Blood Glucose; Blood Glucose Self-Monitoring; Diabetes Mellitus, Type 1; Forecasting; Glucose; Humans; Job analysis; Reactive power; Time series analysis; glucose; insulin; glucose; Auto encoders; Continuous glucose monitoring; Decoding; Disentanglement; Generative model; Latent representation; Multi tasks; Task analysis; Time-series data; Type 1 diabetes mellitus; Article; autoencoder; blood glucose monitoring; controlled study; diabetes mellitus; diagnostic test accuracy study; entropy; forecasting; glucose blood level; glycemic control; human; hyperglycemia; hypoglycemia; insulin dependent diabetes mellitus; long short term memory network; multi task disentangled variational autoencoder; principal component analysis; receiver operating characteristic; recurrent neural network; support vector machine; time series analysis; blood glucose monitoring; insulin dependent diabetes mellitus; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Hossain2022,
	author = {Hossain, K. S. M. Tozammel and Harutyunyan, Hrayr and Ning, Yue and Kennedy, Brendan and Ramakrishnan, Naren and Galstyan, Aram},
	title = {Identifying geopolitical event precursors using attention-based LSTMs},
	year = {2022},
	journal = {Frontiers in Artificial Intelligence},
	volume = {5},
	doi = {10.3389/frai.2022.893875},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142044342&doi=10.3389%2ffrai.2022.893875&partnerID=40&md5=3686f24023aaf8546341f9f9e069a702},
	abstract = {Forecasting societal events such as civil unrest, mass protests, and violent conflicts is a challenging problem with several important real-world applications in planning and policy making. While traditional forecasting approaches have typically relied on historical time series for generating such forecasts, recent research has focused on using open source surrogate data for more accurate and timely forecasts. Furthermore, leveraging such data can also help to identify precursors of those events that can be used to gain insights into the generated forecasts. The key challenge is to develop a unified framework for forecasting and precursor identification that can deal with missing historical data. Other challenges include sufficient flexibility in handling different types of events and providing interpretable representations of identified precursors. Although existing methods exhibit promising performance for predictive modeling in event detection, these models do not adequately address the above challenges. Here, we propose a unified framework based on an attention-based long short-term memory (LSTM) model to simultaneously forecast events with sequential text datasets as well as identify precursors at different granularity such as documents and document excerpts. The key idea is to leverage word context in sequential and time-stamped documents such as news articles and blogs for learning a rich set of precursors. We validate the proposed framework by conducting extensive experiments with two real-world datasets—military action and violent conflicts in the Middle East and mass protests in Latin America. Our results show that overall, the proposed approach generates more accurate forecasts compared to the existing state-of-the-art methods, while at the same time producing a rich set of precursors for the forecasted events. Copyright © 2022 Hossain, Harutyunyan, Ning, Kennedy, Ramakrishnan and Galstyan.},
	author_keywords = {attention-method; deep learning; event forecasting; event precursors; long short-term memory (LSTM); social unrest modeling},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tomaszewski2022,
	author = {Tomaszewski, Dariusz and Rapiński, Jacek and Stolecki, Lech and Śmieja, Michal},
	title = {Switching Edge Detector as a Tool for Seismic Events Detection Based on GNSS Timeseries},
	year = {2022},
	journal = {Archives of Mining Sciences},
	volume = {67},
	number = {2},
	doi = {10.24425/ams.2022.141461},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135180124&doi=10.24425%2fams.2022.141461&partnerID=40&md5=48c16e4bc4341cb37f420cb5478d18e9},
	abstract = {Contemporary mine exploitation requires information about the deposit itself and the impact of mining activities on the surrounding surface areas. In the past, this task was performed using classical seismic and geodetic measurements. Nowadays, the use of new technologies enables the determination of the necessary parameters in global coordinate systems. For this purpose, the relevant services create systems that integrate various methods of determining interesting quantities, e.g., seismometers / GNSS / PSInSAR. These systems allow detecting both terrain deformations and seismic events that occur as a result of exploitation. Additionally, they enable determining the quantity parameters that characterise and influence these events. However, such systems are expensive and cannot be set up for all existing mines. Therefore, other solutions are being sought that will also allow for similar research. In this article, the authors examined the possibilities of using the existing GNSS infrastructure to detect seismic events. For this purpose, an algorithm of automatic discontinuity detection in time series "Switching Edge Detector"was used. The reference data were the results of GNSS measurements from the integrated system (seismic / GNSS / PSI nSA R) installed on the LGCB (Legnica-Glogów Copper Belt) area. The GNSS data from 2020 was examined, for which the integrated system registered seven seismic events. The switching Edge Detector algorithm proved to be an efficient tool in seismic event detection.  © 2022. The Author(s).},
	author_keywords = {GNSS; seismology; switching edge detection; timeseries analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Escottá2022,
	author = {Escottá, Álvaro Teixeira and Beccaro, Wesley and Ramírez, Miguel Arjona},
	title = {Evaluation of 1D and 2D Deep Convolutional Neural Networks for Driving Event Recognition},
	year = {2022},
	journal = {Sensors},
	volume = {22},
	number = {11},
	doi = {10.3390/s22114226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131061626&doi=10.3390%2fs22114226&partnerID=40&md5=9747095b6f090effe5772985ce03e1d9},
	abstract = {Driving event detection and driver behavior recognition have been widely explored for many purposes, including detecting distractions, classifying driver actions, detecting kidnappings, pricing vehicle insurance, evaluating eco-driving, and managing shared and leased vehicles. Some systems can recognize the main driving events (e.g., accelerating, braking, and turning) by using in-vehicle devices, such as inertial measurement unit (IMU) sensors. In general, feature extraction is a commonly used technique to obtain robust and meaningful information from the sensor signals to guarantee the effectiveness of the subsequent classification algorithm. However, a general assessment of deep neural networks merits further investigation, particularly regarding end-to-end models based on Convolutional Neural Networks (CNNs), which combine two components, namely feature extraction and the classification parts. This paper primarily explores supervised deep-learning models based on 1D and 2D CNNs to classify driving events from the signals of linear acceleration and angular velocity obtained with the IMU sensors of a smartphone placed in the instrument panel of the vehicle. Aggressive and non-aggressive behaviors can be recognized by monitoring driving events, such as accelerating, braking, lane changing, and turning. The experimental results obtained are promising since the best classification model achieved accuracy values of up to 82.40%, and macro-and micro-average F1 scores, respectively, equal to 75.36% and 82.40%, thus, demonstrating high performance in the classification of driving events. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {artificial neural networks; convolutional neural networks; deep learning; driving events analysis; machine learning; recurrence plot; time series analysis},
	keywords = {Algorithms; Automobile Driving; Neural Networks, Computer; Smartphone; Behavioral research; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Extraction; Feature extraction; Vehicles; Convolutional neural network; Deep learning; Driving event analyse; Driving events; Event analysis; Features extraction; Inertial measurements units; Model-based OPC; Recurrence plot; Time-series analysis; algorithm; car driving; smartphone; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Li2021234,
	author = {Li, Shuheng and Chowdhury, Ranak Roy and Shang, Jingbo and Gupta, Rajesh K. and Hong, Dezhi},
	title = {UniTS: Short-Time Fourier Inspired Neural Networks for Sensory Time Series Classification},
	year = {2021},
	journal = {SenSys 2021 - Proceedings of the 2021 19th ACM Conference on Embedded Networked Sensor Systems},
	pages = {234 – 247},
	doi = {10.1145/3485730.3485942},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120872249&doi=10.1145%2f3485730.3485942&partnerID=40&md5=ca13af8cdea0b381a064c1add0d413ed},
	abstract = {Discovering patterns in time series data is essential to many key tasks in intelligent sensing systems, such as human activity recognition and event detection. These tasks involve the classification of sensory information from physical measurements such as inertial or temperature change measurements. Due to differences in the underlying physics, existing methods for classification use handcrafted features combined with traditional learning algorithms, or employ distinct deep neural models to directly learn from raw data. We propose here a unified neural architecture, UniTS, for sensory time series classification in various tasks, which obviates the need for domain-specific feature, model customization or polished hyper-parameter tuning. This is possible as we believe that discriminative patterns in sensory measurements would manifest when we combine information from both the time and frequency domains. In particular, to reveal the commonality of sensory signals, we integrate Short-Time Fourier Transform (STFT) into neural networks by initializing convolutional filter weights as the Fourier coefficients. Instead of treating STFT as a static linear transform with fixed coefficients, we make these weights optimizable during network training, which essentially learns to weigh each frequency channel. Recognizing that time-domain signals might represent intuitive physics such as temperature and acceleration, we combine linearly transformed time-domain hidden features with the frequency components within each time chunk. We further extend our model to multiple branches with different time-frequency resolutions to avoid the need of hyper-parameter search. We conducted experiments on four public datasets containing time-series data from various IoT systems, including motion, WiFi, EEG, and air quality, and compared UniTS with numerous recent models. Results demonstrate that our proposed method achieves an average F1 score of 91.85% with a 2.3-point improvement over the state of the art. We also verified the efficacy of STFT-inspired structures through numerous quantitative studies. © 2021 Owner/Author.},
	author_keywords = {Classification; Deep Neural Networks; Sensory Time Series; Time-frequency Analysis},
	keywords = {Air quality; Classification (of information); Convolution; Convolutional neural networks; Fourier analysis; Fourier series; Pattern recognition; Quality control; Sensory analysis; Time domain analysis; Time series; Time series analysis; Fourier; Hyper-parameter; Learn+; Neural-networks; Sensory time series; Short time Fourier transforms; Time series classifications; Time-frequency Analysis; Time-series data; Times series; Deep neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@ARTICLE{Alqudah202394840,
	author = {Alqudah, Mohammad and Obradovic, Zoran},
	title = {Enhancing Weather-Related Outage Prediction and Precursor Discovery Through Attention-Based Multi-Level Modeling},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {94840 – 94851},
	doi = {10.1109/ACCESS.2023.3303110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168267841&doi=10.1109%2fACCESS.2023.3303110&partnerID=40&md5=67b945962a678126522e9c980e0280db},
	abstract = {Electric grid continually monitors spatiotemporal data from sparse service areas. As power systems grow and get more complex, and with the deployment of more sensors and data collection capabilities, monitoring and analyzing data streams for outage prediction will get more complicated. In addition, the burden on human operators to analyze such data is getting challenging. Furthermore, climate change introduces new challenges to power grid reliability and makes the human grid operators' task more critical. To address some of these challenges, this research proposes a novel model to jointly predict power grid outages and discover precursors from spatiotemporal data using multi-level data. The new method utilizes multi-task learning (MTL) and multi-instance learning (MIL) to jointly predict outages and learn event precursors. This is achieved by introducing distance-aware self-attention to capture relationships between locations and improve event detection and precursor discovery while utilizing multi-level data (local weather data, global demand, and forecast data) in a sparse setting. Experiments are conducted using five years of data collected in the U.S. Pacific Northwest. The proposed methodology achieves an Area Under the Precision-Recall Curve (AU-PRC) of 0.97 using 12 hours of data before the event. Experiments showed that the proposed model could predict events several hours ahead with high accuracy, where such early predictions allow grid operators to deploy outage mitigation plans. In addition, the new framework effectively discovers spatiotemporal precursors for power outages. Grid operators can use such event precursors to help mitigate outages and improve grid reliability.  © 2013 IEEE.},
	author_keywords = {big data; climate change; event detection; event precursors; machine learning; power system faults; smart grids; time series analysis; Weather},
	keywords = {Artificial intelligence; Big data; Climate change; Climate models; Learning systems; Outages; Reliability analysis; Smart power grids; Weather forecasting; Event precursor; Events detection; Machine-learning; Power grids; Power system fault; Power systems reliability; Predictive models; Smart grid; Spatiotemporal phenomenon; Time-series analysis; Weather; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Qi20211956,
	author = {Qi, Lin and Qin, Kun and Luo, Ping and Yao, Borui and Zhu, Zhaoyuan},
	title = {Quantitative Expression of Conflict Intensity and Conflict Event Detection based on GDELT News Data; [基于GDELT新闻数据的冲突强度定量表达及冲突事件检测研究]},
	year = {2021},
	journal = {Journal of Geo-Information Science},
	volume = {23},
	number = {11},
	pages = {1956 – 1970},
	doi = {10.12082/dqxxkx.2021.210172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122819047&doi=10.12082%2fdqxxkx.2021.210172&partnerID=40&md5=482155e91d98b5c4e1be7f79ae47cad7},
	abstract = {Conflicts occur frequently at any time and any place in the world. Conflicts often erupt between two or more parties. Analyzing the relation between various conflicts and monitoring the development and evolution of conflicts can help provide measures to intervene in conflicts and provide humanitarian assistance in the embryonic stage of conflicts, which can further help avoid the escalation of conflicts. Various conflict has attracted lots of attention from the public. The occurrence of various conflicts is usually reported by the news media in a timely manner, and each event information can be automatically collected by computers and recorded in news databases. The conflict news database contains a wealth of information. It provides a feasible way to extract the information of conflict events from the new data, quantify the conflict intensity, and analyze the change of national conflict intensity. The GDELT is such an excellent event database which monitors news from different sources around the world in real time, automatically extracts events and event attribute information in news, and classifies the event into conflict events and cooperation events. This paper uses GDELT event database as the data source and comprehensively obtains the number of events, the impact of the events, and the degree of attention to conflict events. We propose a method to quantitatively express the intensity of conflicts by using the global conflict index and the local conflict index for different spatial scales. At the global scale, we calculate the global conflict index of countries around the world to measure the intensity of national conflicts and analyze the spatial distribution of the intensity of global national conflicts. At the country level, the local conflict index is calculated to measure the change of conflict intensity in a country. Based on the quantitative expression of conflict intensity, a distance-based time series conflict detection method is employed to detect the occurrence of conflict events. The results show that: 1) Countries with high conflict intensity are mainly concentrated in Africa and the Middle East, and there is obvious spatial agglomeration of global conflict intensity; 2) The sudden increase in the national conflict index usually corresponds to the occurrence of some conflict events. The method of conflict detection in this paper can effectively detect the sudden increase in time and provide support for the early warning of conflicts. The research results of this paper can provide references for the analysis of international conflict relations and the decision-making of international rescue organizations. 2021, Science Press. All right reserved.},
	author_keywords = {Conflict detection; Conflict intensity; Conflict quantitative expression; GDELT; Global conflict index; Local conflict index; Spatial analysis},
	keywords = {Africa; Middle East; Decision making; Spatial variables measurement; Conflict detection; Conflict intensity; Conflict quantitative expression; Embryonic stages; Events detection; GDELT; Global conflict index; Humanitarian assistances; Local conflict index; Spatial analysis; conflict management; decision making; detection method; gene expression; local participation; mass media; public sector; quantitative analysis; spatial analysis; spatial distribution; Database systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Gea2023,
	author = {Gea, Cristiane and Vereda, Luciano and Ogasawara, Eduardo},
	title = {Detection of Uncertainty Events in the Brazilian Economic and Financial Time Series},
	year = {2023},
	journal = {Computational Economics},
	doi = {10.1007/s10614-023-10483-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174142460&doi=10.1007%2fs10614-023-10483-3&partnerID=40&md5=0ddf6a99528fc7468d88bd706edae6f7},
	abstract = {Economic policy uncertainty shocks change how the economy behaves, moving it away from its pattern. Therefore, these effects can be understood as an event. Given this, the problem of event detection becomes particularly relevant for a more accurate understanding of how uncertainty affects the behavior of economic and financial time series. Thus, the present work aims to answer the following questions: (1) What events do economic policy uncertainty shocks cause in the economic and financial time series? (2) What is the most suitable method for detecting such events? (3) Does applying the ensemble methodology contribute to a more accurate detection? We studied various Brazilian financial time series to answer these questions. The findings indicate that (1) the trend anomaly and the change point are the most prominent types of events for the Brazilian case; (2) in most cases analyzed, the group of financial series presents the highest values observed in the metrics used to evaluate event detection methods; and (3) the application of the ensemble methodology contributes to more accurate event detection, compared to the performance of individual methods. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Anomaly detection; Change point; Economic policy uncertainty; Event detection; Trend anomaly; Volatility anomaly},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li20221818,
	author = {Li, Ziyu and Zhu, Lupei and Officer, Timothy and Shi, Feng and Yu, Tony and Wang, Yanbin},
	title = {A machine-learning-based method of detecting and picking the first P-wave arrivals of acoustic emission events in laboratory experiments},
	year = {2022},
	journal = {Geophysical Journal International},
	volume = {230},
	number = {3},
	pages = {1818 – 1823},
	doi = {10.1093/gji/ggac148},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132518131&doi=10.1093%2fgji%2fggac148&partnerID=40&md5=9664d37348b37dcbebbbb46e47a6cdb4},
	abstract = {Detecting and picking the first P-wave arrivals of seismic events in seismograms is fundamental in observational seismology. Recently, several machine-learning-based algorithms have been developed to incorporate human expertise for picking P-wave arrival times automatically. One shortcoming of these models is that they pick arrival times at individual seismic stations separately, which need to be sorted and associated to identify the seismic event. Also, most of them rely on existence of P-wave arrivals in the seismograms to be picked. Here, we developed a machine-learning-based seismic event detection and P-wave arrival time picking method called MultiNet and applied it to acoustic emission (AE) waveform data recorded in laboratory experiments. The MultiNet uses 2-D waveform images from multichannel AE recordings as the input to a convolutional neural network (CNN) to detect whether there is an AE event in an image and, if so, uses a fully convolutional neural network (FCN) to pick the P-wave arrival time at each channel in the image. We tested the MultiNet using 550 known AE events recorded during syn-deformational phase transformation from olivine to spinel in Mg2GeO4 (an analogue to Mg2SiO4) in a high-pressure experiment. Waveform data of 50 events were used to train the neural networks and the rest of data were used to validate the method. At the optimal image length and detection threshold, the CNN was able to detect all 500 known events plus 48 more events missed previously. Overall, 98.7 per cent of P-wave arrival times picked by the FCN were within 0.5μs from the manually picked times. The average picking errors at different channels range from 0.01 ± 0.05 to -0.06 ± 0.22 μs. Our method greatly reduces the amount of human labour in picking P-wave arrival times for event location and source moment tensor inversion. It can be easily adapted to process continuous waveform data of a seismic network for earthquake detection and location in real time.  © 2022 The Author(s) 2022. Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Acoustic properties; Body waves; Neural networks, fuzzy logic; Time-series analysis},
	keywords = {Acoustic properties; Earthquakes; Fuzzy neural networks; Germanium compounds; Magnesium compounds; Seismic waves; Silicate minerals; Acoustic-emissions; Acoustics property; Body waves; Convolutional neural network; Fuzzy-Logic; Machine-learning; Neural network, fuzzy logic; Neural-networks; P wave arrival time; Time-series analysis; acoustic emission; acoustic property; artificial neural network; body wave; fuzzy mathematics; laboratory method; machine learning; P-wave; seismology; time series analysis; Fuzzy logic},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Zhang202373,
	author = {Zhang, Yihong and Shirakawa, Masumi and Hara, Takahiro},
	title = {Generalized durative event detection on social media},
	year = {2023},
	journal = {Journal of Intelligent Information Systems},
	volume = {60},
	number = {1},
	pages = {73 – 95},
	doi = {10.1007/s10844-022-00730-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135281433&doi=10.1007%2fs10844-022-00730-8&partnerID=40&md5=5f49695b7123310bded08d6dea46f7b5},
	abstract = {Given the recent availability of large volumes of social media discussions, finding temporal unusual phenomena, which can be called events, from such data is of great interest. Previous works on social media event detection either assume a specific type of event, or assume certain behavior of observed variables. In this paper, we propose a general method for event detection on social media that makes few assumptions. The main assumption we make is that when an event occurs, affected semantic aspects will behave differently from their usual behavior, for a sustained period. We generalize the representation of time units based on word embeddings of social media text, and propose an algorithm to detect durative events in time series in a general sense. In addition, we also provide an incremental version of the algorithm for the purpose of real-time detection. We test our approaches on synthetic data and two real-world tasks. With the synthetic dataset, we compare the performance of retrospective and incremental versions of the algorithm. In the first real-world task, we use a novel setting to test if our method and baseline methods can exhaustively catch all real-world news in the test period. The evaluation results show that when the event is quite unusual with regard to the base social media discussion, it can be captured more effectively with our method. In the second real-world task, we use the event captured to help improve the accuracy of stock market movement prediction. We show that our event-based approach has a clear advantage compared to other ways of adding social media information. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Event detection; Heuristic methods; Social media},
	keywords = {Motion estimation; Semantics; Social networking (online); Durative; Embeddings; Events detection; General method; Large volumes; Real-world task; Social media; Time units; Times series; Unit-based; Heuristic methods},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Hu2022,
	author = {Hu, Yue and Qu, Ao and Work, Dan},
	title = {Detecting Extreme Traffic Events Via a Context Augmented Graph Autoencoder},
	year = {2022},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	volume = {13},
	number = {6},
	doi = {10.1145/3539735},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143898509&doi=10.1145%2f3539735&partnerID=40&md5=3af8910698401a68ff95d32eb69fbaa4},
	abstract = {Accurate and timely detection of large events on urban transportation networks enables informed mobility management. This work tackles the problem of extreme event detection on large-scale transportation networks using origin-destination mobility data, which is now widely available. Such data is highly structured in time and space, but high dimensional and sparse. Current multivariate time series anomaly detection methods cannot fully address these challenges. To exploit the structure of mobility data, we formulate the event detection problem in a novel way, as detecting anomalies in a set of time-dependent directed weighted graphs. We further propose a Context augmented Graph Autoencoder (Con-GAE) model to solve the problem, which leverages graph embedding and context embedding techniques to capture the spatial and temporal patterns. Con-GAE adopts an autoencoder framework and detects anomalies via semi-supervised learning. The performance of the method is assessed on several city-scale travel-time datasets from Uber Movement, New York taxis, and Chicago taxis and compared to state-of-the-art approaches. The proposed Con-GAE can achieve an improvement in the area under the curve score as large as 0.15 over the second best method. We also discuss real-world traffic anomalies detected by Con-GAE.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Anomaly detection; autoencoder; graph neural network; transportation},
	keywords = {Directed graphs; Graph embeddings; Graph neural networks; Machine learning; Travel time; Urban transportation; Anomaly detection; Augmented graph; Auto encoders; Events detection; Extreme events; Graph neural networks; Mobility datum; Mobility management; Traffic event; Urban transportation networks; Anomaly detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Nizam202222836,
	author = {Nizam, Hussain and Zafar, Samra and Lv, Zefeng and Wang, Fan and Hu, Xiaopeng},
	title = {Real-Time Deep Anomaly Detection Framework for Multivariate Time-Series Data in Industrial IoT},
	year = {2022},
	journal = {IEEE Sensors Journal},
	volume = {22},
	number = {23},
	pages = {22836 – 22849},
	doi = {10.1109/JSEN.2022.3211874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139865316&doi=10.1109%2fJSEN.2022.3211874&partnerID=40&md5=c7bc1daa774d5316036771ea164ca5d6},
	abstract = {The data produced by millions of connected devices and smart sensors in the Industrial Internet of Things (IIoT) is highly dynamic, large-scale, heterogeneous, and time-stamped. These time-stamped data are the core of IIoT automation and have the potential to affect industrial processes intensely. It poses significant challenges to effectively detect anomalies from time-series data and deliver actionable insights in real time to drive improvements to industrial processes. In most practical applications, where data are used to make automated decisions, real-time anomaly detection is critical. With this focus, in this article, we advise a hybrid end-to-end deep anomaly detection (DAD) framework to accurately detect anomalies and extremely rare events on sensitive, Internet of Things (IoT) streaming data in real time or near real time. The proposed framework is based on a convolutional neural network (CNN) and a two-stage long short-term memory (LSTM)-based Autoencoder (AE). We exploit a two-stage LSTM AE in parallel to detect anomalies and extremely rare events hidden in massive sensor data by identifying short- and long-term variations in actual sensor values from the predicted values. We design and train a hybrid model using the Keras/TensorFlow framework as the backend. The experimental results on one simulation and two real datasets demonstrate that the proposed framework achieved better performance and outperforms other state-of-the-art competitive models. Moreover, to prove that the proposed model can be designed for the network edge, we train, optimize, and quantize the model to run-on resource-constrained (i.e., edge) devices. Further evaluation indicates that the training and inference time for each sample is short enough to carry out anomaly detection on edge.  © 2001-2012 IEEE.},
	author_keywords = {Anomaly detection; deep learning (DL); Industrial Internet of Things (IIoT); long short-term memory (LSTM) autoencoder (AE); machine learning (ML); multivariate time series; rare event detection; sensor data},
	keywords = {Constrained optimization; Digital storage; Edge detection; Feature extraction; Interactive computer systems; Internet of things; Long short-term memory; Real time systems; Smart sensors; Time series; Anomaly detection; Auto encoders; Deep learning; Events detection; Features extraction; Image edge detection; Industrial IIoT; Industrial internet of thing; Intelligent sensors; LSTM autoencoder; Machine-learning; Multivariate time series; Rare event detection; Real - Time system; Sensors data; Anomaly detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Sadeghi2023669,
	author = {Sadeghi, Negin and Weil, Maximillian and Noppe, Nymfa and Weijtjens, Wout and Devriendt, Christof},
	title = {Fatigue Analysis on Four Months of Data on a Steel Railway Bridge: Event Detection and Train Features’ Effect on Fatigue Damage},
	year = {2023},
	journal = {Lecture Notes in Civil Engineering},
	volume = {270 LNCE},
	pages = {669 – 679},
	doi = {10.1007/978-3-031-07322-9_67},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134352041&doi=10.1007%2f978-3-031-07322-9_67&partnerID=40&md5=18669a70ffa9e2f24812c36b0c64b440},
	abstract = {Bridges are critical infrastructures subjected to cyclic loading and require fatigue monitoring to prevent high maintenance costs due to fatigue failure. This paper, part of OWI-lab’s research activities within the SafeLife-Infrabel project, presents a fatigue survey on four months of strain measurements of a steel railway bridge in Belgium, comprising 98 Fiber Bragg Gratings (FBGs). This study aims to develop a data-driven case/event detection scheme including measurements and operational data (e.g., train type and passage time). The first objective is to develop a Python package to separate the events by automatically selecting the train passage events from the strain time series to analyze them and also reduce the dataset size. Over the studied period, a total of 5000 events were detected. Then, the available operational data is complemented with properties estimated from the strain measurements, including the axle number, speed, and direction. Finally, the relation between the fatigue damage and different train features is studied by calculating the attributed fatigue damage using the Rainflow cycle counting method and the Palmgren-Miner rule. A notable damage difference existed between freight and passenger trains. In addition, the damage difference between loaded and empty freight trains was completely distinguishable, while the effect of occupancy was not very visible in passenger trains. Axle number had the highest impact among the passenger trains and had linear relation with damage. Also, the difference in fatigue damage between various types of passenger trains was less distinctive. Finally, the speed and direction affected the damage very slightly. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Event detection; Fatigue damage; Fiber-optic bragg gratings; Steel railway bridge; Structural health monitoring},
	keywords = {Axles; Damage detection; Fatigue damage; Fiber Bragg gratings; Fiber optic sensors; Passenger cars; Railroad bridges; Railroad transportation; Railroads; Steel bridges; Steel fibers; Strain measurement; Events detection; Fatigue analysis; Fatigue monitoring; Fiber-optic Bragg grating; Freight trains; Maintenance cost; Operational data; Passenger train; Steel railway bridge; Strains measurements; Structural health monitoring},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Samanta20222757,
	author = {Samanta, Indu Sekhar and Rout, Pravat Kumar and Mishra, Satyasis and Swain, Kunjabihari and Cherukuri, Murthy},
	title = {Fast TT transform and optimized probabilistic neural network-based power quality event detection and classification},
	year = {2022},
	journal = {Electrical Engineering},
	volume = {104},
	number = {4},
	pages = {2757 – 2774},
	doi = {10.1007/s00202-022-01505-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124842898&doi=10.1007%2fs00202-022-01505-8&partnerID=40&md5=c4251097bccd2a1fe687086453494bbb},
	abstract = {This paper accomplishes the detection and classification of power quality disturbances (PQDs) using a fast time–time (TT) analysis and differential evolution (DE)-based probabilistic neural network (PNN). Applying a translatable and scalable Gaussian window, the TT transform divides a primary time series to a secondary set of time localized time series. In this secondary time series representation, the higher frequencies are highly concentrated in the midpoint of the Gaussian, in comparison with lower frequencies. In this study, fast TT transform is considered to accommodate arbitrarily scalable windows. With generalized S transform, the TT transform is extended to resolve the times of PQ event initiations. Further, to be computationally less complex and faster, the considered TT transform for feature extraction is accommodated with automatic scaling. The extracted features are used as input to the PNN classifier for the classification of the PQDs. Further, a modified mutation-based DE is used to enhance the PNN performance by optimizing the weights and optimum setting of the spread constant value. The obtained simulation results prove the better performance of the proposed approach with significantly less complexity and higher classification accuracy to detect and classify the power quality events even with noise contamination. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {Classification; Fast TT transform; Feature selection; Non-stationary power signals; Power quality; Probabilistic neural network},
	keywords = {Classification (of information); Complex networks; Evolutionary algorithms; Feature extraction; Mathematical transformations; Optimization; Power quality; Time series; Fast time–time transform; Fast-time; Features selection; Neural-networks; Non-stationary power signals; Power quality disturbances; Power quality event; Probabilistic neural network; Probabilistics; Times series; Neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}@ARTICLE{Shashidhar20203130,
	author = {Shashidhar, Dodla and Rodriguez, Ismael Vera and Mallika, Kothamasu and Kühn, Daniela and Wilks, Matthew and Satyanarayana, Hari Venkata Subramanya and Oye, Volker},
	title = {Relative locations of an earthquake sequence recorded during June 2017 on the Koyna–Warna borehole seismic network of western India},
	year = {2020},
	journal = {Bulletin of the Seismological Society of America},
	volume = {110},
	number = {6},
	pages = {3130 – 3138},
	doi = {10.1785/012020068},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096424087&doi=10.1785%2f012020068&partnerID=40&md5=276534954e49cbeddb68a587d3f2a787},
	abstract = {In the Koyna–Warna region, western India, an enormous number of microearthquakes was detected automatically on borehole records. Most of these events could not be identified on the surface network by a routine approach based on visual inspection primarily due to signal attenuation and the presence of noise. In this work, we implemented an automatic detection workflow to analyze the time series of an earthquake sequence that has clear foreshock and aftershock activity associated with an Mw 4.0 earthquake that occurred on 3 June 2017. Further, we applied a nested grid-search algorithm to constrain the absolute earthquake locations. For about one month of data, a total of ∼ 1500 earthquakes were detected based on the automatic detection process, out of which ∼ 1000 earthquakes were locatable. All event detections, P-wave and S-wave phase readings were manually inspected and refined to ensure their quality. Previously, only about 435 events were well located based on the visual inspection approach for the same time period. Also, we analyzed repeated earthquakes based on waveform similarity leading to an improvement in the relocations of earthquakes of the aforementioned earthquake sequence. The relocated seismicity aligns parallel to a deep-reaching lineament derived from recent investigations using airborne light detection and ranging measurements. © Seismological Society of America.},
	keywords = {India; Koyna; Maharashtra; Warna; Boreholes; Inspection; Optical radar; Seismic waves; Shear waves; Automatic Detection; Earthquake location; Earthquake sequences; Light detection and ranging; Relative location; Signal attenuation; Visual inspection; Waveform similarity; aftershock; algorithm; borehole geophysics; detection method; earthquake epicenter; earthquake magnitude; earthquake mechanism; microearthquake; P-wave; S-wave; seismicity; time series; Earthquakes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@ARTICLE{Carta20211,
	author = {Carta, Salvatore and Consoli, Sergio and Piras, Luca and Podda, Alessandro Sebastian and Recupero, Diego Reforgiato},
	title = {Event Detection in Finance Using Hierarchical Clustering Algorithms on News and Tweets},
	year = {2021},
	journal = {PeerJ Computer Science},
	volume = {7},
	pages = {1 – 39},
	doi = {10.7717/PEERJ-CS.438},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107616063&doi=10.7717%2fPEERJ-CS.438&partnerID=40&md5=cf63f2b143d9a9e042efa9d02e7854f3},
	abstract = {In the current age of overwhelming information and massive production of textual data on the Web, Event Detection has become an increasingly important task in various application domains. Several research branches have been developed to tackle the problem from different perspectives, including Natural Language Processing and Big Data analysis, with the goal of providing valuable resources to support decision-making in a wide variety of fields. In this paper, we propose a real- time domain-specific clustering-based event-detection approach that integrates textual information coming, on one hand, from traditional newswires and, on the other hand, from microblogging platforms. The goal of the implemented pipeline is twofold: (i) providing insights to the user about the relevant events that are reported in the press on a daily basis; (ii) alerting the user about potentially important and impactful events, referred to as hot events, for some specific tasks or domains of interest. The algorithm identifies clusters of related news stories published by globally renowned press sources, which guarantee authoritative, noise-free information about current affairs; subsequently, the content extracted from microblogs is associated to the clusters in order to gain an assessment of the relevance of the event in the public opinion. To identify the events of a day d we create the lexicon by looking at news articles and stock data of previous days up to d-1Although the approach can be extended to a variety of domains (e.g. politics, economy, sports), we hereby present a specific implementation in the financial sector. We validated our solution through a qualitative and quantitative evaluation, performed on the Dow Jones’ Data, News and Analytics dataset, on a stream of messages extracted from the microblogging platform Stocktwits, and on the Standard & Poor’s 500 index time- series. The experiments demonstrate the effectiveness of our proposal in extracting meaningful information from real-world events and in spotting hot events in the financial sphere. An added value of the evaluation is given by the visual inspection of a selected number of significant real-world events, starting from the Brexit Referendum and reaching until the recent outbreak of the Covid-19 pandemic in early 2020. Copyright 2021 Carta et al.},
	author_keywords = {Big data; Event detection; Finance; Hierarchical clustering; Natural language processing; News analysis; Social media; Stocktwits; Text mining},
	keywords = {Data streams; Decision making; Finance; Hierarchical clustering; Natural language processing systems; Presses (machine tools); Social aspects; Financial sectors; Massive production; Micro-blogging platforms; NAtural language processing; Quantitative evaluation; Real-time domains; Textual information; Visual inspection; Clustering algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Scharwächter202010,
	author = {Scharwächter, Erik and Müller, Emmanuel},
	title = {Two-sample testing for event impacts in time series},
	year = {2020},
	journal = {Proceedings of the 2020 SIAM International Conference on Data Mining, SDM 2020},
	pages = {10 – 18},
	doi = {10.1137/1.9781611976236.2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089182069&doi=10.1137%2f1.9781611976236.2&partnerID=40&md5=05ef26ec3f7625742c0e865e1938c554},
	abstract = {In many application domains, time series are monitored to detect extreme events like technical faults, natural disasters, or disease outbreaks. Unfortunately, it is often non-trivial to select both a time series that is informative about events and a powerful detection algorithm: detection may fail because the detection algorithm is not suitable, or because there is no shared information between the time series and the events of interest. In this work, we thus propose a non-parametric statistical test for shared information between a time series and a series of observed events. Our test allows identifying time series that carry information on event occurrences without committing to a specific event detection methodology. In a nutshell, we test for divergences of the value distributions of the time series at increasing lags after event occurrences with a multiple two-sample testing approach. In contrast to related tests, our approach is applicable for time series over arbitrary domains, including multivariate numeric, strings or graphs. We perform a large-scale simulation study to show that it outperforms or is on par with related tests on our task for univariate time series. We also demonstrate the real-world applicability of our approach on datasets from social media and smart home environments. Copyright © 2020 by SIAM},
	keywords = {Automation; Disasters; Signal detection; Testing; Time series; Detection algorithm; Disease outbreaks; Large scale simulations; Natural disasters; Non-parametric statistical tests; Shared information; Univariate time series; Value distribution; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Prasad2020,
	author = {Prasad, Lakshman and Alexandrov, Boian S. and Nebgen, Benjamin T.},
	title = {Weak matching of temporal interval graphs of sensors for robust multimodal event detection in noise},
	year = {2020},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {11423},
	doi = {10.1117/12.2558683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088105604&doi=10.1117%2f12.2558683&partnerID=40&md5=499a029925d9bcab513d9f052d15ae67},
	abstract = {We present a weak matching algorithm for interval graphs, to detect recurrent patterns in multimodal temporal data, with feature time series extracted by nonnegative tensor factorization (NTF). NTF enables latent feature extraction as well as uniform representation of multimodal observables. This work builds on our previous work introducing an interval graph representation framework for multi-sensor data. Salient data regions and their relationships are represented by temporal interval graphs, where observables are captured as time intervals (nodes), and temporally proximate nodes are related by edges. Comparing events is then posed as a subgraph matching problem. However, subgraph matching is notoriously difficult (NP-complete) with polynomial algorithms for only very restricted families of graphs. Even in these cases, perturbations to graph structure from missing or extra nodes and edges can lead to brittle matching results. Indeed, realworld sensing involves noisy environments where extraneous or missing observables interfere with event interval graph structures. To cope with these challenges, we propose a proxy representation of interval graphs via their shortest and longest paths and compare graphs by matching their path sets. We describe an attributed path matching scheme that is robust to inclusions and exclusions of nodes by adapting the longest common subsequence algorithm using dynamic programming for attributed path matching. We demonstrate the efficacy of interval graph analysis of tensor features on real-world multimodal sensor data where we investigate the detectability, similarity, and distinguishability of three sets of known events based on ground truth. We illustrate our results with match matrices and ROC curves.  © 2020 SPIE.},
	author_keywords = {Event detection; Feature; Graph matching; Interval graph; Longest common subsequence (LCS) algorithm; Multi-modal; Nonnegative tensor factorization (NTF); Observable},
	keywords = {Dynamic programming; Feature extraction; Graph algorithms; Graph structures; Graphic methods; Signal processing; Tensors; Distinguishability; Longest common subsequences; Matching algorithm; Nonnegative tensor factorizations; Polynomial algorithm; Recurrent patterns; Subgraph matching; Temporal intervals; Graph theory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lazreg202014,
	author = {Lazreg, Mehdi Ben and Anjum, Usman and Zadorozhny, Vladimir and Goodwin, Morten},
	title = {Semantic decay filter for event detection},
	year = {2020},
	journal = {Proceedings of the International ISCRAM Conference},
	volume = {2020-May},
	pages = {14 – 26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120906594&partnerID=40&md5=b2e042777e130946a691c5fb29d97b4a},
	abstract = {Peaks in a time series of social media posts can be used to identify events. Using peaks in the number of posts and keyword bursts has become the go-to method for event detection from social media. However, those methods suffer from the random peaks in posts attributed to the regular daily use of social media. This paper proposes a novel approach to remedy that problem by introducing a semantic decay filter (SDF). The filter’s role is to eliminate the random peaks and preserve the peak related to an event. The filter combines two relevant features, namely the number of posts and the decay in the number of similar tweets in an event-related peak. We tested the filter on three different data sets corresponding to three events: the STEM school shooting, London bridge attacks, and Virginia beach attacks. We show that, for all the events, the filter can eliminate random peaks and preserve the event-related peaks. © 2020 Information Systems for Crisis Response and Management, ISCRAM. All rights reserved.},
	author_keywords = {Crisis Management; Event Detection; String Metric},
	keywords = {Information management; Information systems; Information use; Social networking (online); Crisis management; Daily use; Data set; Events detection; Relevant features; Social media; String metric; Times series; Virginia; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Rodman2021,
	author = {Rodman, Kyle C. and Andrus, Robert A. and Veblen, Thomas T. and Hart, Sarah J.},
	title = {Disturbance detection in landsat time series is influenced by tree mortality agent and severity, not by prior disturbance},
	year = {2021},
	journal = {Remote Sensing of Environment},
	volume = {254},
	doi = {10.1016/j.rse.2020.112244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097707460&doi=10.1016%2fj.rse.2020.112244&partnerID=40&md5=d1948718e477a6b8cc131b8f670f08f3},
	abstract = {Landsat time series (LTS) and associated change detection algorithms are useful for monitoring the effects of global change on Earth's ecosystems. Because LTS algorithms can be easily applied across broad areas, they are commonly used to map changes in forest structure due to wildfire, insect attack, and other important drivers of tree mortality. But factors such as initial forest density, tree mortality agent, and disturbance severity (i.e., percent tree mortality) influence patterns of surface reflectance and may influence the accuracy of LTS algorithms. And while LTS algorithms are widely used in areas with a history of multiple disturbance events during the Landsat record, the effectiveness of LTS algorithms in these conditions is not well understood. We compared products from the LTS algorithm LandTrendr (Landsat-based Detection of Trends in Disturbance and Recovery) with a unique field dataset from a landscape heavily influenced by both wildfire and spruce beetles (Dendroctonus rufipennis) since c. 2000. We also compared LandTrendr to other common methods of mapping fire- and spruce beetle-affected areas. We found that LandTrendr more accurately detected wildfire than spruce beetle-induced tree mortality, and both mortality agents were more easily detected when they occurred at high severity. Surprisingly, prior spruce beetle outbreaks did not influence the detectability of subsequent wildfire. Compared to alternative disturbance mapping approaches, LandTrendr predicted a c. 40% lower area affected by wildfire or spruce beetle outbreaks. Our findings indicate that disturbance type- and severity-specific differences in omission error may have broad implications for disturbance mapping efforts that utilize Landsat data. Gradual, low-severity disturbances (e.g., background tree mortality and non-stand replacing disturbance) are pervasive in forest ecosystems, yet they can be difficult to detect using automated LTS algorithms. Whenever possible, methods to account for these biases should be incorporated in LTS-based mapping efforts, including the use of multispectral ensembles and ancillary spatial data to refine predictions. However, our findings also indicate that LTS algorithms appear to be robust in areas with multiple disturbance events, which is important because these areas will increase as new acquisitions extend the length of the Landsat record. © 2020 Elsevier Inc.},
	author_keywords = {Bark beetle; Event detection; Ground truth; LandTrendr; Multiple disturbances; Overlapping disturbances; Spruce beetle; Wildfire},
	keywords = {Coleoptera; Dendroctonus rufipennis; Hexapoda; Ecosystems; Fires; Mapping; Time series; Change detection algorithms; Dendroctonus rufipennis; Disturbance detection; Disturbance mappings; Influence patterns; Landsat time series; Multiple disturbance; Surface reflectance; detection method; disturbance; forest ecosystem; global change; mortality; satellite data; time series; tree; wildfire; Forestry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Bronze Open Access}
}

@ARTICLE{Daoud2020471,
	author = {Daoud, Mohammad and Daoud, Daoud},
	title = {Sentimental event detection from Arabic tweets},
	year = {2020},
	journal = {International Journal of Business Intelligence and Data Mining},
	volume = {17},
	number = {4},
	pages = {471 – 492},
	doi = {10.1504/IJBIDM.2020.110378},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094149188&doi=10.1504%2fIJBIDM.2020.110378&partnerID=40&md5=c5972e5a9643bd6d129be8e42331477e},
	abstract = {This article presents and evaluates an approach to detect sentimental events from Twitter Arabic data streams. Sentimental events attract strongly opinionated responses from the online community; therefore, we aim at detecting the association of a topic with a positive or a negative sentiment at a particular time. To achieve that, we build sentimental time series where the frequencies of that association (between topics and sentiment) are recorded. And then, we use several algorithms to locate possible events. Events in positive timelines will be considered as positive, and similarly for negative events. Our approaches use Shannon diversity index and hill climbing peak finding. We experimented our proposed algorithms with the domain of football (soccer) news. The results showed good precision and recall considering mainstream media as a reference. The success of such experiment can open the door for many useful applications including reputation and brand monitoring systems for various domains and languages. © 2020 Inderscience Enterprises Ltd.},
	author_keywords = {Data mining; Diversity analysis; Event detection; Sentiment analysis; Social media analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Yang2021432,
	author = {Yang, Shih-Tsung and Jhou, Fong-Ci and Wang, Jia-Ching and Chang, Pao-Chi},
	title = {Sound Event Localization and Detection Based on Time-Frequency Separable Convolutional Compression Network},
	year = {2021},
	journal = {2021 IEEE 10th Global Conference on Consumer Electronics, GCCE 2021},
	pages = {432 – 433},
	doi = {10.1109/GCCE53005.2021.9622019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123468518&doi=10.1109%2fGCCE53005.2021.9622019&partnerID=40&md5=8651a1493707c16a57e0887abe3b8be3},
	abstract = {This work proposes a Time-Frequency Separable Convolutional Compression Network (TFSCCN) as a system architecture for sound event localization and detection. It utilizes 1-D convolution kernels of different dimensions to extract features of time and frequency components separately, and also reduces the amount of model parameters by controlling the increase or decrease of the number of channels in the neural network. In addition, the model combines multi-head self-attention (MHSA) to obtain global and local information in time series features, and uses dual-branch tracking technology to effectively locate and detect the same or different overlapping sound events. © 2021 IEEE.},
	author_keywords = {dual-branch tracking; multi-head self-attention; sound event localization and detection; time-frequency separable convolutional compression network},
	keywords = {Convolution kernel; Dual-branch tracking; Event localizations; Events detection; Multi-head self-attention; Sound event localization and detection; Sound events; Systems architecture; Time frequency; Time-frequency separable convolutional compression network; Convolution},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Odenweller2020,
	author = {Odenweller, Adrian and Donner, Reik V.},
	title = {Disentangling synchrony from serial dependency in paired-event time series},
	year = {2020},
	journal = {Physical Review E},
	volume = {101},
	number = {5},
	doi = {10.1103/PhysRevE.101.052213},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086956274&doi=10.1103%2fPhysRevE.101.052213&partnerID=40&md5=e68d2d47b77e41d1eafbac9201d6ad67},
	abstract = {Quantifying synchronization phenomena based on the timing of events has recently attracted a great deal of interest in various disciplines such as neuroscience or climatology. A multitude of similarity measures has been proposed for this purpose, including event synchronization (ES) and event coincidence analysis (ECA) as two widely applicable examples. While ES defines synchrony in a data-adaptive local way that does not distinguish between different timescales, ECA requires selecting a specific scale for analysis. In this paper, we use slightly modified versions of both ES and ECA that address previous issues with respect to proper normalization and boundary treatment, which are particularly relevant for short time series with low temporal resolution. By numerically studying threshold crossing events in coupled autoregressive processes, we identify a practical limitation of ES when attempting to study synchrony between serially dependent event sequences exhibiting event clustering in time. Practical implications of this observation are demonstrated for the case of functional network representations of climate extremes based on both ES and ECA, while no marked differences between both measures are observed for the case of epileptic electroencephalogram data. Our findings suggest that careful event detection along with diligent preprocessing is recommended when applying ES while less crucial for ECA. Despite the lack of a general modus operandi for both event definition and detection of synchronization, we suggest ECA as a widely robust method, especially for time-resolved synchronization analyses of event time series from various disciplines. © 2020 American Physical Society.},
	keywords = {Synchronization; Time series; Auto regressive process; Boundary treatment; Coincidence analysis; Electroencephalogram data; Event synchronization; Similarity measure; Temporal resolution; Threshold-crossing; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@ARTICLE{Harezlak2020,
	author = {Harezlak, Katarzyna and Kasprowski, Pawel},
	title = {Application of time-scale decomposition of entropy for eye movement analysis},
	year = {2020},
	journal = {Entropy},
	volume = {22},
	number = {2},
	doi = {10.3390/e22020168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080910285&doi=10.3390%2fe22020168&partnerID=40&md5=85585cf939cdcc7494f23cfb4e9c8270},
	abstract = {The methods for nonlinear time series analysis were used in the presented research to reveal eye movement signal characteristics. Three measures were used: approximate entropy, fuzzy entropy, and the Largest Lyapunov Exponent, for which the multilevel maps (MMs), being their time-scale decomposition, were defined. To check whether the estimated characteristics might be useful in eye movement events detection, these structures were applied in the classification process conducted with the usage of the kNN method. The elements of three MMs were used to define feature vectors for this process. They consisted of differently combined MM segments, belonging either to one or several selected levels, as well as included values either of one or all the analysed measures. Such a classification produced an improvement in the accuracy for saccadic latency and saccade, when compared with the previously conducted studies using eye movement dynamics. © 2020 by the authors.},
	author_keywords = {Approximate entropy; Eye movement events detection; Fuzzy entropy; Multilevel entropy map; Nonlinear analysis time series analysis; Time-scale decomposition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Lythgoe20211542,
	author = {Lythgoe, Karen and Loasby, Aidan and Hidayat, Dannie and Wei, Shengji},
	title = {Seismic event detection in urban Singapore using a nodal array and frequency domain array detector: Earthquakes, blasts and thunderquakes},
	year = {2021},
	journal = {Geophysical Journal International},
	volume = {226},
	number = {3},
	pages = {1542 – 1557},
	doi = {10.1093/gji/ggab135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112667986&doi=10.1093%2fgji%2fggab135&partnerID=40&md5=39b60edaece0d4b08a07b1aa731c40d0},
	abstract = {Detection of seismic events at or below the noise level is enabled by the use of dense arrays of receivers and corresponding advances in data analysis methods. It is not only important to detect tectonic events, but also events from man-made, non-earthquake sources and events that originate from coupling between the solid Earth and the atmosphere. In urban environments with high ambient noise levels the effectiveness of event detection methods is unclear, particularly when deployment restrictions result in an irregular receiver array geometry. Here, we deploy a dense nodal array for 1 month in the highly populated city state of Singapore. We develop a new detection method based on image processing that we call spectrogram stacking, which detects anomalous, coherent spectral energy across the array. It simultaneously detects multiple classes of signal with differing spectral content and aids event classification, so it is particularly useful for signal exploration when signal characteristics are unknown. Our approach detects more local events compared to the traditional short-term average over long-term average and waveform similarity methods, while all methods detect similar numbers of teleseismic and regional earthquakes. Local events are principally man-made non-earthquake sources, with several events from the same location exhibiting repeating waveforms. The closest earthquake occurs in peninsular Malaysia, in an area where no earthquakes have previously been detected. We also detect ground motion over a wide frequency range from discrete thunder events that show complex coupling between acoustic and elastic wavefield propagation. We suggest that care should be taken deciphering local high-frequency tectonic events in areas prone to thunder storms.  © 2021 The Author(s) 2021. Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Image processing; Induced seismicity; Seismicity and tectonics; Time-series analysis},
	keywords = {Malaysia; Singapore [Southeast Asia]; West Malaysia; Earth atmosphere; Frequency domain analysis; Image processing; Tectonics; Data analysis methods; Elastic wavefields; Event classification; Regional earthquakes; Signal characteristic; Urban environments; Waveform similarity; Wide frequency range; detection method; earthquake event; geophysical array; image processing; induced seismicity; seismotectonics; spectral analysis; teleseismic wave; time series analysis; Earthquakes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Miralles2021,
	author = {Miralles, Ramón and Lara, Guillermo and Carrión, Alicia and Bou-Cabo, Manuel},
	title = {Assessment of arrow-of-time metrics for the characterization of underwater explosions},
	year = {2021},
	journal = {Sensors},
	volume = {21},
	number = {17},
	doi = {10.3390/s21175952},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114204582&doi=10.3390%2fs21175952&partnerID=40&md5=f562fdf0c85da3c0ca2c5ffd1dddc7b1},
	abstract = {Anthropogenic impulsive sound sources with high intensity are a threat to marine life and it is crucial to keep them under control to preserve the biodiversity of marine ecosystems. Underwater explosions are one of the representatives of these impulsive sound sources, and existing detection techniques are generally based on monitoring the pressure level as well as some frequency-related features. In this paper, we propose a complementary approach to the underwater explosion detection problem through assessing the arrow of time. The arrow of time of the pressure waves coming from underwater explosions conveys information about the complex characteristics of the nonlinear physical processes taking place as a consequence of the explosion to some extent. We present a thorough review of the characterization of arrows of time in time-series, and then provide specific details regarding their applications in passive acoustic monitoring. Visibility graph-based metrics, specifically the direct horizontal visibility graph of the instantaneous phase, have the best performance when assessing the arrow of time in real explosions compared to similar acoustic events of different kinds. The proposed technique has been validated in both simulations and real underwater explosions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Anthropogenic noise characterization; Arrow of time; Impulsive event detection; Passive acoustic monitoring; Surveillance; Underwater explosions},
	keywords = {Acoustics; Benchmarking; Ecosystem; Explosions; Sound; Acoustic generators; Biodiversity; Ecosystems; Graphic methods; Underwater explosions; Visibility; Complex characteristics; Explosion detection; Horizontal visibility graphs; Impulsive sounds; Instantaneous phase; Passive acoustic monitoring; Physical process; Visibility graphs; acoustics; benchmarking; ecosystem; explosion; sound; Underwater acoustic communication},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Li2020,
	author = {Li, Jiada and Hassan, Daniyal and Brewer, Simon and Sitzenfrei, Robert},
	title = {Is clustering time-series water depth useful? An exploratory study for flooding detection in urban drainage systems},
	year = {2020},
	journal = {Water (Switzerland)},
	volume = {12},
	number = {9},
	doi = {10.3390/w12092433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090923909&doi=10.3390%2fw12092433&partnerID=40&md5=bf37fc6be4c40cde655926da6204f650},
	abstract = {As sensor measurements emerge in urban water systems, data-driven unsupervised machine learning algorithms have drawn tremendous interest in event detection and hydraulic water level and flow prediction recently. However, most of them are applied in water distribution systems and few studies consider using unsupervised cluster analysis to group the time-series hydraulic-hydrologic data in stormwater urban drainage systems. To improve the understanding of how cluster analysis contributes to flooding location detection, this study compared the performance of K-means clustering, agglomerative clustering, and spectral clustering in uncovering time-series water depth dissimilarity. In this work, the water depth datasets are simulated by an urban drainage model and then formatted for a clustering problem. Three standard performance evaluation metrics, namely the silhouette coefficient index, Calinski-Harabasz index, and Davies-Bouldin index are employed to assess the clustering performance in flooding prediction under various storms. The results show that silhouette coefficient index and Davies-Bouldin index are more suitable for assessing the performance of K-means and agglomerative clustering, while the Calinski-Harabasz index only works for spectral clustering, indicating these clustering algorithms are metric-dependent flooding predictors. The results also reveal that the agglomerative clustering performs better in forecasting short-duration events while K-means and spectral clustering behave better in predicting long-duration floods. The findings of these investigations can be employed in urban stormwater flood detection at the specific junction-level sites by using the occurrence of anomalous changes in water level in correlated clusters as flood early warning for the local neighborhoods. © 2020 by the authors.},
	author_keywords = {Cluster analysis; Data science; Flooding detection; Machine learning; Smart stormwater},
	keywords = {Cluster analysis; Drainage; Floods; Forecasting; Learning algorithms; Machine learning; Storms; Time series; Time series analysis; Urban growth; Water distribution systems; Water levels; Agglomerative clustering; Clustering time series; Davies-Bouldin index; Short duration events; Standard performance; Unsupervised cluster; Unsupervised machine learning; Urban drainage systems; algorithm; cluster analysis; flooding; machine learning; runoff; time series analysis; unsupervised classification; urban drainage; water depth; water level; K-means clustering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access}
}

@ARTICLE{Arul2021,
	author = {Arul, Monica and Kareem, Ahsan},
	title = {Applications of shapelet transform to time series classification of earthquake, wind and wave data},
	year = {2021},
	journal = {Engineering Structures},
	volume = {228},
	doi = {10.1016/j.engstruct.2020.111564},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097351306&doi=10.1016%2fj.engstruct.2020.111564&partnerID=40&md5=c05dd83c241b6755d7780c7a1f395717},
	abstract = {Autonomous detection of desired events from large databases using time series classification is becoming increasingly important in civil engineering as a result of continued long-term health monitoring of a large number of engineering structures encompassing buildings, bridges, towers, and offshore platforms. In this context, this paper proposes the application of a relatively new time series representation named “Shapelet transform”, which is based on local similarity in the shape of the time series subsequences. In consideration of the individual attributes distinctive to time series signals in earthquake, wind and ocean engineering, the application of this transform yields a new shape-based feature representation. Combining this shape-based representation with a standard machine learning algorithm, a truly “white-box” machine learning model is proposed with understandable features and a transparent algorithm. This model automates event detection without the intervention of domain practitioners, yielding a practical event detection procedure. The efficacy of this proposed shapelet transform-based autonomous detection procedure is demonstrated by examples, to identify known and unknown earthquake events from continuously recorded ground-motion measurements, to detect pulses in the velocity time history of ground motions to distinguish between near-field and far-field ground motions, to identify thunderstorms from continuous wind speed measurements, to detect large-amplitude wind-induced vibrations from the bridge monitoring data, and to identify plunging breaking waves that have a significant impact on offshore structures. © 2020 Elsevier Ltd},
	author_keywords = {Breaking wave detection; Earthquake detection; Machine learning; Shapelet transform; Thunderstorm classification; Time series classification; Time series shapelets},
	keywords = {Bridges; Classification (of information); Earthquakes; Machine learning; Ocean engineering; Offshore oil well production; Offshore structures; Seismic prospecting; Structural health monitoring; Time series; Time series analysis; Wind; Engineering structures; Far-field ground motion; Machine learning models; Plunging breaking waves; Time series classifications; Time series subsequences; Wind induced vibrations; Wind speed measurement; algorithm; breaking wave; bridge; classification; database; earthquake engineering; ground motion; machine learning; thunderstorm; time series analysis; vibration; wind stress; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Green Open Access}
}

@ARTICLE{Wang2021325,
	author = {Wang, Baicun and Li, Yang and Luo, Ying and Li, Xingyu and Freiheit, Theodor},
	title = {Early event detection in a deep-learning driven quality prediction model for ultrasonic welding},
	year = {2021},
	journal = {Journal of Manufacturing Systems},
	volume = {60},
	pages = {325 – 336},
	doi = {10.1016/j.jmsy.2021.06.009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108439938&doi=10.1016%2fj.jmsy.2021.06.009&partnerID=40&md5=215ef4da95176bdd9280382db3776b2d},
	abstract = {A goal in ultrasonic welding (USW) process monitoring is to accurately predict quality outcomes based on monitored signals. However, in most cases, knowing only that the USW process has failed is insufficient. Modern process automation should assess signal information and intercede to rectify process problems. Identification of when a process signal deviates from an acceptable final quality outcome, i.e., the time at which an abnormal event starts, facilitates control action or root cause analysis to bring it back to compliance. A long short-term memory (LSTM) recurrent neural network is proposed to monitor USW and other time-series signals and identify this point. This deep neural network is trained to classify quality outcomes from continuous signals. The process monitoring signals and their sampling time are divided into finite segments as input to this network. The time segment at which the process signal first converges to the final quality class prediction is identified using cross-entropy of the classification probabilities. This procedure is demonstrated using USW quality monitoring algorithms and robot motion failure detection. The examples show an LSTM network not only provides high accuracy for USW quality prediction, but also that the time of classification convergence is consistent with variance observed in USW weld quality factors. Moreover, classification convergence time was shown to be associated to specific robot motion failures, useful as input to adaptive learning. This work realizes deep-learning driven quality prediction and early event detection for quality classification problems, and provides the information necessary for adaptive control algorithms. © 2021 The Society of Manufacturing Engineers},
	author_keywords = {Deep-learning; Event detection; Long short-term memory; Quality prediction; Ultrasonic welding},
	keywords = {Classification (of information); Compliance control; Deep neural networks; Forecasting; Long short-term memory; Predictive analytics; Process control; Process monitoring; Robots; Ultrasonic applications; Ultrasonic welding; Welding; Adaptive control algorithms; Early event detection; Quality classification; Quality monitoring; Quality prediction; Quality prediction models; Root cause analysis; Time series signals; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Du2021,
	author = {Du, Yuhua and Lu, Xiaonan and Wang, Shengyi and Du, Liang and Wang, Yubo and Leao, Bruno and Suresh, Sindhu},
	title = {Physics-Based Feature Extraction from Bulk Time-Series PMU Datasets for Event Detection},
	year = {2021},
	journal = {IEEE Power and Energy Society General Meeting},
	volume = {2021-July},
	doi = {10.1109/PESGM46819.2021.9637906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124142451&doi=10.1109%2fPESGM46819.2021.9637906&partnerID=40&md5=7325c184e3a8ffdd8bb7d3240b0be7b0},
	abstract = {In this work, two physics-based feature extraction techniques are developed for bulk time-series phasor measurement unit (PMU) datasets collected from the field to train the machine learning model for anomaly detection. Two approaches have been developed to extract useful features for different types of events. An admittance-based feature extraction technique is developed to detect events that involve line outages and system topology variations. The developed algorithm extracts the system equivalent admittance variation. Additionally, Fielder's Theory is utilized to further reduce the potential computation burden by sectionalizing large-scale grids and datasets into smaller areas. Second, an oscillation-based feature extraction technique is developed to detect low-frequency oscillations in power grids. The dominant oscillation modes in the grids are extracted using energy-sorted Prony analysis. The extracted dominant oscillation modes by the developed work exhibit a high fitting resolution. Finally, the developed techniques have been validated using large-scale and real-world datasets. © 2021 IEEE.},
	author_keywords = {Event detection; feature extraction; machine learning; PMU; Prony analysis},
	keywords = {Anomaly detection; Computation theory; Electric power transmission networks; Extraction; Feature extraction; Large dataset; Machine learning; Phasor measurement units; Time series analysis; Anomaly detection; Events detection; Feature extraction techniques; Features extraction; Line outage; Machine learning models; Oscillation mode; Physics-based; Prony analysis; Times series; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Feng20212108,
	author = {Feng, Liang and Pazzi, Veronica and Intrieri, Emanuele and Gracchi, Teresa and Gigli, Giovanni},
	title = {Joint detection and classification of rockfalls in a microseismic monitoring network},
	year = {2021},
	journal = {Geophysical Journal International},
	volume = {222},
	number = {3},
	pages = {2108 – 2120},
	doi = {10.1093/gji/ggaa287},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086668466&doi=10.1093%2fgji%2fggaa287&partnerID=40&md5=933dbf484bf678ad667ae1f068117f31},
	abstract = {A rockfall (RF) is a ubiquitous geohazard that is difficult to monitor or predict and poses a significant risk for people and transportation in several hilly and mountainous environments. The seismic signal generated by RF carries abundant physical and mechanical information. Thus, signals can be used by researchers to reconstruct the event location, onset time, volume and trajectory, and develop an efficient early warning system. Therefore, the precise automatic detection and classification of RF events are important objectives for scientists, especially in seismic monitoring arrays. An algorithm called DESTRO (DEtection and STorage of ROckfalls) aimed at combining seismic event automatic detection and classification was implemented ad hoc within the MATLAB environment. In event detection, the STA/LTA (short-time-average through long-time-average) method combined with other parameters, such as the minimum duration of an RF and the minimum interval time between two continuous seismic events is used. Furthermore, nine significant features based on the frequency, amplitude, seismic waveform, duration and multiple station attributes are newly proposed to classify seismic events in a RF environment. In particular, a three-step classification method is proposed for the discrimination of five different source types: RFs, earthquakes (EQs), tremors, multispike events (MSs) and subordinate MS events. Each component (vertical, east–west and north–south) at each station within the monitoring network is analysed, and a three-step classification is performed. At a given time, the event series detected from each component are integrated and reclassified component by component and station by station into a final event-type series as an output result. By this algorithm, a case study of the seven-month-long seismic monitoring of a former quarry in Central Italy was investigated by means of four triaxial velocimeters with continuous acquisition at a sampling rate of 200 Hz. During this monitoring period, a human-induced RF simulation was performed, releasing 95 blocks (in which 90 blocks validated) of different sizes from the benches of the quarry. Consequently, 64.9 per cent of EQs within 100 km were confirmed in a one-month monitoring period, 88 blocks in the RF simulation were classified correctly as RF events and 2 blocks were classified as MSs given their small energy. Finally, an ad hoc section of the algorithm was designed specifically for RF classification combined with EQ recognition. The algorithm could be applied in slope seismic monitoring to monitor the dynamic states of rock masses, as well as in slope instability forecasting and risk evaluation in EQ-prone areas. © 2020 Oxford University Press. All rights reserved.},
	author_keywords = {Fourier analysis; Instability analysis; Seismic noise; Time-series analysis},
	keywords = {Varanidae; MATLAB; Monitoring; Petroleum reservoir evaluation; Quarries; Rock bursts; Seismic waves; Seismology; Automatic Detection; Classification methods; Early Warning System; MATLAB environment; Monitoring network; Monitoring periods; Mountainous environment; Seismic monitoring; classification; detection method; instability; monitoring system; rockfall; seismic noise; time series analysis; Microseismic monitoring},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{2021,
	title = {2nd International Conference on Electrical and Electronics Engineering, ICEEE 2021},
	year = {2021},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {756 LNEE},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107786325&partnerID=40&md5=d93ae5267b62358a0e102ab650bb3926},
	abstract = {The proceedings contain 75 papers. The special focus in this conference is on Electrical and Electronics Engineering. The topics include: Lifecycle assessment of electricity generation transition in ecuador; deep belief convolutional neural network with artificial image creation by gans based diagnosis of pneumonia in radiological samples of the pectoralis major; adaptive linear feedback energy-based backstepping and pid control strategy for pmsg driven by a grid-connected wind turbine; performance improvement for pmsg tidal power conversion system with fuzzy gain supervisor passivity-based current control; rotating acoustic reflector parameter trade-off for near-outdoor audio event detection; loss allocation method for microgrids having variable generation; rooftop antenna for vehicular application; a scalable vlsi architecture for illumination-invariant heterogeneous face recognition; advanced rssi-based wi-fi access point localization using smartphone; a novel design of fss-based absorber integrated microstrip antenna; ontovidrec: A staged knowledge aggregation scheme for annotations-based video retrieval using ontology matching; blockchain aided predictive time series analysis in supply chain system; performance and parametric analysis of iot’s motes with different network topologies; evaluating classical and ann-based load forecasting techniques using univariate and multivariate analysis; data modeling for energy forecasting using machine learning; dimensionality reduction for face recognition using principal component analysis based big bang–big crunch optimization algorithm; design and analysis of brain-implantable antenna for neural signal transmission; active power control for single-phase grid connected transformerless inverter photovoltaic system; ai and iot-based model for photovoltaic power generation; a mutual authentication and key agreement protocol for vehicle to grid technology; fruit classification using deep learning.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xu2020476,
	author = {Xu, Xianghua and Liu, LiQiming and Zhang, Lingjun and Li, Ping and Chen, Jinjun},
	title = {Abnormal visual event detection based on multi-instance learning and autoregressive integrated moving average model in edge-based Smart City surveillance},
	year = {2020},
	journal = {Software - Practice and Experience},
	volume = {50},
	number = {5},
	pages = {476 – 488},
	doi = {10.1002/spe.2701},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065647951&doi=10.1002%2fspe.2701&partnerID=40&md5=a0d88fdb2bd19dd84d939fe68d028851},
	abstract = {The abnormal visual event detection is an important subject in Smart City surveillance where a lot of data can be processed locally in edge computing environment. Real-time and detection effectiveness are critical in such an edge environment. In this paper, we propose an abnormal event detection approach based on multi-instance learning and autoregressive integrated moving average model for video surveillance of crowded scenes in urban public places, focusing on real-time and detection effectiveness. We propose an unsupervised method for abnormal event detection by combining multi-instance visual feature selection and the autoregressive integrated moving average model. In the proposed method, each video clip is modeled as a visual feature bag containing several subvideo clips, each of which is regarded as an instance. The time-transform characteristics of the optical flow characteristics within each subvideo clip are considered as a visual feature instance, and time-series modeling is carried out for multiple visual feature instances related to all subvideo clips in a surveillance video clip. The abnormal events in each surveillance video clip are detected using the multi-instance fusion method. This approach is verified on publically available urban surveillance video datasets and compared with state-of-the-art alternatives. Experimental results demonstrate that the proposed method has better abnormal event detection performance for crowded scene of urban public places with an edge environment. © 2019 John Wiley & Sons, Ltd.},
	author_keywords = {abnormal visual event detection; autoregressive integrated moving average model; crowded scene; multi-instance learning; Smart City},
	keywords = {Monitoring; Security systems; Smart city; Video cameras; Abnormal event detections; Autoregressive integrated moving average models; Computing environments; crowded scene; Event detection; Flow charac-teristics; Multi-instance learning; Time series modeling; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Adams202067,
	author = {Adams, Stephen and Beling, Peter A.},
	title = {Feature selection for hidden markov models with discrete features},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1037},
	pages = {67 – 82},
	doi = {10.1007/978-3-030-29516-5_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072824578&doi=10.1007%2f978-3-030-29516-5_7&partnerID=40&md5=e9c34d466cfbf51fd4c4f2fff7ff1716},
	abstract = {Hidden Markov models (HMMs) are widely used for modeling multivariate time series data. However, all collected data is not always useful for distinguishing between states. In these situations, feature selection should be implemented to save the expense of collecting and processing low utility data. Feature selection for HMMs has been studied but most existing methods assume that the observed data follows a Gaussian distribution. In this paper, a method for simultaneously estimating parameters and selecting features for an HMM with discrete observations is presented. The presented method is an extension of the feature saliency HMM which was originally developed to incorporate feature cost into the feature selection process. Expectation-maximization algorithms are derived for features following a Poisson distribution and features following a discrete non-parametric distribution. The algorithms are evaluated on synthetic data sets and a real-world event detection data set that is composed of both Poisson and non-parametric features. © Springer Nature Switzerland AG 2020.},
	author_keywords = {EM algorithm; Feature selection; Hidden Markov Models},
	keywords = {Data handling; Feature extraction; Genetic algorithms; Intelligent systems; Maximum principle; Parameter estimation; Poisson distribution; Trellis codes; Discrete observations; EM algorithms; Estimating parameters; Expectation-maximization algorithms; Feature saliency; Hidden markov models (HMMs); Multivariate time series; Synthetic datasets; Hidden Markov models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Safarnejad2020,
	author = {Safarnejad, Lida and Xu, Qian and Ge, Yaorong and Bagavathi, Arunkumar and Krishnan, Siddharth and Chen, Shi},
	title = {Identifying influential factors in the discussion dynamics of emerging health issues on social media: Computational study},
	year = {2020},
	journal = {JMIR Public Health and Surveillance},
	volume = {6},
	number = {3},
	doi = {10.2196/17175},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097911580&doi=10.2196%2f17175&partnerID=40&md5=dbb1d7183b9f0c03156e2e32da61df16},
	abstract = {Background: Social media has become a major resource for observing and understanding public opinions using infodemiology and infoveillance methods, especially during emergencies such as disease outbreaks. For public health agencies, understanding the driving forces of web-based discussions will help deliver more effective and efficient information to general users on social media and the web. Objective: The study aimed to identify the major contributors that drove overall Zika-related tweeting dynamics during the 2016 epidemic. In total, 3 hypothetical drivers were proposed: (1) the underlying Zika epidemic quantified as a time series of case counts; (2) sporadic but critical real-world events such as the 2016 Rio Olympics and World Health Organization’s Public Health Emergency of International Concern (PHEIC) announcement, and (3) a few influential users’ tweeting activities. Methods: All tweets and retweets (RTs) containing the keyword Zika posted in 2016 were collected via the Gnip application programming interface (API). We developed an analytical pipeline, EventPeriscope, to identify co-occurring trending events with Zika and quantify the strength of these events. We also retrieved Zika case data and identified the top influencers of the Zika discussion on Twitter. The influence of 3 potential drivers was examined via a multivariate time series analysis, signal processing, a content analysis, and text mining techniques. Results: Zika-related tweeting dynamics were not significantly correlated with the underlying Zika epidemic in the United States in any of the four quarters in 2016 nor in the entire year. Instead, peaks of Zika-related tweeting activity were strongly associated with a few critical real-world events, both planned, such as the Rio Olympics, and unplanned, such as the PHEIC announcement. The Rio Olympics was mentioned in >15% of all Zika-related tweets and PHEIC occurred in 27% of Zika-related tweets around their respective peaks. In addition, the overall tweeting dynamics of the top 100 most actively tweeting users on the Zika topic, the top 100 users receiving most RTs, and the top 100 users mentioned were the most highly correlated to and preceded the overall tweeting dynamics, making these groups of users the potential drivers of tweeting dynamics. The top 100 users who retweeted the most were not critical in driving the overall tweeting dynamics. There were very few overlaps among these different groups of potentially influential users. Conclusions: Using our proposed analytical workflow, EventPeriscope, we identified that Zika discussion dynamics on Twitter were decoupled from the actual disease epidemic in the United States but were closely related to and highly influenced by certain sporadic real-world events as well as by a few influential users. This study provided a methodology framework and insights to better understand the driving forces of web-based public discourse during health emergencies. Therefore, health agencies could deliver more effective and efficient web-based communications in emerging crises. © Lida Safarnejad, Qian Xu, Yaorong Ge, Arunkumar Bagavathi, Siddharth Krishnan, Shi Chen.},
	author_keywords = {Events detection; Health emergency; Infodemic; Infodemiology; Infoveillance; Online influentials; Public engagement; Social media; Tweeting dynamics; Zika},
	keywords = {Data Mining; Humans; North Carolina; Public Opinion; Social Media; Zika Virus Infection; data mining; devices; human; North Carolina; procedures; public opinion; social media; Zika fever},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Vestin2021415,
	author = {Vestin, Jonathan and Kassler, Andreas and Laki, Sandor and Pongracz, Gergely},
	title = {Toward In-Network Event Detection and Filtering for Publish/Subscribe Communication Using Programmable Data Planes},
	year = {2021},
	journal = {IEEE Transactions on Network and Service Management},
	volume = {18},
	number = {1},
	pages = {415 – 428},
	doi = {10.1109/TNSM.2020.3040011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097193608&doi=10.1109%2fTNSM.2020.3040011&partnerID=40&md5=56aab218f051515390e60acfd97ce2d5},
	abstract = {Industrial Internet of Things (I-IoT) applications require a large number of sensor data to be processed under tight delay and jitter constraints. In such applications, flexible event detection and fast reaction to critical events is an important building block. Traditional approaches use either proprietary networks and dedicated hardware or transmit sensor data towards processing elements in the Cloud or at the Network Edge, using distributed stream processing frameworks. For scalability, a large number of servers are needed and processing on commodity CPUs typically involves high and unpredictable latency. In this article, we explore how programmable data planes can be used to detect events flexibly and trigger customized and programmable actions directly from the switch program or the programmable network interface card (SmartNIC). We present FastReact-PS, an event-based publish/subscribe I-IoT processing framework in P4 language, which can be flexibly customized from the control plane. Together with stateful processing, FastReact-PS supports windowed time series analysis as well as complex event detection and processing based on Boolean logic directly in the data plane of newly emerging programmable networking devices. The logic can be adjusted dynamically from the control plane without the need for recompilation. We implement FastReact-PS in P4 and evaluate it on both a SmartNIC and a DPDK-based software switch running in user space. Our evaluation shows that the latency is reduced by one order of magnitude compared to end-host based approaches at significantly lower jitter while being scalable to processing up to 11 million events per second.  © 2021 IEEE.},
	author_keywords = {Event detection; programmable data planes; publish/subscribe},
	keywords = {Computer circuits; Computer hardware description languages; Data communication systems; Distributed parameter control systems; Industrial internet of things (IIoT); Jitter; Program processors; Time series analysis; Complex event detection; Dedicated hardware; Distributed stream processing; Processing elements; Programmable network interface cards; Programmable networkings; Software switches; Traditional approaches; Data streams},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Wortelen2020495,
	author = {Wortelen, Bertram and Herdel, Viviane and Pfeiffer, Oliver and Harre, Marie-Christin and Saager, Marcel and Lanezki, Mathias},
	title = {Efficient Exploration of Long Data Series: A Data Event-driven HMI Concept},
	year = {2020},
	journal = {Communications in Computer and Information Science},
	volume = {1226 CCIS},
	pages = {495 – 503},
	doi = {10.1007/978-3-030-50732-9_64},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088748370&doi=10.1007%2f978-3-030-50732-9_64&partnerID=40&md5=3d9c0d13d064390c4f0ce07e22e4c064},
	abstract = {Today’s easy access to data, low cost sensors and data transmission infrastructure leads to an abundance of data about complex systems in many domains like industrial process control, network intrusion detection or maritime surveillance. Analyzing this data can take a lot of effort and often cannot be fully automated. As it is hard to fully automate such analysis tasks, we present an HMI framework that supports an analyst in exploring and navigating through multiple time series of data. It is a semi-automatic approach that uses algorithms for automatically labelling low-level events in the data, but leaves the task of evaluation and interpretation to the human operator. These events are highlighted on specific time bars in the HMI framework. It enables the analyst to 1) summarize the main features of the data series, 2) filter it depending on the analysis objective, 3) identify and prioritize relevant section in the data and 4) directly jump to these sections. We present the theoretical concept of the HMI framework and demonstrate it on a process control application for hybrid energy systems. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Data exploration; Data visualization; Event detection; System monitoring; Time series},
	keywords = {Costs; Human computer interaction; Intrusion detection; Time series analysis; Hybrid energy system; Industrial process control; Low-cost sensors; Maritime surveillance; Multiple time series; Network intrusion detection; Process-control applications; Semi-automatics; Process control},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Karim2020,
	author = {Karim, Miftah Al and Currie, Jonathan and Lie, Tek-Tjing},
	title = {Distributed machine learning on dynamic power system data features to improve resiliency for the purpose of self-healing},
	year = {2020},
	journal = {Energies},
	volume = {13},
	number = {13},
	doi = {10.3390/en13133494},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090528516&doi=10.3390%2fen13133494&partnerID=40&md5=c842cc3733d7b31bf41cb8d3a3d92731},
	abstract = {Numerous online methods for post-fault restoration have been tested on different types of systems. Modern power systems are usually operated at design limits and therefore more prone to post-fault instability. However, traditional online methods often struggle to accurately identify events from time series data, as pattern-recognition in a stochastic post-fault dynamic scenario requires fast and accurate fault identification in order to safely restore the system. One of the most prominent methods of pattern-recognition is machine learning. However, machine learning alone is neither sufficient nor accurate enough for making decisions with time series data. This article analyses the application of feature selection to assist a machine learning algorithm to make better decisions in order to restore a multi-machine network which has become islanded due to faults. Within an islanded multi-machine system the number of attributes significantly increases, which makes application of machine learning algorithms even more erroneous. This article contributes by proposing a distributed offline-online architecture. The proposal explores the potential of introducing relevant features from a reduced time series data set, in order to accurately identify dynamic events occurring in different islands simultaneously. The identification of events helps the decision making process more accurate. © 2020 by the authors},
	author_keywords = {Event detection; Feature extraction; Machine-learning; Self-healing grid},
	keywords = {Decision making; Machine learning; Online systems; Pattern recognition systems; Restoration; Self-healing materials; Stochastic systems; Time series; Turing machines; Decision making process; Distributed machine learning; Fault identifications; Fault restoration; Making decision; Multimachine systems; Relevant features; Time-series data; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Polz20203835,
	author = {Polz, Julius and Chwala, Christian and Graf, Maximilian and Kunstmann, Harald},
	title = {Rain event detection in commercial microwave link attenuation data using convolutional neural networks},
	year = {2020},
	journal = {Atmospheric Measurement Techniques},
	volume = {13},
	number = {7},
	pages = {3835 – 3853},
	doi = {10.5194/amt-13-3835-2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088918614&doi=10.5194%2famt-13-3835-2020&partnerID=40&md5=f9b90a0457c24914763dbcaab35d5b81},
	abstract = {Quantitative precipitation estimation with commercial microwave links (CMLs) is a technique developed to supplement weather radar and rain gauge observations. It is exploiting the relation between the attenuation of CML signal levels and the integrated rain rate along a CML path. The opportunistic nature of this method requires a sophisticated data processing using robust methods. In this study we focus on the processing step of rain event detection in the signal level time series of the CMLs, which we treat as a binary classification problem. This processing step is particularly challenging, because even when there is no rain, the signal level can show large fluctuations similar to that during rainy periods. False classifications can have a high impact on falsely estimated rainfall amounts. We analyze the performance of a convolutional neural network (CNN), which is trained to detect rainfall-specific attenuation patterns in CML signal levels, using data from 3904 CMLs in Germany. The CNN consists of a feature extraction and a classification part with, in total, 20 layers of neurons and 1.4×105 trainable parameters. With a structure inspired by the visual cortex of mammals, CNNs use local connections of neurons to recognize patterns independent of their location in the time series. We test the CNN's ability to recognize attenuation patterns from CMLs and time periods outside the training data. Our CNN is trained on 4 months of data from 800 randomly selected CMLs and validated on 2 different months of data, once for all CMLs and once for the 3104 CMLs not included in the training. No CMLs are excluded from the analysis. As a reference data set, we use the gauge-adjusted radar product RADOLAN-RW provided by the German meteorological service (DWD). The model predictions and the reference data are compared on an hourly basis. Model performance is compared to a state-of-the-art reference method, which uses the rolling standard deviation of the CML signal level time series as a detection criteria. Our results show that within the analyzed period of April to September 2018, the CNN generalizes well to the validation CMLs and time periods. A receiver operating characteristic (ROC) analysis shows that the CNN is outperforming the reference method, detecting on average 76% of all rainy and 97% of all nonrainy periods. From all periods with a reference rain rate larger than 0.6mmh-1, more than 90% was detected. We also show that the improved event detection leads to a significant reduction of falsely estimated rainfall by up to 51%. At the same time, the quality of the correctly estimated rainfall is kept at the same level in regards to the Pearson correlation with the radar rainfall. In conclusion, we find that CNNs are a robust and promising tool to detect rainfall-induced attenuation patterns in CML signal levels from a large CML data set covering all of Germany. © Author(s) 2020.},
	keywords = {Germany; Mammalia; artificial neural network; data processing; detection method; precipitation assessment; radar; rainfall; raingauge},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Wu2021,
	author = {Wu, Zheng Yi and He, Yekun},
	title = {Time Series Data Decomposition-Based Anomaly Detection and Evaluation Framework for Operational Management of Smart Water Grid},
	year = {2021},
	journal = {Journal of Water Resources Planning and Management},
	volume = {147},
	number = {9},
	doi = {10.1061/(ASCE)WR.1943-5452.0001433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109535730&doi=10.1061%2f%28ASCE%29WR.1943-5452.0001433&partnerID=40&md5=ebd06961f44e1be582e40ac14b646638},
	abstract = {With the increasing adoption of advanced meter infrastructure (AMI), smarter sensors, and temporary and/or permanent data loggers, it is imperative to leverage data analytics methods with hydraulic modeling to improve the quality and efficiency of water service. One important task is to timely detect and evaluate anomaly events so that corresponding actions can be taken to prevent and mitigate the impact of possible water service disruption, which may be caused by the anomaly incidents including but not limited to pipe bursts and unauthorized water usages. In this paper, a comprehensive analysis framework is developed for anomaly event detection and evaluation by developing an integrated solution, which is implemented in multiple components including: (1) data-preprocess or cleansing to eliminate and correct error data records; (2) decomposition of time series data to ensure data stationarity; (3) outlier detection by statistical process control methods with stationary time series; (4) classification of system anomaly events by either correlation analysis of high-flow events with low-pressure events or high-flow outliers with low-pressure outliers; and (5) quantitative evaluation of the system anomaly events with field reported leak incidents. The solution framework has been applied to the water supply zone that is permanent monitored with the flow meter at the inlet and 12 pressure stations throughout the zone with more than 8,000 pipes. Analysis has been conducted with one-year monitoring data and 106 historical leak records, which are employed to validate 526 detected anomaly events. Among them, a 75% true positive rate has been achieved and 90% of 106 field events have been successfully detected with a lead time of more than 24 h. The results obtained indicate that the developed solution method is effective at facilitating the operational management of a smart water grid by maximizing the return of investment in continuously monitoring water distribution networks.  © 2021 American Society of Civil Engineers.},
	author_keywords = {Anomaly classification; Data decomposition; Outlier detection; Smart water grid; Statistical process control},
	keywords = {Advanced metering infrastructures; Data Analytics; Investments; Statistical process control; Time series; Time series analysis; Water distribution systems; Water supply; Classification of systems; Comprehensive analysis; Evaluation framework; Operational management; Quantitative evaluation; Return of investments; Stationary time series; Water distribution networks; classification; decomposition analysis; distribution system; smart grid; time series; water supply; Anomaly detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Leung2020,
	author = {Leung, Hoiyin Christina and Chung, Wingyan},
	title = {A dynamic classification approach to churn prediction in banking industry},
	year = {2020},
	journal = {26th Americas Conference on Information Systems, AMCIS 2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097713084&partnerID=40&md5=234e577c08fa7370803fa8544cdb8bce},
	abstract = {Churn prediction is the process of using transaction data to identify customers who are likely to cease their relationship with a company. To date, most work in churn prediction focuses on sampling strategies and supervised modeling over a short period of time. Few have explored the area of mining customer behavior pattern in longitudinal data. This research developed a dynamic approach to optimizing model specifications by using time-series predictors, multiple time periods, and rare event detection to enable accurate churn prediction. The study used a unique three-year dataset consisting of 32,000 transaction records of a retail bank in Florida, USA. It uses trend modeling to capture the change of customer behavior over time. Results show that data from multiple time periods helped to improve model precision and recall. This dynamic churn prediction approach can be generalized to other fields for which mining long term customer data is necessary. © 2020 26th Americas Conference on Information Systems, AMCIS 2020. All rights reserved.},
	author_keywords = {Banking; Business analytics; Churn prediction; Customer retention; Decision support; Feature engineering},
	keywords = {Banking; Information systems; Information use; Sales; Dynamic approaches; Dynamic classification; Longitudinal data; Modeling precision; Multiple-time periods; Sampling strategies; Time series predictors; Transaction records; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Varadarajan2021,
	author = {Varadarajan, Prasanna Amur and Roguin, Ghislain and Abolins, Nick and Ringer, Maurice},
	title = {A Digital Twin for Real-Time Drilling Hydraulics Simulation Using a Hybrid Approach of Physics and Machine Learning},
	year = {2021},
	journal = {Proceedings of the Annual Offshore Technology Conference},
	doi = {10.4043/31278-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149298094&doi=10.4043%2f31278-MS&partnerID=40&md5=83ad780b0a0823a6532463e5429e1761},
	abstract = {Abnormal hydraulic event detection is essential for offshore well construction operations. These operations require model comparisons and real-time measurements. For this task, physics-based models, which need frequent manual calibration do not accurately capture all the hydraulic trends. The paper presents a method to overcome existing limitations by combining physics-based models with machine learning techniques, which are suited for time series forecasting. This method ensures accurate and reliable predictions during the forecasting period and helps remove the need for frequent manual calibration of the hydraulic input parameters. © 2021, Offshore Technology Conference. All rights reserved.},
	keywords = {Calibration; E-learning; Forecasting; Learning systems; Machine learning; Offshore technology; Drilling hydraulics; Events detection; Hybrid approach; Hydraulic event; Hydraulic simulation; Machine-learning; Manual calibration; Physics learning; Physics-based models; Real time drilling; Offshore oil well production},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2021,
	title = {25th European Conference on Advances in Databases and Information Systems, ADBIS 2021},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12843 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115142312&partnerID=40&md5=73255fdfdd6ed2b8abbaa3f6b4ad488c},
	abstract = {The proceedings contain 20 papers. The special focus in this conference is on Advances in Databases and Information Systems. The topics include: A General Method for Event Detection on Social Media; 5W1H Aware Framework for Representing and Detecting Real Events from Multimedia Digital Ecosystem; MONITOR: A Multimodal Fusion Framework to Assess Message Veracity in Social Networks; Joint Management and Analysis of Textual Documents and Tabular Data Within the AUDAL Data Lake; aggregation and Summarization of Thematically Similar Twitter Microblog Messages; preface; A Perspective on Prescriptive Learning ADBIS’2021 Keynote; Inserting Keys into the Robust Content-and-Structure (RCAS) Index; optimizing Execution Plans in a Multistore; integrity Constraints for Microcontroller Programming in Datalog; chance Constraint as a Basis for Probabilistic Query Model; unsupervised Feature Selection for Efficient Exploration of High Dimensional Data; MuLOT: Multi-level Optimization of the Canonical Polyadic Tensor Decomposition at Large-Scale; from Large Time Series to Patterns Movies: Application to Airbus Helicopters Flight Data; experimental Evaluation Among Reblocking Techniques Applied to the Entity Resolution; FiLiPo: A Sample Driven Approach for Finding Linkage Points Between RDF Data and APIs; SMAT: An Attention-Based Deep Learning Solution to the Automation of Schema Matching; Data Exchange for Digital Government: Where Are We Heading? ADBIS2021 Keynote.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shen2020,
	author = {Shen, Yuchang and Cao, Dingzhou and Ruddy, Kate and de Moraes, Luis Felipe Teixeira},
	title = {Deep learning based hydraulic fracture event recognition enables real-time automated stage-wise analysis},
	year = {2020},
	journal = {Society of Petroleum Engineers - SPE Hydraulic Fracturing Technology Conference and Exhibition 2020, HFTC 2020},
	doi = {10.2118/199738-ms},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085665971&doi=10.2118%2f199738-ms&partnerID=40&md5=37153ba1c33aaa5d48438aa623fb7885},
	abstract = {This paper provides the technical details of developing the automated stage-wise KPIs report generator, which is to be implemented as a module in the Real-Time Completion (RTC) analytics system. The generator is constructed with three models, two of which use Machine Learning (ML), that detect the stage start and end, identify the ball pumpdown and seat operation, and segments of a single stage of time series data into operationally similar sections. These tasks are performed based on the reliably available measurements of slurry rate and wellhead pressure, which enable the real-time automated stage-wise KPI analysis, and also lay the foundation for further advanced analysis regarding operational decision making. The stage start and end detection is treated as a classification task. The slurry rate and wellhead pressure along with their first and second order derivatives are extracted by a fixed-length sliding window and structured as matrices, which resemble the data structure of ML inputs. A Convolutional Neural Network (CNN) is trained for the classification, and each data point is classified as either within a stage's pumping time or otherwise as the data is received, with minimal latency. Data of eight wells with 648 total stages were labeled for the stage start and end detection model. The five-fold cross-validation technique was used to evaluate the performance of the model, and a 15-second-window was used to extract data from the time series data. The model achieved an accuracy of ~99.7% with a tolerance of 25 seconds in all blind tests, meaning the predicted start or end of the stage was fewer than 25 seconds before or after the actual flag. After the start of stage classification is made, the ball pumpdown/seat recognition tasks take place. The ball pumpdown/seat event detection is a two-step strategy. The first step is to detect if there is a ball pumpdown/seat event in a stage, and the second step is to locate the end of that event. The first step is accomplished via a deep learning model with U-Net architecture, which detects the ball pumpdown and seat pattern within the slurry rate and pressure time series data. 179 samples are used to train the U-Net model. The transfer learning technology is used, as the dataset is small, and the U-Net is materialized with the pre-trained ResNet-34. The blind test's F1 score for the U-Net models is 0.97, which indicates excellent performance on the prediction. The second step can be achieved by a rule-based selection given the information from the first step. The third model analyzes a single stage and splits the stage into differently categorized segments. The model takes a three-step strategy. First, the stage data is smoothed by the sequential application of three different filters. The smoothed data is used in the second step, which detects points of interest and categorizes the segments in between. Segments are categorized by the slope of a linear fit or the mean first order derivative along the segment. Finally, a rule-based method is applied to agglomerate segments, which leads to a more interpretable categorization. The solution presented by this paper, provides real-time automated interpretations of hydraulic fracture events, enabling auto-generation of KPI reports, dispelling the need for manual labeling and eliminating human bias and errors. It fills the manual task gaps in the RTC workflow/data pipeline and paves the way for a fully automated RTC system. © 2020, Society of Petroleum Engineers},
	keywords = {Automation; Benchmarking; Convolutional neural networks; Data mining; Decision making; Fracture; Hydraulic fracturing; Labeled data; Learning systems; Report generators; Time series; Transfer learning; Well pressure; Wellheads; Automated interpretation; Classification tasks; Cross-validation technique; First order derivatives; Operational decision making; Second order derivatives; Sequential applications; Three-step strategies; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Lassetter2021117,
	author = {Lassetter, Austin and Cotilla-Sanchez, Eduardo and Kim, Jinsub},
	title = {Using Critical Slowing down Features to Enhance Performance of Artificial Neural Networks for Time-Domain Power System Data},
	year = {2021},
	journal = {2021 9th IEEE International Conference on Smart Energy Grid Engineering, SEGE 2021},
	pages = {117 – 123},
	doi = {10.1109/SEGE52446.2021.9535027},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116070990&doi=10.1109%2fSEGE52446.2021.9535027&partnerID=40&md5=a560bf2f62682cff3e21fc2f0ce5cffe},
	abstract = {This paper explores deep learning approaches to event classification on real world time-domain power system data. We use a statistical method to measure a physical phenomenon known as critical slowing down (CSD) and use this as a feature engineering preprocessing framework to localize events from large intervals of data. Several previous works have discussed power system event detection, including statistical methods like correlation, Principal Component Analysis (PCA) reconstruction, and local outlier factor search. This work aims to improve upon the statistical methods that have been linked to high-sample rate time-domain event detection and then will be evaluated using artificial neural networks. To evaluate how well CSD localizes events from non-events in high sample rate time-series data, we used a Z-score function to predict the time of an event and extract a six second interval centered around the prediction. The performance of CSD-applied data against the raw data was then compared using two ANN architectures: the Fully Convolutional Network (FCN) and the Residual Neural Network (ResNet). The results of both architectures demonstrate that applying CSD to the data significantly improves event localization for larger data intervals, thus signifying an improvement in event detectability. © 2021 IEEE.},
	author_keywords = {Critical Slowing Down; CSD; Phasor Measurement Units; PMU; ResNet; Smart Grid},
	keywords = {Correlation methods; Deep learning; Electric power transmission networks; Network architecture; Neural networks; Principal component analysis; Smart power grids; Time domain analysis; Critical slowing down; Events detection; Neural-networks; Performance; PMU; Residual neural network; Sample rate; Smart grid; Time domain power; Phasor measurement units},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Yao2021,
	author = {Yao, Ruotian and Zhou, Hong and Zhou, Dongguo and Zhang, Heng},
	title = {State Characteristic Clustering for Nonintrusive Load Monitoring with Stochastic Behaviours in Smart Grids},
	year = {2021},
	journal = {Complexity},
	volume = {2021},
	doi = {10.1155/2021/8839595},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112307723&doi=10.1155%2f2021%2f8839595&partnerID=40&md5=14737f6c269fbad63d13d01802b68cef},
	abstract = {Integrating the nonintrusive load monitoring (NILM) technology into smart meters poses challenges in demand-side management (DSM) of the smart grid when capturing detailed power information and stochastic consumption behaviours, due to the difficulties in accurately detecting load operation states in real household environments with the limited information available. In this paper, a state characteristic clustering (SCC) approach is presented for promoting the performance of event detection in NILM, which makes full use of multidimensional characteristic information. After identifying different types of state domains in an established multidimensional characteristic space, we design a sliding window difference search method (SWDS) to extract their initial clustering centre. Meanwhile, the mean-shift updating and iterating procedures are conducted to find the potential terminal stable state according to the probability density function. The above control strategy considers the transient events and stable states in a time-series dataset simultaneously, which thus allows the exact state of complex events to be obtained in a fluctuating environment. Moreover, a multisegment computing scheme is applied for fast computing in the state characteristic clustering process. Experiments of three different cases on both our real household dataset and REDD public dataset are provided to reveal the higher performance of the proposed SCC approach over the existing related methods.  © 2021 Ruotian Yao et al.},
	keywords = {Clustering algorithms; Demand side management; Electric power transmission networks; Electric utilities; Probability density function; State estimation; Stochastic systems; Clustering process; Computing scheme; Control strategies; Event detection; Limited information; Nonintrusive load monitoring; State characteristics; Transient events; Smart power grids},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Le Page2020,
	author = {Le Page, Michel and Jarlan, Lionel and El Hajj, Marcel M. and Zribi, Mehrez and Baghdadi, Nicolas and Boone, Aaron},
	title = {Potential for the detection of irrigation events on maize plots using Sentinel-1 soil moisture products},
	year = {2020},
	journal = {Remote Sensing},
	volume = {12},
	number = {10},
	doi = {10.3390/rs12101621},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085556135&doi=10.3390%2frs12101621&partnerID=40&md5=0319d8514d828a234db9acb60f8e654c},
	abstract = {Although the real timing and flow rates used for crop irrigation are controlled at the scale of individual plots by the irrigator, they are not generally known by the farm upper management. This information is nevertheless essential, not only to compute the water balance of irrigated plots and to schedule irrigation, but also for the management of water resources at regional scales. The aim of the present study was to detect irrigation timing using time series of surface soil moisture (SSM) derived from Sentinel-1 radar observations. The method consisted of assessing the direction of change of surface soil moisture (SSM) between observations and a water balance model, and to use thresholds to be calibrated. The performance of the approach was assessed on the F-score quantifying the accuracy of the irrigation event detections and ranging from 0 (none of the irrigation timing is correct) to 100 (perfect irrigation detection). The study focused on five irrigated and one rainfed plot of maize in South-West France, where the approach was tested using in situ measurements and surface soil moisture (SSM) maps derived from Sentinel-1 radar data. The use of in situ data showed that (1) irrigation timing was detected with a good accuracy (F-score in the range (80-83) for all plots) and (2) the optimal revisit time between two SSM observations was 2-4 days. The higher uncertainties of microwave SSM products, especially when the crop is well developed (normalized difference of vegetation index (NDVI) > 0.7), degraded the score (F-score = 69), but various possibilities of improvement were discussed. This paper opens perspectives for the irrigation detection at the plot scale over large areas and thus for the improvement of irrigation water management. © 2020 by the authors.},
	author_keywords = {Corn; FAO-56; France; Irrigation timing; SAR; Sprinkler; Surface soil moisture},
	keywords = {Crops; Information management; Irrigation; Radar; Radar measurement; Soil moisture; Water management; In-situ measurement; Irrigation water management; Normalized differences; Radar observations; Surface soil moisture; Upper management; Vegetation index; Water balance models; Soil surveys},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Liu2021466,
	author = {Liu, Bo and Hou, Yufan and Luan, Wenpeng and Liu, Zishuai},
	title = {Online Load Data Compression and Reconstruction Based on Segmental Symbolic Aggregate Approximation},
	year = {2021},
	journal = {5th IEEE Conference on Energy Internet and Energy System Integration: Energy Internet for Carbon Neutrality, EI2 2021},
	pages = {466 – 472},
	doi = {10.1109/EI252483.2021.9713124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128224604&doi=10.1109%2fEI252483.2021.9713124&partnerID=40&md5=58ac60ece4e4022330c5155dce5a62ea},
	abstract = {To ensure the performance of load identification, existing non-intrusive load monitoring (NILM) solutions usually need to transmit large amount of continuous power consumption data for cloud analysis, which brings challenges to the communication, storage and computing of NILM systems. In this paper, we propose a segmental online compression and reconstruction method of load data to reduce the data volume for transmission while ensuring the application value of the data. Due to the fact that different segmentations of the load data contain different amounts of information, the time series load data is firstly divided into event segments and non-event segments (also called steady-state segments) by event detection. While the data is retained as it is for the event segment, the symbolic aggregate approximation (SAX) method with nonuniform partition of the time axis is adopted for data compression for the steady-state segment, so as to reduce data size for transmission as much as possible without losing important information. In the master station, the load data including the event and steady-state segments received are respectively reconstructed into original time series with fine resolution in different ways. Comparative experiment results on the private and public datasets show that compared with the existing methods, the proposed method has higher reconstruction accuracy and compression efficiency, which can provide support for the data analysis applications based on high resolution data. © 2021 IEEE},
	author_keywords = {compressive sensing; data compression; event detection; NILM; SAX},
	keywords = {Compressed sensing; Data compression; Data reduction; Digital storage; Electric load management; Time series; Compressive sensing; Events detection; Large amounts; Load data; Load identification; Nonintrusive load monitoring; Performance; Steady state; Symbolic aggregate approximation; Times series; Aggregates},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{González-Vergara2020197,
	author = {González-Vergara, J. and Escobar-González, D. and Chaglla-Aguagallo, D. and Peluffo-Ordóñez, D.H.},
	title = {A Data-Driven Approach for Automatic Classification of Extreme Precipitation Events: Preliminary Results},
	year = {2020},
	journal = {Communications in Computer and Information Science},
	volume = {1277 CCIS},
	pages = {197 – 209},
	doi = {10.1007/978-3-030-61702-8_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096420455&doi=10.1007%2f978-3-030-61702-8_14&partnerID=40&md5=347b594d91337c442c84863516974562},
	abstract = {Even though there exists no universal definition, in the South America Andean Region, extreme precipitation events can be referred to the period of time in which standard thresholds of precipitation are abruptly exceeded. Therefore, their timely forecasting is of great interest for decision makers from many fields, such as: urban planning entities, water researchers and in general, climate related institutions. In this paper, a data-driven study is performed to classify and anticipate extreme precipitation events through hydroclimate features. Since the analysis of precipitation-events-related time series involves complex patterns, input data requires undergoing both pre-processing steps and feature selection methods, in order to achieve a high performance at the data classification stage itself. In this sense, in this study, both individual Principal Component Analysis (PCA) and Regresional Relief (RR) as well as a cascade approach mixing both are considered. Subsequently, the classification is performed by a Support-Vector-Machine-based classifier (SVM). Results reflect the suitability of an approach involving feature selection and classification for precipitation events detection purposes. A remarkable result is the fact that a reduced dataset obtained by applying RR mixed with PCA discriminates better than RR alone but does not significantly hence the SVM rate at two- and three-class problems as done by PCA itself. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Data driven; Extreme precipitation; Feature selection; Forecasting; PCA; Relief; SVM},
	keywords = {Decision making; Feature extraction; Precipitation (meteorology); Support vector machines; Time series analysis; Automatic classification; Data classification; Data-driven approach; Extreme precipitation events; Feature selection and classification; Feature selection methods; Pre-processing step; Precipitation events; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ren2020,
	author = {Ren, Huiying and Hou, Z. Jason and Vyakaranam, Bharat and Wang, Heng and Etingov, Pavel},
	title = {Power System Event Classification and Localization Using a Convolutional Neural Network},
	year = {2020},
	journal = {Frontiers in Energy Research},
	volume = {8},
	doi = {10.3389/fenrg.2020.607826},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097235047&doi=10.3389%2ffenrg.2020.607826&partnerID=40&md5=495ca01d2238164778ed0fd16c0b0900},
	abstract = {Detection and timely identification of power system disturbances are essential for situation awareness and reliable electricity grid operation. Because records of actual events in the system are limited, ensemble simulation-based events are needed to provide adequate data for building event-detection models through deep learning; e.g., a convolutional neural network (CNN). An ensemble numerical simulation-based training data set have been generated through dynamic simulations performed on the Polish system with various types of faults in different locations. Such data augmentation is proven to be able to provide adequate data for deep learning. The synchronous generators’ frequency signals are used and encoded into images for developing and evaluating CNN models for classification of fault types and locations. With a time-domain stacked image set as the benchmark, two different time-series encoding approaches, i.e., wavelet decomposition-based frequency-domain stacking and polar coordinate system-based Gramian Angular Field (GAF) stacking, are also adopted to evaluate and compare the CNN model performance and applicability. The various encoding approaches are suitable for different fault types and spatial zonation. With optimized settings of the developed CNN models, the classification and localization accuracies can go beyond 84 and 91%, respectively. © Copyright © 2020 Ren, Hou, Vyakaranam, Wang and Etingov.},
	author_keywords = {classification; convolutional neural network; fault detection; gramian angular field; localization; time series encoding; wavelet decomposition},
	keywords = {Benchmarking; Convolution; Deep learning; Encoding (symbols); Frequency domain analysis; Signal encoding; Wavelet decomposition; Ensemble simulation; Event classification; Localization accuracy; Polar coordinate systems; Power system disturbances; Simulation-based training; Situation awareness; Timely identification; Convolutional neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Gold Open Access}
}

@ARTICLE{Bazzi2021,
	author = {Bazzi, Hassan and Baghdadi, Nicolas and Amin, Ghaith and Fayad, Ibrahim and Zribi, Mehrez and Demarez, Valérie and Belhouchette, Hatem},
	title = {An operational framework for mapping irrigated areas at plot scale using sentinel‐1 and sentinel‐2 data},
	year = {2021},
	journal = {Remote Sensing},
	volume = {13},
	number = {13},
	doi = {10.3390/rs13132584},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110028972&doi=10.3390%2frs13132584&partnerID=40&md5=56393d18c4259c11d9192a1f546dd276},
	abstract = {In this study, we present an operational methodology for mapping irrigated areas at plot scale, which overcomes the limitation of terrain data availability, using Sentinel‐1 (S1) C‐band SAR (synthetic‐aperture radar) and Sentinel‐2 (S2) optical time series. The method was performed over a study site located near Orléans city of north‐central France for four years (2017 until 2020). First, training data of irrigated and non‐irrigated plots were selected using predefined selection criteria to obtain sufficient samples of irrigated and non‐irrigated plots each year. The training data selection criteria is based on two irrigation metrics; the first one is a SAR‐based metric derived from the S1 time series and the second is an optical‐based metric derived from the NDVI (normalized difference vegetation index) time series of the S2 data. Using the newly developed irrigation event detection model (IEDM) applied for all S1 time series in VV (Vertical‐Vertical) and VH (Vertical‐Horizontal) polarizations, an irrigation weight metric was calculated for each plot. Using the NDVI time series, the maximum NDVI value achieved in the crop cycle was considered as a second selection metric. By fixing threshold values for both metrics, a dataset of irrigated and non‐irrigated samples was constructed each year. Later, a random forest classifier (RF) was built for each year in order to map the summer agricultural plots into irrigated/non‐irrigated. The irrigation classification model uses the S1 and NDVI time series calculated over the selected training plots. Finally, the proposed irrigation classifier was validated using real in situ data collected each year. The results show that, using the proposed classification procedure, the overall accuracy for the irrigation classification reaches 84.3%, 93.0%, 81.8%, and 72.8% for the years 2020, 2019, 2018, and 2017, respectively. The comparison between our proposed classification approach and the RF classifier built directly from in situ data showed that our approach reaches an accuracy nearly similar to that obtained using in situ RF classifiers with a difference in overall accuracy not exceeding 6.2%. The analysis of the obtained classification accuracies of the proposed method with precipitation data revealed that years with higher rainfall amounts during the summer crop‐growing season (irrigation period) had lower overall accuracy (72.8% for 2017) whereas years encountering a drier summer had very good accuracy (93.0% for 2019). © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Irrigation; Normalized difference vegetation index; Soil moisture; Summer crops; Synthetic aperture radar},
	keywords = {Agricultural robots; Crops; Decision trees; Mapping; Precipitation (meteorology); Synthetic aperture radar; Time series; Classification accuracy; Classification approach; Classification models; Classification procedure; Normalized difference vegetation index; Overall accuracies; Random forest classifier; Selection criteria; Irrigation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Xia2020,
	author = {Xia, Min and Liu, Wan'an and Wang, Ke and Song, Wenzhu and Chen, Chunling and Li, Yaping},
	title = {Non-intrusive load disaggregation based on composite deep long short-term memory network},
	year = {2020},
	journal = {Expert Systems with Applications},
	volume = {160},
	doi = {10.1016/j.eswa.2020.113669},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087278131&doi=10.1016%2fj.eswa.2020.113669&partnerID=40&md5=0f20d586a325553989b8f0b845f91a0a},
	abstract = {Non-invasive load monitoring (NILM) is a vital step to realize the smart grid. Although the existing various NILM algorithms have made significant progress in energy consumption feedback, there are still some problems need to further addressed, such as the exponential growth of state space with the increase of the number of multi-state devices, which leads to the dimension disaster; and it is difficult to capture the power fluctuation information effectively because of the neglect of time-dependency problem load disaggregation; traditional disaggregation involves a process of one sequence to one sequence optimization, which is inefficient. In our study, a composite deep LSTM is proposed for load disaggregation. The proposed algorithm considers the process of load disaggregation as a signal separation process and establishes regression learning from a single sequence to multiple sequences to avoid dimension disaster. In addition, an encoder-separation-decoder structure is introduced for load disaggregation. Encoder completes the effective encoding of the mains power and differential power information, the time-dependency of the encoding process implemented by a deep LSTM, separation realizes the disaggregation process by separating the encoded information, and decoder decode the separated signal into the sequences of corresponding electrical appliances. Compared with the one sequence to one sequence disaggregation method, the proposed method simplified disaggregation complexity and improves the efficiency of disaggregation. The experimental results on WikiEnergy and REDD datasets show that the proposed method can reduce the disaggregation error and improve the comprehensive performance of event detection. Besides, our study can provide conditions for the realization of the bidirectional interaction of the smart grid and the improvement of the smart grid scheduling. © 2020 Elsevier Ltd},
	author_keywords = {Cross-layer connection; Long short-term memory network; Non-intrusive load disaggregation; Time series},
	keywords = {Decoding; Disaster prevention; Disasters; Electric load management; Electric power transmission networks; Encoding (symbols); Energy utilization; Separation; Signal encoding; Smart power grids; Bi-directional interaction; Comprehensive performance; Decoder structures; Electrical appliances; Encoded information; Exponential growth; Multiple sequences; Sequence optimization; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 67}
}

@ARTICLE{Khalifa202152,
	author = {Khalifa, Yassin and Mandic, Danilo and Sejdić, Ervin},
	title = {A review of Hidden Markov models and Recurrent Neural Networks for event detection and localization in biomedical signals},
	year = {2021},
	journal = {Information Fusion},
	volume = {69},
	pages = {52 – 72},
	doi = {10.1016/j.inffus.2020.11.008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097578797&doi=10.1016%2fj.inffus.2020.11.008&partnerID=40&md5=0d03f7a59e2e7168d19e2af6cc3f97bd},
	abstract = {Biomedical signals carry signature rhythms of complex physiological processes that control our daily bodily activity. The properties of these rhythms indicate the nature of interaction dynamics among physiological processes that maintain a homeostasis. Abnormalities associated with diseases or disorders usually appear as disruptions in the structure of the rhythms which makes isolating these rhythms and the ability to differentiate between them, indispensable. Computer aided diagnosis systems are ubiquitous nowadays in almost every medical facility and more closely in wearable technology, and rhythm or event detection is the first of many intelligent steps that they perform. How these rhythms are isolated? How to develop a model that can describe the transition between processes in time? Many methods exist in the literature that address these questions and perform the decoding of biomedical signals into separate rhythms. In here, we demystify the most effective methods that are used for detection and isolation of rhythms or events in time series and highlight the way in which they were applied to different biomedical signals and how they contribute to information fusion. The key strengths and limitations of these methods are also discussed as well as the challenges encountered with application in biomedical signals. © 2020 Elsevier B.V.},
	author_keywords = {Biomedical signal processing; Deep learning; Event detection; Hidden Markov models; Recurrent Neural Networks; Transfer learning},
	keywords = {Bioelectric phenomena; Computer aided diagnosis; Hidden Markov models; Physiology; Wearable technology; Biomedical signal; Computer aided diagnosis systems; Event detection; Interaction dynamics; Medical facility; Physiological process; Recurrent neural networks},
	type = {Short survey},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Zhou202170,
	author = {Zhou, Tianyao and He, Zeming and Zhai, Runze and Xu, Xinzhou},
	title = {Sound Event Detection with Speech Interference Using Convolutional Recurrent Neural Networks},
	year = {2021},
	journal = {2021 IEEE 4th International Conference on Big Data and Artificial Intelligence, BDAI 2021},
	pages = {70 – 74},
	doi = {10.1109/BDAI52447.2021.9515259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114489080&doi=10.1109%2fBDAI52447.2021.9515259&partnerID=40&md5=198cfd589442bfaba31f70d0963f7ba9},
	abstract = {Sound event detection (SED) refers to recognizing sound event, in which the prevailing method of SED is to employ deep neural networks at present. However, it remains unknown on the detection performance for sound events with background speech. Thus within this paper, we propose to utilize a Convolutional Recurrent Neural Network (CRNN) in detecting multi-channel audio from overlapping sources in the speech-interference condition with multiple speakers. The approach includes two modules of Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN), in which the CNN module maps acoustic features to the input of the RNN, while the RNN aims to model the time series using Bi-directional Gated Recurrent Units (Bi-GRU). Afterwards, we employ experiments on SED data with speech interference. The experimental results indicate that the proposed approach makes it robust to detect sound events when provided speech signals as the background noise, compared with conventional SED approaches. © 2021 IEEE.},
	author_keywords = {convolutional recurrent neural networks; multi-channel audio; sound event detection; speech interference},
	keywords = {Big data; Convolution; Convolutional neural networks; Deep neural networks; Speech; Speech recognition; Acoustic features; Background noise; Bi-directional; Detection performance; Multichannel audio; Recurrent neural network (RNN); Sound event detection; Speech interference; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Arisa2021166,
	author = {Arisa, Watanabe and Basabi, Chakraborty},
	title = {Time-series Analysis of Newspaper Articles for Automatic Event Detection using LDA},
	year = {2021},
	journal = {4th IEEE International Conference on Knowledge Innovation and Invention 2021, ICKII 2021},
	pages = {166 – 169},
	doi = {10.1109/ICKII51822.2021.9574704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119020814&doi=10.1109%2fICKII51822.2021.9574704&partnerID=40&md5=277b2efb00d50766fedb60c19b04c3d1},
	abstract = {Newspapers are useful for understanding important past events. However, reading all articles is difficult and time-consuming. Automatic detection of characteristic events from past time series text data helps an interested user to find important past events. Automatic topic classification of newspaper articles and visualizing the change of topics over a certain period are used for past event detection. In this study, automatic topic classification is performed using Latent Dirichlet Allocation (LDA). The daily changes in the topics are measured by using different distance metrics to detect the changes which indicate important events. The idea has been implemented with a simple and small data set to check its validity. © 2021 IEEE.},
	author_keywords = {Kullback Leibler divergence; Latent Dirichlet Allocation; Spectral clustering; Topic classification},
	keywords = {Newsprint; Statistics; Time series analysis; Automatic Detection; Daily change; Distance metrics; Events detection; Kullback Leibler divergence; Latent Dirichlet allocation; Spectral clustering; Text data; Times series; Topic Classification; Clustering algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Humm2020138,
	author = {Humm, Bernhard G. and Hutter, Marco},
	title = {Learning patterns for complex event detection in robot sensor data},
	year = {2020},
	journal = {Communications in Computer and Information Science},
	volume = {1173 CCIS},
	pages = {138 – 149},
	doi = {10.1007/978-3-030-41913-4_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080886278&doi=10.1007%2f978-3-030-41913-4_12&partnerID=40&md5=81b3846d9c160189e1f3084aad55a615},
	abstract = {We present an approach for learning patterns for Complex Event Processing (CEP) in robot sensor data. While the robot executes a certain task, sensor data is recorded. The sensor data recordings are classified in terms of events or outcomes that characterize the task. These classified recordings are then used to learn simple rules that describe the events using a simple, domain specific language, in a human-readable and interpretable way. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Complex event detection; Interpretable AI; Machine learning; Robots; Time series},
	keywords = {Learning systems; Problem oriented languages; Time series; Complex event detection; Complex event processing (CEP); Domain specific languages; Human-readable; Learning patterns; Robot sensors; Sensor data; Robots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2021,
	title = {6th International Workshop on Advanced Analytics and Learning on Temporal Data, AALTD 2021, held at the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML-PKDD 2021},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13114 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121912961&partnerID=40&md5=039cf26374db7c8f94b3e4db27b8c76d},
	abstract = {The proceedings contain 12 papers. The special focus in this conference is on Advanced Analytics and Learning on Temporal Data. The topics include: RevDet: Robust and Memory Efficient Event Detection and Tracking in Large News Feeds; from Univariate to Multivariate Time Series Anomaly Detection with Non-Local Information; state Space Approximation of Gaussian Processes for Time Series Forecasting; fast Channel Selection for Scalable Multivariate Time Series Classification; Temporal Phenotyping for Characterisation of Hospital Care Pathways of COVID19 Patients; non-parametric Multivariate Time Series Co-clustering Model Applied to Driving-Assistance Systems Validation; TRAMESINO: Traffic Memory System for Intelligent Optimization of Road Traffic Control; detection of Critical Events in Renewable Energy Production Time Series; multimodal Meta-Learning for Time Series Regression; cluster-Based Forecasting for Intermittent and Non-intermittent Time Series.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2020,
	author = {Zhang, Jin and Wu, Cheng and Wang, Yiming},
	title = {Human fall detection based on body posture spatio-temporal evolution},
	year = {2020},
	journal = {Sensors (Switzerland)},
	volume = {20},
	number = {3},
	doi = {10.3390/s20030946},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079339519&doi=10.3390%2fs20030946&partnerID=40&md5=a70a553722520231f0f5c919304c049a},
	abstract = {Abnormal falls in public places have significant safety hazards and can easily lead to serious consequences, such as trampling by people. Vision-driven fall event detection has the huge advantage of being non-invasive. However, in actual scenes, the fall behavior is rich in diversity, resulting in strong instability in detection. Based on the study of the stability of human body dynamics, the article proposes a new model of human posture representation of fall behavior, called the “five-point inverted pendulum model”, and uses an improved two-branch multi-stage convolutional neural network (M-CNN) to extract and construct the inverted pendulum structure of human posture in real-world complex scenes. Furthermore, we consider the continuity of the fall event in time series, use multimedia analytics to observe the time series changes of human inverted pendulum structure, and construct a spatio-temporal evolution map of human posture movement. Finally, based on the integrated results of computer vision and multimedia analytics, we reveal the visual characteristics of the spatio-temporal evolution of human posture under the potentially unstable state, and explore two key features of human fall behavior: motion rotational energy and generalized force of motion. The experimental results in actual scenes show that the method has strong robustness, wide universality, and high detection accuracy. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Computer vision; Fall behavior detection; Five-point inverted pendulum model; Human posture spatio-temporal map; Motion instability; Rotational energy},
	keywords = {Accidental Falls; Algorithms; Humans; Models, Biological; Motion; Posture; ROC Curve; Time Factors; Walking; Computer vision; Convolutional neural networks; Pendulums; Time series; Behavior detection; Human body dynamics; Human fall detection; Inverted pendulum model; Potentially unstable; Rotational energy; Spatio temporal; Spatiotemporal evolution; algorithm; biological model; body position; falling; human; motion; physiology; receiver operating characteristic; time factor; walking; Behavioral research},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Wang20202674,
	author = {Wang, Tiantong and Zhang, Zhongping and Lin, Youzuo},
	title = {Earthquakegen: Earthquake generator using generative adversarial networks},
	year = {2020},
	journal = {SEG International Exposition and Annual Meeting 2019},
	pages = {2674 – 2678},
	doi = {10.1190/segam2019-3216687.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079498299&doi=10.1190%2fsegam2019-3216687.1&partnerID=40&md5=4ece736076ffb86a06577cad1a7e1c0f},
	abstract = {Earthquake event detection in seismic time series data is an important and challenging problem. The current state-of-the-art machine-learning based detection methods mostly belong to supervised learning category and die detection accuracy highly relies on the quality and quantity of the labeled data. However, acquisition of high-quality training set can be technical challenging and expensive in that it requires intensive training on domain knowledge. Therefore, expanding the dataset with artificially generated labeled data can be extremely useful. In this paper, we develop an earthquake generator, EarthquakeGen, by using generative adversarial networks (GAN). GAN is a recently raised generative model based on neural network. By training in a minmax game process, GAN is able to produce samples looks similar but actually different with the real ones. To verify the performance of our EarthquakeGen, we apply it to seismic field data acquired at Oklahoma, where induced earthquake events have been reported. Through our numerical results, we show that our EarthquakeGen can yield high-quality artificial earthquakes. More importantly, we show that the earthquake detection accuracy can be significantly improved by using augmented training sets combining both artificial and real samples. © 2019 SEG},
	keywords = {Labeled data; Adversarial networks; Artificial earthquake; Detection accuracy; Detection methods; Earthquake detection; Earthquake events; Numerical results; Time-series data; Earthquakes},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Savelonas2020,
	author = {Savelonas, Michalis and Mantzekis, Dimitris and Labiris, Nikos and Tsakiri, Athanasia and Karkanis, Stavros and Spyrou, Evaggelos},
	title = {Hybrid Time-series Representation for the Classification of Driving Behaviour},
	year = {2020},
	journal = {SMAP 2020 - 15th International Workshop on Semantic and Social Media Adaptation and Personalization},
	doi = {10.1109/SMAP49528.2020.9248460},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097594216&doi=10.1109%2fSMAP49528.2020.9248460&partnerID=40&md5=053967737c7fbabcc68188cfde91017d},
	abstract = {The classification of driving behaviour is important for monitoring driving risk and fuel efficiency, as well as for providing a personalized view, or 'fingertip', of each driver, useful in driving assistance and car insurance industry. Intuitively, an aggressive driving style manifests itself in the long run, with distinct frequencies of occurrence for time-series patterns and critical events, such as accelerations, brakings and turnings. In this work, we consider a hybrid classification method, which employs both RNN-guided time-series encoding and rule-guided event detection. Histograms derived from the output of these two components are merged, normalized and used to train a standard perceptron to classify overall driving behavior as normal or aggressive. Experimental evaluation on a publicly available dataset of sensor measurements obtained for various drivers and routes, lead to the conclusion that both RNN-guided and rule-guided components contribute to the obtained classification accuracy.  © 2020 IEEE.},
	author_keywords = {driving behaviour; personalization; recurrent neural networks; time-series.},
	keywords = {Classification (of information); Semantics; Social networking (online); Time series; Aggressive driving; Classification accuracy; Driving assistance; Experimental evaluation; Hybrid classification; Personalized views; Sensor measurements; Time series patterns; Automobile drivers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Daems2021271,
	author = {Daems, P.-J. and Feremans, L. and Verstraeten, T. and Cule, B. and Goethals, B. and Helsen, J.},
	title = {Fleet-Oriented Pattern Mining Combined with Time Series Signature Extraction for Understanding of Wind Farm Response to Storm Conditions},
	year = {2021},
	journal = {Lecture Notes in Mechanical Engineering},
	pages = {271 – 283},
	doi = {10.1007/978-981-15-9199-0_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102630397&doi=10.1007%2f978-981-15-9199-0_25&partnerID=40&md5=256284c2fb57a88956e56b53ead2c25d},
	abstract = {Offshore wind turbine installations are rapidly spreading around Europe and all over the world. These turbines are typically installed in large wind farms combining turbines of the same type. Farm owners target maximal performance of the farm in general and particularly predictability of behaviour. The latter is getting increasingly important since offshore wind farms are being managed more and more as conventional power plants driven by the electricity market supply and demand considerations. The context of zero subsidy farms exposes farm operators to fluctuations in electricity market prices. As such, deep understanding of farm behaviour is essential to come up with a good strategy to deal with these fluctuations. This paper focusses on the automated extraction of farm-wide response to storm conditions. The input data for the analysis are status logs and SCADA 1-second data. The status logs record the important turbine controller events. Typically, they consist of a number, a time of occurrence, and a time of de-activation. The number is linked to a detailed description. The SCADA data consists of time series of the most important sensors in the turbine: power produced, RPM, wind speed,… The advantage of the 1-sec data over the traditional 10-minute averages is that the dynamic event content is much more preserved. Data of several offshore wind farms is used in the analysis to have a solid dataset. In total, 5 years of data of more than 50 turbines is used. We show a novel farm-wide pattern mining approach that extracts events occurring for multiple turbines in the same time period. This allows us to identify those events that are predominantly driven by global wind excitations (e.g., gusts) or grid events (e.g., low voltage ride through). From the extracted events, we lift out the storm conditions. For these conditions, a further investigation of the time series data is done. Using event detection algorithms, we extract the signatures of the stop events that each turbine is performing from the time series data. We show that the extreme change in wind speed and wind direction leads to an excessive misalignment of the turbines in the farm, followed by a stop of those turbines. The extracted patterns are compared to the time signatures to show their correlation and complementarity. As such, the typical turbine response to this event is identified. This can serve as input for identification of novel controller approaches by the farm owner and turbine manufacturer to deal with this problem. © 2021, Springer Nature Singapore Pte Ltd.},
	author_keywords = {Condition monitoring; Dynamic event; Fleet; Pattern mining; Wind farm; Wind turbine},
	keywords = {Condition monitoring; Data mining; Electric industry; Electric power system interconnection; Extraction; Offshore oil well production; Power markets; Storms; Time series; Condition; Dynamic events; Fleet; Pattern mining; Signature extraction; Time-series data; Times series; Turbine installation; Wind farm; Wind speed; Offshore wind farms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2020224,
	author = {Wang, Zhihong and Guo, Yi},
	title = {Rumor events detection enhanced by encoding sentimental information into time series division and word representations},
	year = {2020},
	journal = {Neurocomputing},
	volume = {397},
	pages = {224 – 243},
	doi = {10.1016/j.neucom.2020.01.095},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080054273&doi=10.1016%2fj.neucom.2020.01.095&partnerID=40&md5=08bc8e4ee2a64bf8703de2e54f72c146},
	abstract = {Online Social Networks (OSNs) is an ideal place for spreading rumor events as it is convenient in information production and dissemination. Automatically debunking these rumor events is important to pursue and restore the truth. However, it is a challenging task to employ traditional classification approaches for rumor events detection since they rely on hand-crafted features that require daunting manual efforts. Besides, we observe that the various posts of each rumor event will debate its realness over time. Different individuals also have different emotional reactions to events, which will affect others’ identification. Thus, this paper firstly employs an automatic construction method to develop a Sentiment Dictionary (SD) to capture the fine-grained human emotional reactions to different events. Secondly, a Two-steps Dynamic Time Series (TsDTS) algorithm, involving the sentimental information in the division process, is elaborated to retain the time-span distribution information of microblog events in a natural manner. At last, a novel two-layer Cascaded Gated Recurrent Unit (CGRU) model based on the SD and the TsDTS algorithm is proposed for rumor events detection, named as SD-TsDTS-CGRU. Experimental results on real datasets from OSNs demonstrate that our proposed SD-TsDTS-CGRU model outperforms the latest rumor events detection algorithms. © 2020},
	author_keywords = {Cascaded gated recurrent unit; Dynamic time series; Online social networks; Rumor events detection; Sentiment dictionary},
	keywords = {Signal encoding; Time series; Cascaded gated recurrent unit; Dynamic time; Events detection; On-line social networks; Sentiment dictionaries; adult; article; detection algorithm; female; gated recurrent unit network; human; human experiment; male; online social network; time series analysis; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29}
}

@ARTICLE{Memarzadeh2020,
	author = {Memarzadeh, Milad and Matthews, Bryan and Avrekh, Ilya},
	title = {Unsupervised anomaly detection in flight data using convolutional variational auto-encoder},
	year = {2020},
	journal = {Aerospace},
	volume = {7},
	number = {8},
	doi = {10.3390/AEROSPACE7080115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090092090&doi=10.3390%2fAEROSPACE7080115&partnerID=40&md5=9ddbf9d4fb2c388c4639d89100244b72},
	abstract = {The modern National Airspace System (NAS) is an extremely safe system and the aviation industry has experienced a steady decrease in fatalities over the years. This is in part due the airlines, manufacturers, FAA, and research institutions all continually working to improve the safety of the operations. However, the current approach for identifying vulnerabilities in NAS operations leverages domain expertise using knowledge about how the system should behave within the expected tolerances to known safety margins. This approach works well when the system has a well-defined operating condition. However, the operations in the NAS can be highly complex with various nuances that render it difficult to assess risk based on pre-defined safety vulnerabilities. Moreover, state-of-the-art machine learning models that are developed for event detection in aerospace data usually rely on supervised learning. However, in many real-world problems, such as flight safety, creating labels for the data requires specialized expertise that is time consuming and therefore largely impractical. To address this challenge, we develop a Convolutional Variational Auto-Encoder (CVAE), an unsupervised deep generative model for anomaly detection in high-dimensional time-series data. Validating on Yahoo's benchmark data as well as a case study of identifying anomalies in commercial flights' take-offs, we show that CVAE outperforms both classic and deep learning-based approaches in precision and recall of detecting anomalies. © 2020 by the authors.},
	author_keywords = {Anomaly detection; Flight safety; Time series; Variational autoencoder},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 53; All Open Access, Gold Open Access}
}

@CONFERENCE{Kalalas2020,
	author = {Kalalas, Charalampos and Alonso-Zarate, Jesus},
	title = {Sensor data reconstruction in industrial environments with cellular connectivity},
	year = {2020},
	journal = {IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC},
	volume = {2020-August},
	doi = {10.1109/PIMRC48278.2020.9217234},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094105409&doi=10.1109%2fPIMRC48278.2020.9217234&partnerID=40&md5=975f566654f4f0c07689db057b3d7158},
	abstract = {The reliable acquisition of monitoring information is critical for several industrial use cases relying on wireless sensor network deployments. However, missing sensor measurements are typical in industrial systems empowered by cellular connectivity due to the stochastic nature of the wireless channel. In this paper, we propose a sensor data reconstruction scheme that exploits the hidden data dynamics to accurately estimate the missing measurements. Based on an analytical framework for the network model and a closed-form expression for the outage probability, the impact on the reconstruction error performance is thoroughly explored. Considering a dataset with high spatiotemporal correlation in the sensor observations, our proposed scheme is shown to outperform two baseline data recovery methods in terms of reconstruction error for various network configurations. In addition, despite the presence of imperfect cellular connectivity, our proposed scheme exhibits high event-detection accuracy. © 2020 IEEE.},
	author_keywords = {Expectation maximization; Industrial IoT; Missing data; Parameter learning; Time series; Uplink communication},
	keywords = {Mobile radio systems; Radio communication; Stochastic systems; Cellular connectivity; Closed-form expression; Industrial environments; Monitoring information; Network configuration; Sensor data reconstruction; Spatiotemporal correlation; Wireless sensor network deployment; Wireless sensor networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@CONFERENCE{Provotar2019513,
	author = {Provotar, Oleksandr I. and Linder, Yaroslav M. and Veres, Maksym M.},
	title = {Unsupervised Anomaly Detection in Time Series Using LSTM-Based Autoencoders},
	year = {2019},
	journal = {2019 IEEE International Conference on Advanced Trends in Information Theory, ATIT 2019 - Proceedings},
	pages = {513 – 517},
	doi = {10.1109/ATIT49449.2019.9030505},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082717191&doi=10.1109%2fATIT49449.2019.9030505&partnerID=40&md5=6fae45c80f2818ff042ef65833662ac3},
	abstract = {Automatic anomaly detection in data mining has a wide range of applications such as fraud detection, system health monitoring, fault detection, event detection systems in sensor networks, and so on. The main challenge related to such problem is unknown nature of the anomaly. Therefore, it is impossible to use classical machine learning techniques to train the model, as we don't have labels of time series with anomaly. For periodic time series it is advisable to use STL decomposition of the signal. In such case anomaly detection task is reduced to residuals peak detection. If time series is not periodic (for example, forex price or sound) the only way is using machine learning methods. One of the best machine learning methods is autoencoder-based anomaly detection. An autoencoder is a type of artificial neural network used to learn efficient data encodings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal 'noise'. Unsupervised anomaly detection method based on autoencoders was tested on two types of data: various artificial signal datasets and detection of rare sound events dataset. (Abstract) © 2019 IEEE.},
	author_keywords = {Anomaly detection; Autoencoders (key words); Machine learning; Neural network},
	keywords = {Data mining; Dimensionality reduction; Encoding (symbols); Fault detection; Learning systems; Long short-term memory; Neural networks; Sensor networks; Signal processing; Time series; Artificial signals; Event detection; Fraud detection; Key words; Machine learning methods; Machine learning techniques; System health monitoring; Unsupervised anomaly detection; Anomaly detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 77}
}

@ARTICLE{Huchtkoetter202070,
	author = {Huchtkoetter, Jana and Reinhardt, Andreas and Hossain, Sakif},
	title = {ANNO: A Time Series Annotation Tool to Evaluate Event Detection Algorithms},
	year = {2020},
	journal = {Communications in Computer and Information Science},
	volume = {1199 CCIS},
	pages = {70 – 87},
	doi = {10.1007/978-3-030-45718-1_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085210852&doi=10.1007%2f978-3-030-45718-1_5&partnerID=40&md5=92cd596d4cb521d6cb892aa3edc9b9b6},
	abstract = {The research field of energy analytics is concerned with the collection and processing of data related to electrical power generation and consumption. Electricity consumption data can reveal information pertaining to the nature of underlying appliances, their mode of operation, and many other aspects. Sudden load changes, so-called events, constitute the principal source of information in such time series data, thus their reliable detection and interpretation is a prerequisite for accurate energy analytics. The development of event detection algorithms is, however, hampered due to the unavailability of comprehensive data sets that feature energy consumption time series with corresponding event annotations. We hence present ANNO, a tool to provide annotations to time series consumption data in a supervised fashion and use them for the development of energy analytics algorithms, in this work. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Load signature analysis; Supervised data set annotation},
	keywords = {Energy utilization; Signal detection; Time series; Annotation tool; Electrical power generation; Electricity-consumption; Event detection algorithm; Mode of operations; Reliable detection; Research fields; Time-series data; Data handling},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Lan2021,
	author = {Lan, Tu and Lin, You and Wang, Jianhui and Leao, Bruno and Fradkin, Dmitriy},
	title = {Unsupervised Power System Event Detection and Classification Using Unlabeled PMU Data},
	year = {2021},
	journal = {Proceedings of 2021 IEEE PES Innovative Smart Grid Technologies Europe: Smart Grids: Toward a Carbon-Free Future, ISGT Europe 2021},
	doi = {10.1109/ISGTEurope52324.2021.9639995},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123937179&doi=10.1109%2fISGTEurope52324.2021.9639995&partnerID=40&md5=35ebb294e8c2aa7ec1154a2b2ec43ce1},
	abstract = {This paper proposes a novel data-driven power system event detection and classification method based on 5 TB of actual PMU measurements collected from the US western interconnect. Firstly, a set of comprehensive power quality rules are proposed to pre-filter the raw data and extract the regions of interest (ROI). Six distinct event categories are defined, and corresponding patterns are chosen as references. Meanwhile, detailed characteristics of patterns are summarized to enhance our understanding of the actual events. Then, the time-independent feature vectors are generated by extracting the statistical, temporal, and spectral features from the raw time-series data. Furthermore, an ensemble model is proposed to cluster the events by combining multiple K-means clustering models using a voting strategy. Besides, both system-level and PMU-level clustering models are developed. The accuracy and robustness of the event detection method are further improved through interactive evaluation of the two-level clustering results. This paper summarizes the actual characteristics of each event category and provides a reliable basis for accurate label generation. The experiments demonstrate the effectiveness of the proposed event detection and classification method. © 2021 IEEE.},
	author_keywords = {event characteristics; event classification; event labeling; PMU; Power system event detection; time series clustering; unsupervised learning},
	keywords = {Classification (of information); Cluster analysis; Data mining; K-means clustering; Unsupervised learning; Detection methods; Event characteristic; Event labeling; Events classification; Events detection; Labelings; PMU; Power; Power system event detection; Time series clustering; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{2020,
	title = {24th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12084 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085752162&partnerID=40&md5=7b0dca78a23dacee9cfa20f756461312},
	abstract = {The proceedings contain 135 papers. The special focus in this conference is on Knowledge Discovery and Data Mining. The topics include: Fashion Recommendation with Multi-relational Representation Learning; modeling Users’ Multifaceted Interest Correlation for Social Recommendation; Modeling POI-Specific Spatial-Temporal Context for Point-of-Interest Recommendation; MsFcNET: Multi-scale Feature-Crossing Attention Network for Multi-field Sparse Data; balancing Between Accuracy and Fairness for Interactive Recommendation with Reinforcement Learning; joint Relational Dependency Learning for Sequential Recommendation; modelling Temporal Dynamics and Repeated Behaviors for Recommendation; HIN: Hierarchical Inference Network for Document-Level Relation Extraction; multi-Layer Cross Loss Model for Zero-Shot Human Activity Recognition; hierarchical Gradient Smoothing for Probability Estimation Trees; Optimized Transformer Models for FAQ Answering; off-Policy Recommendation System Without Exploration; online Algorithms for Multiclass Classification Using Partial Labels; what’s in a Gist? Towards an Unsupervised Gist Representation for Few-Shot Large Document Classification; SGCN: A Graph Sparsifier Based on Graph Convolutional Networks; fast Community Detection with Graph Sparsification; deep Multimodal Clustering with Cross Reconstruction; deep Multivariate Time Series Embedding Clustering via Attentive-Gated Autoencoder; spectral Clustering by Subspace Randomization and Graph Fusion for High-Dimensional Data; Decentralized and Adaptive K-Means Clustering for Non-IID Data Using HyperLogLog Counters; detecting Arbitrarily Oriented Subspace Clusters in Data Streams Using Hough Transform; strong Baselines for Author Name Disambiguation with and Without Neural Networks; GAMMA: A Graph and Multi-view Memory Attention Mechanism for Top-N Heterogeneous Recommendation; retrofitting Embeddings for Unsupervised User Identity Linkage; image Analysis Enhanced Event Detection from Geo-Tagged Tweet Streams; TemporalGAT: Attention-Based Dynamic Graph Representation Learning; attention-Based Graph Evolution; prototype Similarity Learning for Activity Recognition.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2021,
	title = {Proceedings of WILF 2021 - 13th International Workshop on Fuzzy Logic and Applications},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3074},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123281089&partnerID=40&md5=d77345cfb0fbc4d7917f4e4076c115fa},
	abstract = {The proceedings contain 27 papers. The topics discussed include: general admissibly ordered interval-valued overlap functions; reconstruction of lattice-valued functions by integral transforms; on fuzzy truth-values and quasi-standard completeness; fuzzy orthopartitions and their logical entropy; improving Michigan-style fuzzy-rule base classification generation using a Choquet-like copula-based aggregation function; Mamdani-Assilian rules: with or without continuity?; spatial weighted robust clustering of multivariate time series based on quantile dependence with an application to mobility during COVID-19 pandemic; anomaly detection based on interval-valued fuzzy sets: application to rare sound event detection; and using an adaptive neuro-fuzzy inference system for the classification of hypertension.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Aldabbas202139111,
	author = {Aldabbas, Ashraf and Gal, Zoltan and Ghori, Khawaja Moyeezullah and Imran, Muhammad and Shoaib, Muhammad},
	title = {Deep Learning-Based Approach for Detecting Trajectory Modifications of Cassini-Huygens Spacecraft},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {39111 – 39125},
	doi = {10.1109/ACCESS.2021.3064753},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102656412&doi=10.1109%2fACCESS.2021.3064753&partnerID=40&md5=d6aeb1b3cd4e8bcc7705f156ee0451a9},
	abstract = {There were necessary trajectory modifications of Cassini spacecraft during its last 14 years movement cycle of the interplanetary research project. In the scale 1.3 hour of signal propagation time and 1.4-billion-kilometer size of Earth-Cassini channel, complex event detection in the orbit modifications requires special investigation and analysis of the collected big data. The technologies for space exploration warrant a high standard of nuanced and detailed research. The Cassini mission has accumulated quite huge volumes of science records. This generated a curiosity derives mainly from a need to use machine learning to analyze deep space missions. For energy saving considerations, the communication between the Earth and Cassini was executed in non-periodic mode. This paper provides a sophisticated in-depth learning approach for detecting Cassini spacecraft trajectory modifications in post-processing mode. The proposed model utilizes the ability of Long Short Term Memory (LSTM) neural networks for drawing out useful data and learning the time series inner data pattern, along with the forcefulness of LSTM layers for distinguishing dependencies among the long-short term. Our research study exploited the statistical rates, Matthews correlation coefficient, and F1 score to evaluate our models. We carried out multiple tests and evaluated the provided approach against several advanced models. The preparatory analysis showed that exploiting the LSTM layer provides a notable boost in rising the detection process performance. The proposed model achieved a number of 232 trajectory modification detections with 99.98% accuracy among the last 13.35 years of the Cassini spacecraft life. © 2013 IEEE.},
	author_keywords = {big data; Cassini-Huygens interplanetary project; complex event; knowledge representation; neural network; pattern processing; sensory data},
	keywords = {Backpropagation; Data flow analysis; Energy conservation; Interplanetary spacecraft; Long short-term memory; Multilayer neural networks; Orbits; Cassini spacecraft; Complex event detection; Investigation and analysis; Learning approach; Learning-based approach; Signal propagation; Spacecraft trajectories; Trajectory modification; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Garcia2020,
	author = {Garcia, Diego and Puig, Vicenç and Quevedo, Joseba},
	title = {Prognosis of water quality sensors using advanced data analytics: Application to the barcelona drinking water network},
	year = {2020},
	journal = {Sensors (Switzerland)},
	volume = {20},
	number = {5},
	doi = {10.3390/s20051342},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081035889&doi=10.3390%2fs20051342&partnerID=40&md5=7cdee66fdcfd01df3e689300f864db04},
	abstract = {Water Utilities (WU) are responsible for supplying water for residential, commercial and industrial use guaranteeing the sanitary and quality standards established by different regulations. To assure the satisfaction of such standards a set of quality sensors that monitor continuously the Water Distribution System (WDS) are used. Unfortunately, those sensors require continuous maintenance in order to guarantee their right and reliable operation. In order to program the maintenance of those sensors taking into account the health state of the sensor, a prognosis system should be deployed. Moreover, before proceeding with the prognosis of the sensors, the data provided with those sensors should be validated using data from other sensors and models. This paper provides an advanced data analytics framework that will allow us to diagnose water quality sensor faults and to detect water quality events. Moreover, a data-driven prognosis module will be able to assess the sensitivity degradation of the chlorine sensors estimating the remaining useful life (RUL), taking into account uncertainty quantification, that allows us to program the maintenance actions based on the state of health of sensors instead on a regular basis. The fault and event detection module is based on a methodology that combines time and spatial models obtained from historical data that are integrated with a discrete-event system and are able to distinguish between a quality event or a sensor fault. The prognosis module analyses the quality sensor time series forecasting the degradation and therefore providing a predictive maintenance plan avoiding unsafe situations in the WDS. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Sensor prognosis; Water distribution network; Water quality monitoring},
	keywords = {Drinking Water; Environmental Monitoring; Water Quality; Advanced Analytics; Data Analytics; Discrete event simulation; Fault detection; Potable water; Predictive maintenance; Time series analysis; Uncertainty analysis; Water quality; drinking water; Continuous maintenance; Drinking water networks; Remaining useful lives; Time series forecasting; Uncertainty quantifications; Water distribution networks; Water quality monitoring; Water quality sensors; environmental monitoring; procedures; water quality; Water distribution systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Arnold202131,
	author = {Arnold, M. and Hoyer, M. and Keller, S.},
	title = {CONVOLUTIONAL NEURAL NETWORKS for DETECTING BRIDGE CROSSING EVENTS with GROUND-BASED INTERFEROMETRIC RADAR DATA},
	year = {2021},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	volume = {5},
	number = {1},
	pages = {31 – 38},
	doi = {10.5194/isprs-annals-V-1-2021-31-2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119671333&doi=10.5194%2fisprs-annals-V-1-2021-31-2021&partnerID=40&md5=36b2eab3379271afc2607405dbecca87},
	abstract = {This study focuses on detecting vehicle crossings (events) with ground-based interferometric radar (GBR) time series data recorded at bridges in the course of critical infrastructure monitoring. To address the challenging event detection and time series classification task, we rely on a deep learning (DL) architecture. The GBR-displacement data originates from real-world measurements at two German bridges under normal traffic conditions. As preprocessing, we only apply a low-pass filter. We develop and evaluate a one-dimensional convolutional neural network (CNN) to achieve a solely data-driven event detection. As a baseline machine learning approach, we use a Random Forest (RF) with a selected feature-based input. Both models' performance is evaluated on two datasets by focusing on identifying events and pure bridge oscillations. Generally, the event classification results are promising, and the CNN outperforms the RF with an overall accuracy of 94.7% on the test subset. By relying on an entirely unknown second dataset, we focus on the models' performances regarding the distinction between events and decays. On this dataset, the CNN meets this challenge successfully, while the feature-based RF classifies the majority of non-event decays as events. To sum up, the presented results reveal the potential of a data-driven DL approach concerning the detection of bridge crossing events in GBR-based displacement time series data. Based on such an event detection, a prospective assessment of bridge conditions seems feasible as an extension to previous structural health monitoring approaches. © Author(s) 2021.},
	author_keywords = {CNN; Event Detection; Field Campaign; Ground-based Interferometric Radar; Infrastructure Monitoring; Machine Learning; Time series classification; UAV},
	keywords = {Aircraft detection; Convolutional neural networks; Decision trees; Deep learning; Interferometry; Low pass filters; Structural health monitoring; Time series; Unmanned aerial vehicles (UAV); Bridge crossing; Convolutional neural network; Events detection; Field campaign; Ground-based interferometric radars; Infrastructure monitoring; Machine-learning; Random forests; Time series classifications; Time-series data; Convolution},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Bhattacharjee2021,
	author = {Bhattacharjee, Shameek and Madhavarapu, Venkata Praveen Kumar and Silvestri, Simone and Das, Sajal K.},
	title = {Attack Context Embedded Data Driven Trust Diagnostics in Smart Metering Infrastructure},
	year = {2021},
	journal = {ACM Transactions on Privacy and Security},
	volume = {24},
	number = {2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100828103&partnerID=40&md5=ed19e44841949f0592d25d00f4507630},
	abstract = {Spurious power consumption data reported from compromised meters controlled by organized adversaries in the Advanced Metering Infrastructure (AMI) may have drastic consequences on a smart grid's operations. While existing research on data falsification in smart grids mostly defends against isolated electricity theft, we introduce a taxonomy of various data falsification attack types, when smart meters are compromised by organized or strategic rivals. To counter these attacks, we first propose a coarse-grained and a fine-grained anomaly-based security event detection technique that uses indicators such as deviation and directional change in the time series of the proposed anomaly detection metrics to indicate: (i) occurrence, (ii) type of attack, and (iii) attack strategy used, collectively known asattack context. Leveraging the attack context information, we propose three attack response metrics to the inferred attack context: (a) an unbiased mean indicating a robust location parameter; (b) a median absolute deviation indicating a robust scale parameter; and (c) an attack probability time ratio metric indicating the active time horizon of attacks. Subsequently, we propose a trust scoring model based on Kullback-Leibler (KL) divergence, that embeds the appropriate unbiased mean, the median absolute deviation, and the attack probability ratio metric at runtime to produce trust scores for each smart meter. These trust scores help classify compromised smart meters from the non-compromised ones. The embedding of the attack context, into the trust scoring model, facilitates accurate and rapid classification of compromised meters, even under large fractions of compromised meters, generalize across various attack strategies and margins of false data. Using real datasets collected from two different AMIs, experimental results show that our proposed framework has a high true positive detection rate, while the average false alarm and missed detection rates are much lesser than 10% for most attack combinations for two different real AMI micro-grid datasets. Finally, we also establish fundamental theoretical limits of the proposed method, which will help assess the applicability of our method to other domains.  © 2021 ACM.},
	author_keywords = {Advanced metering infrastructure; anomaly detection; artificial-intelligence-based security; data falsification attacks; data integrity; smart metering; smart-grid security; trust},
	keywords = {Advanced metering infrastructures; Anomaly detection; Crime; Electric power measurement; Electric power system control; Electric power transmission networks; Microgrids; Smart meters; Attack strategies; Context information; Directional changes; Electricity theft; Kullback-Leibler divergence; Location parameters; Median absolute deviation; Theoretical limits; Smart power grids},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Fu2020195,
	author = {Fu, Xiaoyi and Jiang, Xu and Qi, Yunfei and Xu, Meng and Song, Yuhang and Zhang, Jie and Wu, Xindong},
	title = {An event-centric prediction system for COVID-19},
	year = {2020},
	journal = {Proceedings - 11th IEEE International Conference on Knowledge Graph, ICKG 2020},
	pages = {195 – 202},
	doi = {10.1109/ICBK50248.2020.00037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092462108&doi=10.1109%2fICBK50248.2020.00037&partnerID=40&md5=604cd738db798464044cdc8f226ed17f},
	abstract = {As COVID-19 evolved into a pandemic, a lot of effort has been made by scientific community to intervene in its spread. One of them was to predict the trend of the epidemic to provide a basis for the decision making of both the public and private sectors. In this paper, a system for predicting the spread of COVID-19 based on detecting and tracking events evolution in social media is proposed. The system includes a pipeline for building Event-Centric Knowledge Graphs from Twitter data streams about COVID-19, and uses the graph statistics to obtain a more accurate prediction based on the simulation of epidemic dynamic models. Experiments of 128 countries or regions conducted on the data set released by Johns Hopkins University on COVID-19 confirmed the effectiveness of the system. At the same time, the guidance our system provided to the plan of return-to-work for an enterprise has attracted the attention of and reported by top influential media. © 2020 IEEE.},
	author_keywords = {COVID-19; Epidemic Model; Event Detection; Event-Centric Knowledge Graphs; Time-Series Prediction},
	keywords = {Data streams; Decision making; Knowledge representation; Social networking (online); Accurate prediction; Epidemic dynamics; Graph statistics; Johns hopkins universities; Knowledge graphs; Prediction systems; Public and private sector; Scientific community; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@BOOK{Abid202133,
	author = {Abid, M. and Ouakrim, Y. and Mitiche, A. and Vendittoli, P.A. and Hagemeister, N. and Mezghani, N.},
	title = {A comparative study of end-to-end discriminative deep learning models for knee joint kinematic time series classification},
	year = {2021},
	journal = {Biomedical Signal Processing: Innovation and Applications},
	pages = {33 – 61},
	doi = {10.1007/978-3-030-67494-6_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150399757&doi=10.1007%2f978-3-030-67494-6_2&partnerID=40&md5=ca9dd3c1ee71b2d734496b584b203f3c},
	abstract = {One of the main motivations for classifying knee kinematic signals, which measure flexion/extension, abduction/adduction, and internal/external rotation angle variations during locomotion, is to assist diagnosis of knee joint pathologies. These signals are informative but of high dimensionality and high within-subject variability, serious difficulties which are often referred to as the curse of dimensionality. In general, current machine learning studies of knee pathology classification include feature extraction as an essential component, where feature design is time-consuming and generally not applicable to newly acquired data. To overcome such problems, the purpose of this study is to investigate classification of knee kinematic signals through the entire gait using deep neural networks. The signals are first pre-processed to identify representative patterns of a given subject using the within-subject variability evaluation for outliers' removal and reliable curves' selection. The patterns are then used for deep learning of discriminative classifiers. The proposed pre-processing method encompasses steps of gait events detection, normalization, outlier detection, and cycles' selection. In order to measure the reliability of the subjects' curves before and after pre-processing, we computed the intraclass correlation (ICC) estimates and their 95% confidence intervals for knee kinematics of a multicentric dataset of 239 subjects: 49 asymptomatic (AS) subjects and 190 knee osteoarthrosis (OA) patients. Then, we describe experiments which support the comparison of five deep neural networks, that have been performed on similar data, to distinguish between asymptomatic (AS) subjects and knee osteoarthrosis (OA) patients and justify further investigation in similar applications. © The Author(s), 2021. All rights reserved.},
	author_keywords = {Deep learning; Knee kinematic data; Knee pathology diagnosis; Pattern classification},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Maître2020,
	author = {Maître, Elliot and Dousset, Bernard and Chemli, Zakaria and Gitto, Jean-Philippe and Chevalier, Max and Teste, Olivier},
	title = {Event detection and time series alignment to improve stock market forecasting},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2621},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090509971&partnerID=40&md5=599cc68cc53c6d537ceede0c2d1f989a},
	abstract = {Buying commodities is a critical issue for multiple industries because the variations of stock prices are induced not only by multiple economic parameters but also by external events. Raw material buyers must keep track of information in numerous fields, which constitutes a major challenge considering the exponential growth of online data. To tackle this issue, we propose an event detection approach in order to assist them in their anticipation process. Indeed, a lot of contextual information is contained in text and exploiting it can allow one to improve its anticipation ability. Thus, we develop a framework of event detection and qualification, then we quantify the impact of these events on stock market to help buyers in their anticipation process. In this paper, we will first introduce our context, then explain the scope of our work and our goals. After detailing the related work, we will present our proposition, conclude and propose some future work possibilities. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Commodities; Event detection; Neural networks; Nlp; Text analysis; Time series},
	keywords = {Commerce; Information retrieval; Contextual information; Critical issues; Economic parameters; Event detection; Exponential growth; Keep track of; Related works; Stock market forecasting; Financial markets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zerouali2021,
	author = {Zerouali, Bilel and Al-Ansari, Nadhir and Chettih, Mohamed and Mohamed, Mesbah and Abda, Zaki and Santos, Celso Augusto Guimarães and Zerouali, Bilal and Elbeltagi, Ahmed},
	title = {An enhanced innovative triangular trend analysis of rainfall based on a spectral approach},
	year = {2021},
	journal = {Water (Switzerland)},
	volume = {13},
	number = {5},
	doi = {10.3390/w13050727},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102727153&doi=10.3390%2fw13050727&partnerID=40&md5=6df01937ab4ee9436834596114d2f3ec},
	abstract = {The world is currently witnessing high rainfall variability at the spatiotemporal level. In this paper, data from three representative rain gauges in northern Algeria, from 1920 to 2011, at an annual scale, were used to assess a relatively new hybrid method, which combines the innovative triangular trend analysis (ITTA) with the orthogonal discrete wavelet transform (DWT) for partial trend identification. The analysis revealed that the period from 1950 to 1975 transported the wettest periods, followed by a long-term dry period beginning in 1973. The analysis also revealed a rainfall increase during the latter decade. The combined method (ITTA–DWT) showed a good efficiency for extreme rainfall event detection. In addition, the analysis indicated the inter- to multiannual phenomena that explained the short to medium processes that dominated the high rainfall variability, masking the partial trend components existing in the rainfall time series and making the identification of such trends a challenging task. The results indicate that the approaches—combining ITTA and selected input combination models resulting from the DWT—are auspicious compared to those found using the original rainfall observations. This analysis revealed that the ITTA–DWT method outperformed the ITTA method for partial trend identification, which proved DWT’s efficiency as a coupling method. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Algeria; Discrete wavelet transform; Hybrid method; Innovative triangular trend analysis; Rainfall},
	keywords = {Algeria; Discrete wavelet transforms; Efficiency; Rain gages; Signal reconstruction; Time series analysis; Combination models; Combined method; Coupling methods; Extreme rainfall; Hybrid method; Orthogonal discrete wavelet transform; Rainfall variability; Trend analysis; detection method; rainfall; spatiotemporal analysis; spectral analysis; trend analysis; Rain},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhou2021,
	author = {Zhou, Fan and Li, Liang and Zhang, Kunpeng and Trajcevski, Goce},
	title = {Urban flow prediction with spatial–temporal neural ODEs},
	year = {2021},
	journal = {Transportation Research Part C: Emerging Technologies},
	volume = {124},
	doi = {10.1016/j.trc.2020.102912},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097721555&doi=10.1016%2fj.trc.2020.102912&partnerID=40&md5=dc22292ffe25aa56e87865f04ca013d3},
	abstract = {With the recent advances in deep learning, data-driven methods have shown compelling performance in various application domains enabling the Smart Cities paradigm. Leveraging spatial–temporal data from multiple sources for (citywide) traffic forecasting is a key to strengthen the smart city management in areas such as urban traffic control, abnormal event detection, etc. Existing approaches of traffic flow prediction mainly rely on the development of various deep neural networks –e.g., Convolutional Neural Networks such as ResNet are used for modeling spatial dependencies among different regions, whereas recurrent neural networks are increasingly implemented for temporal dynamics modeling. Despite their advantages, the existing approaches suffer from limitations of intensive computations, lack of capabilities to properly deal with missing values, and simplistic integration of heterogeneous data. In this paper, we propose a novel urban flow prediction framework by generalizing the hidden states of the model with continuous-time dynamics of the latent states using neural ordinary differential equations (ODE). Specifically, we introduce a discretize-then-optimize approach to improve and balance the prediction accuracy and computational efficiency. It not only guarantees the prediction error but also provides high flexibility for decision-makers. Furthermore, we investigate the factors, both intrinsic and extrinsic, that affect the city traffic volume and use separate neural networks to extract and disentangle the influencing factors, which avoids the brute-force data fusion in previous works. Extensive experiments conducted on the real-world large-scale datasets demonstrate that our method outperforms the state-of-the-art baselines, while requiring significantly less memory cost and fewer model parameters. © 2020 Elsevier Ltd},
	author_keywords = {Intelligent transportation system; Ordinary differential equations; Spatial–temporal learning; Time series prediction; Urban flow},
	keywords = {Computational efficiency; Continuous time systems; Convolutional neural networks; Data fusion; Decision making; Deep neural networks; Forecasting; Large dataset; Ordinary differential equations; Smart city; Street traffic control; Abnormal event detections; Continuous-time dynamics; Large-scale datasets; Ordinary differential equation (ODE); Prediction accuracy; Spatial dependencies; Traffic flow prediction; Urban traffic control; artificial neural network; decision making; intelligent transportation system; prediction; spatiotemporal analysis; time series analysis; traffic management; urban transport; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Bronze Open Access}
}

@ARTICLE{Zhang202143,
	author = {Zhang, Yihong and Shirakawa, Masumi and Hara, Takahiro},
	title = {A General Method for Event Detection on Social Media},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12843 LNCS},
	pages = {43 – 56},
	doi = {10.1007/978-3-030-82472-3_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115175408&doi=10.1007%2f978-3-030-82472-3_5&partnerID=40&md5=54e734e06421eb50ac3fc02382f504f2},
	abstract = {Event detection on social media has attracted a number of researches, given the recent availability of large volumes of social media discussions. Previous works on social media event detection either assume a specific type of event, or assume certain behavior of observed variables. In this paper, we propose a general method for event detection on social media that makes few assumptions. The main assumption we make is that when an event occurs, affected semantic aspects will behave differently from its usual behavior. We generalize the representation of time units based on word embeddings of social media text, and propose an algorithm to detect events in time series in a general sense. In the experimental evaluation, we use a novel setting to test if our method and baseline methods can exhaustively catch all real-world news in the test period. The evaluation results show that when the event is quite unusual with regard to the base social media discussion, it can be captured more effectively with our method. Our method can be easily implemented and can be treated as a starting point for more specific applications. © 2021, Springer Nature Switzerland AG.},
	keywords = {Information systems; Information use; Semantics; Baseline methods; Evaluation results; Event detection; Experimental evaluation; General method; Large volumes; Social media; Time units; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@CONFERENCE{ALDabbas202119,
	author = {ALDabbas, Ashraf and Gál, Zoltán},
	title = {Deep learning-based method for detecting cassini-huygens spacecraft trajectory modifications},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2874},
	pages = {19 – 31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107901573&partnerID=40&md5=1b5888a7348309d5c82333637b041386},
	abstract = {During the last 13.5 year motion cycle of the interplanetary research project, there were necessary flight path modifications of the Cassini spacecraft. In the order of signal travel time (approximatively 80 minutes) on the Earth-Cassini long sized channel, complex event detection of orbital modifications requires special investigation and analysis of the collected large trajectory dataset. This paper presents a sophisticated, in-depth learning approach for detecting Cassini spacecraft’s trajectory modifications in post-processing mode. The model uses neural networks with Long Short-Term Memory (LSTM) to extract useful data and learn the time series’ inner data pattern, together with the penetrability of the LSTM layers distinguish dependencies between the long- and short-term phases. Copyright © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Artificial intelligence; Big data; Cassini-Huygens interplanetary project; Complex event; Knowledge representation; Pattern processing; Sensory data},
	keywords = {Data Science; Interplanetary flight; Interplanetary spacecraft; Large dataset; Long short-term memory; Multilayer neural networks; Orbits; Travel time; Cassini spacecraft; Complex event detection; Flight path modification; Investigation and analysis; Learning approach; Learning-based methods; Spacecraft trajectories; Trajectory modification; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kapp2020,
	author = {Kapp, Vadim and May, Marvin Carl and Lanza, Gisela and Wuest, Thorsten},
	title = {Pattern recognition in multivariate time series: Towards an automated event detection method for smart manufacturing systems},
	year = {2020},
	journal = {Journal of Manufacturing and Materials Processing},
	volume = {4},
	number = {3},
	doi = {10.3390/JMMP4030088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091945725&doi=10.3390%2fJMMP4030088&partnerID=40&md5=13d180ce02b9ef1d7cb0b495bd90313f},
	abstract = {This paper presents a framework to utilize multivariate time series data to automatically identify reoccurring events, e.g., resembling failure patterns in real-world manufacturing data by combining selected data mining techniques. The use case revolves around the auxiliary polymer manufacturing process of drying and feeding plastic granulate to extrusion or injection molding machines. The overall framework presented in this paper includes a comparison of two different approaches towards the identification of unique patterns in the real-world industrial data set. The first approach uses a subsequent heuristic segmentation and clustering approach, the second branch features a collaborative method with a built-in time dependency structure at its core (TICC). Both alternatives have been facilitated by a standard principle component analysis PCA (feature fusion) and a hyperparameter optimization (TPE) approach. The performance of the corresponding approaches was evaluated through established and commonly accepted metrics in the field of (unsupervised) machine learning. The results suggest the existence of several common failure sources (patterns) for the machine. Insights such as these automatically detected events can be harnessed to develop an advanced monitoring method to predict upcoming failures, ultimately reducing unplanned machine downtime in the future. © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).},
	author_keywords = {Clustering; Industry 4.0; Polymer manufacturing; Polymer processing; Segmentation; Smart maintenance; Smart manufacturing; Time series analysis; Unsupervised learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Nalepa2021,
	author = {Nalepa, Jakub and Myller, Michal and Andrzejewski, Jacek and Benecki, Pawel and Piechaczek, Szymon and Kostrzewa, Daniel},
	title = {Evaluating anomaly detection in satellite telemetry data},
	year = {2021},
	journal = {Proceedings of the International Astronautical Congress, IAC},
	volume = {B6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127750631&partnerID=40&md5=ff9d592721e2970271a92840d7d01f84},
	abstract = {Detecting anomalies in telemetry data captured on-board a spacecraft is critical to ensure its safe operation. Although there exist various techniques for automatically detecting point, contextual, and collective anomalies from time-series data, quantifying their performance remains under-researched. In this paper, we present our approach for the task of anomalous event detection that is built upon a two-stage technique, in which the telemetry signal is predicted using a long short-term memory network based on the historical data, and then the prediction is compared with the actual (captured) data. If the difference between those two is sufficiently large, we can infer that an anomalous event has happened. To thoroughly evaluate the capabilities of such detection techniques, we discuss a set of commonly used metrics, and present their shortcomings, especially related to their inability of capturing the temporal aspects of detectors. Finally, we discuss the Antelope Toolbox – our software tool that allows us to simulate nominal telemetry data of given characteristics, and to perform the quantitative and qualitative analysis of anomaly detection techniques over simulated events. Copyright ©2021 by the International Astronautical Federation (IAF). All rights reserved.},
	author_keywords = {anomaly detection; deep learning; evaluation; LSTM; quantitative and qualitative analysis; recurrent neural network},
	keywords = {Long short-term memory; Telemetering equipment; Anomalous events; Anomaly detection; Deep learning; Detecting point; Evaluation; LSTM; Quantitative and qualitative analysis; Safe operation; Satellite telemetry data; Telemetry data; Anomaly detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bouaouni2021158456,
	author = {Bouaouni, Mohamed Yacine and Yahia, Rayane Ait Ali and Boubezoul, Abderrahmane},
	title = {Driving-Pattern Identification and Event Detection Based on an Unsupervised Learning Framework: Case of a Motorcycle-Riding Simulator},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {158456 – 158469},
	doi = {10.1109/ACCESS.2021.3130400},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120071785&doi=10.1109%2fACCESS.2021.3130400&partnerID=40&md5=4d7dd7a9dddac1eba04c84f0442f0cd0},
	abstract = {Analysis of human driving behavior aims to inspect drivers' behavior in the real-world and in a virtual environment. The study of driving behaviors can be conducted in naturalistic situations or controlled experiments. Analyzing driving behaviors based on the data collected in naturalistic driving experiments or controlled experiments in the real-world or in a virtual environment is beneficial to fill in many of the knowledge gaps about driving behaviors and risk factors. The amount of data collected during complex experiments with many laps and many drivers tested under different experimental conditions and with different instructions can be huge. Analyzing such data can thus be considered challenging and time-consuming if done manually because it requires calling on experts in traffic psychology to inspect and understand various specific situations at a macroscopic scale involving different riders and at a microscopic scale for a particular rider on a specific lap. Also, it can be challenging in an unsupervised context to detect and match the same patterns in different laps to study similar patterns and spot important and risky events. This paper proposes a multi-step framework for analyzing driving behavior on both the macroscopic and microscopic scales. The core step of this framework is based on unsupervised machine learning algorithms applied to driving-pattern identification and the detection of critical driving events using anomaly-detection algorithms. The detected events are interpreted and described by computing their feature importance using graphs centrality measures. This provides new insight into driving behavior by identifying the motives behind the driver's actions. The present experimental study, based on a dataset collected from the Honda Riding Trainer (HRT) simulator was conducted in the context of the European project SimuSafe and demonstrates the effectiveness of the proposed methodology. These results argue in favor of the development of such methodologies in driving-behavior studies. © 2013 IEEE.},
	author_keywords = {Anomaly detection; Driving-pattern identification; Motorcycle simulator; Time series analysis; Time series segmentation; Unsupervised learning},
	keywords = {Accidents; Anomaly detection; Automobile simulators; Behavioral research; Feature extraction; Learning algorithms; Motorcycles; Time series analysis; Unsupervised learning; Anomaly detection; Driving behaviour; Driving pattern; Driving-pattern identification; Features extraction; Motorcycle simulator; Pattern identification; Real-world; Time-series analysis; Time-series segmentation; Virtual reality},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Wang20203585,
	author = {Wang, Zhihong and Guo, Yi},
	title = {Empower rumor events detection from Chinese microblogs with multi-type individual information},
	year = {2020},
	journal = {Knowledge and Information Systems},
	volume = {62},
	number = {9},
	pages = {3585 – 3614},
	doi = {10.1007/s10115-020-01463-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083728043&doi=10.1007%2fs10115-020-01463-2&partnerID=40&md5=1f75598ba4553036138c69917248bc4e},
	abstract = {Online social media has become an ideal place in spreading rumor events with its convenience in communication and information dissemination, which raises the difficulty in debunking rumor events automatically. To deal with such a challenge, traditional classification approaches relying on manually labeled features have to face a daunting number of human efforts. With the consideration of the realness of a rumor event, it will be verified and authenticated with multi-type individual information, especially with individuals’ emotional expressions to events and their own credibility. This paper presents a novel two-layer GRU model for rumor events detection based on multi-type individual information (MII) and a dynamic time-series (DTS) algorithm, named as MII–DTS-GRU. Specifically, MII refers to adopt the sentiment dictionary to identify fine-grained human emotional expressions to events and fuse with the individual credibility. Besides, the DTS algorithm retains the time distribution of social events. Experimental results on Sina Weibo datasets show that our model achieves a high accuracy of 96.3% and demonstrate that our proposed MII–DTS-GRU model outperforms the state-of-the-art models on rumor events detection. © 2020, Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Chinese microblogs; Dynamic time series; GRU; Individual information; Rumor events detection; Sentiment dictionary},
	keywords = {Information dissemination; Classification approach; Emotional expressions; Events detection; High-accuracy; Online social medias; Sentiment dictionaries; State of the art; Time distribution; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Hai2021127420,
	author = {Hai, Ameen Abdel and Dokic, Tatjana and Pavlovski, Martin and Mohamed, Taif and Saranovic, Daniel and Alqudah, Mohammad and Kezunovic, Mladen and Obradovic, Zoran},
	title = {Transfer Learning for Event Detection from PMU Measurements with Scarce Labels},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {127420 – 127432},
	doi = {10.1109/ACCESS.2021.3111727},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114720821&doi=10.1109%2fACCESS.2021.3111727&partnerID=40&md5=e0be6181c5a87e1e449dc422105263d1},
	abstract = {Event detection in electrical grids is a challenging problem for machine learning methods due to spatiotemporally nonstationary systems and the inability to automate event labeling in high-volume data such as PMU measurements. As a result, the existing historical event logs created manually do not correlate well with the corresponding PMU measurements due to scarce and temporally imprecise labels. Trying to overcome this problem by extending event logs to a complete set of labeled events is very costly and often infeasible. We focused on utilizing a transfer learning model to reduce the need for additional data labeling by leveraging some labeled data instances available from a small number of well-defined event detection task. To demonstrate the feasibility, we tested our approach on a large dataset collected by 38 PMUs from the Western Interconnection of the U.S.A. over two years. The model evaluation performed based on varying percentages of labeled source data corresponding to \sim 20 -700 characteristic events on different sizes of time windows ranging from 2-seconds to 1-minute demonstrates that the developed method can significantly improve automated event detection based on PMU measurements when extensive labeling is costly or impossible to obtain. When compared to the state-of-the-art machine learning algorithms (unsupervised, semi-supervised, and supervised), the results show that the transfer learning method has significantly better performances when detecting events by learning from as low as 20 representative labeled data instances.  © 2013 IEEE.},
	author_keywords = {Big data applications; event detection; machine learning; phasor measurement units; power system faults; signal sampling; smart grids; time series analysis},
	keywords = {Labeled data; Large dataset; Learning systems; Semi-supervised learning; Transfer learning; Electrical grids; Machine learning methods; Model evaluation; Nonstationary systems; PMU measurements; State of the art; Transfer learning methods; Western interconnections; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access}
}

@ARTICLE{Wu20212407,
	author = {Wu, Jingyi and Shang, Lin and Gao, Xiaoying},
	title = {Sentiment Time Series Calibration for Event Detection},
	year = {2021},
	journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
	volume = {29},
	pages = {2407 – 2420},
	doi = {10.1109/TASLP.2021.3096653},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110876529&doi=10.1109%2fTASLP.2021.3096653&partnerID=40&md5=2790dee6d8dd3825d858691d1f37d69d},
	abstract = {Event detection based on sentiment time series, which describe the trend of users' emotions or attitudes towards specific topics over time, has been widely applied in the analysis of social network or text mining. Most of the contributions directly generate time series sequences by classifiers. However, due to the missing corpus labels or the limited performance of the classifier, such generated sentiment time series may not correspond to the actual values, especially when the sentiment value changes drastically, called extreme value. We propose a new method to calibrate sentiment times series for event detection based on evaluation on a sampling dataset. Theoretical analysis of the calibration method is explicated, and it is proved that the sampling error of the performance indicators can be limited to a minimal range for extreme values, thus sentiment value error can be reduced. Experiments on simulated datasets and real-world datasets illustrate the effectiveness and robustness of our method. © 2014 IEEE.},
	author_keywords = {event detection; proportion estimation; Sentiment analysis},
	keywords = {Calibration; Text mining; Time series; Calibration method; Event detection; Extreme value; Performance indicators; Real-world datasets; Sampling errors; Simulated datasets; Times series; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Maisonnave2020,
	author = {Maisonnave, Mariano and Delbianco, Fernando and Tohmé, Fernando and Maguitman, Ana G. and Milios, Evangelos E.},
	title = {Assessing Causality Structures learned from Digital Text Media},
	year = {2020},
	journal = {Proceedings of the ACM Symposium on Document Engineering, DocEng 2020},
	doi = {10.1145/3395027.3419594},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093106735&doi=10.1145%2f3395027.3419594&partnerID=40&md5=73f77cfebbba1971672d4cf21b275f4a},
	abstract = {In this paper we describe a framework to uncover potential causal relations between event mentions from streaming text of news media. This framework relies on a dataset of manually labeled events to train a recurrent neural network for event detection. It then creates a time series of event clusters, where clusters are based on BERT contextual word embedding representations of the identified events. Using these time series dataset, we assess four methods based on Granger causality for inferring causal relations. Granger causality is a statistical concept of causality that is based on forecasting. It states that a cause occurs before the effect, and the cause produces unique changes in the effect, so past values of the cause help predict future values of the effect. The four analyzed methods are the pairwise Granger test, VAR(1), BigVar and SiMoNe. The framework is applied to the New York Times dataset, which covers news for a period of 246 months. This preliminary analysis delivers important insights into the nature of each method, identifies differences and commonalities, and points out some of their strengths and weaknesses.  © 2020 ACM.},
	author_keywords = {Event Detection; Granger Causality; Time Series},
	keywords = {Media streaming; Statistical tests; Time series; Causal relations; Contextual words; Event detection; Granger Causality; New york time; Preliminary analysis; Statistical concepts; Streaming texts; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Piao2020178,
	author = {Piao, Bingxu and Wu, Xu and Wu, Jingchen and Xie, Xiaqing},
	title = {Real-time event detection and tracking in microblog via text chain and sentiment time series},
	year = {2020},
	journal = {Proceedings - 2020 IEEE 5th International Conference on Data Science in Cyberspace, DSC 2020},
	pages = {178 – 185},
	doi = {10.1109/DSC50466.2020.00034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092073227&doi=10.1109%2fDSC50466.2020.00034&partnerID=40&md5=ae75115b25a6046dceb5e098b76e473d},
	abstract = {Microblog becomes one of the most popular media for sharing first-hand information. As more close to real event, detecting and tracking event in microblogs is a research hotspot. To alleviate feature sparsity problem, traditional event detection and tracking methods exploit comments, replies, and reposts to enrich the information of posts. However, ignoring text relationship only leads to more irrelevant information. Aiming at this issue, a novel real-time event detection and tracking method for microblog stream is proposed. For each microblog from the real-time stream, similarity against historical event set is first evaluated. Then, known event microblogs are partitioned by the proposed method sentiment time series, clustered based on word relation graph, and compare with the previous graph to track burst keywords. Meanwhile, text chain is introduced to detect events for unknown event microblogs. Text chain is a unique relationship of microblogs, in which comments, replies, and reposts are used to form a word relation graph of the corresponding post. Posts and attached graphs are clustered to detect new events. Experiments are performed on real-time microblog datasets to evaluate the effectiveness of methods. Results show that the proposed method gains better F-measure than similar methods.  © 2020 IEEE.},
	author_keywords = {Event detection and tracking; Real-time data; Sentiment time series; Text Chain},
	keywords = {Computers; Data Science; Event detection and tracking; F measure; Hot spot; Micro-blog; Microblogs; Real time; Real-time streams; Sparsity problems; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tito2021185,
	author = {Tito, Shafiqur Rahman and Ur Rehman, Attique and Kim, Youngyoon and Nieuwoudt, Pieter and Aslam, Saad and Soltic, Snjezana and Lie, Tek Tjing and Pandey, Neel and Ahmed, M Daud},
	title = {Image Segmentation-based Event Detection for Non-Intrusive Load Monitoring using Gramian Angular Summation Field},
	year = {2021},
	journal = {IEACon 2021 - 2021 IEEE Industrial Electronics and Applications Conference},
	pages = {185 – 190},
	doi = {10.1109/IEACon51066.2021.9654789},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124566980&doi=10.1109%2fIEACon51066.2021.9654789&partnerID=40&md5=8c69a299f93c2b3a44bfece39d20724f},
	abstract = {A Non-intrusive Load Monitoring approach extracts the operation time of individual appliances from an aggregated load measured at a single entry-point using their energy consumption characteristics. Event detection represents an important step for load segregation where energy state change on aggregated load and duration are obtained. This paper proposes two event detection algorithms using image segmentation based on two diverse methodologies namely, k-means clustering and thresholding technique. The proposed algorithms are applied to an image generated by encoded Gramian Angular Summation Field of time series data. The method is simple to implement and efficient in computation. The proposed approach is tested and validated using real-world load measurements: Almanac of Minutely Power dataset, and for said purposes, comprehensive simulation studies have been carried out on a low-cost Raspberry Pi 3B+ platform. The corresponding results are promising in terms of event detection and indicate that the proposed approach has a strong potential towards more robust and accurate event-based NILM systems.  © 2021 IEEE.},
	author_keywords = {Event Detection; Image Segmentation; k-means Clustering; Raspberry Pi 3B+; Thresholding Technique},
	keywords = {Energy utilization; K-means clustering; Simulation platform; Events detection; Gramians; Images segmentations; K-means++ clustering; Monitoring approach; Nonintrusive load monitoring; Operation time; Raspberry pi 3b+; Single entry; Thresholding techniques; Image segmentation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Han20191131,
	author = {Han, Yi and Karunasekera, Shanika and Leckie, Christopher and Harwood, Aaron},
	title = {Multi-spatial Scale Event Detection from Geo-tagged Tweet Streams via Power-law Verification},
	year = {2019},
	journal = {Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019},
	pages = {1131 – 1136},
	doi = {10.1109/BigData47090.2019.9006302},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081319471&doi=10.1109%2fBigData47090.2019.9006302&partnerID=40&md5=a639b8bffd474051719e8b7971246877},
	abstract = {Compared with traditional news media, social media nowadays provides a richer and more timely source of news. We are interested in multi-spatial level event detection from geo-tagged tweet streams. Specifically, in this paper we (1) examine the statistical characteristic for the time series of the number of geo-tagged tweets posted from specific regions during a short time interval, e.g., one minute; (2) verify from over thirty datasets that while almost all such time series exhibit self-similarity, those that correspond to events, especially short-term and unplanned outbursts, follow a power-law distribution; (3) demonstrate that these findings can be applied to facilitate event detection from tweet streams. We propose two algorithms-Power-law basic and Power-law advanced, where Power-law basic only checks the existence of power-law distributions in the time series from tweet streams at multi-spatial scales, without looking into the content of each tweet, and Power-law advanced integrates power-law verification with semantic analysis via word embedding. Our experiments on multiple datasets show that when combined with a Quad-tree, the seemingly naive algorithm of Power-law basic achieves comparable results with more advanced event detection methods, while the semantic analysis enhanced version, Power-law advanced, can significantly increase both the precision and the recall. © 2019 IEEE.},
	author_keywords = {multi-spatial event detection; power-law distribution; self-similarity},
	keywords = {Big data; Semantics; Time series; Trees (mathematics); Event detection; Multiple data sets; Power law distribution; Self-similarities; Semantic analysis; Short time intervals; Spatial events; Statistical characteristics; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@ARTICLE{Kim202155777,
	author = {Kim, Young-Jin and Kim, Hanjin and Lee, Seunggi and Kim, Won-Tae},
	title = {Trustworthy Building Fire Detection Framework with Simulation-Based Learning},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {55777 – 55789},
	doi = {10.1109/ACCESS.2021.3071552},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103873924&doi=10.1109%2fACCESS.2021.3071552&partnerID=40&md5=00e02e2b00e19d45a43a5dfe1dbf7624},
	abstract = {With the difficulty of collecting desirable training data due to the heterogeneities of IoT sensors in various buildings and the scarcity of fire events, it is time consuming and expensive to apply data-driven deep learning approaches to fire detection systems in specific building environments. Simulation-based learning has been actively researched to mitigate data scarcity problems by reproducing potential fire events. Since simulation-based learning mainly depends on synthetic training data, trained deep learning models may generate erroneous predictions in real-world scenarios that are unlike any of the training samples. In this paper, we propose a trustworthy building fire detection framework based on a multioutput encoder-decoder network, named MEDNet, which is designed for the practical usage of simulation-based learning in building fire detection. The fundamental steps of our approach are (1) modeling and simulating fire events to create realistic synthetic data that reflect data from actual buildings, (2) predicting a fire event and dissimilarities between real input data and synthetic training data based on the trained MEDNet model, and (3) operating a switching mechanism to use a knowledge-based method that does not depend on synthetic training data when dissimilarities exist. Finally, we perform simulation experiments based on a real building compartment where the proposed framework is compared with conventional time-series classification networks on various evaluation datasets. The proposed framework is trustworthy in practical usage becauseMEDNet with a switching mechanism achieves a 36.65% higher F1-score than conventional time-series classification networks and generates false-positive predictions lower than 0.02% even in unpredictable scenarios.  © 2013 IEEE.},
	author_keywords = {building fire detection; deep learning; encoder-decoder network; modeling and simulation; Simulation-based learning; supervised learning-based rare event detection},
	keywords = {Buildings; Classification (of information); Deep learning; Fire detectors; Fire hazards; Fires; Forecasting; Knowledge based systems; Time series; Building environment; Fire detection systems; Knowledge-based methods; Modeling and simulating; Simulation-based learning; Switching mechanism; Synthetic training data; Time series classifications; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access}
}

@CONFERENCE{Kajabad2020565,
	author = {Kajabad, Ebrahim Najafi and Ivanov, Sergey V. and Khodnenko, Ivan},
	title = {LSTM Algorithm for Forecasting Events in Changing Electric Consumption},
	year = {2020},
	journal = {Proceedings - 2020 International Conference on Computational Science and Computational Intelligence, CSCI 2020},
	pages = {565 – 571},
	doi = {10.1109/CSCI51800.2020.00101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113376627&doi=10.1109%2fCSCI51800.2020.00101&partnerID=40&md5=b662cb1c909b4843b05588dc798fe317},
	abstract = {The industrial sections have always been thirsty to predict events and be aware of future sudden changes. Where using time-series forecasting based on deep learning techniques can have a significant effect on addressing this issue. In this paper, we present Stacked Long Short-Term Memory (LSTM) networks to predict significant electric consumption changes when a group of devices is activated or deactivated randomly. Three Power quadratic phases are used as a dataset. The goal is to predict multi-steps in the future minutes. The supervised learning technique is used to transform series data to supervised data for training and prediction, and then the Walk-forward cross-validation is implemented to evaluate subsequent time steps prediction and output is a vector of prediction. Finally, the root-mean-square error (RMSE) method is employed as a metric for each lead time on an output vector. Furthermore, we compared our proposed model with the Vanilla and Bidirectional LSTMs architecture, in which the performance of our method shows that it was successful. Our experimental results support the view that enough data is crucial to event detection in time series data and suggest that Stacked LSTM is a good architecture with which to address it.  © 2020 IEEE.},
	author_keywords = {Electric Consumption; LSTM algorithm; Machine learning; Recurrent Neural Network (RNN); Time series forecasting},
	keywords = {Deep learning; Electric power utilization; Forecasting; Intelligent computing; Learning systems; Mean square error; Network architecture; Supervised learning; Time series; Cross validation; Electric consumption; Event detection; Learning techniques; Output vectors; Root mean square errors; Time series forecasting; Time-series data; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Riera2020238,
	author = {Riera, Luis and Ozcan, Koray and Merickel, Jennifer and Rizzo, Mathew and Sarkar, Soumik and Sharma, Anuj},
	title = {Detecting and Tracking Unsafe Lane Departure Events for Predicting Driver Safety in Challenging Naturalistic Driving Data},
	year = {2020},
	journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
	pages = {238 – 245},
	doi = {10.1109/IV47402.2020.9304536},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099881828&doi=10.1109%2fIV47402.2020.9304536&partnerID=40&md5=ee88287c4db94a27eea88de15d696e71},
	abstract = {Our goal is to improve driver safety predictions in at-risk medical or aging populations from naturalistic driving video data. To meet this goal, we developed a novel model capable of detecting and tracking unsafe lane departure events (e.g., changes and incursions), which may occur more frequently in at-risk driver populations. The model detects and tracks roadway lane markings in challenging, low-resolution driving videos using a semantic lane detection pre-processor (Mask R-CNN) utilizing the driver's forward lane region, demarking the convex hull that represents the driver's lane. The hull centroid is tracked over time, improving lane tracking over approaches which detect lane markers from single video frames. The lane time series was denoised using a Fix-lag Kalman filter. Preliminary results show promise for robust lane departure event detection. Overall recall for detecting lane departure events was 81.82%. The F1 score was 75% (precision 69.23%) and 70.59% (precision 62.07%) for left and right lane departures, respectively. Future investigations include exploring (1) horizontal offset as a means to detect lead vehicle proximity, even when image perspectives are known to have a chirp effect and (2) Long Short Term Memory (LSTM) models to detect peaks instead of a peak detection algorithm. © 2020 IEEE.},
	keywords = {Chemical detection; Population statistics; Road and street markings; Safety engineering; Semantics; Aging population; Chirp effects; Event detection; Lane departure; Lane detection; Lead vehicles; Low resolution; Peak detection; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Van Vaerenbergh2021293,
	author = {Van Vaerenbergh, Kevin and Tourwé, Tom},
	title = {Distributed Data Compression for Edge Devices},
	year = {2021},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {628},
	pages = {293 – 304},
	doi = {10.1007/978-3-030-79157-5_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112592339&doi=10.1007%2f978-3-030-79157-5_24&partnerID=40&md5=4a38b2f06e11673d5c6d09b96fb598ea},
	abstract = {In this paper, we elaborate on the issue of reliable storage and efficient communication of large quantities of data in the absence of continuous connectivity. We illustrate how advanced machine learning techniques can run locally at the edge, in the context of data compression related to special-purpose vehicles. Two different data compression techniques are compared by calculating general compression metrics, e.g., compression rate and root mean-squared error, while also validating the results using an event detection algorithm. These techniques exploit real-world usage data captured in the field using the I-HUMS platform provided by our industrial partner ILIAS solutions Inc. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {Distributed data analysis; IoT; Time series compression},
	keywords = {Biomedical engineering; Data compression; Digital storage; Energy efficiency; Learning systems; Mean square error; Compression rates; Data compression techniques; Distributed data; Efficient communications; Event detection algorithm; Industrial partners; Machine learning techniques; Root mean squared errors; Artificial intelligence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Lee202173799,
	author = {Lee, Sang-Hee and Park, Cheol-Min},
	title = {A New Measure to Characterize the Self-Similarity of Binary Time Series and its Application},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {73799 – 73807},
	doi = {10.1109/ACCESS.2021.3081400},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107111868&doi=10.1109%2fACCESS.2021.3081400&partnerID=40&md5=919ee3bc3db40c269c6f5a4d9946f996},
	abstract = {In this study, the branch-length similarity entropy profile is estimated by mapping the time-series signal to the circumference of the time circle, and the self-similarity is defined based on the profile. To explore the self-similarity property, the effect of the distance between two signals, '0' and '1', on the entropy value for signal '1' is investigated. Furthermore, two application problems are addressed: quantification of the mixing state of fragments and clusters, and characterization of the behavioral trajectory of an organism. The results indicate that use of the self-similarity property solves both the problems. Additionally, the problems that must be addressed to broaden the applicability of self-similarity are discussed.  © 2013 IEEE.},
	author_keywords = {Animal behavior; classification; data structure; discrete transforms; entropy; environmental monitoring; event detection; signal analysis; signal processing algorithms; time-series analysis},
	keywords = {Entropy; Application problems; Binary time series; Branch length; ITS applications; Self similarity properties; Self-similarities; Similarity entropies; Time series signals; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{D'Antoni2020,
	author = {D'Antoni, Federico and Merone, Mario and Piemonte, Vincenzo and Iannello, Giulio and Soda, Paolo},
	title = {Auto-Regressive Time Delayed jump neural network for blood glucose levels forecasting},
	year = {2020},
	journal = {Knowledge-Based Systems},
	volume = {203},
	doi = {10.1016/j.knosys.2020.106134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086498376&doi=10.1016%2fj.knosys.2020.106134&partnerID=40&md5=9bbe258426474801a3c684cc42d16892},
	abstract = {Diabetes mellitus is a widespread chronic disease and is one of the main causes of death worldwide. In order to improve the quality of life of people with diabetes and reduce the occurrence of complications, it is fundamental to prevent glycemic levels from exceeding the physiologic range. With this purpose, many works in recent years have been developed to forecast future glycemic trends using machine learning algorithms that exploit the reading of continuous glucose monitoring sensors, which gather glycemic data from diabetic patients 24 h a day. However, their application is limited in practice by the fact that they usually require a large amount of training data and other heterogeneous features gathered from patients. For this reason, in this work we present a novel neural network capable of predicting future glycemic levels using only the past glucose values as input while needing a small amount of training data. The model is a jump neural network with the addition of feedback connections from the output to the hidden layer, and time delays for each of the input-to-hidden, output-to-hidden and input-to-output connections. Experiments were conducted on a private and a public dataset. We evaluated performance in terms of RMSE and of adverse event detection. The proposed model outperforms other methods suited for time series forecasting, as well as models for blood glucose level prediction present in the literature. © 2020 Elsevier B.V.},
	author_keywords = {Bio-medical patterns; Diabetes; Neural networks; Precision medicine; Time series forecasting},
	keywords = {Blood; Forecasting; Glucose; Learning algorithms; Machine learning; Time delay; Time series analysis; Blood glucose level; Continuous glucose monitoring sensors; Diabetes mellitus; Diabetic patient; Feedback connection; Heterogeneous features; Novel neural network; Time series forecasting; Multilayer neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Ravindranath202053,
	author = {Ravindranath, Manjusha and Selcuk Candan, K. and Sapino, Maria Luisa},
	title = {M2NN: Rare Event Inference through Multi-variate Multi-scale Attention},
	year = {2020},
	journal = {Proceedings - 2020 IEEE International Conference on Smart Data Services, SMDS 2020},
	pages = {53 – 62},
	doi = {10.1109/SMDS49396.2020.00014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099194949&doi=10.1109%2fSMDS49396.2020.00014&partnerID=40&md5=c2b20192390290b0cfc8a7490726665d},
	abstract = {With the increasing availability of sensory data, inferring the existence of relevant events in the observations is becoming a critical task for smart data service delivery in applications that rely on such data sources. Yet, existing solutions tend to fail when the events that are being inferred are rare, for instance when one attempts to infer seizure events in electroencephalogram (EEG) data. In this paper, we note that multi-variate time series often carry robust localized multi-variate temporal features that could, at least in theory, help identify these events; however, the lack of sufficient data to train for these events make it impossible for neural architectures to identify and make use of these features. To tackle this challenge, we propose an LSTM-based neural architecture, M2N N, with an attention mechanism that leverages robust multivariate temporal features that are extracted a priori and fed into the NN as a side information. In particular, multi-variate temporal features are extracted by simultaneously considering, at multiple scales, temporal characteristics of the time series along with external knowledge, including variate relationships that are known a priori. We then show that a single layer LSTM with dual-layer attention that leverages these multi-scale, multi-variate features provides significant gains in rare seizure detection on EEG data. In addition, in order to illustrate the broader applicability (and reproducibility) of M2N N, we also evaluate it in other publicly available rare event detection tasks, such as anomaly detection in manufacturing. We further show that the proposed M2N N technique is beneficial in tackling more traditional inference problems, such as travel-time prediction, where rare accident events can cause congestions.  © 2020 IEEE.},
	author_keywords = {Brain EEG analysis; Multi-scale attention; Multivariate time series; Rare event inference},
	keywords = {Anomaly detection; Electroencephalography; Internet protocols; Time series; Travel time; Attention mechanisms; Electroencephalogram (EEG) datum; External knowledge; Inference problem; Neural architectures; Temporal characteristics; Temporal features; Travel time prediction; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Wei2021290,
	author = {Wei, Dezhi and Lin, Li'Na},
	title = {A Method of Hot Event Detection Based on Improved TOPSIS},
	year = {2021},
	journal = {2021 IEEE International Conference on Advances in Electrical Engineering and Computer Applications, AEECA 2021},
	pages = {290 – 293},
	doi = {10.1109/AEECA52519.2021.9574290},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119085045&doi=10.1109%2fAEECA52519.2021.9574290&partnerID=40&md5=58104bd57c15c6938b94edc75dd7017f},
	abstract = {A time series based ranking model was proposed in this paper to solve the problem of hot event detection in network public opinions. Firstly, the weight of indicators was determined by entropy method. Then, TOPSIS method and gray correlation method were combined to calculate in the form of relative proximity to judge the advantages and disadvantages of the scheme. Finally, it was proved that this method has better objectivity and accuracy by experimental verification and comparison with other hot event detection algorithms. © 2021 IEEE.},
	author_keywords = {hot news; Internet public opinion; ranking model},
	keywords = {Entropy methods; Grey correlation methods; Hot event detection; Hot news; In networks; Internet public opinions; Network public opinions; Ranking model; Times series; TOPSIS method; Social aspects},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Bazzi20201,
	author = {Bazzi, Hassan and Baghdadi, Nicolas and Fayad, Ibrahim and Charron, François and Zribi, Mehrez and Belhouchette, Hatem},
	title = {Irrigation events detection over intensively irrigated grassland plots using sentinel-1 data},
	year = {2020},
	journal = {Remote Sensing},
	volume = {12},
	number = {24},
	pages = {1 – 22},
	doi = {10.3390/rs12244058},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098263082&doi=10.3390%2frs12244058&partnerID=40&md5=c06fc1d4a009e1b0b8be0b59f4cd6a8b},
	abstract = {Better management of water consumption and irrigation schedule in irrigated agriculture is essential in order to save water resources, especially at regional scales and under changing climatic conditions. In the context of water management, the aim of this study is to monitor irrigation activities by detecting the irrigation episodes at plot scale using the Sentinel-1 (S1) C-band SAR (synthetic-aperture radar) time series over intensively irrigated grassland plots located in the Crau plain of southeast France. The method consisted of assessing the newly developed irrigation detection model (IDM) at plot scale over the irrigated grassland plots. First, four S1-SAR time series acquired from four different S1-SAR acquisitions (different S1 orbits), each at six-day revisit time, were obtained over the study site. Next, the IDM was applied at each available SAR image from each S1-SAR series to obtain an irrigation indicator at each SAR image (no, low, medium, or high irrigation possibility). Then, the irrigation indicators obtained at each image from each S1-SAR time series (four series) were added and combined by threshold value criteria to determine the existence or absence of an irrigation event. Finally, the performance of the IDM for irrigation detection was assessed by comparing the in situ recorded irrigation events at each plot and the detected irrigation events. The results show that using only the VV polarization, 82.4% of the in situ registered irrigation events are correctly detected with an F_score value reaching 73.8%. Less accuracy is obtained using only the VH polarization, where 79.9% of the in situ irrigation events are correctly detected with an F_score of 72.2%. The combined use of the VV and VH polarization showed that 74.1% of the irrigation events are detected with a higher F_score value of 76.4%. The analysis of the undetected irrigation events revealed that, in the presence of very well-developed vegetation cover (normalized difference of vegetation index (NDVI) ≥ 0.8); higher uncertainty in irrigation detection is observed, where 80% of the undetected events correspond to an NDVI value greater than 0.8. The results also showed that small-sized plots encounter more false irrigation detections than large-sized plots certainly because the pixel spacing of S1 data (10 m × 10 m) is not adapted to small size plots. The obtained results prove the efficiency of the S1 C-band data and the IDM for detecting irrigation events at the plot scale, which would help in improving the irrigation water management at large scales especially with availability and global coverage of the S1 product. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Change detection; Crau plain; France; Grassland; Irrigation; Sentinel-1},
	keywords = {Agricultural robots; Polarization; Radar imaging; Synthetic aperture radar; Time series; Uncertainty analysis; Vegetation; Water management; Water supply; Climatic conditions; Detection models; Irrigated agriculture; Irrigation schedule; Irrigation water management; Normalized differences; SAR(synthetic aperture radar); Water consumption; Irrigation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Xie20195945,
	author = {Xie, Shu-Yi and Ma, Jian and Luo, Yu-Bin and Jiang, Lian-Xin and Jin, Shirly and Mo, Yang and Shen, Jian-Ping},
	title = {Models and Features with Covariate Shift Adaptation for Suspicious Network Event Recognition},
	year = {2019},
	journal = {Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019},
	pages = {5945 – 5950},
	doi = {10.1109/BigData47090.2019.9006292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081367000&doi=10.1109%2fBigData47090.2019.9006292&partnerID=40&md5=91d7ff1ff7df6d25beebd1ffdcc5d135},
	abstract = {Detecting a small number of suspicious network events from large amount of network traffic data is a very challenging task. We extract time series features from the network log data and use models such as LightGBM and stacked CNN-LSTM deep neural networks to predict whether the investigated alerts are suspicious. We apply feature alignment, covariate shift adaptation to overcome the covariate shift between training data and test data. In the IEEE Big Data 2019 Cup: Suspicious Network Event Recognition Competition, our model scored the first place on the public board and the fourth place on the final board respectively. © 2019 IEEE.},
	author_keywords = {covariate shift adaptation; feature alignment; stacked CNN-LSTM deep neural networks; suspicious network event detection},
	keywords = {Big data; Deep neural networks; Covariate shifts; Event detection; Event recognition; Feature alignment; Large amounts; Network traffic; Time series features; Training data; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gardy2020101,
	author = {Gardy, Ludovic and Barbeau, Emmanuel J. and Hurter, Christophe},
	title = {Automatic detection of epileptic spikes in intracerebral EEG with convolutional kernel density estimation},
	year = {2020},
	journal = {VISIGRAPP 2020 - Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
	volume = {2},
	pages = {101 – 109},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083493125&partnerID=40&md5=6f03848df00e7463bd48ff10abf10d84},
	abstract = {Analyzing the electroencephalographic (EEG) signal of epileptic patients as part of their diagnosis is a very long and tedious operation. The most common technique used by medical teams is to visualize the raw signal in order to find pathological events such as interictal epileptic spikes (IESs) or abnormal oscillations. More and more efforts are being adopted to try to facilitate the work of doctors by automating this process. Our goal was to analyze signal density fields to improve the visualization and automatic detection of pathological events. We transformed the EEG signal into images on which we applied a convolution filter based on a Kernel Density Estimation (KDE). This method that we propose to call CKDE for Convolutional Kernel Density Estimation allowed the emergence of local density fields leading to a better visualization as well as automatic detection of IESs. Future work will be necessary to make this technique more efficient, but preliminary results are very encouraging and show a high performance compared to a visual inspection of the data or some other automatic detection techniques. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Accessibility; Convolution; EEG; Electroencephalography; Epilepsy; Event detection; Kernel density estimation; Noisy signal; Signal processing; Time series visualization},
	keywords = {Computer graphics; Convolution; Electroencephalography; Statistics; Visualization; Automatic Detection; Convolution filters; Convolutional kernel; Electroencephalographic signals; Epileptic patients; Intra-cerebral EEG; Kernel Density Estimation; Visual inspection; Computer vision},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2021,
	title = {ICICSE 2021 - 2021 10th International Conference on Internet Computing for Science and Engineering},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123995992&partnerID=40&md5=7993d6cab50c70f16fb1148a0a40932c},
	abstract = {The proceedings contain 21 papers. The topics discussed include: multi-granularity context semantic fusion model for Chinese event detection; adversarial attacks on deep neural networks for time series prediction; a scalable ideal progressive visual cryptography scheme; design and implementation of special data encyclopedia system; forensics studies based on docker containers; a nemo-lisp based architecture for body area networks; the development of computer communication technology and its application in electronic information engineering; a countermeasure for advanced encryption standard against power analysis attack using chaotic system; prediction method of fan main shaft fault state based on sliding window characteristics; and research on a time series deep learning model of non-point source water pollution in a river basin.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shi2020,
	author = {Shi, Jie and Foggo, Brandon and Kong, Xianghao and Cheng, Yuanbin and Yu, Nanpeng and Yamashita, Koji},
	title = {Online event detection in synchrophasor data with graph signal processing},
	year = {2020},
	journal = {2020 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2020},
	doi = {10.1109/SmartGridComm47815.2020.9302947},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098807252&doi=10.1109%2fSmartGridComm47815.2020.9302947&partnerID=40&md5=9d4b1dad5c428cf2e0d9c8b49d3b1a6c},
	abstract = {Online detection of anomalies is crucial to enhancing the reliability and resiliency of power systems. We propose a novel data-driven online event detection algorithm with synchrophasor data using graph signal processing. In addition to being extremely scalable, our proposed algorithm can accurately capture and leverage the spatio-temporal correlations of the streaming PMU data. This paper also develops a general technique to decouple spatial and temporal correlations in multiple time series. Finally, we develop a unique framework to construct a weighted adjacency matrix and graph Laplacian for product graph. Case studies with real-world, large-scale synchrophasor data demonstrate the scalability and accuracy of our proposed event detection algorithm. Compared to the state-of-the-art benchmark, the proposed method not only achieves higher detection accuracy but also yields higher computational efficiency. © 2020 IEEE.},
	author_keywords = {Event detection; Graph Fourier transform; Graph signal processing; Phasor measurement unit},
	keywords = {Computational efficiency; Electric power transmission networks; Online systems; Signal detection; Smart power grids; Detection accuracy; Event detection algorithm; Multiple time series; Online event detection; Spatial and temporal correlation; Spatiotemporal correlation; Synchrophasor datum; Weighted adjacency matrixes; Graph algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Green Open Access}
}

@ARTICLE{Lyu2021,
	author = {Lyu, Chengang and Jiang, Jianying and Li, Baihua and Huo, Ziqiang and Yang, Jiachen},
	title = {Abnormal events detection based on RP and inception network using distributed optical fiber perimeter system},
	year = {2021},
	journal = {Optics and Lasers in Engineering},
	volume = {137},
	doi = {10.1016/j.optlaseng.2020.106377},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090904626&doi=10.1016%2fj.optlaseng.2020.106377&partnerID=40&md5=49abab62b08bc3947032375cde10f188},
	abstract = {For establishing an accurate and reliable distributed optical fiber perimeter security system, this paper proposes a novel abnormity detection solution to security using Recurrent Plot (RP) and deep learning technology. Take advantage of the temporal correlation of intrusion signals, we encode the sensing signals into two-dimensional images through the RP algorithm. The RP algorithm can extract the motion characteristics of the signal from the complex time series, and it is robust to instrument noise. These encoded image signatures can reveal the deeper temporal correlation of the intrusion signals’ motion. After that, Inception network can adaptively extract the features of these images to complete the accurate identification of a series of noisy intrusion signals. We conducted experiments on three most frequent natural events and three representative man-made intrusion events, including heavy rain, light rain, wind blowing, treading, slapping, and impacting. The results show that the detection accuracy has reached 99.7%. This method can achieve 0.35 s real-time detection in the online detection of abnormal events while ensuring accuracy, providing a new intrusion pattern identification idea for perimeter security. © 2020 Elsevier Ltd},
	author_keywords = {Distributed optical fiber sensing; Events detection; Inception network; Recurrent plot},
	keywords = {Network security; Optical fibers; Rain; Recurrent neural networks; Complex time series; Distributed optical fiber; Learning technology; Motion characteristics; Perimeter security systems; Real-time detection; Temporal correlations; Two dimensional images; Intrusion detection},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Green Open Access}
}

@ARTICLE{Kiskin2020915,
	author = {Kiskin, Ivan and Zilli, Davide and Li, Yunpeng and Sinka, Marianne and Willis, Kathy and Roberts, Stephen},
	title = {Bioacoustic detection with wavelet-conditioned convolutional neural networks},
	year = {2020},
	journal = {Neural Computing and Applications},
	volume = {32},
	number = {4},
	pages = {915 – 927},
	doi = {10.1007/s00521-018-3626-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051252773&doi=10.1007%2fs00521-018-3626-7&partnerID=40&md5=4d3ed755c98fb61177e7235859940acb},
	abstract = {Many real-world time series analysis problems are characterized by low signal-to-noise ratios and compounded by scarce data. Solutions to these types of problems often rely on handcrafted features extracted in the time or frequency domain. Recent high-profile advances in deep learning have improved performance across many application domains; however, they typically rely on large data sets that may not always be available. This paper presents an application of deep learning for acoustic event detection in a challenging, data-scarce, real-world problem. We show that convolutional neural networks (CNNs), operating on wavelet transformations of audio recordings, demonstrate superior performance over conventional classifiers that utilize handcrafted features. Our key result is that wavelet transformations offer a clear benefit over the more commonly used short-time Fourier transform. Furthermore, we show that features, handcrafted for a particular dataset, do not generalize well to other datasets. Conversely, CNNs trained on generic features are able to achieve comparable results across multiple datasets, along with outperforming human labellers. We present our results on the application of both detecting the presence of mosquitoes and the classification of bird species. © 2018, The Author(s).},
	author_keywords = {Acoustic signal processing; Classification and detection; Convolutional neural networks; Short-time Fourier transform; Spectrograms; Wavelets},
	keywords = {Acoustic signal processing; Convolution; Deep learning; Fourier transforms; Frequency domain analysis; Neural networks; Signal processing; Signal to noise ratio; Time series analysis; Acoustic event detections; Conventional classifier; Convolutional neural network; Low signal-to-noise ratio; Short time Fourier transforms; Spectrograms; Wavelet transformations; Wavelets; Wavelet transforms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 35; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Wu2021,
	author = {Wu, Junfeng and Yao, Li and Liu, Bin and Ding, Zheyuan and Zhang, Lei},
	title = {Multi-task learning based Encoder-Decoder: A comprehensive detection and diagnosis system for multi-sensor data},
	year = {2021},
	journal = {Advances in Mechanical Engineering},
	volume = {13},
	number = {5},
	doi = {10.1177/16878140211013138},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106323055&doi=10.1177%2f16878140211013138&partnerID=40&md5=e831765d56e3b2db50f9067ef606247f},
	abstract = {As more and more sensor data have been collected, automated detection, and diagnosis systems are urgently needed to lessen the increasing monitoring burden and reduce the risk of system faults. A plethora of researches have been done on anomaly detection, event detection, anomaly diagnosis respectively. However, none of current approaches can explore all these respects in one unified framework. In this work, a Multi-Task Learning based Encoder-Decoder (MTLED) which can simultaneously detect anomalies, diagnose anomalies, and detect events is proposed. In MTLED, feature matrix is introduced so that features are extracted for each time point and point-wise anomaly detection can be realized in an end-to-end way. Anomaly diagnosis and event detection share the same feature matrix with anomaly detection in the multi-task learning framework and also provide important information for system monitoring. To train such a comprehensive detection and diagnosis system, a large-scale multivariate time series dataset which contains anomalies of multiple types is generated with simulation tools. Extensive experiments on the synthetic dataset verify the effectiveness of MTLED and its multi-task learning framework, and the evaluation on a real-world dataset demonstrates that MTLED can be used in other application scenarios through transfer learning. © The Author(s) 2021.},
	author_keywords = {Anomaly detection; anomaly diagnosis; event detection; feature matrix; multi-task learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@ARTICLE{2020,
	title = {7th International Workshop on Big Data Management and Service, BDMS 2020, 6th International Symposium on Semantic Computing and Personalization, SeCoP 2020, 5th Big Data Quality Management, BDQM 2020, 4th International Workshop on Graph Data Management and Analysis, GDMA 2020, 1st International Workshop on Artificial Intelligence for Data Engineering, AIDE 2020, held in  conjunction with the 25th International Conference on Database Systems for Advanced Applications, DASFAA 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12115 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092127113&partnerID=40&md5=82dfa0cf7b5497fc8642c3c0034b3064},
	abstract = {The proceedings contain 22 papers. The special focus in this conference is on Big Data Management and Service. The topics include: Core research topics of studies on personalized feedback in the past four decades; maintenance method of logistics vehicle based on data science and quality; an efficient and metadata-aware big data storage architecture; kernel design of intelligent historical database for multi-objective combustion optimization; threshold functional dependencies for time series data; a survey on modularization of chatbot conversational systems; a long short-term memory neural network model for predicting air pollution index based on popular learning; domain ontology construction for intelligent anti-telephone-fraud applications; improving gaussian embedding for extracting local semantic connectivity in networks; a novel shilling attack detection method based on t-distribution over the dynamic time intervals; question answering over knowledge base with symmetric complementary attention; long- and short-term preference model based on graph embedding for sequential recommendation; event detection on literature by utilizing word embedding; user sequential behavior classification for click-through rate prediction; supervised learning for human action recognition from multiple kinects; discovery of chasing patterns in trajectory data; a cloud-based platform for ecg monitoring and early warning using big data and artificial intelligence technologies; what are moocs learners’ concerns? text analysis of reviews for computer science courses; a new context-aware method based on hybrid ranking for community-oriented lexical simplification; two-level convolutional neural network for aspect extraction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2021,
	title = {4th IEEE International Conference on Knowledge Innovation and Invention 2021, ICKII 2021},
	year = {2021},
	journal = {4th IEEE International Conference on Knowledge Innovation and Invention 2021, ICKII 2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118976736&partnerID=40&md5=97ff481bd9d18124d1b950ea8eb10db4},
	abstract = {The proceedings contain 48 papers. The topics discussed include: modularized architecture of attribute generative adversarial network for image synthesis; authentication system by using HOG face recognition technique and web-based for medical dispenser machine; time-series analysis of newspaper articles for automatic event detection using LDA; a distributed simulated annealing based decision tree (DSABDT) for cancer classification; air quality forecast and evaluation based on long short-term memory network and fuzzy algorithm; phase dependent power in a transmission line circuit; the research on the best mode of the negative-ion smoke-removal helmet and the negative-ion emitters equipped in a fire scene; and design and implementation of the inverse kinematics and monitoring module for six-axis crank arm platform.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Birnie2020504,
	author = {Birnie, Claire and Chambers, Kit and Angus, Doug and Stork, Anna L.},
	title = {On the importance of benchmarking algorithms under realistic noise conditions},
	year = {2020},
	journal = {Geophysical Journal International},
	volume = {221},
	number = {1},
	pages = {504 – 520},
	doi = {10.1093/gji/ggaa025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099870951&doi=10.1093%2fgji%2fggaa025&partnerID=40&md5=ca69797431d5d4056b10788e8a35f01a},
	abstract = {Testingwith synthetic data sets is a vital stage in an algorithm's development for benchmarking the algorithm's performance. A common addition to synthetic data sets is White, Gaussian Noise (WGN) which is used to mimic noise that would be present in recorded data sets. The first section of this paper focuses on comparing the effects of WGN and realistic modelled noise on standard microseismic event detection and imaging algorithms using synthetic data sets with recorded noise as a benchmark. The data sets with WGN underperform on the traceby- trace algorithmwhile overperforming on algorithms utilizing the full array. Throughout, the data sets with realistic modelled noise perform near identically to the recorded noise data sets. The study concludes by testing an algorithm that simultaneously solves for the source location and moment tensor of a microseismic event. Not only does the algorithm fail to perform at the signal-to-noise ratios indicated by the WGN results but the results with realistic modelled noise highlight pitfalls of the algorithm not previously identified. The misleading results from theWGN data sets highlight the need to test algorithms under realistic noise conditions to gain an understanding of the conditions under which an algorithm can perform and to minimize the risk of misinterpretation of the results.  © The Author(s) 2020.},
	author_keywords = {Induced seismicity; Numerical modelling; Site effects; Statistical methods; Statistical seismology; Time-series analysis},
	keywords = {Gaussian noise (electronic); Seismology; Signal to noise ratio; Algorithm's performance; Benchmarking algorithm; Imaging algorithm; Microseismic events; Noise conditions; Source location; Synthetic datasets; Test algorithms; algorithm; benchmarking; data interpretation; induced seismicity; model test; model validation; numerical model; performance assessment; seismology; signal-to-noise ratio; site effect; statistical analysis; time series analysis; Benchmarking},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Zhao202015,
	author = {Zhao, Qinpei and Zhang, Yinjia and Shi, Yang and Li, Jiangfeng},
	title = {Analyzing and Visualizing Anomalies and Events in Time Series of Network Traffic},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {936},
	pages = {15 – 25},
	doi = {10.1007/978-3-030-19861-9_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065905776&doi=10.1007%2f978-3-030-19861-9_2&partnerID=40&md5=816a3c0a5d63bad1f825cf1d870720a8},
	abstract = {The traffic among the hosts and behaviors of the anomalous hosts in the network is usually complex. In network traffic, there is a key problem that is how to identify the security incidents. The corresponding question that who have contributed to the incidents is arisen then. A method, which detects both anomalies and events at the same time is quite helpful. A data from network traffic can be composed of the hosts and different attributes (traffic flow like amount of upload package and download package) in time series. Based on the structure of the network traffic data, we propose an anomaly and event detection method based on the network attributes in time series. The method analyzes both the host’s behavior and the temporal features of the network traffic. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Anomaly detection; Network traffic; Security incidents; Time series},
	keywords = {Anomaly detection; Time series; Event detection; In networks; Network traffic; Security incident; Temporal features; Traffic flow; Computer networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{2021,
	title = {2021 IEEE Data Science and Learning Workshop, DSLW 2021},
	year = {2021},
	journal = {2021 IEEE Data Science and Learning Workshop, DSLW 2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115399644&partnerID=40&md5=efe26b31785bd92364dc6ed29f43db38},
	abstract = {The proceedings contain 17 papers. The topics discussed include: online non-linear topology identification from graph-connected time series; multimodal generative neural network for anomaly events detection and localization in videos; multilayer graph clustering with optimized node embedding; the 2020 ESPNET update: new features, broadened applications, performance improvements, and future plans; model-based deep learning: key approaches and design guidelines; ESPN: extremely sparse pruned networks; fast on-device adaptation for spiking neural networks via online-within-online meta-learning; crafting an adversarial example in the DNN representation space by minimizing the distance from the decision boundary; and low-rank matrix recovery with scaled subgradient methods: fast and robust convergence without the condition number.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Savelonas2021,
	author = {Savelonas, Michalis and Vernikos, Ioannis and Mantzekis, Dimitris and Spyrou, Evaggelos and Tsakiri, Athanasia and Karkanis, Stavros},
	title = {Hybrid representation of sensor data for the classification of driving behaviour},
	year = {2021},
	journal = {Applied Sciences (Switzerland)},
	volume = {11},
	number = {18},
	doi = {10.3390/app11188574},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115260794&doi=10.3390%2fapp11188574&partnerID=40&md5=981e1182e16380b1fd2151bb37e6e2dc},
	abstract = {Monitoring driving behaviour is important in controlling driving risk, fuel consump-tion, and CO2 emissions. Recent advances in machine learning, which include several variants of convolutional neural networks (CNNs), and recurrent neural networks (RNNs), such as long short-term memory (LSTM) and gated recurrent unit (GRU) networks, could be valuable for the development of objective and efficient computational tools in this direction. The main idea in this work is to complement data-driven classification of driving behaviour with rules derived from domain knowledge. In this light, we present a hybrid representation approach, which employs NN-based time-series encoding and rule-guided event detection. Histograms derived from the output of these two components are concatenated, normalized, and used to train a standard support vector machine (SVM). For the NN-based component, CNN-based, LSTM-based, and GRU-based variants are investigated. The CNN-based variant uses image-like representations of sensor measurements, whereas the RNN-based variants (LSTM and GRU) directly process sensor measurements in the form of time-series. Experimental evaluation on three datasets leads to the conclusion that the proposed approach outperforms a state-of-the-art camera-based approaches in distinguishing between normal and aggressive driving behaviour without using data derived from a camera. Moreover, it is demonstrated that both NN-guided time-series encoding and rule-guided event detection contribute to overall classification accuracy. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Convolutional neural networks; Driving behaviour; Recurrent neural networks; Telematics sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@CONFERENCE{Makara2021,
	author = {Makara, Árpád László and Deli, Tamás and Csurgai-Horváth, László},
	title = {AI-SUPPORTED FADING PREDICTION ON Q-BAND SATELLITE CHANNEL},
	year = {2021},
	journal = {Ka and Broadband Communications Conference},
	volume = {2021-September},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171463974&partnerID=40&md5=b72da118941b8ed49c37a9529527b22b},
	abstract = {Broadband satellite communication services require high speed radio channels. As the frequency bands below 15 GHz become more and more crowded, the using of higher frequency bands is increasingly timely. At these frequencies, special challenges arise mainly due to the higher impacts of the atmospheric impairments. The attenuation on the millimeter wavelength satellite radio channel significantly influences the quality of the service; therefore different methods are under investigation to combat against the atmospheric effects. In order to investigate the radio propagation in Ka-band and above, ASI conceived and supported the experiment [1] executed by the European Space Agency (ESA) through the realization of the Aldo Paraboni TDP#5 payload on board of the Alphasat satellite. The experiment supports propagation measurements over Europe in the Ka/Q-band, furthermore conducting radio communication experiments in the Q/V band especially for site diversity and adaptive coding and modulation (ACM) research. In Budapest University of Technology and Economics, Department of Broadband Infocommunications and Electromagnetic Theory (BME-HVT) a propagation terminal [2] and a ground station for the communication experiment [3] was designed and installed with the support of ESA. Since 2014, both propagation and ACM measurements are performed. The ACM operation is especially sensitive to the actual state of the radio channel. The throughput of the radio connection depends on the signal-to-noise ratio and the actually selected modulation and coding (ModCod) method. To find an optimal balance between the channel conditions and the transmission scheme is a challenging task and highly influenced by the momentary variation of the fading process Hiba! A hivatkozási forrás nem található.. The Alphasat communication experiment is based on the DVB-S2 standard, allowing the rapid changing of the ModCod that could be significantly improved by the prediction of the channel state. In this paper we will outline our research work to implement a neural network-based solution to predict the fade events based on the current and preceding channel state information. This work includes the design of the most appropriate neural network, preparing the training data and finally the testing the operation of the machine learning algorithm on real-time data. The primary purpose of this research is to develop a neural network that is capable to support the ACM operation of the site diversity experiment over Alphasat TDP#5. Moreover, an automated fade event detection have further application area, considering the preprocessing of the measured received signal power time series. Attenuation statistics of the fading channel is especially important for propagation engineers [4], and a neural network-based solution may support and speed up the laborious data preparation process. © 2021 FGM Events LLC. All rights reserved.},
	keywords = {Backpropagation; Channel capacity; Channel state information; Electric fields; Fading (radio); Millimeter waves; Radio communication; Radio waves; Satellite communication systems; Satellites; Signal to noise ratio; Adaptive coding and modulation; European Space Agency; Fading prediction; Modulation and coding; Network-based solutions; Neural-networks; Q-bands; Radio channels; Satellite channel; Site diversity; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2020,
	title = {2nd International Workshop on Simulation Science, SimScience 2019},
	year = {2020},
	journal = {Communications in Computer and Information Science},
	volume = {1199 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085169030&partnerID=40&md5=45335faee95798f13136a63f1600ba3a},
	abstract = {The proceedings contain 12 papers. The special focus in this conference is on Simulation Science. The topics include: A Novel Approach to Multiscale MD/FE Simulations of Frictional Contacts; Numerical Investigation of Tri-Axial Braid Composite Structures as Crush Specimens Using the VPS-Solver; reinforcement the Seismic Interaction of Soil-Damaged Piles-Bridge by Using Micropiles; dynamic Management of Multi-level-simulation Workflows in the Cloud; on Approximate Bayesian Computation Methods for Multiple Object Tracking; investigating the Role of Pedestrian Groups in Shared Spaces through Simulation Modeling; ANNO: A Time Series Annotation Tool to Evaluate Event Detection Algorithms; vibration Frequency Spectrum of Water-Filled Porous Silica Investigated by Molecular Dynamics Simulation; numerical Study of Dispersive Mass Transport in Homogeneous and Heterogeneous Porous Media; generative Design Solutions for Free-Form Structures Based on Biomimicry.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@ARTICLE{Demargne201913,
	author = {Demargne, Julie and Javelle, Pierre and Organde, Didier and Garandeau, Léa and Janet, Bruno},
	title = {Integrating high-resolution precipitation nowcasts for improved flash flood warnings; [Intégration des prévisions immédiates de pluie à haute-résolution pour une meilleure anticipation des crues soudaines]},
	year = {2019},
	journal = {Houille Blanche},
	volume = {105},
	number = {3-4},
	pages = {13 – 21},
	doi = {10.1051/lhb/2019023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081548281&doi=10.1051%2flhb%2f2019023&partnerID=40&md5=c104d278b6001572e2dc846551aa4376},
	abstract = {The national warning system, Vigicrues Flash, developed by the French national service in charge of flood forecasting (SCHAPI), provides flash flood warnings at ungauged locations based on a discharge-threshold flood warning method called AIGA. The AIGA method leads to characterize flood hazard in real time at any point along the river network. A simplified hourly-distributed hydrologic model ingests the operational radar-based Quantitative Precipitation Estimate grids from Météo-France at a 1-km2 resolution to produce real-time peak discharge estimates along the river network. Every 15 minutes, these discharges are compared to reference flood quantiles, which were estimated from streamflow simulated time series (using the same model). A web interface provides in real time maps of the rivers exceeding the high flood and very high flood thresholds, as well as the associated municipalities. The automated system sends warning messages to registered users who might be impacted to help them better mitigate flood risk impacts. To better detect and anticipate flash flooding, the hydrologic model is being enhanced to ingest the Météo-France's AROME-NWC high-resolution precipitation nowcasts, provided at a 1.3-km resolution for a 6-hr forecast horizon, and hourly updated. To account for the forecast uncertainties, the deterministic AROME-NWC forecasts are ingested as time-lagged ensembles and combined with multiple sets of hydrological regionalized parameters. The resulting flow ensembles lead to define probabilistic flood warnings. The evaluation, carried out on 13 significant events from October 2015 to June 2017 for 750 French basins, shows significant improvements in terms of flash flood event detection and effective warning lead time, compared to warnings from the current Vigicrues Flash setup (without any future precipitation), and the added value of probabilistic warnings. © SHF, Published by EDP Sciences, 2019.},
	author_keywords = {Ensemble forecast; Flash flood; Nowcast; Uncertainty; Warning},
	keywords = {France; early warning system; ensemble forecasting; flash flood; flood forecasting; flooding; hydrological modeling; nowcasting; peak discharge; precipitation (climatology); risk assessment; streamflow; time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@ARTICLE{Wagner20191268,
	author = {Wagner, F. and Tryggvason, A. and Roberts, R. and Gudmundsson, Ó.},
	title = {Processing automatic seismic event detections: An iterative sorting algorithm improving earthquake hypocentres using interevent cross-correlation},
	year = {2019},
	journal = {Geophysical Journal International},
	volume = {219},
	number = {2},
	pages = {1268 – 1280},
	doi = {10.1093/gji/ggz362},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073338400&doi=10.1093%2fgji%2fggz362&partnerID=40&md5=4bed24c098b954824fd4c2391c919f6f},
	abstract = {We present an iterative classification scheme using interevent cross-correlation to update an existing earthquake catalogue with similar events from a list of automatic seismic event detections. The algorithm automatically produces catalogue quality events, with improved hypocentres and reliable P- and S-arrival time information. Detected events are classified into four event categories with the purpose of using the top category, with the highest assessed event quality and highest true-to-false ratio, directly for local earthquake tomography without additional manual analysis. The remaining categories have varying proportions of lower quality events, quality being defined primarily by the number of observed phase onsets, and can be viewed as different priority groups for manual inspection to reduce the time spent by a seismic analyst. A list of 3348 event detections from the geothermally active volcanic region around Hengill, southwest Iceland, produced by our migration and stack detector (Wagner et al. 2017), was processed using a reference catalogue of 1108 manually picked events from the same area. P- and S-phase onset times were automatically determined for the detected events using correlation time lags with respect to manually picked phase arrivals from different multiple reference events at the same station. A significant improvement of the initial hypocentre estimates was achieved after relocating the detected events using the computed phase onset times. The differential time data set resulting from the correlation was successfully used for a double-difference relocation of the final updated catalogue. The routine can potentially be implemented in real-time seismic monitoring environments in combination with a variety of seismic event/phase detectors. © 2019 The Author(s). Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Induced seismicity; Time-series analysis},
	keywords = {Induced Seismicity; Iterative methods; Quality control; Time series analysis; Classification scheme; Cross correlations; Double differences; Earthquake catalogues; Manual inspection; Multiple references; Seismic monitoring; Sorting algorithm; algorithm; correlation; earthquake catalogue; earthquake hypocenter; induced seismicity; seismicity; time series analysis; Earthquakes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kim201999,
	author = {Kim, Heeyoung and Duan, Rong and Kim, Sungil and Lee, Jaehwan and Ma, Guang-Qin},
	title = {Spatial cluster detection in mobility networks: a copula approach},
	year = {2019},
	journal = {Journal of the Royal Statistical Society. Series C: Applied Statistics},
	volume = {68},
	number = {1},
	pages = {99 – 120},
	doi = {10.1111/rssc.12307},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052406609&doi=10.1111%2frssc.12307&partnerID=40&md5=8c147eee6e7137c5a656801ed88eba49},
	abstract = {In mobility network capacity planning, characterizing the mobility network traffic is one of the most challenging tasks. Besides the growth trend and multiple periodic temporal patterns for normal traffic, the problem is complicated by the occasionally intense traffic for special events and its dynamic spatial relationships. Identifying the areas that have different traffic patterns compared with their neighbouring areas is a problem of spatial hotspot detection. In the paper, a copula-based method is proposed: using a multivariate extreme value copula, the upper tail dependence of the traffic distributions of neighbouring cell towers is evaluated, and then a cluster of multiple time series (i.e. multiple cell towers) with high upper tail dependence is detected. The method proposed is validated by using synthetic data as well as real mobility traffic data. © 2018 Royal Statistical Society},
	author_keywords = {Hotspot detection; Mobility network; Multivariate extreme value copula; Spatial event detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Shang2018366,
	author = {Shang, Di and Dai, Xin-Yu and Ge, Weiyi and Huang, Shujiang and Chen, Jiajun},
	title = {A multi-view clustering model for event detection in twitter},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10762 LNCS},
	pages = {366 – 378},
	doi = {10.1007/978-3-319-77116-8_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055680784&doi=10.1007%2f978-3-319-77116-8_27&partnerID=40&md5=8c418897ac7df4c24ab626f332da7265},
	abstract = {Event detection in Twitter is an attractive and hard task. Existing methods mainly consider words co-occurrence or topic distribution of tweets to detect the event. Few of them consider the time-series information in the text stream. In this paper, for event detection in twitter, we propose a novel multi-view clustering model which can consider both topic information and time-series information. First, we build a topic similarity matrix and a time-series similarity matrix by using the topic model and the wavelet analysis, respectively. Then, the multi-view clustering algorithms are used to group keywords. Each cluster of keywords is finally represented as an event. The experiments show that our method achieves better performance than other related works. © Springer Nature Switzerland AG 2018.},
	author_keywords = {Multi-view clustering; Time-series; Twitter event detection},
	keywords = {Cluster analysis; Computational linguistics; Social networking (online); Text processing; Time series; Time series analysis; Event detection; Multi-view clustering; Related works; Similarity matrix; Time series informations; Topic distributions; Topic Modeling; Topic similarity; Clustering algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Doubravová2019672,
	author = {Doubravová, Jana and Horálek, Josef},
	title = {Single Layer Recurrent Neural Network for detection of local swarm-like earthquakes - The application},
	year = {2019},
	journal = {Geophysical Journal International},
	volume = {219},
	number = {1},
	pages = {672 – 689},
	doi = {10.1093/gji/ggz321},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096502105&doi=10.1093%2fgji%2fggz321&partnerID=40&md5=da9fdcd943c95012c2962349629243f2},
	abstract = {We present results of applying a local event detector based on artificial neural networks (ANNs) to two seismically active regions. The concept of ANNs enables us to recognize earthquake-like signals in seismograms because well-trained neural networks are characterized by the ability to generalize to unseen examples. This means that once the ANN is trained, in our case by few tens to hundreds of examples of local event seismograms, the algorithm can then recognize similar features in unknown records. The detailed description of the single-station detection, design and training of the ANN has been described in our previous paper. Here we show the practical application of our ANN to the same seismoactive region we used for its training, West Bohemia/Vogtland (border area Czechia-Saxony, local seismic network WEBNET), and to different seismogenic area, Reykjanes Peninsula (South-West Iceland, local seismic network REYKJANET). The training process requires carefully prepared data set which is preferably achieved by manual processing. Such data were available for the West Bohemia/Vogtland earthquake-swarm region, so we used them to train the ANN and test its performance. Due to the absence of completely manually processed activity for the Reykjanes Peninsula, we use the trained ANN for swarm-like activity in such a different tectonic setting. The application of a coincidence of the single-station detections helps to reduce significantly the number of undetected events as well as the number of false alarms. Setting up the minimum number of stations which are required to confirm an event detection enables us to choose the balance between minimum magnitude threshold and a number of false alarms. The ANN detection results for the Reykjanes Peninsula are compared to manual readings on the stations of the REYKJANET network, manual processing from Icelandic regional network SIL (the SIL catalogues by the Icelandic Meteorological Office) and two tested automatic location algorithms. The neural network shows persuasively better detection results in terms of completeness than the SIL catalogues and automatic location algorithms. Subsequently, we show that our ANN is capable of detecting events from various focal zones in West Bohemia/Vogtland although mainly the focal zone of Nový Kostel was used for training. The performance of our detector is comparable to an expert manual processing and we can state that no important event is missed this way even in case of complicated multiple events during the earthquake swarms. © 2019 The Author(s) 2019. Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Earthquake source observation; Neural networks, fuzzy logic; Time-series analysis},
	keywords = {Czech Republic; Germany; Iceland; Reykjanes Peninsula; Saxony; Vogtland; Data handling; Earthquakes; Errors; Multilayer neural networks; Network layers; Signal processing; Automatic location; Earthquake swarms; Manual processing; Number of false alarms; Regional networks; Seismically active region; Tectonic settings; Trained neural networks; algorithm; artificial neural network; detection method; earthquake swarm; fuzzy mathematics; seismic source; seismogram; time series analysis; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Andryukhin20181458,
	author = {Andryukhin, Evgeny V. and Veligura, Aleksandr N.},
	title = {Industrial network anomaly behavior detection via exponential smoothing model},
	year = {2018},
	journal = {Proceedings of the 2018 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering, ElConRus 2018},
	volume = {2018-January},
	pages = {1458 – 1462},
	doi = {10.1109/EIConRus.2018.8317372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047991876&doi=10.1109%2fEIConRus.2018.8317372&partnerID=40&md5=d7c528d0f854a16df43d3b0debfec48f},
	abstract = {There are a lot of network monitors which are capable of performing network packets deep inspection (DPI) as a set of information security check. These steps include intrusion detection system check, exfiltration, detection and parental filtering. However, it is not allowed to use such a slow mechanism as DPI in industrial networks. Hence, architectors have to choose only one of two capabilities of the system: system is required to be fast and fail safe even without any protection mechanisms such as encryption and/or signatures. The proposed approach describes a model of abnormal activity detection, which uses two algorithms to work with industrial network traffic: one is based on Brown's adaptive prediction model and another one based on Support Vector Machine (SVM) predict method. Not typical events detection is demonstrated on test traffic captures. © 2018 IEEE.},
	author_keywords = {anomaly detection; forecasting; industrial network; network traffic; statistical analysis; time series methods},
	keywords = {Cryptography; Forecasting; Network architecture; Network security; Statistical methods; Support vector machines; Time series analysis; Abnormal activity detection; Anomaly detection; Exponential smoothing model; Industrial networks; Information security checks; Intrusion Detection Systems; Network traffic; Time series method; Intrusion detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{2019,
	title = {23rd Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2019},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11439 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064930382&partnerID=40&md5=91a077b67100d7e3c614f3ef8582d643},
	abstract = {The proceedings contain 42 papers. The special focus in this conference is on Knowledge Discovery and Data Mining. The topics include: Syntax-aware representation for aspect term extraction; short text similarity measurement based on coupled semantic relation and strong classification features; a novel hybrid sequential model for review-based rating prediction; integrating topic model and heterogeneous information network for aspect mining with rating bias; dependency-aware attention model for emotion analysis for online news; multi-task learning for target-dependent sentiment classification; Sc-NER: A sequence-to-sequence model with sentence classification for named entity recognition; BAB-QA: A new neural model for emotion detection in multi-party dialogue; unsupervised user behavior representation for fraud review detection with cold-start problem; gated convolutional encoder-decoder for semi-supervised affect prediction; cost sensitive learning in the presence of symmetric label noise; Complaint classification using hybrid-attention GRU neural network; FGST: Fine-grained spatial-temporal based regression for stationless bike traffic prediction; customer segmentation based on transactional data using stream clustering; spatio-temporal event detection from multiple data sources; discovering all-Chain set in streaming time series; hawkes process with stochastic triggering kernel; concept drift based multi-dimensional data streams sampling method; spatial-temporal multi-task learning for within-field cotton yield prediction; online data fusion using incremental tensor learning; co-clustering from tensor data; semantic explanations in ensemble learning; a data-aware latent factor model for web service Qos prediction; keyword extraction with character-level convolutional neural tensor networks; neural variational matrix factorization with side information for collaborative filtering; variational deep collaborative matrix factorization for social recommendation; time-dependent survival neural network for remaining useful life prediction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kidziński2019,
	author = {Kidziński, Łukasz and Delp, Scott and Schwartz, Michael},
	title = {Automatic real-time gait event detection in children using deep neural networks},
	year = {2019},
	journal = {PLoS ONE},
	volume = {14},
	number = {1},
	doi = {10.1371/journal.pone.0211466},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060911007&doi=10.1371%2fjournal.pone.0211466&partnerID=40&md5=8dbd1917a7b372cd33db0be008b80c3d},
	abstract = {Annotation of foot-contact and foot-off events is the initial step in post-processing for most quantitative gait analysis workflows. If clean force plate strikes are present, the events can be automatically detected. Otherwise, annotation of gait events is performed manually, since reliable automatic tools are not available. Automatic annotation methods have been proposed for normal gait, but are usually based on heuristics of the coordinates and velocities of motion capture markers placed on the feet. These heuristics do not generalize to pathological gait due to greater variability in kinematics and anatomy of patients, as well as the presence of assistive devices. In this paper, we use a data-driven approach to predict foot-contact and foot-off events from kinematic and marker time series in children with normal and pathological gait. Through analysis of 9092 gait cycle measurements we build a predictive model using Long Short-Term Memory (LSTM) artificial neural networks. The best-performing model identifies foot-contact and foot-off events with an average error of 10 and 13 milliseconds respectively, outperforming popular heuristic-based approaches. We conclude that the accuracy of our approach is sufficient for most clinical and research applications in the pediatric population. Moreover, the LSTM architecture enables real-time predictions, enabling applications for real-time control of active assistive devices, orthoses, or prostheses. We provide the model, usage examples, and the training code in an open-source package. © 2019 Kidzin´ski et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Adolescent; Adult; Algorithms; Biomechanical Phenomena; Cerebral Palsy; Child; Child, Preschool; Developmental Disabilities; Female; Foot; Gait; Humans; Male; Nervous System Diseases; Neural Networks (Computer); Young Adult; adolescent; adult; algorithm; Article; artificial neural network; automation; child; clinical practice; clinical research; computer heuristics; computer model; controlled study; data analysis software; disease severity; gait; gait disorder; human; kinematics; long term memory; measurement accuracy; population distribution; population research; short term memory; time series analysis; algorithm; biomechanics; cerebral palsy; developmental disorder; female; foot; gait; male; neurologic disease; pathophysiology; physiology; preschool child; young adult},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 60; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sarsam20191,
	author = {Sarsam, Samer Muthana and Al-Samarraie, Hosam and Omar, Bahiyah},
	title = {Geo-spatial-based emotions: A mechanism for event detection in microblogs},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	volume = {Part F147956},
	pages = {1 – 5},
	doi = {10.1145/3316615.3316640},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066036206&doi=10.1145%2f3316615.3316640&partnerID=40&md5=c66ef893a6d7a1da92212b009ff957ce},
	abstract = {The use of emotions in microblogs to trace the occurrence of certain events and determine their locations is an open challenge for sentiment analysis. This study investigated the potential of detecting the geographical location of events based on existing linkages between the types of emotion embedded in tweets (degree of polarity) and the source location of those tweets. The extracted tweets were clustered using K-means algorithm and a predictive model was developed using Naïve Bayes algorithm. Then, a time series forecasting technique was applied using linear regression analysis. This method was used to predict the amount of emotions in association with the event of interest. Latitude and longitude were used to evaluate the results of the linear regression model on a real-time world map. Results showed that happy emotion tends to be a reliable source for detecting the geographical location of an event. This study revealed the feasibility of using the time series forecasting approach in investigating the degree of emotions in twitter messages. © 2019 Association for Computing Machinery.},
	author_keywords = {Microblogs; Polarity; Sentiment analysis; Time series forecasting},
	keywords = {Application programs; Forecasting; K-means clustering; Location; Maps; Predictive analytics; Regression analysis; Sentiment analysis; Time series; Bayes algorithms; Geographical locations; Linear regression models; Microblogs; Polarity; Predictive modeling; Source location; Time series forecasting; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Mahfoud20181300,
	author = {Mahfoud, Elias and Wegba, Kodzo and Li, Yuemeng and Han, Honglei and Lu, Aidong},
	title = {Immersive visualization for abnormal detection in heterogeneous data for on-site decision making},
	year = {2018},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2018-January},
	pages = {1300 – 1309},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065581858&partnerID=40&md5=ec1e9fcb3f5c6415f7c9f09fff748b03},
	abstract = {The latest advances in mixed reality promote new capabilities that allow head-mounted displays, such as Microsoft HoloLens, to visualize various data and information in a real physical environment. While such new features have great potential for new generations of visualization systems, they require fundamentally different visualization and interaction techniques that have not been well explored. This paper presents an immersive visualization approach for investigating abnormal events in heterogeneous, multi-source, and time-series sensor data collections in real-time on the site of the event. Our approach explores the essential components for an analyst to visualize complex data and explore hidden connections in mixed reality; it also combines automatic event detection algorithms to identify suspicious activities. We demonstrate our prototype system by using the developer version of Microsoft HoloLens and presenting case studies that require an analyst to investigate related data on site. We also discuss the limitations of the current infrastructure and potential applications for security visualization. © 2018 IEEE Computer Society. All rights reserved.},
	keywords = {Decision making; Helmet mounted displays; Mixed reality; Visualization; Event detection algorithm; Head mounted displays; Immersive visualization; Interaction techniques; Physical environments; Security visualization; Sensor data collections; Visualization system; Data visualization},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Nguyen2018429,
	author = {Nguyen, Minh and Logofătu, Doina},
	title = {Applying Tree Ensemble to Detect Anomalies in Real-World Water Composition Dataset},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11314 LNCS},
	pages = {429 – 438},
	doi = {10.1007/978-3-030-03493-1_45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057126958&doi=10.1007%2f978-3-030-03493-1_45&partnerID=40&md5=dd51ee676de5b05ba36e013e12b60e69},
	abstract = {Drinking water is one of fundamental human needs. During delivery in distribution network, drinking water is susceptible to contaminants. Early recognition of changes in water quality is essential in the provision of clean and safe drinking water. For this purpose, Contamination warning system (CWS) composed of sensors, central database and event detection system (EDS) has been developed. Conventionally, EDS employs time series analysis and domain knowledge for automated detection. This paper proposes a general data driven approach to construct an automated online event detention system for drinking water. Various tree ensemble models are investigated in application to real-world water quality data. In particular, gradient boosting methods are shown to overcome challenges in time series data imbalanced class and collinearity and yield satisfied predictive performance. © 2018, Springer Nature Switzerland AG.},
	author_keywords = {Anomaly detection; Class imbalance; Contamination; Gradient boosting; Random forest; Time series; Tree ensemble; Water quality},
	keywords = {Automation; Contamination; Decision trees; Forestry; Pollution detection; Time series; Time series analysis; Water quality; Anomaly detection; Class imbalance; Gradient boosting; Random forests; Tree ensembles; Potable water},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Afzalan201995,
	author = {Afzalan, Milad and Jazizadeh, Farrokh and Wang, Jue},
	title = {Self-configuring event detection in electricity monitoring for human-building interaction},
	year = {2019},
	journal = {Energy and Buildings},
	volume = {187},
	pages = {95 – 109},
	doi = {10.1016/j.enbuild.2019.01.036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061198910&doi=10.1016%2fj.enbuild.2019.01.036&partnerID=40&md5=5a3ef05aaae9ed41b491fcdfd03f1742},
	abstract = {Monitoring the temporal changes in the operational states of appliances is a key step in inferring the dynamics of operations in smart homes. This information could be leveraged in a variety of energy management applications including energy breakdown of individual loads, inferring the occupancy patterns, and associating the energy use to occupants’ activities. The operational states of appliances could be identified through detecting and classifying the events on power time-series. Despite the advancements in the field of event detection, they often require in-situ configuration of model parameters to achieve a higher level of performance according to each new context. In order to address such limitation, in this paper, we have proposed a self-configuring event detection framework for detecting the changes in operational states of appliances. The framework seeks to autonomously learn the contextual characteristics of the loads from the environment and adapt the event detection parameters. The proposed unsupervised framework couples an automated clustering for identifying the recurring motifs, which are representations of the appliances’ transient power draw signatures in a given environment and a proximity-based motif matching for detecting the events. The framework was evaluated on EMBED dataset, a publicly available fully labeled electricity disaggregation dataset, collected from three apartments with different categories of the appliances. The evaluations demonstrate that the proposed event detection framework outperforms the conventional event detection in detecting the operational states of different classes of loads across different environments. The proposed framework could also facilitate human-building interactions in training smart home applications by populating motifs to infer the operations of appliances and activities of occupants. © 2019 Elsevier B.V.},
	author_keywords = {Clustering; Electricity disaggregation; Event detection; Non-intrusive load monitoring; Unsupervised learning},
	keywords = {Automation; Energy utilization; Intelligent buildings; Unsupervised learning; Automated clustering; Clustering; Disaggregation; Electricity monitoring; Event detection; Management applications; Nonintrusive load monitoring; Operational state; Electric load management},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@ARTICLE{Stelter2018320,
	author = {Stelter, Simon and Bartels, Georg and Beetz, Michael},
	title = {Multidimensional Time-Series Shapelets Reliably Detect and Classify Contact Events in Force Measurements of Wiping Actions},
	year = {2018},
	journal = {IEEE Robotics and Automation Letters},
	volume = {3},
	number = {1},
	pages = {320 – 327},
	doi = {10.1109/LRA.2017.2716423},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061750539&doi=10.1109%2fLRA.2017.2716423&partnerID=40&md5=70ef783ae99df6bb218a685d07599b4a},
	abstract = {The vision of service robots that autonomously manipulate objects as skillfully and flexibly as humans is still an open challenge. Findings from cognitive psychology suggest that the human brain structures manipulation actions along representations of contact events and their perceptually distinctive sensory signals. In this letter, we investigate how to reliably detect and classify contact events during robotic wiping actions. We present an algorithm that learns the distinct shapes of force measurements during contact events using multidimensional time-series shapelets. We evaluate our approach on a dataset consisting of 460 real-world robot wiping episodes that we collected using a table-mounted robot with a wrist-mounted force/torque sensor. Our approach shows good performance with tenfold cross validation yielding 97.5% precision and 99.3% recall, and can also be used for online contact event detection and classification. © 2017 IEEE.},
	author_keywords = {Force and tactile sensing; learning and adaptive systems; service robots},
	keywords = {Force measurement; Mobile robots; Cognitive psychology; Cross validation; Force/torque sensor; Learning and adaptive system; Multidimensional time series; Sensory signals; Service robots; Tactile sensing; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Humm2019398,
	author = {Humm, Bernhard G. and Van Der Meer, Guglielmo},
	title = {Detecting domain-specific events based on robot sensor data},
	year = {2019},
	journal = {ICINCO 2019 - Proceedings of the 16th International Conference on Informatics in Control, Automation and Robotics},
	volume = {1},
	pages = {398 – 405},
	doi = {10.5220/0007952503980405},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073116965&doi=10.5220%2f0007952503980405&partnerID=40&md5=88b349365a6291c71bba554fcdc9a687},
	abstract = {This paper presents an approach for detecting domain-specific events based on robot sensor data. Events may be error situations as well as successfully executed manufacturing steps, depending on the application domain at hand. The approach includes segmenting streams of sensor data into meaningful intervals and subsequently matching patterns on those segments. Pattern matching is performed in near real-time allowing events to be detected continuously during the execution of a robotics application. The approach is demonstrated by means of a real-world manufacturing use case, namely the automated assembly of electrical components by a robot. The approach has been implemented prototypically had has been evaluated successfully. Copyright © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Complex event detection; Robots; Time series},
	keywords = {Manufacture; Pattern matching; Robotics; Time series; Automated assembly; Complex event detection; Domain specific; Electrical components; Matching patterns; Near-real time; Robot sensors; Robotics applications; Robots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Eswaran20191030,
	author = {Eswaran, Dhivya and Faloutsos, Christos and Mishra, Nina and Naamad, Yonatan},
	title = {Intervention-aware early warning},
	year = {2019},
	journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
	volume = {2019-November},
	pages = {1030 – 1035},
	doi = {10.1109/ICDM.2019.00119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078895111&doi=10.1109%2fICDM.2019.00119&partnerID=40&md5=c7d163bbb756332b1834e0f4eff13707},
	abstract = {How can we early warn against an impending student drop out or an adverse health condition in near real-time? More challengingly, how do we learn to early warn from data containing confounding interventions-e.g., tutoring or medicines-while remaining interpretable to the human decision maker? We consider the problem of learning to interpretably early warn from labeled data tainted by interventions. We first identify three principles that an early warning system should follow. We then propose SmokeAlarm which provably obeys these principles and produces early warning scores in an online manner. Notably, learned model is 'bi-inspectable', i.e., it can be visualized both in the presence and in the absence of interventions. Experiments demonstrate the efficacy of SmokeAlarm over prior approaches. © 2019 IEEE.},
	author_keywords = {Early prediction; Early warning; Event detection; Intervention awareness; Time series},
	keywords = {Decision making; Smoke; Time series; Early prediction; Early warning; Early warning score; Early Warning System; Event detection; Health condition; Human decisions; Intervention awareness; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xu20186393,
	author = {Xu, Qinyi and Han, Yi and Wang, Beibei and Wu, Min and Liu, K.J. Ray},
	title = {Real-Time Indoor Event Monitoring Using CSI Time Series},
	year = {2018},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	volume = {2018-April},
	pages = {6393 – 6397},
	doi = {10.1109/ICASSP.2018.8461521},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054205885&doi=10.1109%2fICASSP.2018.8461521&partnerID=40&md5=798558d521001a07b39ecb780b4958e9},
	abstract = {Environmental information is recorded in the multipath propagation, and can be accessed in the form of channel state information (CSI) through commodity WiFi devices. A single CSI reading for event detection is adopted in most existing CSI based indoor monitoring system. However, due to the impact of noise, event inconsistency and environmental dynamics, this type of approaches is not very robust. In this work, we design efficient algorithms to fully exploit the information embedded in the CSI time series to combat interference introduced by CSI perturbations, and propose an indoor event monitoring system that achieves accurate real-time monitoring. The accuracy and robustness of the proposed system is evaluated through experiments, which illustrate its potential in future smart home applications. © 2018 IEEE.},
	author_keywords = {Indoor event monitoring; Real-time monitoring; Smart radio},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sun2018xi,
	author = {Sun, Wei and Sun, Yonghua and Zhang, Youquan and Qiu, Qi and Wang, Tao and Wang, Yanbing},
	title = {Ground validation of GPM IMERG rainfall products over the Capital Circle in Northeast China on rainstorm monitoring},
	year = {2018},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {10783},
	pages = {xi},
	doi = {10.1117/12.2500087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056478243&doi=10.1117%2f12.2500087&partnerID=40&md5=19e62ddca07c7147a282bacea28d1f28},
	abstract = {Obtaining accurate satellite precipitation data is crucial for monitoring flood and flood disasters and analysing climate change. As a new generation of satellite precipitation product, global rainfall observation program GPM is integrated with advanced microwave detection technology and data correction algorithm, providing more choices for studying precipitation in global regions. The main purpose of this paper is to evaluate the adaptability of GPM three-stage precipitation product IMERG (Final Run mode) at different temporal resolutions in the Beijing-Tianjin-Hebei region. After screening, the precipitation data of 107 national meteorological stations in the Beijing-Tianjin-Hebei region was used as the verification data, and the detection capability of GPM satellite precipitation data in different time scales of day, month and season as well as extreme precipitation events was analysed. The following conclusions were obtained: (1) Compared with the IMERG products with half-hourly and daily temporal resolution, the IMERG satellite precipitation data with 1month temporal resolution has a strong correlation, reaching 0.90. It can reflect the precipitation event accurately in the Beijing-Tianjin-Hebei region. The poor performance of IMERG satellite is concentrated in the north-western and south-eastern edges of the Beijing-Tianjin-Hebei region.(2) The performance of IMERG precipitation data in the humid season on the monthly scale is better than that in the dry season, and GPM satellite precipitation data are generally overestimated.(3) In the process of extreme precipitation event detection using 0.5h temporal resolution data, the tendency of IMERG satellite precipitation data to accumulate precipitation is roughly consistent with that of the station, but the phenomenon of overestimation still exists, especially in places with large precipitation, overestimation is more obvious. In view of this precipitation event, satellite precipitation data covers almost the entire precipitation process, and some values are still high. Although the data has good detection capability for extreme precipitation events, the monitoring of precipitation peak is not accurate enough. According to the comprehensive analysis, its Final GPM product has a strong ability to detect rainfall events, which can provide data support for the long time series analysis in the Beijing-Tianjin-Hebei region. © SPIE. Downloading of the abstract is permitted for personal use only.},
	author_keywords = {Adaptability; Beijing-Tianjin-Hebei; Extreme precipitation; GPM},
	keywords = {Agriculture; Climate change; Ecosystems; Floods; Rain; Remote sensing; Soil moisture; Storms; Time series analysis; Adaptability; Beijing-tianjin-hebei regions; Extreme precipitation; Extreme precipitation events; Precipitation products; Satellite precipitation; Satellite precipitation products; Tianjin; Satellites},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Marmelat2019,
	author = {Marmelat, Vivien and Duncan, Austin and Meltz, Shane},
	title = {Effect of sampling frequency on fractal fluctuations during treadmill walking},
	year = {2019},
	journal = {PLoS ONE},
	volume = {14},
	number = {11},
	doi = {10.1371/journal.pone.0218908},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074631868&doi=10.1371%2fjournal.pone.0218908&partnerID=40&md5=5081d8bca23451f82a0bb8581ff3b3f8},
	abstract = {The temporal dynamics of stride-to-stride fluctuations in steady-state walking reveal important information about locomotor control and can be quantified using so-called fractal analyses, notably the detrended fluctuation analysis (DFA). Gait dynamics are often collected during treadmill walking using 3-D motion capture to identify gait events from kinematic data. The sampling frequency of motion capture systems may impact the precision of event detection and consequently impact the quantification of stride-to-stride variability. This study aimed i) to determine if collecting multiple walking trials with different sampling frequency affects DFA values of spatiotemporal parameters during treadmill walking, and ii) to determine the reliability of DFA values across downsampled conditions. Seventeen healthy young adults walked on a treadmill while their gait dynamics was captured using different sampling frequency (60, 120 and 240 Hz) in each condition. We also compared data from the highest sampling frequency to downsampled versions of itself. We applied DFA to the following time series: step length, time and speed, and stride length, time and speed. Reliability between experimental conditions and between downsampled conditions were measured with 1) intraclass correlation estimates and their 95% confident intervals, calculated based on a single-measurement, absolute-agreement, two-way mixed-effects model (ICC 3,1), and 2) Bland-Altman bias and limits of agreement. Both analyses revealed a poor reliability of DFA results between conditions using different sampling frequencies, but a relatively good reliability between original and downsampled spatiotemporal variables. Collectively, our results suggest that using sampling frequencies of 120 Hz or 240 Hz provide similar results, but that using 60 Hz may alter DFA values. We recommend that gait kinematics should be collected at around 120 Hz, which provides a compromise between event detection accuracy and processing time. © 2019 Marmelat et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Adult; Biomechanical Phenomena; Exercise Test; Female; Fractals; Gait; Humans; Male; Reproducibility of Results; Walking; Young Adult; adult; Article; controlled study; detrended fluctuation analysis; exercise test; female; fractal analysis; human; human experiment; kinematics; male; normal human; sampling; self report; spatiotemporal analysis; step length; step time; stride length; stride time; treadmill exercise; walking speed; young adult; biomechanics; fractal analysis; gait; physiology; procedures; reproducibility; walking},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Attal20184011,
	author = {Attal, Ferhat and Boubezoul, Abderrahmane and Same, Allou and Oukhellou, Latifa and Espie, Stephane},
	title = {Powered two-wheelers critical events detection and recognition using data-driven approaches},
	year = {2018},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	volume = {19},
	number = {12},
	pages = {4011 – 4022},
	doi = {10.1109/TITS.2018.2797065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042177444&doi=10.1109%2fTITS.2018.2797065&partnerID=40&md5=75be4556a7b31733f2a9668e9bbff65f},
	abstract = {Driving errors are considered to be the greatest contributory cause in all road accidents and an important contributory cause of most fatal accidents. This is particularly the case for the users of powered two-wheeled vehicles (PTWs), perhaps because PTW riders play a greater role in the control of their vehicles' stability than four-wheeled vehicle drivers. Thus, observing and analyzing the evolution of riders' behavior in a real-life context is an important step in the identification of the road environment characteristics that constitute a risk factor for PTW riders. A relevant research issue in naturalistic studies is related to the detection and identification of critical riding events from among the vast amount of data recorded during the experiment. In this paper, two approaches were used to automatically detect such critical riding events. First, we formalized this problem in terms of detecting changes in the mean and variance of the signals generated by the acceleration and angular velocity sensors. For this purpose, two steps were performed: 1) a data segmentation and feature extraction step in which the multidimensional time series of accelerometer and angular velocity data were segmented and modeled using a Gaussian mixture model with quadratic logistic proportions; and 2) a classification step in which each detected segment was assigned to the appropriate riding sequence, whether 'naturalistic' or 'critical' (i.e., fall or near fall), using the k-nearest neighbor algorithm. The second approach was based on online fall detection. This methodology used control charts (a multivariate cumulative sum), an approach that has been traditionally employed for sequential detection. These two algorithms were applied to a database composed of data from a real-life driving experiment. The obtained results show the effectiveness of both methodologies. © 2000-2011 IEEE.},
	author_keywords = {critical events detection and recognition; data mining approaches; Powered two-wheelers},
	keywords = {Acceleration; Accident prevention; Accidents; Angular velocity; Feature extraction; Gaussian distribution; Highway accidents; Nearest neighbor search; Roads and streets; Sensors; Vehicles; Acceleration and angular velocity sensors; Critical events; Detection and identifications; Event detection; K nearest neighbor algorithm; Multidimensional time series; Roads; Two wheelers; Data mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@ARTICLE{Linville20181514,
	author = {Linville, Lisa M. and Pankow, Kristine L. and Kilb, Debi L.},
	title = {Contour-based frequency-domain event detection for seismic arrays},
	year = {2018},
	journal = {Seismological Research Letters},
	volume = {89},
	number = {4},
	pages = {1514 – 1523},
	doi = {10.1785/0220170242},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049792128&doi=10.1785%2f0220170242&partnerID=40&md5=a0a66a5e15f6876c7fec81c9d9358f74},
	abstract = {We develop a frequency-domain array-based detection algorithm that exploits the gridded station configuration (interstation spacing of 70 km) of the EarthScopeTransportable Array to detect and locate small magnitude (M < 2:5) earthquakes.Our method uses the geographic extent of frequency-amplitude time-series data to determine epicentral locations for events regardless of their ability to generate impulsive amplitude excursions at multiple stations. We apply the method to three sedimentary basins in the central United States (CUS), finding a total of 484 new earthquakes. Our results identify new seismicity in all three sedimentary basins but disproportionate increases in seismicity between regions (Williston basin: 50%, Permian: 300%, Denver: 1000%). A majority of the newly detected seismicity in the Permian and Denver-Julesburg basins may be linked to active wells, while there continues to be a lack of evidence for induced seismicity in theWilliston basin. We also apply this method to a dataset from Yellowstone National Park with average interstation distances of 80 m. Results from the Yellowstone data demonstrate that when array station spacing remains regular, events from nonearthquake sources such as hydrothermal features can be successfully detected and located without the necessity to tune parameters for specific sources. The capability to generalize across source types makes this algorithm potentially useful for signal exploration when signal characteristics are unknown. © 2018 Seismological Society of America. All rights reserved.},
	keywords = {United States; Williston Basin; Yellowstone National Park; Frequency domain analysis; Sedimentology; Settling tanks; Detection algorithm; Event detection; Frequency domains; Sedimentary basin; Signal characteristic; Time-series data; Williston basin; Yellowstone national parks; algorithm; array; detection method; earthquake epicenter; frequency-magnitude distribution; sedimentary basin; seismic data; time series; Induced Seismicity},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Keshri2019141,
	author = {Keshri, Suraj and Oh, Min-Hwan and Zhang, Sheng and Iyengar, Garud},
	title = {Automatic event detection in basketball using HMM with energy based defensive assignment},
	year = {2019},
	journal = {Journal of Quantitative Analysis in Sports},
	volume = {15},
	number = {2},
	pages = {141 – 153},
	doi = {10.1515/jqas-2017-0126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062466652&doi=10.1515%2fjqas-2017-0126&partnerID=40&md5=f934440cb2704976cc8261db9430bcdd},
	abstract = {We propose a unsupervised learning framework for automatically labeling events in a basketball game. Our framework uses the the optical player tracking data in the NBA. We first learn the time series of defensive assignments using a novel player and location dependent attraction based model which uses hidden Markov models (HMMs), Gaussian processes, and a "bond breaking" model for changes in defensive assignments. Next, we use the learned defensive assignments as an input to a set of HMMs that automatically detect events such as ball screens, drives and post-ups. We show that our models provide significant improvements over existing benchmarks both on defensive assignments and event detection. © 2019 Walter de Gruyter GmbH, Berlin/Boston.},
	author_keywords = {defensive assignment; gaussian process; HMM; NBA; unsupervised learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Berrios2018,
	author = {Berrios, Jorge and Wallace, Scott and Zhao, Xinghui and Cotilla-Sanchez, Eduardo and Bass, Robert B.},
	title = {Generator Event Detection from Synchrophasor Data Using a Two-Step Time-Series Machine Learning Algorithm},
	year = {2018},
	journal = {2018 9th International Green and Sustainable Computing Conference, IGSC 2018},
	doi = {10.1109/IGCC.2018.8752121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069497350&doi=10.1109%2fIGCC.2018.8752121&partnerID=40&md5=d541fe3377586f4d02c5ef70a1163a15},
	abstract = {The electrical faults of generators on an electrical grid, i.e., generator events (GE), must be detected efficiently when they occur, as these events can propagate to the rest of the grid in a cascading manner, leading to outages and wide-area blackouts. Many reasons exist that give rise to these faults, but at its most fundamental, they constitute an inability of a generator to match the grid usage requirements. In this paper, we present an efficient algorithm to accurately identify the occurrence of generator events within an electrical grid, using the monitoring data obtained from phasor measurement units (PMUs). Specifically, we have developed a machine learning algorithm that takes as input PMU data, and subsequently flags instances where a GE had taken place. The detection is performed in near real-time with the help of a standard off-the-shelf processing unit. Furthermore, we set out to create electrical fault maps that demarcate the progression of the event as it takes place. Experimental results show that our algorithm can accurately and efficiently identify the occurrence of a GE. In addition, we are also able to report a fault network map, which provides a powerful tool for troubleshooting. © 2018 IEEE.},
	author_keywords = {generator event; machine learning; phasor measurement unit},
	keywords = {Electric power transmission networks; Green computing; Learning systems; Machine learning; Phase measurement; Phasor measurement units; Electrical faults; Electrical grids; Event detection; generator event; Phasor measurement unit (PMUs); Processing units; Synchrophasor datum; Wide area blackout; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Umeda2018489,
	author = {Umeda, Shogo and Kawasaki, Yosuke and Kuwahara, Masao and Iihoshi, Akira},
	title = {Construction of road anomaly event detection method for occurrences of disasters via state-space model that utilizes weather and probe data},
	year = {2018},
	journal = {Transportation Systems in the Connected Era - Proceedings of the 23rd International Conference of Hong Kong Society for Transportation Studies, HKSTS 2018},
	pages = {489 – 496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064662843&partnerID=40&md5=02482628bd025b77116e8b5ab80c03aa},
	abstract = {In this research we propose a method to detect road abnormality events (standstill) in the event of natural disasters, using weather data and probe data. The proposed method compares the predicted value by the state space model with the filtered estimator and detects abnormality when the deviation is large. The proposed method was applied to cases of standstill at heavy snow occurring in Fukui and Tokyo, and showed that abnormality can be detected before standstill happening. In addition, we compare the accuracy of abnormality detection between the proposed method and the conventional time series model, and the proposed method has higher prediction accuracy. © 2018 Transportation Systems in the Connected Era - Proceedings of the 23rd International Conference of Hong Kong Society for Transportation Studies, HKSTS 2018. All rights reserved.},
	author_keywords = {Disaster; Probe Data; Risk Analysis; State Space Model; Time Series Analysis},
	keywords = {Disasters; Probes; Risk analysis; Risk assessment; Roads and streets; State space methods; Abnormality detection; Event detection; Natural disasters; Prediction accuracy; State - space models; Time series modeling; Weather data; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Amornbunchornvej2018,
	author = {Amornbunchornvej, Chainarong and Brugere, Ivan and Strandburg-Peshkin, Ariana and Farine, Damien R. and Crofoot, Margaret C. and Berger-Wolf, Tanya Y.},
	title = {Coordination event detection and initiator identification in time series data},
	year = {2018},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	volume = {12},
	number = {5},
	doi = {10.1145/3201406},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060597224&doi=10.1145%2f3201406&partnerID=40&md5=ac873101003def3c4b02b374a0582198},
	abstract = {Behavior initiation is a form of leadership and is an important aspect of social organization that affects the processes of group formation, dynamics, and decision-making in human societies and other social animal species. In this work, we formalize the Coordination Initiator Inference Problem and propose a simple yet powerful framework for extracting periods of coordinated activity and determining individuals who initiated this coordination, based solely on the activity of individuals within a group during those periods. The proposed approach, given arbitrary individual time series, automatically (1) identifies times of coordinated group activity, (2) determines the identities of initiators of those activities, and (3) classifies the likely mechanism by which the group coordination occurred, all of which are novel computational tasks.We demonstrate our framework on both simulated and real-world data: trajectories tracking of animals as well as stock market data. Our method is competitive with existing global leadership inference methods but provides the first approaches for local leadership and coordination mechanism classification. Our results are consistent with ground-truthed biological data and the framework finds many known events in financial data which are not otherwise reflected in the aggregate NASDAQ index. Our method is easily generalizable to any coordinated time series data from interacting entities. © 2018 ACM.},
	author_keywords = {Coordination; Influence; Leadership; Time series},
	keywords = {Animals; Decision making; Coordinated activity; Coordination; Coordination mechanisms; Group coordination; Influence; Interacting entities; Leadership; Social organizations; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Park2019,
	author = {Park, Pangun and Di Marco, Piergiuseppe and Shin, Hyejeon and Bang, Junseong},
	title = {Fault detection and diagnosis using combined autoencoder and long short-term memory network},
	year = {2019},
	journal = {Sensors (Switzerland)},
	volume = {19},
	number = {21},
	doi = {10.3390/s19214612},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074167310&doi=10.3390%2fs19214612&partnerID=40&md5=a0a4c81dc0c3a297ca836a257d5f0f24},
	abstract = {Fault detection and diagnosis is one of the most critical components of preventing accidents and ensuring the system safety of industrial processes. In this paper, we propose an integrated learning approach for jointly achieving fault detection and fault diagnosis of rare events in multivariate time series data. The proposed approach combines an autoencoder to detect a rare fault event and a long short-term memory (LSTM) network to classify different types of faults. The autoencoder is trained with offline normal data, which is then used as the anomaly detection. The predicted faulty data, captured by autoencoder, are put into the LSTM network to identify the types of faults. It basically combines the strong low-dimensional nonlinear representations of the autoencoder for the rare event detection and the strong time series learning ability of LSTM for the fault diagnosis. The proposed approach is compared with a deep convolutional neural network approach for fault detection and identification on the Tennessee Eastman process. Experimental results show that the combined approach accurately detects deviations from normal behaviour and identifies the types of faults within the useful time. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Autoencoder; Fault detection; Fault diagnosis; Long short-term memory; Rare event; Time delay},
	keywords = {Accident prevention; Anomaly detection; Brain; Deep neural networks; Failure analysis; Long short-term memory; Time delay; Time series; Auto encoders; Convolutional neural network; Fault detection and diagnosis; Fault detection and identification; Multivariate time series; Rare event; Tennessee Eastman process; Time series learning; article; autoencoder; convolutional neural network; learning; long short term memory network; Tennessee; time series analysis; Fault detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 108; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Doltsinis2018,
	author = {Doltsinis, Stefanos and Krestenitis, Marios and Doulgeri, Zoe},
	title = {Real-Time Event Detection in Time-Series Classification Based on Amplitude Rejection},
	year = {2018},
	journal = {2018 IEEE (SMC) International Conference on Innovations in Intelligent Systems and Applications, INISTA 2018},
	doi = {10.1109/INISTA.2018.8466266},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055529636&doi=10.1109%2fINISTA.2018.8466266&partnerID=40&md5=8cfb615e0d7f2eae437590bc9893691c},
	abstract = {Classification methods are widely used in several types of applications and a lot of research works report highly accurate results on their ability to predict in unseen data. However, results are usually based on strong assumptions related to data preprocessing that might not hold in real world applications. The training set in practice can significantly differ to that of testing, especially when the classification process is carried out in real-time and the required preprocessing is not applicable without prior knowledge on the testing signals such as its length and amplitude. Sampling methods like sliding or additive window are usually employed, but not always resolve the problem that in many cases results in false positives. This work proposes an algorithm for real-time classification of signals with unknown length, based on a feature transformation that enables the classifier only when the signal's amplitude is within the expected event range. The proposed transformation can be used to generalize a classifier in similar data by only requiring knowledge of the expected event amplitude. The real-time performance of the proposed algorithm is evaluated in two industrial processes and its generalization ability in two novel (a synthetic and an industrial) data sets. © 2018 IEEE.},
	keywords = {Intelligent systems; Metadata; Classification methods; Classification process; Feature transformations; Generalization ability; Industrial processs; Real time performance; real-Time event detections; Time series classifications; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hong2019203,
	author = {Hong, Dezhi and Cai, Renqin and Wang, Hongning and Whitehouse, Kamin},
	title = {Learning from correlated events for equipment relation inference in buildings},
	year = {2019},
	journal = {BuildSys 2019 - Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
	pages = {203 – 212},
	doi = {10.1145/3360322.3360852},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077259574&doi=10.1145%2f3360322.3360852&partnerID=40&md5=c2ab4d4665a1cac0b7d8d5d25193ed4f},
	abstract = {Modern buildings produce thousands of data streams, and the ability to automatically infer the physical context of such data is the key to enabling building analytics at scale. As acquiring this contextual information is currently a time-consuming and error-prone manual process, in this study we make the first attempt at automatically inferring one important contextual aspect of the equipment in buildings - - how each equipment is functionally connected with another. The main insight behind our solution is that functionally connected equipment is exposed to the same events in the physical world, creating correlated changes in the time series data of both equipment. Because events are of indeterminate length in time series, however, identifying them requires solving a non-polynomial combinatorial data segmentation problem. We present a solution that first extracts latent events from the sensory time series data, and then sifts out coincident events with a customized correlation procedure to identify the relationship between equipment. We evaluated our approach on data collected from over 1,000 pieces of equipment from 5 commercial buildings of various sizes located in different geographical regions in the US. Results show that this approach achieves 94.38% accuracy in relation inference, compared to 85.49% by the best baseline. © 2019 ACM.},
	author_keywords = {Event detection; Probabilistic modeling; Relation inference; Smart buildings; Time series analysis},
	keywords = {Geographical regions; Intelligent buildings; Office buildings; Time series analysis; Commercial building; Contextual information; Data segmentation; Event detection; Modern buildings; Probabilistic modeling; Relation inference; Time-series data; Energy efficiency},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Sahani2019,
	author = {Sahani, Mrutyunjaya and Dash, P.K.},
	title = {Fault location estimation for series-compensated double-circuit transmission line using parameter optimized variational mode decomposition and weighted P-norm random vector functional link network},
	year = {2019},
	journal = {Applied Soft Computing Journal},
	volume = {85},
	doi = {10.1016/j.asoc.2019.105860},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074386408&doi=10.1016%2fj.asoc.2019.105860&partnerID=40&md5=c65451f0f6a41c48fc2c13a27a520b8f},
	abstract = {In this paper, both the proposed parameter optimized variational mode decomposition (POVMD) and weighted P-norm random vector functional link network (WPRVFLN) are integrated for fault detection, location estimation, and classification in a series capacitor compensated double circuit transmission line (SCCDCTL). The required number of decomposition is determined from the magnitude spectrum of full-cycle current signals from the point of fault inception. An entropy index is used to obtain the optimum value of data-fidelity factor for extracting the most suitable band-limited intrinsic mode functions (BLIMFs). The four efficacious features namely standard deviation of the magnitude, energy, Renyi entropy and crest factor are computed from the Hilbert transformed array of the BLIMFs to construct the feature vector. A diagonal matrix W is computed based on zero sequence current of the original current signals as a weighting factor to categorize the ground fault accurately. Numerous faults are generated with a wide variation of the system conditions in MATLAB/Simulink simulation environment. An efficient WPRVFLN computational intelligence technique is proposed to recognize the fault by taking the extracted feature vector with weight factor, and its performances are compared with the recently developed classifiers in the MATLAB interface. The lesser computational complexity, faster learning speed, superior fault location estimation accuracy, and short event detection time prove that the proposed POVMD–WPRVFLN method can be implemented in the real power system for online fault recognition. Finally, the feasibility of the proposed method is tested and validated by using the fast FPGA digital circuitry in a loop. © 2019 Elsevier B.V.},
	author_keywords = {Random vector functional link network; Real-time analysis; Series capacitor compensated double circuit transmission line; Variational mode decomposition},
	keywords = {Computational efficiency; Electric grounding; Electric lines; Location; MATLAB; Parameter estimation; Time series analysis; Timing circuits; Vectors; Computational intelligence techniques; Double-circuit transmission lines; Fault location estimation; Functional-link network; Intrinsic Mode functions; Matlab/Simulink simulation; Mode decomposition; Real time analysis; Fault detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{Wang20192674,
	author = {Wang, Uantong and Zhang, Zhongping and Lin, Youzuo},
	title = {EarthquakeGen: Earthquake Generator Using Generative Adversarial Networks},
	year = {2019},
	journal = {SEG Technical Program Expanded Abstracts},
	pages = {2674 – 2678},
	doi = {10.1190/segam2019-3216687.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121856251&doi=10.1190%2fsegam2019-3216687.1&partnerID=40&md5=054bcacc1e3ad6ad220f7713e1da1305},
	abstract = {Kanhquakc event detection in seismic time series data is an important and challenging problem. The current stale-of-the-art machine-learning based detection methods mostly belong to supervised learning category and lhe detection accuracy highly relics on the quality and quantity of the labeled data. However, acquisition of high-quality training set can be technical challenging and expensive in that it requires intensive training on domain knowledge. Therefore, expanding Ihc dalasel with artificially generated labeled data can be extremely useful. In this paper, we develop an earthquake generator, EarthquakeGen, by using generative adversaria] networks (GAN). GAN is a recently raised generative model based on neural network. By training in a minmax game process, GAN is able to produce samples looks similar but actually different with the real ones. To verify the performance of our HarthquakeGen, we apply it to seismic field data acquired at Oklahoma, where induced earthquake events have been reported. Through our numerical results, we show- that our BarlhquakeGen can yield high-quality artificial earthquakes. More importantly, wc show that the earthquake detection accuracy can be significantly improved by using augmented training sets combining both artificial and real samples. © 2019 SEG},
	keywords = {Domain Knowledge; Generative adversarial networks; 'current; Detection accuracy; Detection methods; Domain knowledge; Events detection; High quality; Labeled data; Quality training; Time-series data; Training sets; Earthquakes},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Wang2019,
	author = {Wang, Zhihong and Guo, Yi and Li, Zhen and Tang, Minwei and Qi, Tianmei and Wang, Jixiang},
	title = {Research on Microblog Rumor Events Detection via Dynamic Time Series Based GRU Model},
	year = {2019},
	journal = {IEEE International Conference on Communications},
	volume = {2019-May},
	doi = {10.1109/ICC.2019.8761457},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070217617&doi=10.1109%2fICC.2019.8761457&partnerID=40&md5=f53061ab3d71ac1f7337fa565d1cfbf7},
	abstract = {The convenience of online social media in communication and information dissemination has made it an ideal place for spreading rumor events and automatically debunking rumor events is a crucial problem. However, it is a challenging task to employ traditional classification approaches to rumor events detection since they rely on hand-crafted features which require daunting manual efforts. Besides, the various posts on a rumor event will debate its realness over time, and the distribution of the posts is special in time dimension. Thus, this paper presents a novel method for rumor event detection based on a dynamic time series (DTS) algorithm and a two layer Gated Recurrent Unit (GRU) model, named 2-GRU-DTS. The proposed model uses the DTS algorithm to retain the distribution information of social events over time and uses the two layers GRU model to learn the hidden event representations. Experimental results on real datasets from Sina Weibo demonstrate that our proposed 2-GRU-DTS model outperforms latest rumor event detection algorithms. © 2019 IEEE.},
	keywords = {Information dissemination; Social networking (online); Classification approach; Event detection; Event detection algorithm; Event representations; Events detection; Online social medias; Real data sets; Time dimension; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Zhang201990863,
	author = {Zhang, Cong and Liu, Yuanan and Wu, Fan and Fan, Wenhao and Tang, Jielong and Liu, Haosong},
	title = {Multi-Dimensional Joint Prediction Model for IoT Sensor Data Search},
	year = {2019},
	journal = {IEEE Access},
	volume = {7},
	pages = {90863 – 90873},
	doi = {10.1109/ACCESS.2019.2927239},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073891001&doi=10.1109%2fACCESS.2019.2927239&partnerID=40&md5=a3659193e98df487099ab0d03fcb527e},
	abstract = {In recent years, with the rapid deployment of various Internet of Things (IoT) devices, it becomes a crucial and practical challenge to enable real-time search for objects, data, and services in the Internet of Everything. The IoT data prediction model can not only provide solutions for the real-time acquisition of the IoT sensor data but also provide more meaningful applications than the traditional IoT event detection model. In this paper, we use the complex time series formed by various types of sensors to establish a multi-dimensional feature selection model and a dynamic sensor-data prediction model. Compared with the traditional data prediction model, our model improves the accuracy and stability of the long-term prediction results of the IoT sensor data. Finally, we evaluate our prediction model using the Intel Berkeley Research Lab sensor data with an accuracy of over 98% and 92% accuracy on the Chicago Park District weatherwater data. © 2013 IEEE.},
	author_keywords = {complex time series; IoT sensor data prediction; multi-dimensional feature selection},
	keywords = {Feature extraction; Forecasting; Time series; Complex time series; Internet of Things (IOT); Long-term prediction; Multi dimensional; Rapid deployments; Real time acquisition; Real-time searches; Sensor data; Internet of things},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access}
}

@ARTICLE{Dos Santos20182971,
	author = {Dos Santos, Elder Donizetti and Quiles, Marcos Gonçalves and Faria, Fabio Augusto},
	title = {A correlation-based approach for event detection in Instagram},
	year = {2018},
	journal = {Journal of Intelligent and Fuzzy Systems},
	volume = {34},
	number = {5},
	pages = {2971 – 2982},
	doi = {10.3233/JIFS-169482},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062069888&doi=10.3233%2fJIFS-169482&partnerID=40&md5=088d7dfc77a16372c8d2651b6f224508},
	abstract = {Online social networks like Instagram has more than 600 million users and creates over 300 million new posts every day. All those data can be used to detect real world events. Many works have been proposed in the literature to detect such events using different techniques, but this task is still hard. It involves many challenges including the processing of large volumes of data, the lack of a ground truth and the need for an adaptive approach. In this sense, our work attempts to tackle these problems with a semi-supervised learning approach to overcome those challenges using times series from Instagram posts. Experimental studies demonstrate that similar time series can be used to generalize the knowledge and predict the occurrence of an event. Also, we demonstrate that Support Vector Regression is a good alternative to Gaussian Process Regression as the first provides good results using much less computing resources than the second. Moreover, we made our labeled dataset public, hoping it can be useful to other researchers as well. © 2018-IOS Press and the authors. All rights reserved.},
	author_keywords = {Event detection; Instagram; Pearson correlation; Social networks},
	keywords = {Correlation methods; Machine learning; Supervised learning; Computing resource; Event detection; Gaussian process regression; Instagram; On-line social networks; Pearson correlation; Semi- supervised learning; Support vector regression (SVR); Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Yang2019,
	author = {Yang, Thomas H. and Yang, Weiguo},
	title = {Spatial Frequency Domain Entropy Dissimilarity Measure},
	year = {2019},
	journal = {Conference Proceedings - IEEE SOUTHEASTCON},
	volume = {2019-April},
	doi = {10.1109/SoutheastCon42311.2019.9020500},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082392962&doi=10.1109%2fSoutheastCon42311.2019.9020500&partnerID=40&md5=744d594a052ffa0ae315472f07bc77f4},
	abstract = {An entropy-based spatial frequency domain 2D image dissimilarity measure is proposed and demonstrated. The metric is an extension to pixel-pixel based entropy dissimilarity measures (EDM) proposed by Tsai and Wu. The new spatial frequency domain EDM maintained all desired features of EDM while overcoming limitations such as requiring the two digital images to be compared to have the same size in pixels. The research in inspired by the need of analyzing the Advanced LIGO time series data sets in developing a real-time and blind gravitational wave event detection algorithm. Compared to other dissimilarity measures, frequency domain entropy dissimilarity measure (FD-EDM) is spatial information sensitive and agnostic to image sizes and resolutions. It also further improves the computational efficiency of normal pixel-pixel EDM. © 2019 IEEE.},
	author_keywords = {entropy; image processing; similarity/dissimilarity measure; spatial frequency domain},
	keywords = {Computational efficiency; Entropy; Gravity waves; Image processing; Pixels; Digital image; Dissimilarity measures; Event detection algorithm; Frequency domains; similarity/dissimilarity measure; Spatial frequency domains; Spatial informations; Time-series data; Frequency domain analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tan2019128,
	author = {Tan, Hui Xing and Aung, Nway Nway and Tian, Jing and Chua, Matthew Chin Heng and Yang, Youheng Ou},
	title = {Time series classification using a modified LSTM approach from accelerometer-based data: A comparative study for gait cycle detection},
	year = {2019},
	journal = {Gait and Posture},
	volume = {74},
	pages = {128 – 134},
	doi = {10.1016/j.gaitpost.2019.09.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071878468&doi=10.1016%2fj.gaitpost.2019.09.007&partnerID=40&md5=44c9c2cc20d7bd7c1dd5c9309ae71f0e},
	abstract = {Background: Gait event detection (GED) is an important aspect in identifying and interpret a user's gait to assess gait abnormalities and design intelligent assistive devices. Research question: There is a need to develop robust GED models that can accurately detect various gait instances in different scenarios and environments. Methods: This paper presents a novel method of detecting heel strikes (HS) and toe offs (TO) during the user's gait cycle using a modified Long Short-Term Memory (LSTM) networks approach. The method was tested on a database from Movement Analysis in Real-world Environments using Accelerometers (MAREA) (n = 20 healthy subjects) that consisted of walking and running in indoor and outdoor environments with accelerometers positioned on waist, wrist and both ankles. Modifications include oversampling, composite accelerations and optimizing the LSTM network architecture were made. Results: Performance of our modified model was found to be better than six state-of-the-art GED algorithms, with a median F1 score of 0.98 for Heel Strikes and 0.98 for Toe Offs in the scenario of steady walking in an indoor environment, and a median F1 score of 0.94 for Heel Strikes and 0.68 for Toe-offs in the scenario of walking and running in an outdoor environment. Significance: This paper highlights the potential of the single proposed model to be an alternative to the six GED models in gait detection under various conditions. © 2019 Elsevier B.V.},
	author_keywords = {Gait; Gait event detection; Inertial sensors; Long-short term memory models; LSTM},
	keywords = {Accelerometry; Algorithms; Databases, Factual; Female; Gait; Humans; Male; Movement Disorders; Walking; acceleration; accelerometry; algorithm; Article; comparative study; controlled study; gait; heel strike; human; human experiment; locomotion; long short term memory network; normal human; priority journal; running; time series analysis; toe off; walking; accelerometry; factual database; female; gait; male; motor dysfunction; physiology; procedures; walking},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40}
}

@ARTICLE{Alatrista-Salas2019475,
	author = {Alatrista-Salas, Hugo and León-Payano, Mauro and Nunez-del-Prado, Miguel},
	title = {Extreme Climate Event Detection Through High Volume of Transactional Consumption Data},
	year = {2019},
	journal = {Communications in Computer and Information Science},
	volume = {1064},
	pages = {475 – 486},
	doi = {10.1007/978-3-030-30278-8_46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072946050&doi=10.1007%2f978-3-030-30278-8_46&partnerID=40&md5=9f4882ac06f2280ed50cb7adbcd9a443},
	abstract = {Extreme weather events cause irreparable damage to society. At the beginning of 2017, the coast of Peru was hit by the phenomenon called “El Niño Costero”, characterized by heavy rains and floods. According to the United Nations International Strategy for Disasters ISDR, natural disasters comprise a 5-step process. In the last stage - recovery - strategies are aimed at bringing the situation back to normality. However, this step is difficult to achieve if one does not know how the economic sectors have been affected by the extreme event. In this paper, we use two well-known techniques, such as Autoregressive integrated moving average (ARIMA) and Kullback-Leibler divergence to capture a phenomenon and show how the key economic sectors are affected. To do this, we use a large real dataset from banking transactions stored in a Massively Parallel Processing (MPP). Our results show the interest of applying these techniques to better understand the impact of a natural disaster into economic activities in a specific geographical area. © Springer Nature Switzerland AG 2019.},
	author_keywords = {Extreme climate event detection; Parallel processing; Time series; Transactional banking data},
	keywords = {Economics; Information systems; Information use; Large dataset; Technology transfer; Time series; Auto-regressive integrated moving average; Extreme climates; Extreme weather events; Kullback Leibler divergence; Massively parallel processing; Parallel processing; Recovery strategies; Transactional banking data; Disasters},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yadav20191521,
	author = {Yadav, Ravi and Pradhan, Ashok Kumar and Kamwa, Innocent},
	title = {Real-Time Multiple Event Detection and Classification in Power System Using Signal Energy Transformations},
	year = {2019},
	journal = {IEEE Transactions on Industrial Informatics},
	volume = {15},
	number = {3},
	pages = {1521 – 1531},
	doi = {10.1109/TII.2018.2855428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049785975&doi=10.1109%2fTII.2018.2855428&partnerID=40&md5=d7d1105322ea0a2c5ab09608d7e8b7c1},
	abstract = {Real-time multiple event analysis is important for reliable situational awareness and secure operation of the power system. Multiple sequential events can induce complex superimposed pattern in the data and are challenging to analyze in real time. This paper proposes a method for accurate detection, temporal localization, and classification of multiple events in real time using synchrophasor data. For detection and temporal localization, a Teager-Kaiser energy operator (TKEO) based method is proposed. For event classification, a time series classification based method using energy similarity measure (ESM) is proposed. The proposed method is tested for simulated multiple event cases in the IEEE-118 bus system using DigSilent/PowerFactory and real PMU data for the Indian grid. © 2005-2012 IEEE.},
	author_keywords = {Energy similarity measure; event classification; event detection; multiple events; Teager-Kaiser energy operator (TKEO); temporal localization},
	keywords = {Electrical engineering; Industry; Energy operators; Event classification; Event detection; Multiple events; Similarity measure; Temporal localization; Electric power systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 79}
}

@CONFERENCE{Valovage20185791,
	author = {Valovage, Mark},
	title = {Machine learning approaches to reduce electrical waste and improve power grid stability},
	year = {2018},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	volume = {2018-July},
	pages = {5791 – 5792},
	doi = {10.24963/ijcai.2018/839},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055701438&doi=10.24963%2fijcai.2018%2f839&partnerID=40&md5=43787c8f3d3096f6743c7595f8494a48},
	abstract = {Machine learning applications to electrical time series data will have wide-ranging impacts in the near future, including reducing billions of dollars of annual electrical waste. My contributions to electricity disaggregation include the first label correction approach for training samples, event detection for unsupervised disaggregation that does not require parameter tuning, and appliance discovery that makes no assumptions on appliance types. © 2018 International Joint Conferences on Artificial Intelligence.All right reserved.},
	keywords = {Electric power transmission networks; Electronic Waste; Machine learning; Correction approaches; Electrical wastes; Machine learning applications; Machine learning approaches; Parameter-tuning; Power grid stability; Time-series data; Training sample; Electric power system stability},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Götz201967,
	author = {Götz, Markus and Kononets, Mikhail and Bodenstein, Christian and Riedel, Morris and Book, Matthias and Palsson, Olafur Petur},
	title = {Automatic water mixing event identification in the Koljö fjord observatory data},
	year = {2019},
	journal = {International Journal of Data Science and Analytics},
	volume = {7},
	number = {1},
	pages = {67 – 79},
	doi = {10.1007/s41060-018-0132-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088165238&doi=10.1007%2fs41060-018-0132-z&partnerID=40&md5=a136427969e306b04f7228e4ee6a0782},
	abstract = {This study addresses the task of automatically identifying water mixing events in the multivariate time series of salinity, temperature and dissolved oxygen provided by the Koljö fjord observatory. The observatory is used to test new underwater sensory technology and to monitor water quality with respect to hypoxia and oxygenation in the fjord and has been collecting data since April 2011. The fjord water properties change, manifesting as peaks or drops of dissolved oxygen, salinity and temperature, when affected by inflows of new water originating from the open sea or by rivers connected to the fjord system. An acute state of oxygen depletion can harm wildlife and the ecosystem permanently. The major challenge for the analysis is that the water property changes are marked by highly varying peak strength and correlation between the signals. The proposed data-driven analysis method extends existing univariate outlier detection approaches, based on clustering techniques, to identify the water mixing events. It incorporates three major steps: 1. smoothing of the input data, to counter noise, 2. individual outlier detection within the separate variables, 3. clustering of the results using the DBSCAN clustering algorithm to determine the anomalous events. The proposed approach is able to detect the water mixing events with a F1-measure of 0.885, a precision of 0.931—that is 93.1% of all events have been correctly detected—and a recall of 0.843–84.3% of events that should have been found actually also have been. Using the proposed method, the oceanographers can be informed automatically about the status of the fjord without manual interaction or physical presence at the experiment site. © 2018, Springer International Publishing AG, part of Springer Nature.},
	author_keywords = {Clustering; DBSCAN; Koljö fjord observatory; Multivariate time series analysis; Water mixing event detection},
	keywords = {Anomaly detection; Cluster analysis; Clustering algorithms; Dissolved oxygen; Mixing; Observatories; Statistics; Water quality; Anomalous events; Clustering techniques; Data-driven analysis; Detection approach; Event identification; Manual interaction; Multivariate time series; Sensory technologies; Biochemical oxygen demand},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2018,
	title = {2018 IEEE (SMC) International Conference on Innovations in Intelligent Systems and Applications, INISTA 2018},
	year = {2018},
	journal = {2018 IEEE (SMC) International Conference on Innovations in Intelligent Systems and Applications, INISTA 2018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055479060&partnerID=40&md5=cbc170bdeba0b1f3e25b1c85995df1c1},
	abstract = {The proceedings contain 63 papers. The topics discussed include: selective equation constructor: a scalable genetic algorithm; human heading perception based on form and motion combination; real-time event detection in time-series classification based on amplitude rejection; classification performances of data mining clustering algorithms for remotely sensed multispectral image data; emotional condition in the health smart homes environment: emotion recognition using ensemble of classifiers; a fuzzy-based throughput prediction for wireless communication systems; neuro-fuzzy modeling and prediction of current total harmonic distortion for high power nonlinear loads; and making sense of fractions using e-learning platforms - a survey.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pelech-Pilichowski20181260,
	author = {Pelech-Pilichowski, T.},
	title = {On adaptive prediction of nonstationary and inconsistent large time series data},
	year = {2018},
	journal = {2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2018 - Proceedings},
	pages = {1260 – 1265},
	doi = {10.23919/MIPRO.2018.8400228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050241970&doi=10.23919%2fMIPRO.2018.8400228&partnerID=40&md5=40fb810da6b949725cc998d071851295},
	abstract = {The use of time series prediction results in benefits for an organization. Forecasting efficiency relies on applied prediction formula and quality of data received from technical devices and manually inputted. They are often of low quality, with inconsistencies. However, high data quality is crucial for efficient forecasting/prediction purposes (also event detection from time series and pattern recognition), in particular during large data sets processing (often heterogeneous, including data obtained from IoT devices). Such processing should cover inconsistency analysis, interpolation of missing/lacking data, as well as the use of data pre-transformations. The paper presents problems of inconsistent, nonstationary data prediction on the example of stock level daily forecasting. Selected methods of time series interpolation are outlined. Results of implementation of algorithms for short-term time series prediction are illustrated and discussed. Prediction quality measured based on errors values calculated both in total and in a moving window is discussed. A concept of an adaptive algorithm based on a change in the prognostic formula depending on short-term characteristics of time series is outlined. © 2018 Croatian Society MIPRO.},
	author_keywords = {adaptive prediction algorithms; Big Data; forecasting; interpolation; IoT; prediction; time series analysis},
	keywords = {Adaptive algorithms; Data handling; Forecasting; Internet of things; Interpolation; Microelectronics; Pattern recognition; Time series analysis; Adaptive predictions; Event detection; Forecasting efficiencies; Nonstationary data; Prediction quality; Quality of data; Time series prediction; Time-series data; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Leite2018198,
	author = {Leite, Roger A. and Gschwandtner, Theresia and Miksch, Silvia and Gstrein, Erich and Kuntner, Johannes},
	title = {Visual analytics for event detection: Focusing on fraud},
	year = {2018},
	journal = {Visual Informatics},
	volume = {2},
	number = {4},
	pages = {198 – 212},
	doi = {10.1016/j.visinf.2018.11.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066761405&doi=10.1016%2fj.visinf.2018.11.001&partnerID=40&md5=000a6dfe790cfd553bda47a6368c3bcd},
	abstract = {The detection of anomalous events in huge amounts of data is sought in many domains. For instance, in the context of financial data, the detection of suspicious events is a prerequisite to identify and prevent attempts to defraud. Hence, various financial fraud detection approaches have started to exploit Visual Analytics techniques. However, there is no study available giving a systematic outline of the different approaches in this field to understand common strategies but also differences. Thus, we present a survey of existing approaches of visual fraud detection in order to classify different tasks and solutions, to identify and to propose further research opportunities. In this work, fraud detection solutions are explored through five main domains: banks, the stock market, telecommunication companies, insurance companies, and internal frauds. The selected domains explored in this survey were chosen for sharing similar time-oriented and multivariate data characteristics. In this survey, we (1) analyze the current state of the art in this field; (2) define a categorization scheme covering different application domains, visualization methods, interaction techniques, and analytical methods which are used in the context of fraud detection; (3) describe and discuss each approach according to the proposed scheme; and (4) identify challenges and future research topics. © 2018 Zhejiang University and Zhejiang University Press},
	author_keywords = {Business and finance visualization; Financial fraud detection; Time series data; Visual knowledge discovery},
	keywords = {Data visualization; Insurance; Surveys; Telecommunication industry; Visualization; Financial fraud detections; Insurance companies; Interaction techniques; Research opportunities; Telecommunication companies; Time-series data; Visual knowledge discovery; Visualization method; Crime},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30; All Open Access, Gold Open Access}
}

@ARTICLE{Bergen20181984,
	author = {Bergen, Karianne J. and Beroza, Gregory C.},
	title = {Detecting earthquakes over a seismic network using single-station similarity measures},
	year = {2018},
	journal = {Geophysical Journal International},
	volume = {213},
	number = {3},
	pages = {1984 – 1998},
	doi = {10.1093/gji/ggy100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058897471&doi=10.1093%2fgji%2fggy100&partnerID=40&md5=d6eab63f5c5e2d124504e570ed0e0a36},
	abstract = {New blind waveform-similarity-based detection methods, such as Fingerprint and Similarity Thresholding (FAST), have shown promise for detecting weak signals in long-duration, continuous waveform data. While blind detectors are capable of identifying similar or repeating waveforms without templates, they can also be susceptible to false detections due to local correlated noise. In this work, we present a set of three new methods that allow us to extend single-station similarity-based detection over a seismic network; event-pair extraction, pairwise pseudo-association, and event resolution complete a post-processing pipeline that combines single-station similarity measures (e.g. FAST sparse similarity matrix) from each station in a network into a list of candidate events. The core technique, pairwise pseudo-association, leverages the pairwise structure of event detections in its network detection model, which allows it to identify events observed at multiple stations in the network without modeling the expected moveout. Though our approach is general, we apply it to extend FAST over a sparse seismic network. We demonstrate that our network-based extension of FAST is both sensitive and maintains a low false detection rate. As a test case, we apply our approach to 2 weeks of continuous waveform data from five stations during the foreshock sequence prior to the 2014 Mw 8.2 Iquique earthquake. Our method identifies nearly five times as many events as the local seismicity catalogue (including 95 per cent of the catalogue events), and less than 1 per cent of these candidate events are false detections. © The Author(s) 2018. Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Computational seismology; Earthquake monitoring; Self-organization; Test-ban treaty verification; Time-series analysis},
	keywords = {Chile; Iquique; Tarapaca; Time series analysis; Waveform analysis; Computational seismologies; Continuous waveforms; Earthquake monitoring; Foreshock sequences; Resolution complete; Self organizations; Similarity measure; Waveform similarity; detection method; earthquake catalogue; foreshock; self organization; signal-to-noise ratio; time series analysis; Earthquakes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32; All Open Access, Bronze Open Access}
}

@ARTICLE{Das20181257,
	author = {Das, Saptarshi and Chen, Xi and Hobson, Michael P. and Phadke, Suhas and van Beest, Bertwim and Goudswaard, Jeroen and Hohl, Detlef},
	title = {Surrogate regression modelling for fast seismogram generation and detection of microseismic events in heterogeneous velocity models},
	year = {2018},
	journal = {Geophysical Journal International},
	volume = {215},
	number = {2},
	pages = {1257 – 1290},
	doi = {10.1093/GJI/GGY283},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055351202&doi=10.1093%2fGJI%2fGGY283&partnerID=40&md5=88760a408103c4b63f15b694d28b82ee},
	abstract = {Given a 3D heterogeneous velocity model with a fewmillion voxels, fast generation of accurate seismic responses at specified receiver positions from known microseismic event locations is a well-known challenge in geophysics, since it typically involves numerical solution of the computationally expensive elastic wave equation. Thousands of such forward simulations are often a routine requirement for parameter estimation of microseimsic events via a suitable source inversion process. Parameter estimation based on forward modelling is often advantageous over a direct regression-based inversion approach when there are unknown number of parameters to be estimated and the seismic data have complicated noise characteristics which may not always allow a stable and unique solution in a direct inversion process. In this paper, starting from Graphics Processing Unit based synthetic simulations of a few thousand forward seismic shots due to microseismic events via pseudo-spectral solution of elastic wave equation, we develop a step-by-step process to generate a surrogate regression modelling framework, using machine learning techniques that can produce accurate seismograms at specified receiver locations. The trained surrogate models can then be used as a high-speed meta-model/emulator or proxy for the original full elastic wave propagator to generate seismic responses for other microseismic event locations also. The accuracies of the surrogate models have been evaluated using two independent sets of training and testing Latin hypercube quasi-random samples, drawn from a heterogeneous marine velocity model. The predicted seismograms have been used thereafter to calculate batch likelihood functions, with specified noise characteristics. Finally, the trained models on 23 receivers placed at the sea-bed in a marine velocity model are used to determine the maximum likelihood estimate of the event locations which can in future be used in a Bayesian analysis for microseismic event detection. © The Author(s) 2018.},
	author_keywords = {Computational seismology; Joint inversion; Seismic noise; Statistical methods; Statistical seismology; Time-series analysis},
	keywords = {Computer graphics; Elastic waves; Graphics processing unit; Learning systems; Location; Parameter estimation; Program processors; Regression analysis; Seismic response; Statistical methods; Time series analysis; Velocity; Wave equations; Computational seismologies; Joint inversion; Machine learning techniques; Maximum likelihood estimate; Noise characteristic; Seismic noise; Statistical seismologies; Synthetic simulation; computer simulation; data inversion; detection method; heterogeneity; maximum likelihood analysis; microearthquake; modeling; numerical model; regression analysis; seismic velocity; seismogram; statistical analysis; time series analysis; Maximum likelihood estimation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@CONFERENCE{Kummerow2019,
	author = {Kummerow, Andre and Rosch, Dennis and Monsalve, Cristian and Nicolai, Steffen and Bretschneider, Peter and Brosinsky, Christoph and Westermann, Dirk},
	title = {Challenges and opportunities for phasor data based event detection in transmission control centers under cyber security constraints},
	year = {2019},
	journal = {2019 IEEE Milan PowerTech, PowerTech 2019},
	doi = {10.1109/PTC.2019.8810711},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072341884&doi=10.1109%2fPTC.2019.8810711&partnerID=40&md5=82852292f7bb55f20cd8862016b67058},
	abstract = {The scope of this survey is the phasor based event detection under cyber security constraints in modern transmission control centers. A general concept for a physical and cyber event detection is developed as a combination of state-of-the-art disturbance classification and cyber-attack detection methods. This requires the incorporation of heterogeneous data sources and advanced data fusion and analysis techniques. An enhanced and robust recognition of the current grid situation is proposed to distinguish between different scheduled and unscheduled grid events. Furthermore, Digital Twins are considered as new promising technology for control centers and potential benefits for physical and cyber event detection are described. © 2019 IEEE.},
	author_keywords = {Cyber security; Digital Twin; Event detection; PMU; Time series classification},
	keywords = {Analysis techniques; Cyber security; Digital Twin; Disturbance classification; Event detection; Heterogeneous data sources; Time series classifications; Transmission control; Data fusion},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@ARTICLE{Zhou20192979,
	author = {Zhou, Mengze and Wang, Yuhui and Srivastava, Anurag K. and Wu, Yinghui and Banerjee, P.},
	title = {Ensemble-Based Algorithm for Synchrophasor Data Anomaly Detection},
	year = {2019},
	journal = {IEEE Transactions on Smart Grid},
	volume = {10},
	number = {3},
	pages = {2979 – 2988},
	doi = {10.1109/TSG.2018.2816027},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043779338&doi=10.1109%2fTSG.2018.2816027&partnerID=40&md5=04917e711ca2d7731d60de9d308cb0e5},
	abstract = {With the advent of phasor measurement units (PMUs), high resolution synchronized phasor measurements enables real time system monitoring and control. PMUs transmit data to local controllers in substations and phasor data concentrators for system wide monitoring and control application in the control center. They provide real-time phasor data for critical power system applications such as remedial action schemes, oscillation detection, and state estimation. The quality of phasor data from PMUs is critical for smart grid applications. Several methods are developed to detect anomalies in time series data, tailored for PMU data analysis. Nevertheless, applying stand alone methods (with fixed parameters) takes great tuning effort, and does not always achieve high accuracy. In this paper, we adopt an unsupervised ensemble learning approach to develop fast, scalable bad data/event detection for PMU data. The ensemble method invokes a set of base detectors to generate anomaly scores of the PMU data, and makes decisions by aggregating the scores from each detector. We develop two algorithms: 1) a learning algorithm that trains the ensemble model and 2) an online algorithm that infers the anomaly scores with the ensemble model over PMU data streams. The proposed method provides flag for data anomalies and triggers further analysis to differentiate between events and bad data. Using both simulated and real-world PMU data, we show that our ensemble model can be efficiently trained, can achieve high accuracy in detecting diversified errors/events, and outperforms its counterparts that use single standalone detection method. © 2010-2012 IEEE.},
	author_keywords = {Chebyshev; data analytics; data anomaly; data quality; DBSCAN; ensemble; linear regression; Phasor measurement units; power grid operation},
	keywords = {Data structures; Detectors; Electric power systems; Interactive computer systems; Learning algorithms; Monitoring; Phase measurement; Real time systems; State estimation; Time series analysis; Anomaly detection; Distributed database; Ensemble learning approach; Monitoring and control; Phasor data concentrators; Phasor Measurement Unit (PMUs); Smart grid applications; Synchronized phasor measurements; Phasor measurement units},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 97; All Open Access, Bronze Open Access}
}

@CONFERENCE{Peng2018,
	author = {Peng, Huaiyue and Huang, Jingfeng and Jin, Hongwei and Sun, Han and Chai, Dengfeng and Wang, Xiuzhen and Han, Bing and Zhou, Zhen and Xu, Libing},
	title = {Detecting Coffee (Coffea Arabica L.) sequential flowering events based on image segmentation},
	year = {2018},
	journal = {2018 7th International Conference on Agro-Geoinformatics, Agro-Geoinformatics 2018},
	doi = {10.1109/Agro-Geoinformatics.2018.8476057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055876930&doi=10.1109%2fAgro-Geoinformatics.2018.8476057&partnerID=40&md5=1fcaeae184f02eaa28daefeb588d871d},
	abstract = {Coffee sequential flowering events detection and flower density estimation is essential to predict the ripening time and yield of coffee. In this study, we detected coffee flowering events automatically based on estimated flower densities in high spatial time-series digital images, using a multi-scale region based flower segmentation method. The study area is a coffee plantation in Lujiangba in the Yunnan Province of China. There are 5 flowering events in the coffee flowering period. A digital camera obtained 24 RGB images at each shooting time of day (8:00, 9:00, 10:00, 11:00, 12:00, 13:00, 14:00, 15:00, 16:00, 17:00, 17:30) by automatic adjusting the sensor with 3 depression angles and 8 azimuth angles during the coffee flowering period from March 1st to May 31st. For segment the flowers in one image, multi-scale regions were primarily generated by equally-sized superpixel segmentation and subsequent superpixel merging process. Next, the feature vectors of each region were extracted by color moments (CM) operator and local binary patterns (LBP) operator. Afterwards, the support vector machine (SVM) classifier trained on these features was applied to recognize the flower regions. Thus, the percentage of flower pixels referred as flower proportion (FP), which can estimate the image-based flower density, was calculated in preparation for detecting flowering events of time-series images. In this stage, coefficients of Recall, Precision and intersection over union (IoU) were employed to evaluate the performance of segmentation methods on 14 test images at threes depression angles and then the best flower segmentation algorithm and the optimal angle can be determined. In the stage of flowering events detection, the FPs of different shooting time multitemporal images under the optimal depression angle were calculated and plotted. Then, a threshold of FP, K, was selected to determine whether an image is on a flowering day. To determine the best shooting time for flowering events detection, Recall, Precision and IoU were also employed to evaluate the performance of time-series images shot at 11 time of day for flowering day detection. The results show that the images shot at the depression angle of 77.5 degree is the optimal depression angle for flower segmentation and meanwhile our proposed method achieves the best performance with Recall, Precision and IoU of 84.89%, 74.83% and 65.46% respectively. In the test of flowering day detection of 11 shooting time multitemporal images, the time-series images shot at 13:00 is superior to the time-series images shot at other time of day, with Recall of 65.00%, Precision of 100% and IoU of 65.00% when the K set as 0.4%. Meanwhile, all flowering events can be detected except the fifth event which has few flowers and the FPs of time-series images can correctly indicate the flower densities of each events. In conclusion, our approach can estimate the image-based flower density and detect the coffee sequential flowering events in small fields, so the results can be used for coffee fruit maturity prediction and yield estimation. © 2018 IEEE.},
	author_keywords = {coffee flowering events; color moment; flower segmentation; local binary patterns; superpixel merging; support vector machine},
	keywords = {Coffee; Color; Merging; Pixels; Superpixels; Support vector machines; Time series; Coffee plantation; Color moments; Local binary pattern (LBP); Local binary patterns; Multi-temporal image; Segmentation algorithms; Segmentation methods; Superpixel segmentations; Image segmentation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Liu2019162,
	author = {Liu, Hengyong and Shi, Shuaibin and Xu, Xuhui and Zhou, Dongguo and Min, Ruolin and Hu, Wenshan},
	title = {A non-intrusive load identification method based on RNN model; [一种关联RNN模型的非侵入式负荷辨识方法]},
	year = {2019},
	journal = {Dianli Xitong Baohu yu Kongzhi/Power System Protection and Control},
	volume = {47},
	number = {13},
	pages = {162 – 170},
	doi = {10.19783/j.cnki.pspc.180785},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072209581&doi=10.19783%2fj.cnki.pspc.180785&partnerID=40&md5=d67222bc428dc72407974e82a8e685e4},
	abstract = {In order to extend the application by using supervised learning methods in non-intrusive load identification, a load identification method based on Recurrent Neural Networks (RNN) model is proposed. Firstly, the time window for detecting load event is introduced, and then the harmonic components are taken as the load characteristics to be used as the inputs of the RNN model. According to the memory of its memory history input feature quantity, the internal mapping of the input to the output as well as the RNN load identification method for time series inputs are established. Furthermore, in this model, the suitable activation function and loss function are selected in order to avoid the "gradient disappearance" problem. Finally, the experiment on the single and multi-load identification demonstrates the model can effectively realize the identification of the load status. © 2019, Power System Protection and Control Press. All right reserved.},
	author_keywords = {Deep learning; Event detection; Load identification; Non-intrusive; RNN},
	keywords = {Deep learning; Events detection; Harmonics component; Identification method; Load characteristics; Load identification; Non-intrusive; Recurrent neural network model; Supervised learning methods; Time windows; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Nguyen2018393,
	author = {Nguyen, Van Quan and Van Ma, Linh and Kim, Jin-Young and Kim, Kwangki and Kim, Jinsul},
	title = {Applications of anomaly detection using deep learning on time series data},
	year = {2018},
	journal = {Proceedings - IEEE 16th International Conference on Dependable, Autonomic and Secure Computing, IEEE 16th International Conference on Pervasive Intelligence and Computing, IEEE 4th International Conference on Big Data Intelligence and Computing and IEEE 3rd Cyber Science and Technology Congress, DASC-PICom-DataCom-CyberSciTec 2018},
	pages = {393 – 396},
	doi = {10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056875532&doi=10.1109%2fDASC%2fPiCom%2fDataCom%2fCyberSciTec.2018.00078&partnerID=40&md5=07017a9b0fa62cc052a1bc36a9a19dab},
	abstract = {In the modern world, time series data has become a critical part of many systems underlying various types that are recorded to reflect the status of objects according to the timeline. There are many kinds of research investigating to automate the process of analyzing time series data. Long Short-Term Memory (LSTM) network have been demonstrated to be a useful tool for learning sequence data. In this paper, we explore LSTM based approach to analyzing temporal data for abnormal detection. Stacked Long Short-Term Memory (LSTM) network is utilized as a predictor which is trained on normal data to learn the higher level temporal features, then such predictor is used to predict future values. An error-distribution estimation model is built to calculate the anomaly in the score of the observation. Anomalies are detected using a window-based method based on anomaly scores. To prove the promise applicable potential of our approach, we conducted the experiment on some domains (industry system, health monitor system, social based event detection system) come up with time series data including power consumption, ECG signal, and social data respectively. © 2018 IEEE.},
	author_keywords = {Anomaly Detection; Deep Learning; Long Short Term Memory (LSTM); Recurrent Neural Network (RNN); Time Series Data},
	keywords = {Big data; Brain; Deep learning; Monitoring; Time series; Abnormal detection; Anomaly detection; Error distributions; Industry systems; Learning sequences; Recurrent neural network (RNN); Temporal features; Time-series data; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Qu2018498,
	author = {Qu, Qiang and Yu, Hongtao and Huang, Ruiyang},
	title = {An approach for detecting spammer invasion events with poisson process},
	year = {2018},
	journal = {Proceedings - 2018 3rd International Conference on Mechanical, Control and Computer Engineering, ICMCCE 2018},
	pages = {498 – 505},
	doi = {10.1109/ICMCCE.2018.00111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059866652&doi=10.1109%2fICMCCE.2018.00111&partnerID=40&md5=562d835845cfda0fdb528ccdd1b28dfa},
	abstract = {The spammer, referring to the user who sends large amount of unrelated information to recipients without permission in a short period, brings a serious threat to social network security. Interestingly, we find that the change of network structure can be helpful for the identification of spammer invasion events. In the paper, a method which aggregates fifteen kinds of network structure indicators together is proposed to detect spammer invasion events in time series based on Poisson process. Tested on the dataset of Tagged.com, our proposed approach outperforms other state-of-the-art methods in precision, recall and F1-score. Also, the result validates that the key indicators for detecting spammer invasion events are comprised of ABC, SHC, MD. The method presented will be refined and extended to cases of detecting spammers dynamically. © 2018 IEEE.},
	author_keywords = {Cyber security; Network structure indicators; Poisson processes; Spammer invasion event detection},
	keywords = {Poisson distribution; Cyber security; Event detection; Key indicator; Large amounts; Network structures; Poisson process; Short periods; State-of-the-art methods; Network security},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hayama2018917,
	author = {Hayama, Tessai},
	title = {Detecting TV Program highlight scenes using twitter data classified by twitter user behavior and evaluating it to soccer game TV programs},
	year = {2018},
	journal = {IEICE Transactions on Information and Systems},
	volume = {E101D},
	number = {4},
	pages = {917 – 924},
	doi = {10.1587/transinf.2016IIP0020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044753161&doi=10.1587%2ftransinf.2016IIP0020&partnerID=40&md5=a61ed836fc4ff50bddb359cce8723218},
	abstract = {This paper presents a novel TV event detection method for automatically generating TV program digests by using Twitter data. Previous studies of TV program digest generation based on Twitter data have developed TV event detection methods that analyze the frequency time series of tweets that users made while watching a given TV program; however, in most of the previous studies, differences in how Twitter is used, e.g., sharing information versus conversing, have not been taken into consideration. Since these different types of Twitter data are lumped together into one category, it is difficult to detect highlight scenes of TV programs and correctly extract their content from the Twitter data. Therefore, this paper presents a highlight scene detection method to automatically generate TV program digests for TV programs based on Twitter data classified by Twitter user behavior. To confirm the effectiveness of the proposed method, experiments using 49 soccer game TV programs were conducted. Copyright © 2018 The Institute of Electronics, Information and Communication Engineers.},
	author_keywords = {Burst detection; Highlight-scene detection; TV digest generation; Twitter data},
	keywords = {Behavioral research; Sports; Burst detection; Event detection; Scene detection; Sharing information; Soccer games; TV programs; Twitter datum; User behaviors; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Bagattini2019,
	author = {Bagattini, Francesco and Karlsson, Isak and Rebane, Jonathan and Papapetrou, Panagiotis},
	title = {A classification framework for exploiting sparse multi-variate temporal features with application to adverse drug event detection in medical records},
	year = {2019},
	journal = {BMC Medical Informatics and Decision Making},
	volume = {19},
	number = {1},
	doi = {10.1186/s12911-018-0717-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059800920&doi=10.1186%2fs12911-018-0717-4&partnerID=40&md5=d6727df4498c05a4cc452a8ffab9bd65},
	abstract = {Background: Adverse drug events (ADEs) as well as other preventable adverse events in the hospital setting incur a yearly monetary cost of approximately 3.5 billion, in the United States alone. Therefore, it is of paramount importance to reduce the impact and prevalence of ADEs within the healthcare sector, not only since it will result in reducing human suffering, but also as a means to substantially reduce economical strains on the healthcare system. One approach to mitigate this problem is to employ predictive models. While existing methods have been focusing on the exploitation of static features, limited attention has been given to temporal features. Methods: In this paper, we present a novel classification framework for detecting ADEs in complex Electronic health records (EHRs) by exploiting the temporality and sparsity of the underlying features. The proposed framework consists of three phases for transforming sparse and multi-variate time series features into a single-valued feature representation, which can then be used by any classifier. Moreover, we propose and evaluate three different strategies for leveraging feature sparsity by incorporating it into the new representation. Results: A large-scale evaluation on 15 ADE datasets extracted from a real-world EHR system shows that the proposed framework achieves significantly improved predictive performance compared to state-of-the-art. Moreover, our framework can reveal features that are clinically consistent with medical findings on ADE detection. Conclusions: Our study and experimental findings demonstrate that temporal multi-variate features of variable length and with high sparsity can be effectively utilized to predict ADEs from EHRs. Two key advantages of our framework are that it is method agnostic, i.e., versatile, and of low computational cost, i.e., fast; hence providing an important building block for future exploitation within the domain of machine learning from EHRs. © 2019 The Author(s).},
	author_keywords = {Adverse drug events; Data mining; Electronic health records; Machine learning; Shapelets; Sparse multi-variate features; Temporal abstraction},
	keywords = {Data Mining; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Hospitals; Humans; Machine Learning; Medical Informatics Applications; Models, Statistical; adverse drug reaction; data mining; electronic health record; hospital; human; machine learning; medical informatics; statistical model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Liemohn20182079,
	author = {Liemohn, Michael W. and McCollough, James P. and Jordanova, Vania K. and Ngwira, Chigomezyo M. and Morley, Steven K. and Cid, Consuelo and Tobiska, W. Kent and Wintoft, Peter and Ganushkina, Natalia Yu. and Welling, Daniel T. and Bingham, Suzy and Balikhin, Michael A. and Opgenoorth, Hermann J. and Engel, Miles A. and Weigel, Robert S. and Singer, Howard J. and Buresova, Dalia and Bruinsma, Sean and Zhelavskaya, Irina S. and Shprits, Yuri Y. and Vasile, Ruggero},
	title = {Model Evaluation Guidelines for Geomagnetic Index Predictions},
	year = {2018},
	journal = {Space Weather},
	volume = {16},
	number = {12},
	pages = {2079 – 2102},
	doi = {10.1029/2018SW002067},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059289856&doi=10.1029%2f2018SW002067&partnerID=40&md5=1493cc4ba657456fc6ce7f7e446e27ce},
	abstract = {Geomagnetic indices are convenient quantities that distill the complicated physics of some region or aspect of near-Earth space into a single parameter. Most of the best-known indices are calculated from ground-based magnetometer data sets, such as Dst, SYM-H, Kp, AE, AL, and PC. Many models have been created that predict the values of these indices, often using solar wind measurements upstream from Earth as the input variables to the calculation. This document reviews the current state of models that predict geomagnetic indices and the methods used to assess their ability to reproduce the target index time series. These existing methods are synthesized into a baseline collection of metrics for benchmarking a new or updated geomagnetic index prediction model. These methods fall into two categories: (1) fit performance metrics such as root-mean-square error and mean absolute error that are applied to a time series comparison of model output and observations and (2) event detection performance metrics such as Heidke Skill Score and probability of detection that are derived from a contingency table that compares model and observation values exceeding (or not) a threshold value. A few examples of codes being used with this set of metrics are presented, and other aspects of metrics assessment best practices, limitations, and uncertainties are discussed, including several caveats to consider when using geomagnetic indices. ©2018. American Geophysical Union. All Rights Reserved.},
	author_keywords = {forecasting; geomagnetic indices; metrics; ROC curve; space weather; statistical analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 54; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Alves Ribeiro2018,
	author = {Alves Ribeiro, Victor Henrique and Reynoso-Meza, Gilberto},
	title = {Multi-objective Support Vector Machines Ensemble Generation for Water Quality Monitoring},
	year = {2018},
	journal = {2018 IEEE Congress on Evolutionary Computation, CEC 2018 - Proceedings},
	doi = {10.1109/CEC.2018.8477745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056253826&doi=10.1109%2fCEC.2018.8477745&partnerID=40&md5=3154f668c7c3eebb8c538ebf510a37dd},
	abstract = {Real-world classification problems generally deal with imbalanced data, where one class represents the majority of the data set. The present work deals with event detection on a drinking-water quality time series, where the presence of a quality event is the minority class. In order to solve such problems, supervised learning algorithms are recommended. Researchers have also used multi-objective optimization (MOO) in order to generate diverse models to build ensembles of classifiers. Although MOO has been used for ensemble member generation, there is a lack on it's application for member selection, which is usually done by selecting a specific subset from the resulting models, or by using meta-algorithms, such as boosting. The proposed work comprises the application of MOO design in the whole process of ensemble generation. To do so, one multi-objective problem (MOP) is defined for the creation of a set of non-dominated solutions with Pareto-optimal support vector machines (SVM). After that, a second MOP is defined for the selection of such SVMs as members of an ensemble. Such methodology is compared to other member selection methods, such as: The single best classifier, an ensemble composed of the full set of non-dominated solutions, and the selection of a specific subset from the Pareto front. Results show that the proposed method is suitable for the creation of ensembles, achieving the highest classification scores. © 2018 IEEE.},
	author_keywords = {ensemble methods; genetic algorithms; machine learning; supervised learning; support vector machines},
	keywords = {Classification (of information); Genetic algorithms; Learning systems; Multiobjective optimization; Pareto principle; Potable water; Problem solving; Supervised learning; Support vector machines; Water quality; Ensemble members; Ensemble methods; Ensembles of classifiers; Event detection; Member selection; Multi-objective problem; Nondominated solutions; Water quality monitoring; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Munjani2018,
	author = {Munjani, Jayesh H. and Bhavsar, Moxanki A. and Joshi, Maulin},
	title = {Target Tracking in WSN using NARX model},
	year = {2018},
	journal = {2017 14th IEEE India Council International Conference, INDICON 2017},
	doi = {10.1109/INDICON.2017.8487989},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056382729&doi=10.1109%2fINDICON.2017.8487989&partnerID=40&md5=1df8186b5fb376b1df5cf9be8f4c7e81},
	abstract = {Wireless Sensor Networks (WSN) are increasingly being envisioned for event detection and collection of physical or environmental data. Tracking applications require ensuring continuous monitoring which is a much difficult task that mere detection of an event. Energy-saving tracking is a difficult task of resource constrained wireless sensor network. A network lifetime can be enhanced by incorporating prediction based scheme, which saves energy of sensors by limiting communication. While basic Kalman filter is successfully implemented for linear applications, is unable to perform best of its capability in case of maneuvering target. Considering target movement as time series, neural network based approach is a good alternative as it is a model free estimator. In this paper, Nonlinear Autoregressive Network with Exogenous Inputs (NARX) neural network is proposed for tracking of the non-cooperative moving target. Simulation results show that proposed NARX based approach gives better accuracy as compared to Kalman filter. © 2017 IEEE.},
	author_keywords = {Kalman filtering; Neural Networks; Nonlinear Autoregressive Network with Exogenous Inputs (NARX); Prediction mechanism; Target tracking; Wireless Sensor Network},
	keywords = {Clutter (information theory); Energy conservation; Kalman filters; Neural networks; Target tracking; Continuous monitoring; Environmental data; Kalman-filtering; Maneuvering targets; Network-based approach; Nonlinear Autoregressive Network with exogenous inputs; Prediction mechanisms; Tracking application; Wireless sensor networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Giannetti2019,
	author = {Giannetti, C. and Essien, A. and Pang, Y.O.},
	title = {A novel deep learning approach for event detection in smart manufacturing},
	year = {2019},
	journal = {Proceedings of International Conference on Computers and Industrial Engineering, CIE},
	volume = {2019-October},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079503114&partnerID=40&md5=037a370fba88cbfb5f995718e2130b55},
	abstract = {In a smart factory, the ability to detect time series events associated with particular conditions of equipment such as peaks, changeovers and failures is an important task that supports process monitoring and drives optimal performance. This task can be formulated as a Machine Learning time-series classification problem (TSC), requiring algorithms that combine good predictive performance and fast training time. In this paper, we propose a novel approach that uses Deep Learning models to predict changeover events from large data streams collected from a metal packaging manufacturing plant. The specific model architecture comprises deep Convolutional Neural Network (CNN) and Bidirectional Long Short-Term Memory (CNN-LSTM) stacked autoencoders. This architecture combines the advantage power of CNNs in automatic feature extraction and the adept sequential learning ability of LSTMs. We empirically evaluate the performance of our proposed model in time-series classification using historical real-world machine speed data. The findings from our experiments demonstrate the applicability of Deep Learning to Smart Manufacturing and support the potential of the proposed approach when compared to state-of-the-art event detection classifiers, especially in the significantly reduced model training time. © 2019, Computers and Industrial Engineering. All rights reserved.},
	author_keywords = {CNN-LSTM; Deep learning; Industry 4.0; Stacked autoencoders},
	keywords = {Deep neural networks; Digital storage; Flow control; Long short-term memory; Network architecture; Process monitoring; Time series; Auto encoders; Convolutional neural network; Convolutional neural network-LSTM; Deep learning; Events detection; Learning approach; Smart manufacturing; Stacked autoencoder; Time series classifications; Training time; Industry 4.0},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Matsuoka2019,
	author = {Matsuoka, Daisuke and Araki, Fumiaki and Sasaki, Hideharu},
	title = {Event detection and visualization of ocean eddies simulated by ocean general circulation model},
	year = {2019},
	journal = {International Journal of Modeling, Simulation, and Scientific Computing},
	volume = {10},
	number = {3},
	doi = {10.1142/S1793962319500181},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067008948&doi=10.1142%2fS1793962319500181&partnerID=40&md5=95787a8d9b5a1c82aac56b36feb9dfb3},
	abstract = {Numerical study of ocean eddies has been carried out by using high-resolution ocean general circulation models. In order to understand ocean eddies from the large volume data produced by simulations, visualizing only eddy distribution at each time step is insufficient; time-variations in eddy events and phenomena must also be considered. However, existing methods cannot precisely find and track eddy events such as amalgamation and bifurcation. In this study, we propose an original approach for eddy detection, tracking, and event visualization based on an eddy classification system. The proposed method detects streams and currents as well as eddies, and it classifies discovered eddies into several categories using the additional stream and current information. By tracking how the classified eddies vary over time, detecting events such as eddy amalgamation and bifurcation as well as the interaction between eddies and ocean currents becomes achievable. We adopt the proposed method for two ocean areas in which strong ocean currents exist as case studies. We visualize the detected eddies and events in a time series of images, allowing us to acquire an intuitive understanding of a region of interest concealed in a high-resolution data set. Furthermore, our proposed method succeeded in clarifying the occurrence place and seasonality of each type of eddy event. © 2019 The Author(s).},
	author_keywords = {ocean current; ocean eddy; Ocean simulation; visualization},
	keywords = {Bifurcation (mathematics); Flow visualization; Image segmentation; Metals; Visualization; Classification system; High resolution; High resolution data; Intuitive understanding; Ocean eddies; Ocean general circulation models; Ocean simulation; Region of interest; Ocean currents},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Langston20191691,
	author = {Langston, Charles A. and Mousavi, Seyed Mostafa},
	title = {Separating signal from noise and from other signal using nonlinear thresholding and scale-time windowing of continuous wavelet transforms},
	year = {2019},
	journal = {Bulletin of the Seismological Society of America},
	volume = {109},
	number = {5},
	pages = {1691 – 1700},
	doi = {10.1785/0120190073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073437250&doi=10.1785%2f0120190073&partnerID=40&md5=0bcf15bf2eaa84f701af040733f7d953},
	abstract = {A procedure for removing noise or signal from seismic time series using the continuous wavelet transform (CWT) is developed through the common assumption of noise stationarity for pre‐event or postevent estimates of the noise. Noise and signal are efficiently separated using nonlinear thresholding of the CWT avoiding computationally intensive block thresholding algorithms on the wavelet scale‐time plane. Efficiency is gained by estimating the characteristic statistics of pre‐event noise using empirical cumulative distribution functions and then using these characteristics to threshold the entire time series using hard or soft nonlinear thresholding. In addition, scale‐time windowing of the CWT scalogram and inverse transforming into the time domain allows unprecedented control in partitioning a seismogram into component wave types that can subsequently be used to infer characteristics of Earth structure and source excitation. Noise can be separated from signal and signals decomposed into discrete wave groups. CWT techniques offer unique and intuitive alternatives to traditional Fourier methods for analyzing noise and signal useful for structure and source studies, event detection, and ambient‐noise interferometry. © 2019, Seismological Society of America. All rights reserved.},
	keywords = {Distribution functions; Inverse problems; Seismology; Separation; Signal processing; Time domain analysis; Time series; Block thresholding; Continuous Wavelet Transform; Continuous wavelet transforms; Earth structures; Empirical cumulative distribution functions; Event detection; Fourier methods; Nonlinear thresholding; algorithm; Earth structure; interferometry; signal processing; signal-to-noise ratio; time series; wavelet; Wavelet transforms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@ARTICLE{AlDhanhani2019226,
	author = {AlDhanhani, Ahmed and Damiani, Ernesto and Mizouni, Rabeb and Wang, Di},
	title = {Framework for traffic event detection using Shapelet Transform},
	year = {2019},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {82},
	pages = {226 – 235},
	doi = {10.1016/j.engappai.2019.04.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064719498&doi=10.1016%2fj.engappai.2019.04.002&partnerID=40&md5=ea24cc7f9fc6c483844b9b44c9e4990f},
	abstract = {Early detection of traffic events is essential for informing Traffic Centers, drivers and intelligent vehicles about incoming dangers or congestion. In this study, a framework based on the shapelets technique for automated incident detection is proposed. Using the shapelets time series classification technique, sub sequences of the time series are generated, which represent patterns of incidents/congestion as well as regular traffic situations. Using such shapelets, our framework is able to detect whether an incident is occurring or not. Application of this approach to real-life data of the London Orbital Motorway (M25) proved that our approach not only has the potential to improve the performance of the classification in terms of false alarm rates or/and accuracy but also provides the human expert with insightful interpretation of the decision made by the event detectors. © 2019 Elsevier Ltd},
	author_keywords = {Automated incident detection; Shapelet Transform; Time series analysis},
	keywords = {Time series analysis; Event detectors; False alarm rate; Incident detection; London orbitals; Real life data; Time series classifications; Traffic event; Traffic situations; Traffic congestion},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Goltz2019,
	author = {Goltz, Jonas and Grossberg, Michael and Etemadpour, Ronak},
	title = {Exploring simple neural network architectures for eye movement classification},
	year = {2019},
	journal = {Eye Tracking Research and Applications Symposium (ETRA)},
	doi = {10.1145/3314111.3319813},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069533165&doi=10.1145%2f3314111.3319813&partnerID=40&md5=932138a42630f9ff1181f7bb3bb53181},
	abstract = {Analysis of eye-gaze is a critical tool for studying human-computer interaction and visualization. Yet eye tracking systems only report eye-gaze on the scene by producing large volumes of coordinate time series data. To be able to use this data, we must first extract salient events such as eye fixations, saccades, and post-saccadic oscillations (PSO). Manually extracting these events is time-consuming, labor-intensive and subject to variability. In this paper, we present and evaluate simple and fast automatic solutions for eye-gaze analysis based on supervised learning. Similar to some recent studies, we developed different simple neural networks demonstrating that feature learning produces superior results in identifying events from sequences of gaze coordinates. We do not apply any ad-hoc post-processing, thus creating a fully automated end-to-end algorithms that perform as good as current state-of-the-art architectures. Once trained they are fast enough to be run in a near real time setting. © 2019 Association for Computing Machinery.},
	author_keywords = {Deep learning; Event detection; Eye movement; Machine learning},
	keywords = {Deep learning; Eye movements; Human computer interaction; Learning systems; Machine learning; Network architecture; Neural networks; Coordinate time series; Event detection; Eye movement classifications; Eye tracking systems; Feature learning; Fully automated; Post processing; State of the art; Eye tracking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Wu201962,
	author = {Wu, Yue and Lin, Youzuo and Zhou, Zheng and Bolton, David Chas and Liu, Ji and Johnson, Paul},
	title = {DeepDetect: A Cascaded Region-Based Densely Connected Network for Seismic Event Detection},
	year = {2019},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	volume = {57},
	number = {1},
	pages = {62 – 75},
	doi = {10.1109/TGRS.2018.2852302},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051019612&doi=10.1109%2fTGRS.2018.2852302&partnerID=40&md5=9826b286adc8b83014012771da055cba},
	abstract = {Automatic event detection from time series signals has broad applications. Traditional detection methods detect events primarily by the use of similarity and correlation in data. Those methods can be inefficient and yield low accuracy. In recent years, machine learning techniques have revolutionized many sciences and engineering domains. In particular, the performance of object detection in a 2-D image data has significantly improved due to deep neural networks. In this paper, we develop a deep-learning-based detection method, called 'DeepDetect,' to detect events from seismic signals. We find that the direct adaptation of similar ideas from 2-D object detection to our problem faces two challenges. The first challenge is that the duration of earthquake event varies significantly; the other is that the proposals generated are temporally correlated. To address these challenges, we propose a novel cascaded region-based convolutional neural network to capture earthquake events in different sizes while incorporating contextual information to enrich features for each proposal. To achieve a better generalization performance, we use densely connected blocks as the backbone of our network. Because some positive events are not correctly annotated, we further formulate the detection problem as a learning-from-noise problem. To verify the performance, we employ the seismic data generated from the Pennsylvania State University Rock and Sediment Mechanics Laboratory, and we acquire labels with the help of experts. We show that our techniques yield high accuracy. Therefore, our novel deep-learning-based detection methods can potentially be powerful tools for identifying events from the time series data in various applications. © 1980-2012 IEEE.},
	author_keywords = {Convolutional neural network (CNN); event detection; seismic signals; time series segmentation},
	keywords = {Pennsylvania; United States; Convolution; Correlation methods; Deep neural networks; Earthquakes; Feature extraction; Image enhancement; Neural networks; Noise pollution; Object detection; Object recognition; Seismic waves; Signal detection; Time series analysis; Convolutional Neural Networks (CNN); Event detection; Proposals; Seismic signals; Time-series segmentation; accuracy assessment; detection method; earthquake event; machine learning; numerical method; segmentation; seismic data; time series; Correlation detectors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 82; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Wang2019,
	author = {Wang, Yunli and Goutte, Cyril},
	title = {Event Detection using Images of Temporal Word},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2411},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070662732&partnerID=40&md5=7a5091cb0082e8f05feabd19fde85a1d},
	abstract = {Detecting events from social media requires to deal with the noisy sequences of user gen-erated text. Previous work typically focuses either on semantic patterns, using e.g.Topic models, or on temporal patterns of word usage, e.g. using wavelet analysis. In our study, we propose a novel method to capture the temporal patterns of word usage on social media, by transforming time series of word oc-currence frequency into images, and clustering images using features extracted from the images using the convolutional neural network ResNet. These clusters are then ranked by burstiness, identifying the top ranked clusters as detected events. Words in the clusters are also filtered using co-occurrence similarity, in order to identify the most representative words describing the event. We test our approach on one Instagram and one Twitter datasets, and obtain performance of up to 80% precision from the top five detected events on both datasets. © 2019. CEUR-WS. All rights reserved.},
	keywords = {Neural networks; Semantics; Social networking (online); Burstiness; Co-occurrence; Convolutional neural network; Event detection; Semantic pattern; Social media; Temporal pattern; Information retrieval},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Faverjon2018126,
	author = {Faverjon, Céline and Berezowski, John},
	title = {Choosing the best algorithm for event detection based on the intend application: A conceptual framework for syndromic surveillance},
	year = {2018},
	journal = {Journal of Biomedical Informatics},
	volume = {85},
	pages = {126 – 135},
	doi = {10.1016/j.jbi.2018.08.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051398838&doi=10.1016%2fj.jbi.2018.08.001&partnerID=40&md5=c1aedb6862f1202e03b8f5a2f963b524},
	abstract = {There is an extensive list of methods available for the early detection of an epidemic signal in syndromic surveillance data. However, there is no commonly accepted classification system for the statistical methods used for event detection in syndromic surveillance. Comparing and choosing appropriate event detection algorithms is an increasingly challenging task. Although lists of selection criteria, and statistical methods used for signal detection have been reported, selection criteria are rarely linked to a specific set of appropriate statistical methods. The paper presents a practical approach for guiding surveillance practitioners to make an informed choice from among the most popular event detection algorithms based on the intended application of the algorithm. We developed selection criteria by mapping the assumptions and performance characteristics of event detection algorithms directly to important characteristics of the time series used in syndromic surveillance. We also considered types of epidemics that may be expected and other characteristics of the surveillance system. These guidelines will provide decisions makers, data analysts, public health practitioners, and researchers with a comprehensive but practical overview of the domain, which may reduce the technical barriers to the development and implementation of syndromic surveillance systems in animal and human health. The classification scheme was restricted to univariate and temporal methods because they are the most commonly used algorithms in syndromic surveillance. © 2018 Elsevier Inc.},
	author_keywords = {Biosurveillance; Epidemics; Public health surveillance; Syndromic surveillance},
	keywords = {Algorithms; Animals; Computational Biology; Epidemics; Humans; Models, Statistical; Poisson Distribution; Population Surveillance; Sentinel Surveillance; classification algorithm; clinical practice; conceptual framework; decision making; disease surveillance; health care personnel; human; Note; performance; practice guideline; priority journal; regression analysis; sensitivity and specificity; syndromic surveillance; algorithm; animal; biology; epidemic; health survey; Poisson distribution; procedures; sentinel surveillance; statistical model},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Bronze Open Access}
}

@CONFERENCE{Mohammed20181664,
	author = {Mohammed, Hadi and Hameed, Ibrahim A. and Seidu, Razak},
	title = {Machine learning - Based detection of water contamination in water distribution systems},
	year = {2018},
	journal = {GECCO 2018 Companion - Proceedings of the 2018 Genetic and Evolutionary Computation Conference Companion},
	pages = {1664 – 1671},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051482676&partnerID=40&md5=61fcbf53e7d70a9622fc8b27db85a67c},
	abstract = {Accurate detection of natural or intentional contamination events in water distribution pipes is critical to drinking water safety. Efficient early warning systems that can detect contamination events require detection algorithms that can accurately predict the occurrence of such events. This paper presents the development of adaptive neuro-fuzzy inference system (ANFIS) models for detecting the safety condition of water in pipe networks when concentrations of water quality variables in the pipes exceed their maximum thresholds. The event detection is based on time series data composed of pH, turbidity, color and bacteria count measured at the effluent of a drinking water utility and nine different locations of sensors in the distribution network in the city of Ålesund, Norway. The proposed ANFIS models correctly detected between 92% and 96% of the safety condition of the water in the pipe network, with approximately 1% false alarm rate during the testing stage. The models also achieved high rates of specificity and precision, with very high correlations between the predictions and actual conditions of the water in the pipes. The accuracy of the models achieved in this study suggests that the models can be useful in real time contamination event detection in the pipe networks.},
	author_keywords = {Contaminant detection; Distribution network; Machine-learning algorithms; Water safety},
	keywords = {Contamination; Effluents; Electric power distribution; Evolutionary algorithms; Fuzzy inference; Fuzzy neural networks; Fuzzy systems; Learning algorithms; Learning systems; Potable water; Safety testing; Water distribution systems; Water pollution; Water quality; Adaptive neuro fuzzy inference systems (ANFIS); Contaminant detection; Contamination events; Early Warning System; Intentional contaminations; Water distribution pipes; Water quality variables; Water safety; Pollution detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Li2019414,
	author = {Li, Tao and Chen, Lei},
	title = {Space event detection method based on cluster analysis of satellite historical orbital data},
	year = {2019},
	journal = {Acta Astronautica},
	volume = {160},
	pages = {414 – 420},
	doi = {10.1016/j.actaastro.2019.04.038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065513199&doi=10.1016%2fj.actaastro.2019.04.038&partnerID=40&md5=0786b5b55e20a126aa36719205712fbd},
	abstract = {A new method of detecting space events using satellite two-line element (TLE) histories is proposed. Anomalous data segments in the TLE-derived time series of a specific orbital element is detected to locate space events. After data preprocessing, a series of equal-length data segments are extracted from the time series and converted into a data form that is uniformly sampled in the time domain. Anomaly detection is achieved by clustering the data segments using a one-dimensional self-organizing map. After the clustering operation, the same type of data segments are grouped together and different types of data segments are divided into different groups. Thus, the type of space event and the associated orbital anomaly pattern can be obtained simultaneously. Space event detection results of typical active satellites show that the proposed method can accurately avoid false detections while maintaining a high detection rate. By comparing detection results of different clustering granularities, the ability to obtain detailed information of space events is also proved. © 2019 IAA},
	author_keywords = {Clustering; Self-organizing map; Space event detection; Two-line element},
	keywords = {Cluster analysis; Conformal mapping; Orbits; Satellites; Self organizing maps; Time domain analysis; Time series; Active satellites; Anomaly patterns; Clustering; Clustering operation; Data preprocessing; Event detection; High detection rate; Two line elements; Anomaly detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Faverjon2019,
	author = {Faverjon, Céline and Carmo, Luís Pedro and Berezowski, John},
	title = {Multivariate syndromic surveillance for cattle diseases: Epidemic simulation and algorithm performance evaluation},
	year = {2019},
	journal = {Preventive Veterinary Medicine},
	volume = {172},
	doi = {10.1016/j.prevetmed.2019.104778},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072780520&doi=10.1016%2fj.prevetmed.2019.104778&partnerID=40&md5=c700a3a4672cf254796312d58e851f2d},
	abstract = {Multivariate Syndromic Surveillance (SyS) systems that simultaneously assess and combine information from different data sources are especially useful for strengthening surveillance systems for early detection of infectious disease epidemics. Despite the strong motivation for implementing multivariate SyS and there being numerous methods reported, the number of operational multivariate SyS systems in veterinary medicine is still very small. One possible reason is that assessing the performance of such surveillance systems remains challenging because field epidemic data are often unavailable. The objective of this study is to demonstrate a practical multivariate event detection method (directionally sensitive multivariate control charts) that can be easily applied in livestock disease SyS, using syndrome time series data from the Swiss cattle population as an example. We present a standardized method for simulating multivariate epidemics of different diseases using four diseases as examples: Bovine Virus Diarrhea (BVD), Infectious Bovine Rhinotracheitis (IBR), Bluetongue virus (BTV) and Schmallenberg virus (SV). Two directional multivariate control chart algorithms, Multivariate Exponentially Weighted Moving Average (MEWMA) and Multivariate Cumulative Sum (MCUSUM) were compared. The two algorithms were evaluated using 12 syndrome time series extracted from two Swiss national databases. The two algorithms were able to detect all simulated epidemics around 4.5 months after the start of the epidemic, with a specificity of 95%. However, the results varied depending on the algorithm and the disease. The MEWMA algorithm always detected epidemics earlier than the MCUSUM, and epidemics of IBR and SV were detected earlier than epidemics of BVD and BTV. Our results show that the two directional multivariate control charts are promising methods for combining information from multiple time series for early detection of subtle changes in time series from a population without producing an unreasonable amount of false alarms. The approach that we used for simulating multivariate epidemics is relatively easy to implement and could be used in other situations where real epidemic data are unavailable. We believe that our study results can support the implementation and assessment of multivariate SyS systems in animal health. © 2019 Elsevier B.V.},
	author_keywords = {Directional multivariate control charts; Epidemic simulation; MCUSUM; MEWMA; Syndromic surveillance; Time series},
	keywords = {Article; Bluetongue orbivirus; bovine viral diarrhea; cattle disease; detection algorithm; disease simulation; epidemic; infectious bovine rhinotracheitis; nonhuman; priority journal; Schmallenberg virus; Switzerland; time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Chambon201964,
	author = {Chambon, S. and Thorey, V. and Arnal, P.J. and Mignot, E. and Gramfort, A.},
	title = {DOSED: A deep learning approach to detect multiple sleep micro-events in EEG signal},
	year = {2019},
	journal = {Journal of Neuroscience Methods},
	volume = {321},
	pages = {64 – 78},
	doi = {10.1016/j.jneumeth.2019.03.017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064531767&doi=10.1016%2fj.jneumeth.2019.03.017&partnerID=40&md5=7c95771baccf0d80be04d58e16ea576a},
	abstract = {Background: Electroencephalography (EEG) monitors brain activity during sleep and is used to identify sleep disorders. In sleep medicine, clinicians interpret raw EEG signals in so-called sleep stages, which are assigned by experts to every 30s window of signal. For diagnosis, they also rely on shorter prototypical micro-architecture events which exhibit variable durations and shapes, such as spindles, K-complexes or arousals. Annotating such events is traditionally performed by a trained sleep expert, making the process time consuming, tedious and subject to inter-scorer variability. To automate this procedure, various methods have been developed, yet these are event-specific and rely on the extraction of hand-crafted features. New method: We propose a novel deep learning architecture called Dreem One Shot Event Detector (DOSED). DOSED jointly predicts locations, durations and types of events in EEG time series. The proposed approach, applied here on sleep related micro-architecture events, is inspired by object detectors developed for computer vision such as YOLO and SSD. It relies on a convolutional neural network that builds a feature representation from raw EEG signals, as well as two modules performing localization and classification respectively. Results and comparison with other methods: The proposed approach is tested on 4 datasets and 3 types of events (spindles, K-complexes, arousals) and compared to the current state-of-the-art detection algorithms. Conclusions: Results demonstrate the versatility of this new approach and improved performance compared to the current state-of-the-art detection methods. © 2019},
	author_keywords = {Deep learning; EEG; Event detection; Machine learning; Sleep},
	keywords = {Adult; Arousal; Brain; Deep Learning; Electroencephalography; Female; Humans; Male; Polysomnography; Signal Processing, Computer-Assisted; Sleep; Sleep Stages; Young Adult; arousal; Article; deep learning; electroencephalography; human; priority journal; sleep; sleep stage; supervised machine learning; time series analysis; vision; adult; brain; female; male; physiology; polysomnography; procedures; signal processing; sleep; young adult},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40; All Open Access, Green Open Access}
}

@ARTICLE{Salem20181018,
	author = {Salem, Osman and Serhrouchni, Ahmed and Mehaoua, Ahmed and Boutaba, Raouf},
	title = {Event Detection in Wireless Body Area Networks Using Kalman Filter and Power Divergence},
	year = {2018},
	journal = {IEEE Transactions on Network and Service Management},
	volume = {15},
	number = {3},
	pages = {1018 – 1034},
	doi = {10.1109/TNSM.2018.2842195},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047805512&doi=10.1109%2fTNSM.2018.2842195&partnerID=40&md5=7a16c1ed698933aedb81b5d31de28aac},
	abstract = {The collected data by biomedical sensors must be analyzed for automatic detection of physiological changes. The early identification of an event in collected data is required to trigger an alarm upon detection of patient health degradation. Such alarms inform healthcare professionals and allow them to quickly react by taking appropriate actions. However, events result from physiological change or faulty measurements, and lead to false alarms and unnecessary medical intervention. In this paper, we propose a framework for automatic detection of events from collected data by biomedical sensors. The proposed approach is based on the Kalman filter to forecast the current measurement and to derive the baseline of the time series. The power divergence is used to measure the distance between the forecasted and measured values. When a change occurs, this metric significantly deviates from past values. To distinguish emergency events from faulty measurements, we exploit the spatial correlation between the monitored attributes. We conduct experiments on real physiological data set and our results show that our proposed framework achieves a good detection accuracy with a low false alarm rate. Its simplicity and processing speed make our proposed framework efficient and effective for real-world deployment. © 2004-2012 IEEE.},
	author_keywords = {anomaly detection; fault detection; Kalman filter; power divergence; reliability; Wireless body area networks},
	keywords = {Alarm systems; Bandpass filters; Biomedical signal processing; Biosensors; Errors; Fault detection; Kalman filters; Physiology; Reliability; Anomaly detection; Faulty measurements; Health care professionals; Medical intervention; Power Divergence; Real world deployment; Spatial correlations; Wireless body area network; Wireless local area networks (WLAN)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@ARTICLE{Li20194762,
	author = {Li, Wenting and Wang, Meng},
	title = {Identifying Overlapping Successive Events Using a Shallow Convolutional Neural Network},
	year = {2019},
	journal = {IEEE Transactions on Power Systems},
	volume = {34},
	number = {6},
	pages = {4762 – 4772},
	doi = {10.1109/TPWRS.2019.2914774},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074447154&doi=10.1109%2fTPWRS.2019.2914774&partnerID=40&md5=3c056cc8afa572ef1d2b25d916fd3f7b},
	abstract = {Real-time identification of successive events in power systems is crucial to avoid cascading failures. Existing identification methods are mainly designed for single events and may not accurately identify a subsequent event that occurs when the system is under going the disturbance of a previous event. Since overlapping successive events do not frequently happen in power systems, insufficient multievent data sets exist for training. We develop a data-driven event identification method that can accurately identify the types of overlapping events. Our approach only requires a small number of recorded phasor measurement unit data of single events to train a two-layer convolutional neural network (CNN) classifier offline. We extract the dominant eigenvalues and singular values as features instead of training on time series directly. That reduces the required number of training data sets and enhances the robustness to measurement inaccuracy. In real time, our method first predicts and subtracts the impact of previous events. It then extracts the dominant features from the residual measurements and applies the classifier. We evaluate the method on simulated events in the IEEE 68-bus power system. Our classifier is demonstrated to be more accurate and stable than a direct application of CNN on time series. The robustness of the proposed method to the delay in event detection and noise is validated. © 1969-2012 IEEE.},
	author_keywords = {cascading failures; convolutional neural network (CNN); dominant features; Event identification; phasor measurement unit (PMU)},
	keywords = {Convolution; Eigenvalues and eigenfunctions; Network layers; Phase measurement; Phasor measurement units; Real time systems; Time series; Cascading failures; Convolutional neural network; Dominant eigenvalues; dominant features; Event identification; Identification method; Real-time identification; Residual measurements; Multilayer neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Bronze Open Access}
}

@ARTICLE{Nguyen2019,
	author = {Nguyen, Van Quan and Anh, Tien Nguyen and Yang, Hyung-Jeong},
	title = {Real-time event detection using recurrent neural network in social sensors},
	year = {2019},
	journal = {International Journal of Distributed Sensor Networks},
	volume = {15},
	number = {6},
	doi = {10.1177/1550147719856492},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067335701&doi=10.1177%2f1550147719856492&partnerID=40&md5=eea30e1a2262842686d2b34bb42933f0},
	abstract = {We proposed an approach for temporal event detection using deep learning and multi-embedding on a set of text data from social media. First, a convolutional neural network augmented with multiple word-embedding architectures is used as a text classifier for the pre-processing of the input textual data. Second, an event detection model using a recurrent neural network is employed to learn time series data features by extracting temporal information. Recently, convolutional neural networks have been used in natural language processing problems and have obtained excellent results as performing on available embedding vector. In this article, word-embedding features at the embedding layer are combined and fed to convolutional neural network. The proposed method shows no size limitation, supplementation of more embeddings than standard multichannel based approaches, and obtained similar performance (accuracy score) on some benchmark data sets, especially in an imbalanced data set. For event detection, a long short-term memory network is used as a predictor that learns higher level temporal features so as to predict future values. An error distribution estimation model is built to calculate the anomaly score of observation. Events are detected using a window-based method on the anomaly scores. © The Author(s) 2019.},
	author_keywords = {event detection; long short-term memory; multiple word embedding; neural network; real-time; Social data},
	keywords = {Benchmarking; Brain; Classification (of information); Convolution; Deep learning; Embeddings; Long short-term memory; Natural language processing systems; Neural networks; Convolutional neural network; Event detection; Imbalanced Data-sets; multiple word embedding; NAtural language processing; Real time; Social datum; Temporal information; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Gold Open Access}
}

@CONFERENCE{Aldhanhani201841,
	author = {Aldhanhani, Ahmed and Damiani, Ernesto and Mizouni, Rabeb and Wang, Di},
	title = {Analysis of shapelet transform usage in traffic event detection},
	year = {2018},
	journal = {Proceedings - 2018 IEEE International Conference on Cognitive Computing, ICCC 2018 - Part of the 2018 IEEE World Congress on Services},
	pages = {41 – 48},
	doi = {10.1109/ICCC.2018.00013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057737761&doi=10.1109%2fICCC.2018.00013&partnerID=40&md5=a45c3ae3168fe8a0de0ce04997f4e7cd},
	abstract = {Automatic traffic incident detection from sensors data is a long studied topic that has been advancing with the introduction of new algorithms and recently from machine learning. While the traffic incidents detection problem can be treated as a time series classification task, there are not many attempts in this area and further investigations should be conducted. Recently, the Shapelet Transform algorithm has been proposed as a promising solution for time series classification. In this paper, we study the usage of Shapelet Transform in the field of traffic event detection. We first prove the applicability of the algorithm for automatic incident detection where it provides comparable performance to other techniques. In addition, we show how the Shapelet Transform algorithm can help in improving the detection by guiding the expert input in a cognitive approach. We test our approach using a real data set produced from road sensors of the M25 London Circular road. Results show an improvement comparing to using Shapelet Transform solely. © 2018 IEEE.},
	author_keywords = {Automatic incident detection; Shapelet transform; Time series classification},
	keywords = {Learning systems; Roads and streets; Statistical tests; Automatic incident detection; Cognitive approaches; Detection problems; Real data sets; Time series classifications; Traffic incident detections; Traffic incidents; Transform algorithm; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Chow2018140,
	author = {Chow, Christopher W.K. and Liu, Jixue and Li, Jiuyong and Swain, Nick and Reid, Katherine and Saint, Christopher P.},
	title = {Development of smart data analytics tools to support wastewater treatment plant operation},
	year = {2018},
	journal = {Chemometrics and Intelligent Laboratory Systems},
	volume = {177},
	pages = {140 – 150},
	doi = {10.1016/j.chemolab.2018.03.006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046118373&doi=10.1016%2fj.chemolab.2018.03.006&partnerID=40&md5=ce4ba59ab81a3e3e7e29e062a93e1741},
	abstract = {A case study of applying chemometrics approach, k-means, a clustering algorithm to develop a real-time industrial process early warning system using online measurements was conducted. An online spectrophotometer was installed for an eighteen-month monitoring study between 2013 and 2015 at the inlet of a wastewater treatment plant. During this time a web-based prototype portal with data integration, visualization, prediction and anomaly detection functions for complex online data sets was developed in-house to assess the spectral data acquired by the spectrophotometer together with other databases (such as rainfall and temperature). Several chemometrics options, such as association analysis and feature selection, were used to extract useful operational information from the acquired data. In this paper, the anomaly detection function which includes pattern learning and comparison algorithms and a powerful user interface was described in detail. By using the functions, process upsets were successfully detected from the spectral data at the inlet of the treatment plant. The detected events/upsets were then compared with the treatment plant logs and they were found aligned well, which proved that the anomaly detection technique was effective and has the potential to inform decision to assist plant operators. In addition, the proposed anomaly detection technique is also a flexible algorithm which works with any similar time series data to detect other process related issues to provide real-time warning to support treatment plant operations. © 2018 Elsevier B.V.},
	author_keywords = {Data analytics; Event detection; Online monitoring; UV–Vis spectroscopy; Wastewater treatment process},
	keywords = {water; algorithm; Article; automated pattern recognition; data analytics; environmental reclamation; information processing; online monitoring; priority journal; waste water management; waste water treatment plant; water quality},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@ARTICLE{Amelkin2019,
	author = {Amelkin, Victor and Bogdanov, Petko and Singh, Ambuj K.},
	title = {A Distance Measure for the Analysis of Polar Opinion Dynamics in Social Networks},
	year = {2019},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	volume = {13},
	number = {4},
	doi = {10.1145/3332168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075581957&doi=10.1145%2f3332168&partnerID=40&md5=5d9d49a1e6ef22b0df21f4cd0aaf78f3},
	abstract = {Analysis of opinion dynamics in social networks plays an important role in today's life. For predicting users' political preference, it is particularly important to be able to analyze the dynamics of competing polar opinions, such as pro-Democrat vs. pro-Republican. While observing the evolution of polar opinions in a social network over time, can we tell when the network evolved abnormally? Furthermore, can we predict how the opinions of the users will change in the future? To answer such questions, it is insufficient to study individual user behavior, since opinions can spread beyond users' ego-networks. Instead, we need to consider the opinion dynamics of all users simultaneously and capture the connection between the individuals' behavior and the global evolution pattern of the social network. In this work, we introduce the Social Network Distance (SND)-A distance measure that quantifies the likelihood of evolution of one snapshot of a social network into another snapshot under a chosen model of polar opinion dynamics. SND has a rich semantics of a transportation problem, yet, is computable in time linear in the number of users and, as such, is applicable to large-scale online social networks. In our experiments with synthetic and Twitter data, we demonstrate the utility of our distance measure for anomalous event detection. It achieves a true positive rate of 0.83, twice as high as that of alternatives. The same predictions presented in precision-recall space show that SND retains perfect precision for recall up to 0.2. Its precision then decreases while maintaining more than 2-fold improvement over alternatives for recall up to 0.95. When used for opinion prediction in Twitter data, SND's accuracy is 75.6%, which is 7.5% higher than that of the next best method. © 2019 Association for Computing Machinery. All rights reserved.},
	author_keywords = {anomaly detection; competing opinions; distance measure; earth mover's distance; minimum-cost network flow; model-driven analysis; opinion dynamics; opinion prediction; polar opinions; polarization; Social network; time-series; transportation problem; wasserstein metric},
	keywords = {Anomaly detection; Behavioral research; Clustering algorithms; Dynamics; Forecasting; Polarization; Semantics; Time series; Time series analysis; competing opinions; Distance measure; Earth Mover's distance; Minimum cost network flow; Model-driven; Opinion dynamics; polar opinions; Transportation problem; Wasserstein metric; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Chambon2018,
	author = {Chambon, Stanislas and Thorey, Valentin and Arnal, Pierrick J. and Mignot, Emmanuel and Gramfort, Alexandre},
	title = {A deep learning architecture to detect events in EEG signals during sleep},
	year = {2018},
	journal = {IEEE International Workshop on Machine Learning for Signal Processing, MLSP},
	volume = {2018-September},
	doi = {10.1109/MLSP.2018.8517067},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057050061&doi=10.1109%2fMLSP.2018.8517067&partnerID=40&md5=dc457b80dfcc91f19dcab5478cdbec2e},
	abstract = {Electroencephalography (EEG) during sleep is used by clinicians to evaluate various neurological disorders. In sleep medicine, it is relevant to detect macro-events (≥ 10s) such as sleep stages, and micro-events (≤ 2s) such as spindles and K-complexes. Annotations of such events require a trained sleep expert, a time consuming and tedious process with a large inter-scorer variability. Automatic algorithms have been developed to detect various types of events but these are event-specific. We propose a deep learning method that jointly predicts locations, durations and types of events in EEG time series. It relies on a convolutional neural network that builds a feature representation from raw EEG signals. Numerical experiments demonstrate efficiency of this new approach on various event detection tasks compared to current state-of-the-art, event specific, algorithms. © 2018 IEEE.},
	author_keywords = {Deep learning; EEG; EEG-patterns; Event detection; Sleep; Time series},
	keywords = {Electroencephalography; Electrophysiology; Neural networks; Pattern recognition; Signal processing; Sleep research; Time series; Convolutional neural network; EEG pattern; Event detection; Feature representation; Learning architectures; Neurological disorders; Numerical experiments; Sleep; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Green Open Access}
}

@CONFERENCE{Marik2019889,
	author = {Marik, Radek and Bohac, Leos},
	title = {Non-stationary Events Detection Based on Extrema Value Theory},
	year = {2019},
	journal = {2018 5th International Conference on Systems and Informatics, ICSAI 2018},
	pages = {889 – 894},
	doi = {10.1109/ICSAI.2018.8599319},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061492452&doi=10.1109%2fICSAI.2018.8599319&partnerID=40&md5=3e95dca19fcf57d847dc83868562326e},
	abstract = {A detection of anomaly events in a non-stationary time series resembling vibration aspects is often based on the signal envelope. Both commonly used approaches, i.e. the Hilbert transform and the empirical mode decomposition, lead to high processing power requirements. As anomalies are assumed to be rare, we propose simplified methods based on extreme value theory that enable trend corrections and anomaly event occurrence detection. Both methods are based on the upper and lower envelope approximations that are constructed using maxima and minima limits of the signal. © 2018 IEEE.},
	keywords = {Mathematical transformations; Empirical Mode Decomposition; Events detection; Extreme value theory; High processing power; Hilbert transform; Non-stationary time series; Signal envelope; Simplified method; Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Yuan2018105,
	author = {Yuan, Lufeng and Yao, Erlin and Tan, Guangming},
	title = {Automated and precise event detection method for big data in biomedical imaging with support vector machine},
	year = {2018},
	journal = {Computer Systems Science and Engineering},
	volume = {33},
	number = {2},
	pages = {105 – 114},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051405246&partnerID=40&md5=d5fd8bd042fb96214de86c0c1f9a270b},
	abstract = {This paper proposes a machine learning based method which can detect certain events automatically and precisely in biomedical imaging. We detect one important and not well-defined event, which is called flash, in fluorescence images of Escherichia coli. Given a time series of images, first we propose a scheme to transform the event detection on region of interest (ROD in images to a classification problem. Then with supervised human labeling data, we develop a feature selection technique to utilize support vector machine (SVM) to solve this classification problem. To reduce the time in training SVM model, a parallel version of SVM training is implemented. On ten stacks of fluorescence images labeled by experts, each of which owns one hundred 512 -512 images with in total 4906 ROIs and 72056 labeled events, event detection with proposed method takes 19 seconds, while human labeling roughly costs 60 hours. With human labeling as the standard, the accuracy of our method achieves an F-value of about 0.81. This method is much faster than human detection and expects to be more precise with bigger data. It also can be expanded to a series of event detection with similar properties and improve efficiency of detection greatly. © 2018 CRL.},
	author_keywords = {Big data; Biomedical imaging; Event detection; Machine learning; Support vector machine},
	keywords = {Artificial intelligence; Big data; Escherichia coli; Fluorescence; Image retrieval; Image segmentation; Learning systems; Medical imaging; Biomedical imaging; Event detection; F values; Feature selection techniques; Human detection; Parallel version; Region of interest; SVM model; Detection methods; Events detection; Fluorescence image; Human labelling; Learning-based methods; Machine-learning; Regions of interest; Support vectors machine; Times series; Support vector machines},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Guanche García2019849,
	author = {Guanche García, Yanira and Shadaydeh, Maha and Mahecha, Miguel and Denzler, Joachim},
	title = {Extreme anomaly event detection in biosphere using linear regression and a spatiotemporal MRF model},
	year = {2019},
	journal = {Natural Hazards},
	volume = {98},
	number = {3},
	pages = {849 – 867},
	doi = {10.1007/s11069-018-3415-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050693266&doi=10.1007%2fs11069-018-3415-8&partnerID=40&md5=06c3d7d5fd3e63724ab8bc22f800fe88},
	abstract = {Detecting abnormal events within time series is crucial for analyzing and understanding the dynamics of the system in many research areas. In this paper, we propose a methodology to detect these anomalies in multivariate environmental data. Five biosphere variables from a preliminary version of the Earth System Data Cube have been used in this study: Gross Primary Productivity, Latent Energy, Net Ecosystem Exchange, Sensible Heat and Terrestrial Ecosystem Respiration. To tackle the spatiotemporal dependencies of the biosphere variables, the proposed methodology after preprocessing the data is divided into two steps: a feature extraction step applied to each time series in the grid independently, followed by a spatiotemporal event detection step applied to the obtained novelty scores over the entire study area. The first step is based on the assumption that the time series of each variable can be represented by an autoregressive moving average (ARMA) process, and the anomalies are those time instances that are not well represented by the estimated ARMA model. The Mahalanobis distance of the ARMA models’ multivariate residuals is used as a novelty score. In the second step, the obtained novelty scores of the entire study are treated as time series of images. Markov random fields (MRFs) provide an effective and theoretically well-established methodology for integrating spatiotemporal dependency into the classification of image time series. In this study, the classification of the novelty score images into three classes, intense anomaly, possible anomaly, and normal, is performed using unsupervised K-means clustering followed by multi-temporal MRF segmentation applied recursively on the images of each consecutive L≥ 1 time steps. The proposed methodology was applied to an area covering Europe and Africa. Experimental results and validation based on known historic events show that the method is able to detect historic events and also provides a useful tool to define sensitive regions. © 2018, The Author(s).},
	author_keywords = {Autoregressive models; Mahalanobis distance; Markov random field model; Spatiotemporal event detection},
	keywords = {Africa; Europe; biosphere; detection method; extreme event; hazard assessment; image classification; regression analysis; spatiotemporal analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Perera20183001,
	author = {Perera, Ian and Hwang, Jena and Bayas, Kevin and Dorr, Bonnie and Wilks, Yorick},
	title = {Cyberattack Prediction Through Public Text Analysis and Mini-Theories},
	year = {2018},
	journal = {Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018},
	pages = {3001 – 3010},
	doi = {10.1109/BigData.2018.8622106},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062615999&doi=10.1109%2fBigData.2018.8622106&partnerID=40&md5=730093b9d6beb6ff660cc7860071c60d},
	abstract = {This paper describes a new approach to detection and tracking of potential cyberattacks from analyzing large quantities of cyber-related webpage text, using ontological knowledge about such attacks combined with composable causal models represented in Probabilistic Soft Logic. The stages of a cyberattack kill chain are viewed as a sequence of both observed and unobserved events (e.g., reconnaissance, weaponize, exploit, install) and explicit mentions of, or related to, such events are examined as potential signals for a future attack. Using a suite of natural language processing techniques, sentences from input news texts are automatically classified according to the described cyberattack event, then enriched with named entity recognition for the rapid detection of key elements that might be associated with potential cyberattacks. We present our work as a framework for rapid and flexible predictive analysis of the ever-increasing amount of cyber-related text data, with initial experiments indicating that event detection using parsing and named entity recognition combined with statistical relational learning show promise in time-series prediction from news text. © 2018 IEEE.},
	author_keywords = {Big Data; Cybersecurity; Natural Language Processing; Statistical Relational Learning},
	keywords = {Character recognition; Computation theory; Cybersecurity; Natural language processing systems; Syntactics; Time series analysis; Cyber security; Cyber-attacks; Detection and tracking; Language processing; Named entity recognition; Natural language processing; Natural languages; New approaches; Statistical relational learning; Text analysis; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@ARTICLE{Faverjon2019,
	author = {Faverjon, Céline and Schärrer, Sara and Hadorn, Daniela C. and Berezowski, John},
	title = {Simulation Based Evaluation of Time Series for Syndromic Surveillance of Cattle in Switzerland},
	year = {2019},
	journal = {Frontiers in Veterinary Science},
	volume = {6},
	doi = {10.3389/fvets.2019.00389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075332982&doi=10.3389%2ffvets.2019.00389&partnerID=40&md5=c2a87e3b8e56a77befa7e3126d019590},
	abstract = {Choosing the syndrome time series to monitor in a syndromic surveillance system is not a straight forward process. Defining which syndromes to monitor in order to maximize detection performance has been recently identified as one of the research priorities in Syndromic surveillance. Estimating the minimum size of an epidemic that could potentially be detected in a specific syndrome could be used as a criteria for comparing the performance of different syndrome time series, and could provide some guidance for syndrome selection. The aim of our study was to estimate the potential value of different time series for building a national syndromic surveillance system for cattle in Switzerland. Simulations were used to produce outbreaks of different size and shape and to estimate the ability of each time series and aberration detection algorithm to detect them with high sensitivity, specificity and timeliness. Two temporal aberration detection algorithms were also compared: Holt–Winters generalized exponential smoothing (HW) and Exponential Weighted Moving Average (EWMA). Our results indicated that a specific aberration detection algorithm should be used for each time series. In addition, time series with high counts per unit of time had good overall detection performance, but poor detection performance for small epidemics making them of limited use for an early detection system. Estimating the minimum size of simulated epidemics that could potentially be detected in syndrome TS-event detection pairs can help surveillance system designers choosing the most appropriate syndrome TS to include in their early epidemic surveillance system. © Copyright © 2019 Faverjon, Schärrer, Hadorn and Berezowski.},
	author_keywords = {EWMA; Holt-Winters; syndrome selection; syndromic surveillance; time series},
	keywords = {agricultural worker; Article; autocorrelation; bovine; bovine viral diarrhea; controlled study; detection algorithm; disease surveillance; epidemic; infectious bovine rhinotracheitis; nonhuman; prediction; predictive value; simulation; stillbirth; Switzerland; time series analysis; veterinarian},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hossny2018,
	author = {Hossny, Ahmad Hany and Moschuo, Terry and Osborne, Grant and Mitchell, Lewis and Lothian, Nick},
	title = {Enhancing keyword correlation for event detection in social networks using SVD and k-means: Twitter case study},
	year = {2018},
	journal = {Social Network Analysis and Mining},
	volume = {8},
	number = {1},
	doi = {10.1007/s13278-018-0519-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050568693&doi=10.1007%2fs13278-018-0519-9&partnerID=40&md5=2cd050aba7916c837d72887634258eb0},
	abstract = {Extracting textual features from tweets is a challenging task due to the noisy nature of the content and the weak signal of most of the words used. In this paper, we propose using singular value decomposition (SVD) with clustering to group related words as enhanced signals for textual features in tweets in order to improve the correlation with events. The proposed method applies SVD to the time series vector for each feature to factorize the matrix of feature/day counts, to ensure the independence of the feature vectors. Then, k-means clustering is applied to build a look-up table that maps members of each cluster to the cluster centroid. The look-up table is used to map each feature in the original data to the centroid of its cluster. Then, we calculate the sum of the term-frequency vectors of all features in each cluster to the term-frequency vector of the cluster centroid. To evaluate the method, we calculated the correlations of the cluster centroids with the golden standard record vector before and after summing the vectors of the cluster members to the centroid vector. The proposed method is applied to multiple correlation techniques including the Pearson, Spearman, distance correlation, and Kendal Tao. The experiments also considered the different word forms and lengths of the features including keywords, n grams, skip grams, and bags-of-words. The correlation results are enhanced significantly as the highest correlation scores have increased from 0.22 to 0.70, and the average correlation scores have increased from 0.22 to 0.60. © 2018, Springer-Verlag GmbH Austria, part of Springer Nature.},
	author_keywords = {Correlation; Event detection; Feature extraction; Social network; SVD},
	keywords = {Correlation methods; Singular value decomposition; Social networking (online); Table lookup; Vectors; Cluster centroids; Event detection; Feature vectors; K - means clustering; Keyword correlations; Multiple correlation; Term Frequency; Textual features; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@CONFERENCE{Nadkarni2018,
	author = {Nadkarni, Aditya and Soman, S.A.},
	title = {Applications of trend-filtering to bulk PMU time-series data for wide-area operator awareness},
	year = {2018},
	journal = {20th Power Systems Computation Conference, PSCC 2018},
	doi = {10.23919/PSCC.2018.8443000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054031227&doi=10.23919%2fPSCC.2018.8443000&partnerID=40&md5=bcb3bbc598d1649c39b15eb647b8a69c},
	abstract = {Extraction of dominant trend-component forms the backbone of time-series analysis and forecasting. In power system operation, knowledge of real-time trends in network variables such as bus voltage magnitude, angular separation, line loading is helpful to build situational awareness. In this work, a multivariate trend filtering scheme is presented to detect, quantify and extrapolate real-time trends in measurement data. The multivariate formulation is necessary so as to provide single framework for wide-area visualization of the network's state. Using the method, two control center applications are demonstrated, namely, monitoring of line loading and frequency-data event detection. Performance of the scheme is validated on field data obtained from the wide-area measurement system implemented on the Indian grid. Results indicate application potential in areas such as dynamic security, stability assessment in addition to general network diagnostics. © 2018 Power Systems Computation Conference.},
	author_keywords = {Event detection; Real-time Monitoring; Situational awareness; Time-series analysis; Trends},
	keywords = {Electric power system measurement; Harmonic analysis; System stability; Wide area networks; Angular separation; Bus voltage magnitude; Event detection; Power system operations; Real time monitoring; Situational awareness; Stability assessment; Trends; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Nuño Ayón2018230,
	author = {Nuño Ayón, José de Jesús and Castañon, Julián Sotelo and de Alba, Carlos Alberto López},
	title = {Extracting Low-Frequency Spatio-Temporal Patterns in Ambient Power System Data Using Blind Source Separation},
	year = {2018},
	journal = {Electric Power Components and Systems},
	volume = {46},
	number = {2},
	pages = {230 – 241},
	doi = {10.1080/15325008.2018.1445796},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045031318&doi=10.1080%2f15325008.2018.1445796&partnerID=40&md5=fe20b95c0f68b84634abfd2ac150635e},
	abstract = {Wide-area techniques provide a powerful tool to extract spatio-temporal patterns from high-dimensional datasets and can be used for event detection and visualization, data fusion, stability assessment, and coherency analysis. In this paper, a novel blind source separation-based approach for extracting low-frequency spatio-temporal patterns from measured ambient power system data is proposed and a spatio-temporal visualization index is also suggested. This methodology combines a nonlinear hierarchical neural network with a Blind Source Separation (BSS) technique. The neural network allows reducing noise and removing the nonlinear relations among data (preserve dynamic features of interest), while the BSS technique permits extracting spatial and temporal patterns. In addition, the proposed approach takes advantage of the latest techniques in nonlinear estimation of non-stationary time series. Finally, application examples of the proposed framework on real test cases recorded from an actual power system by Phasor Measurement Units (PMUs) are presented. The obtained results show that the temporal patterns can be used for extracting and identifying the low-frequency oscillation modes and the spatial patterns can be used for identifying modes with the most contribution in original data. Compared to other BSS approaches, the proposed method has shown to be better for the analysis of real ambient data. © 2018, Copyright © Taylor & Francis Group, LLC.},
	author_keywords = {ambient power system data; blind source separation; hierarchical nonlinear principal component analysis; spatio-temporal patterns; wide-area techniques},
	keywords = {Data fusion; Data visualization; Nonlinear analysis; Phasor measurement units; Principal component analysis; System stability; Visualization; Hierarchical neural networks; Nonlinear principal component analysis; Phasor Measurement Unit (PMUs); Power System; Spatial and temporal patterns; Spatio-temporal visualizations; Spatiotemporal patterns; wide-area techniques; Blind source separation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Haines20195153,
	author = {Haines, John and Wallace, Laura M. and Dimitrova, Lada},
	title = {Slow Slip Event Detection in Cascadia Using Vertical Derivatives of Horizontal Stress Rates},
	year = {2019},
	journal = {Journal of Geophysical Research: Solid Earth},
	volume = {124},
	number = {5},
	pages = {5153 – 5173},
	doi = {10.1029/2018JB016898},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066893591&doi=10.1029%2f2018JB016898&partnerID=40&md5=6806818c675a1782725d295ffcb18f48},
	abstract = {We present a new approach assuming elastic behavior at the Earth's surface to invert continuous GPS time series for Vertical Derivatives of Horizontal Stress rates. This approach enables detection of transient slow slip events at the Cascadia subduction zone. Vertical Derivatives of Horizontal Stress rates are the most spatially compact expression of surface deformation due to subsurface deformation sources (compared to GPS displacement/velocity fields, and strain rates), and enable identification of transient slip events and temporal evolution of locking on the interface throughout the slow slip cycle. Slow slip events (SSEs) identified by our method coincide spatially and temporally with tremor episodes, and agree well with SSEs identified by previous geodetic studies. We present daily slip models that fit the Vertical Derivatives of Horizontal Stress rates, showing phases of locking, unlocking, and SSEs on the subduction interface for the 2009–2015 period. Similar to previous studies, our results highlight along-strike variations in SSEs and locking behavior from northern Cascadia to southern Cascadia. Between events, the SSE source zone in northern Cascadia appears to be completely locked. In contrast, we suggest that some fraction of plate motion in the SSE zone in central and southern Cascadia is accommodated by steady creep (or very small, frequent SSEs) between large SSE events. We observe rapid relocking of the interface (within weeks) following the end of most SSEs, with implications for the time scales of fault healing following deformation events. Our results present a promising approach to transient deformation detection, with a fine temporal and spatial resolution of the surface expression of deformation. ©2019. American Geophysical Union. All Rights Reserved.},
	author_keywords = {cascadia; geodesy; inversion; slow slip events; subduction; transient detection},
	keywords = {Cascadia Subduction Zone; Pacific Ocean; data inversion; deformation mechanism; detection method; geodesy; GPS; plate motion; slip rate; spatial resolution; strain rate; stress field; subduction zone; temporal variation; time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Ribeiro20191,
	author = {Ribeiro, Victor Henrique Alves and Reynoso-Meza, Gilberto},
	title = {Monitoring of drinking-water quality by means of a multi-objective ensemble learning approach},
	year = {2019},
	journal = {GECCO 2019 Companion - Proceedings of the 2019 Genetic and Evolutionary Computation Conference Companion},
	pages = {1 – 2},
	doi = {10.1145/3319619.3326745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070591000&doi=10.1145%2f3319619.3326745&partnerID=40&md5=c452e71e57d038650d33cedde86c9f46},
	abstract = {This paper proposes the use of multi-objective ensemble learning to monitor drinking-water quality. Such problem consists of a data set with an extreme imbalance ratio where the events, the minority class, must be correctly detected given a time series denoting water quality and operative data on a minutely basis. First, the given data set is preprocessed for imputing missing data, adjusting concept drift and adding new statistical features, such as moving average, moving standard deviation, moving maximum and moving minimum. Next, two ensemble learning techniques are used, namely SMOTEBoost and RUSBoost. Such techniques have been developed specifically for dealing with imbalanced data, where the base learners are trained by adjusting the ratio between the classes. The first algorithm focuses on oversampling the minority class, while the second focuses on under-sampling the majority class. Finally, multiobjective optimisation is used for pruning the base models of such ensembles in order to maximise the prediction score without reducing generalisation performance. In the training phase, the model is trained, optimised and evaluated using hold-out validation on a given training data set. At the end, the trained model is inserted into a framework, which is used for online event detection and assessing the model's performance. © 2019 Copyright held by the owner/author(s).},
	author_keywords = {Anomaly detection; Evolutionary computation; Machine learning; Time series},
	keywords = {Anomaly detection; Calculations; Evolutionary algorithms; Multiobjective optimization; Potable water; Time series; Water distribution systems; Water quality; Ensemble learning; Ensemble learning approach; Moving averages; Multi objective; Online event detection; Standard deviation; Statistical features; Training data sets; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Zhao2019,
	author = {Zhao, Jie and Chen, Xiaomei and He, Miao},
	title = {Detection of impending ramp for improved wind farm power forecasting},
	year = {2019},
	journal = {2019 IEEE Texas Power and Energy Conference, TPEC 2019},
	doi = {10.1109/TPEC.2019.8662203},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063883199&doi=10.1109%2fTPEC.2019.8662203&partnerID=40&md5=024f4c3b1e376be6044bb2457867eefc},
	abstract = {Detection of impending front-induced ramp events is studied as a new class of change detection problem - change detection for multiple time series with spatial dependency. A critical step to ramp event detection is to capture the spatial dependency between neighbor turbines' power output. To this end, a graphical model is utilized to model the dependency of turbine-level ramp events. Then, change point detection is carried out for the time series of individual turbines' power output, by using the belief from neighbor turbines in the dependency graph. Once an impending ramp is detected, the magnitude of ramp is then forecasted by using current measurement data. A key observation is that due to the movement of front, the best predictors for individual turbines' power output vary across three different regions of the wind farm. With this insight, different predictive models are adopted for forecasting power output from each region. Through numerical experiments, the proposed detection-based wind power forecasting method is proven to outperform conventional methods for wind power ramps. © 2019 IEEE.},
	author_keywords = {Ramp events; short-term wind power forecasting; wind farm},
	keywords = {Electric utilities; Numerical methods; Thermoelectric power; Time series; Turbines; Weather forecasting; Wind power; Change point detection; Conventional methods; Multiple time series; Numerical experiments; Ramp events; Short-term wind power forecasting; Wind farm; Wind power forecasting; Electric power system interconnection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Gensler2018543,
	author = {Gensler, André and Sick, Bernhard},
	title = {Performing event detection in time series with SwiftEvent: an algorithm with supervised learning of detection criteria},
	year = {2018},
	journal = {Pattern Analysis and Applications},
	volume = {21},
	number = {2},
	pages = {543 – 562},
	doi = {10.1007/s10044-017-0657-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034620093&doi=10.1007%2fs10044-017-0657-0&partnerID=40&md5=8ed9f9ad04afbf7464b271c741038c78},
	abstract = {The automated detection of points in a time series with a special meaning to a user, commonly referred to as the detection of events, is an important aspect of temporal data mining. These events often are points in a time series that can be peaks, level changes, sudden changes of spectral characteristics, etc. Fast algorithms are needed for event detection for online applications or applications with huge time series data sets. In this article, we present a very fast algorithm for event detection that learns detection criteria from labeled sample time series (i.e., time series where events are marked). This algorithm is based on fast transformations of time series into low-dimensional feature spaces and probabilistic modeling techniques to identify criteria in a supervised manner. Events are then found in one, single fast pass over the signal (therefore, the algorithm is called SwiftEvent) by evaluating learned thresholds on Mahalanobis distances in the feature space. We analyze the run-time complexity of SwiftEvent and demonstrate its application in some use cases with artificial and real-world data sets in comparison with other state-of-the-art techniques. © 2017, Springer-Verlag London Ltd.},
	author_keywords = {Change point detection; Event detection; Polynomial approximation; Segmentation; Supervised learning; Temporal data mining; Time series classification; User-defined points},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Yang2019111,
	author = {Yang, Zhi-Fang and Lin, Yi-Cyuan},
	title = {Reduction in number of constraints in max-margin early event detectors},
	year = {2019},
	journal = {Pattern Recognition},
	volume = {91},
	pages = {111 – 122},
	doi = {10.1016/j.patcog.2019.02.017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061793510&doi=10.1016%2fj.patcog.2019.02.017&partnerID=40&md5=5e2585e04cdc23ad9e6b527128972147},
	abstract = {                             Early action detection aims to detect the action as soon as possible, and has a variety of applications. In the field of computer vision, the first learning formulation on early event detection, the max-margin early event detector(MMED), is investigated by Hoai and Torre [1, 2]. In this study, the purpose of the proposed approach is to reduce the large number of constraints generated in the MMED method. The basic idea is to remove the redundancy among every three consecutive constraints in the MMED method. The number of constraints is reduced from O(IL                             3                             ) to O(IL                             2                             ) where I is the number of training examples and L is the length of the example time series. Proof and the experimental results are provided to show the correctness and feasibility of the proposed approach.                          © 2019 Elsevier Ltd},
	author_keywords = {Early detection; Max-margin; MMED},
	keywords = {Software engineering; Early event detection; Event detectors; Learning formulation; Max-margin; MMED; Training example; Pattern recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Su2019103,
	author = {Su, Yuting and Wang, Shan and Nie, Weizhi and An, Yang},
	title = {Pooled time series representation for mitosis event recognition},
	year = {2019},
	journal = {Multimedia Systems},
	volume = {25},
	number = {2},
	pages = {103 – 108},
	doi = {10.1007/s00530-017-0572-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033371248&doi=10.1007%2fs00530-017-0572-7&partnerID=40&md5=5a868dc4f94f39ba5967a8d43457cb96},
	abstract = {This paper proposes a new feature representation for mitotic event detection in time-lapse phase contrast microscopy image sequences of stem cell populations. First, an imaging model-based microscopy image segmentation method is implemented for mitotic candidate extraction. Then, a new feature representation framework based on time series pooling is proposed for sequential events. At last, a support vector machine classifier is utilized for mitotic cell modeling and detection. Different from other feature representations including bag-of-visual-words when using identical underlying feature descriptors, this method can take advantage of temporal relations among frames, the idea is to keep track of how descriptor values are changing over time and summarize them to represent appearance in the cell sequence. The comparison experiments demonstrate the superiority of the proposed method. © 2017, Springer-Verlag GmbH Germany.},
	author_keywords = {Feature fusion; Feature representation; Time series pooling},
	keywords = {Cell culture; Cell proliferation; Image retrieval; Image segmentation; Stem cells; Bag-of-visual words; Event recognition; Feature descriptors; Feature fusion; Feature representation; Phase-contrast microscopy images; Segmentation methods; Support vector machine classifiers; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Schaetti2019,
	author = {Schaetti, Nils},
	title = {Behaviors of Reservoir Computing Models for Textual Documents Classification},
	year = {2019},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	volume = {2019-July},
	doi = {10.1109/IJCNN.2019.8852304},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073226562&doi=10.1109%2fIJCNN.2019.8852304&partnerID=40&md5=a696a828c78fd59ef740283342d6dfd3},
	abstract = {Reservoir Computing is a paradigm of recurrent neural network (RNN) models, attractive because of its ease of training and new neuromorphic optoelectronic implementations. Applied with success to time series prediction and speech recognition, few works have so far studied the behavior of these networks on natural language processing (NLP) tasks. Therefore, we decided to explore the ability of Echo State Network-based Reservoir Computing (ESN) models with additional embedding layers to classify text documents of the Reuters C50 data set based on authorship. We explored various learned representations such as word and character embedding and deep feature extractors. Our experiments demonstrate that ESN models can achieve state-of-the-art results on this task and are competitive with common models such as Support Vector Machines (SVM). Moreover, we show that these models compute documents as data streams and could then be able to handle other tasks such as event detection and text segmentation. The best performance is obtained by an ESN with a large reservoir of 1,500 neurons based on word vectors. We think that these results demonstrate the possibility of processing massive quantities of textual data in the future using Reservoir Computing-based systems. © 2019 IEEE.},
	author_keywords = {Auhorship Attribution; Natural Language Processing; Recurrent Neural Network; Reservoir Computing},
	keywords = {Classification (of information); Embeddings; Information retrieval systems; Natural language processing systems; Optoelectronic devices; Speech recognition; Support vector machines; Auhorship Attribution; Echo state networks; Massive quantities; NAtural language processing; Recurrent neural network (RNN); Reservoir Computing; Time series prediction; Word and characters; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Wang2019103000,
	author = {Wang, Zhihong and Guo, Yi and Wang, Jiahui and Li, Zhen and Tang, Minwei},
	title = {Rumor Events Detection from Chinese Microblogs via Sentiments Enhancement},
	year = {2019},
	journal = {IEEE Access},
	volume = {7},
	pages = {103000 – 103018},
	doi = {10.1109/ACCESS.2019.2928044},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085164533&doi=10.1109%2fACCESS.2019.2928044&partnerID=40&md5=44cdbbed13956edec414d7cfc78668ae},
	abstract = {The convenience of social media in communication and information dissemination has made it an ideal place for spreading rumor events, which raises a higher requirement for automatic debunking of rumor events. Meanwhile, the traditional rumor classification approaches relying on manual labeled features have to face a daunting number of manual efforts. In general, when facing a dubious claim, people can authenticate and verify the realness of an event with the contents of continuous posts, such as source credibility, public sentiments, propagation structures, and so on. In this paper, we pay more attention to the emotional expressions of posts host, especially the fine-grained sentiments, which are effective for rumor events detection. Thus, this paper presents a novel two-layer GRU model for rumor events detection based on a Sentiment Dictionary (SD) and a dynamic time series (DTS) algorithm, named as SD-DTS-GRU. The model learns continuous representations of microblog events in a better manner by making use of the SD to identify fine-grained human emotional expressions of each event and retaining the time distribution of social events by the DTS algorithm. The experimental results on Sina Weibo datasets show that our model achieves a high accuracy of 95.2% and demonstrate that our proposed SD-DTS-GRU model outperforms latest explorations on rumor events detection. © 2013 IEEE.},
	author_keywords = {dynamic time series; GRU; online social networks; Rumor events detection; sentiment dictionary},
	keywords = {Information dissemination; Classification approach; Emotional expressions; Events detection; Public sentiments; Sentiment dictionaries; Social events; Source credibilities; Time distribution; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access}
}

@ARTICLE{Bramson2019,
	author = {Bramson, Aaron and Baland, Adrien and Iriki, Atsushi},
	title = {Measuring Dynamical Uncertainty With Revealed Dynamics Markov Models},
	year = {2019},
	journal = {Frontiers in Applied Mathematics and Statistics},
	volume = {5},
	doi = {10.3389/fams.2019.00007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077675007&doi=10.3389%2ffams.2019.00007&partnerID=40&md5=8328a2ec54488dc182c7ae74adbde53d},
	abstract = {Concepts and measures of time series uncertainty and complexity have been applied across domains for behavior classification, risk assessments, and event detection/prediction. This paper contributes three new measures based on an encoding of the series' phase space into a descriptive Markov model. Here we describe constructing this kind of “Revealed Dynamics Markov Model” (RDMM) and using it to calculate the three uncertainty measures: entropy, uniformity, and effective edge density. We compare our approach to existing methods such as approximate entropy (ApEn) and permutation entropy using simulated and empirical time series with known uncertainty features. While previous measures capture local noise or the regularity of short patterns, our measures track holistic features of time series dynamics that also satisfy criteria as being approximate measures of information generation (Kolmogorov entropy). As such, we show that they can distinguish dynamical patterns inaccessible to previous measures and more accurately reflect their relative complexity. We also discuss the benefits and limitations of the Markov model encoding as well as requirements on the sample size. © Copyright © 2019 Bramson, Baland and Iriki.},
	author_keywords = {complexity; entropy; markov model; time series; uncertainty},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Shaw2019,
	author = {Shaw, Justin and Stastna, Marek and Coutino, Aaron and Walter, Ryan K. and Reinhardt, Eduard},
	title = {Feature identification in time series data sets},
	year = {2019},
	journal = {Heliyon},
	volume = {5},
	number = {5},
	doi = {10.1016/j.heliyon.2019.e01708},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066031294&doi=10.1016%2fj.heliyon.2019.e01708&partnerID=40&md5=dbc389763fb749d177ec8841ffa4e613},
	abstract = {We present a computationally inexpensive, flexible feature identification method which uses a comparison of time series to identify a rank-ordered set of features in geophysically-sourced data sets. Many physical phenomena perturb multiple physical variables nearly simultaneously, and so features are identified as time periods in which there are local maxima of absolute deviation in all time series. Unlike other available methods, this method allows the analyst to tune the method using their knowledge of the physical context. The method is applied to a data set from a moored array of instruments deployed in the coastal environment of Monterey Bay, California, and a data set from sensors placed within the submerged Yax Chen Cave System in Tulum, Quintana Roo, Mexico. These example data sets demonstrate that the method allows for the automated identification of features which are worthy of further study. © 2019},
	author_keywords = {Atmospheric science; Environmental science; Event detection; Feature identification; Geology; Geophysics; Hydrology; Oceanography; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Peng2018595,
	author = {Peng, Nengsong and Zhang, Weiwei and Zhang, Yuzhao and Huang, Chao and Zheng, Lixin},
	title = {Anomaly Detection Method for Wireless Sensor Networks Based on Time Series Data; [基于时间序列数据的无线传感器网络的异常检测方法]},
	year = {2018},
	journal = {Chinese Journal of Sensors and Actuators},
	volume = {31},
	number = {4},
	pages = {595 – 601},
	doi = {10.3969/j.issn.1004-1699.2018.04.017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059104497&doi=10.3969%2fj.issn.1004-1699.2018.04.017&partnerID=40&md5=fb3da5b21f9110c6d1f45b051e24b38e},
	abstract = {With the development and widespread application of wireless sensor networks,focusing on the problems of high variation in sampling value from sensors and the increase of inaccuracy of event detection in wireless sensor networks,a method based on sensor network time series data is presented. Using the median of k normal data collected by the sensor to establish the pivot amount and construct the confidence interval,a method to calculate the data interval discrepancy is proposed to judge the origin of the anomaly. The experimental results show that the detection rate of the abnormal data in the sensor network is above 98% and the false alarm rate remains below 0.5%,which have some certain utilities and commonality. © 2018, The Editorial Office of Chinese Journal of Sensors and Actuators. All right reserved.},
	author_keywords = {Anomaly detection; Confidence interval; Difference degree; Time series; Wireless sensor network},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Garioud2019,
	author = {Garioud, Anatol and Giordano, Sebastien and Valero, Silvia and Mallet, Clement},
	title = {Challenges in Grassland Mowing Event Detection with Multimodal Sentinel Images},
	year = {2019},
	journal = {2019 10th International Workshop on the Analysis of Multitemporal Remote Sensing Images, MultiTemp 2019},
	doi = {10.1109/Multi-Temp.2019.8866914},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074252489&doi=10.1109%2fMulti-Temp.2019.8866914&partnerID=40&md5=469b2c24470a6b66d21c8ac7085f948d},
	abstract = {Permanent Grasslands (PG) are heterogeneous environments with high spatial and temporal dynamics, subject to increasing environmental challenges. This study aims to identify requirements, key constraining factors and solutions for robust and complete detection of Mowing Events. Remote sensing is a powerful tool to monitor and investigate Near-Real-Time and seasonally PG cover. Here, pros and cons of Sentinel-2 (S2) and Sentinel-1 (S1) time series exploitation for Mowing Events (MowEve) detection are analysed. A deep-based approach is proposed to obtain consistent and homogeneous biophysical parameter times series for MowEve detection. Recurrent Neural Networks are proposed as regression strategy allowing the synergistic integration of optical and Synthetic Aperture Radar data to reconstruct dense NDVI times series. Experimental results corroborates the interest of deriving consistent and homogeneous series of biophysical parameters for subsequent MowEve detection. © 2019 IEEE.},
	author_keywords = {Mowing Events; NDVI; Permanent Grasslands; Recurrent Neural Networks; Regression; Sentinel; Time Series},
	keywords = {Image analysis; Recurrent neural networks; Synthetic aperture radar; Time series; Mowing Events; NDVI; Permanent grassland; Regression; Sentinel; Remote sensing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Berezowski2019,
	author = {Berezowski, John and Rüegg, Simon R. and Faverjon, Céline},
	title = {Complex system approaches for animal health surveillance},
	year = {2019},
	journal = {Frontiers in Veterinary Science},
	volume = {6},
	number = {MAY},
	doi = {10.3389/fvets.2019.00153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068238009&doi=10.3389%2ffvets.2019.00153&partnerID=40&md5=497f17d18c2dfd6c5e0fb869dd2a5931},
	abstract = {Many new and highly variable data are currently being produced by the many participants in farmed animal productions systems. These data hold the promise of new information with potential value for animal health surveillance. The current analytical paradigm for dealing with these new data is to implement syndromic surveillance systems, which focus mainly on univariate event detection methods applied to individual time series, with the goal of identifying epidemics in the population. This approach is relatively limited in the scope and not well-suited for extracting much of the additional information that is contained within these data. These approaches have value and should not be abandoned. However, an additional, new analytical paradigm will be needed if surveillance and disease control agencies wish to extract additional information from these data. We propose a more holistic analytical approach borrowed from complex system science that considers animal disease to be a product of the complex interactions between the many individuals, organizations and other factors that are involved in, or influence food production systems. We will discuss the characteristics of farmed animal food production systems that make them complex adaptive systems and propose practical applications of methods borrowed from complex system science to help animal health surveillance practitioners extract additional information from these new data. © 2019 Berezowski, Rüegg and Faverjon. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.},
	author_keywords = {Animal disease surveillance; Animal health surveillance; Complex adaptive system; Complex systems; Food animal production; Food animal systems; Food animal value chains; Systems science},
	keywords = {animal disease; animal food; animal health; Article; disease control; disease surveillance; ecosystem; food industry; human; information processing; nonhuman; science; theoretical model; veterinary medicine},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhou20191619,
	author = {Zhou, Yuxun and Arghandeh, Reza and Zou, Han and Spanos, Costas J.},
	title = {Nonparametric Event Detection in Multiple Time Series for Power Distribution Networks},
	year = {2019},
	journal = {IEEE Transactions on Industrial Electronics},
	volume = {66},
	number = {2},
	pages = {1619 – 1628},
	doi = {10.1109/TIE.2018.2840508},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048011249&doi=10.1109%2fTIE.2018.2840508&partnerID=40&md5=976795c5fa404eaec03054e7a34d1c70},
	abstract = {With the unprecedented advancement of sensing technology, smart city applications are now enriched with massive measurement data related to system states, patterns, and the behavior of its users. However, classic data analysis or machine learning tools ignore some unique characteristics of the multistream measurement data, in particular, the coexistence of strong temporal correlation and interstream relatedness. To this end, in this paper we discuss the problem of novelty detection with multiple coevolving time series data. To capture both the temporal dependence and the interseries relatedness, a multitask nonparametric model is proposed, which can be extended to family of data distributions by adopting the notion of Bregman divergence. Albeit convex, the learning problem can be hard as the time series accumulate. In this regard, an efficient randomized block coordinate descent algorithm is proposed. The model and the algorithm is tested with a real-world application, involving novelty detection and event analysis in smart city power distribution networks with high-resolution multistream measurements. It is shown that the incorporation of interseries relatedness enables the detection of system-level events, which would otherwise be unobservable with traditional methods. The experimental results not only justify the benefits of incorporating information from different sources, but also demonstrate the potential of the proposed multistream analysis tool as one of the core computational components to improve smart city observability, security, and reliability. © 1982-2012 IEEE.},
	author_keywords = {Artificial intelligence; electrical fault detection; power system analysis; statistical learning},
	keywords = {Artificial intelligence; Electric network analysis; Fault detection; Learning systems; Smart city; Time series; Block coordinate descents; Electrical fault detections; Exponential family distributions; Power distribution network; Power system analysis; Smart city applications; Statistical learning; Temporal correlations; Electric fault location},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25}
}

@ARTICLE{Roma2018457,
	author = {Roma, Gerard and Herrera, Perfecto and Nogueira, Waldo},
	title = {Environmental sound recognition using short-time feature aggregation},
	year = {2018},
	journal = {Journal of Intelligent Information Systems},
	volume = {51},
	number = {3},
	pages = {457 – 475},
	doi = {10.1007/s10844-017-0481-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027725549&doi=10.1007%2fs10844-017-0481-4&partnerID=40&md5=04c7a26abb271e816e58715088f5d749},
	abstract = {Recognition of environmental sound is usually based on two main architectures, depending on whether the model is trained with frame-level features or with aggregated descriptions of acoustic scenes or events. The former architecture is appropriate for applications where target categories are known in advance, while the later affords a less supervised approach. In this paper, we propose a framework for environmental sound recognition based on blind segmentation and feature aggregation. We describe a new set of descriptors, based on Recurrence Quantification Analysis (RQA), which can be extracted from the similarity matrix of a time series of audio descriptors. We analyze their usefulness for recognition of acoustic scenes and events in addition to standard feature aggregation. Our results show the potential of non-linear time series analysis techniques for dealing with environmental sounds. © 2017, Springer Science+Business Media, LLC.},
	author_keywords = {Audio databases; Audio features; Environmental sound recognition; Event detection; Pattern recognition; Recurrence quantification analysis},
	keywords = {Multivariable control systems; Pattern recognition; Time series analysis; Audio database; Audio features; Environmental sound recognition; Event detection; Recurrence quantification analysis; Audio acoustics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{McFee20182180,
	author = {McFee, Brian and Salamon, Justin and Bello, Juan Pablo},
	title = {Adaptive Pooling Operators for Weakly Labeled Sound Event Detection},
	year = {2018},
	journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
	volume = {26},
	number = {11},
	pages = {2180 – 2193},
	doi = {10.1109/TASLP.2018.2858559},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052399585&doi=10.1109%2fTASLP.2018.2858559&partnerID=40&md5=9143801d7f2300da3b10468bf8b7aaa5},
	abstract = {Sound event detection (SED) methods are tasked with labeling segments of audio recordings by the presence of active sound sources. SED is typically posed as a supervised machine learning problem, requiring strong annotations for the presence or absence of each sound source at every time instant within the recording. However, strong annotations of this type are both labor- and cost-intensive for human annotators to produce, which limits the practical scalability of SED methods. In this paper, we treat SED as a multiple instance learning (MIL) problem, where training labels are static over a short excerpt, indicating the presence or absence of sound sources but not their temporal locality. The models, however, must still produce temporally dynamic predictions, which must be aggregated (pooled) when comparing against static labels during training. To facilitate this aggregation, we develop a family of adaptive pooling operators - referred to as autopool - which smoothly interpolate between common pooling operators, such as min-, max-, or average-pooling, and automatically adapt to the characteristics of the sound sources in question. We evaluate the proposed pooling operators on three datasets, and demonstrate that in each case, the proposed methods outperform nonadaptive pooling operators for static prediction, and nearly match the performance of models trained with strong, dynamic annotations. The proposed method is evaluated in conjunction with convolutional neural networks, but can be readily applied to any differentiable model for time-series label prediction. While this paper focuses on SED applications, the proposed methods are general, and could be applied widely to MIL problems in any domain. © 2014 IEEE.},
	author_keywords = {deep learning; machine learning; multiple instance learning; Sound event detection},
	keywords = {Acoustic generators; Deep learning; Forecasting; Learning systems; Neural networks; Supervised learning; Convolutional neural network; Cost-intensive; Dynamic prediction; Label predictions; Multiple instance learning; Sound event detection; Supervised machine learning; Temporal locality; Audio acoustics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 97; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Daoud2018129,
	author = {Daoud, Daoud M.},
	title = {Detecting and ranking events in Twitter using diversity analysis},
	year = {2018},
	journal = {International Journal of Business Intelligence and Data Mining},
	volume = {13},
	number = {1-3},
	pages = {129 – 146},
	doi = {10.1504/IJBIDM.2018.088423},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116047832&doi=10.1504%2fIJBIDM.2018.088423&partnerID=40&md5=c8f51fb103b93a22c7f05810724ce08b},
	abstract = {In Twitter and in other social media channels, detecting events is very important and has many applications. However, this task is very challenging because of the huge number of tweets that are posted every minute and the massive scale of the spamming activities. In this paper, we present an innovative approach for detecting events using data posted to Twitter. The proposed approach is based on the concept of user's attention by quantitatively modelling the diversity of hashtags using Shannon's index. Our method records the diversity values on an hourly basis time-series. Using statistical techniques, the method locates the intervals having diversity values that fall outside the range of forecasted ones (normal state). We also present the labelling and ranking techniques that are implemented in this research. Experimental results on a dataset consisting of 15 million Arabic tweets show that our proposed approach can effectively detect real-world events in Twitter.  Copyright © 2018 Inderscience Enterprises Ltd.},
	author_keywords = {Arabic; Diversity index; Event detection; Events labelling; Events ranking; Hashtags; Social media; Time-series analysis; Twitter; Z-score},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Newman2019,
	author = {Newman, Jacob L. and Phillips, John S. and Cox, Stephen J. and FitzGerald, John and Bath, Andrew},
	title = {Automatic nystagmus detection and quantification in long-term continuous eye-movement data},
	year = {2019},
	journal = {Computers in Biology and Medicine},
	volume = {114},
	doi = {10.1016/j.compbiomed.2019.103448},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072697484&doi=10.1016%2fj.compbiomed.2019.103448&partnerID=40&md5=92871f63ee82101c47cc2a5845dad8ea},
	abstract = {Symptoms of dizziness or imbalance are frequently reported by people over 65. Dizziness is usually episodic and can have many causes, making diagnosis problematic. When it is due to inner-ear malfunctions, it is usually accompanied by abnormal eye-movements called nystagmus. The CAVA (Continuous Ambulatory Vestibular Assessment) device has been developed to provide continuous monitoring of eye-movements to gain insight into the physiological parameters present during a dizziness attack. In this paper, we describe novel algorithms for detecting short periods of artificially induced nystagmus from the long-term eye movement data collected by the CAVA device. In a blinded trial involving 17 healthy subjects, each participant induced nystagmus artificially on up to eight occasions by watching a short video on a VR headset. Our algorithms detected these short periods with an accuracy of 98.77%. Additionally, data relating to vestibular induced nystagmus was collected, analysed and then compared to a conventional technique for assessing nystagmus during caloric testing. The results show that a range of nystagmus can be identified and quantified using computational methods applied to long-term eye-movement data captured by the CAVA device. © 2019 Elsevier Ltd},
	author_keywords = {Biomedical signal processing; Dizziness; Electronystagmography; Event detection; Nystagmus; Time series classification; Vestibular diseases},
	keywords = {Algorithms; Dizziness; Electronystagmography; Equipment Design; Eye Movements; Humans; Monitoring, Ambulatory; Nystagmus, Pathologic; Signal Processing, Computer-Assisted; Biomedical signal processing; Diagnosis; Occupational diseases; Physiological models; Signal processing; Continuous monitoring; Conventional techniques; Detection and quantifications; Dizziness; Electronystagmography; Event detection; Physiological parameters; Time series classifications; algorithm; Article; automation; clinical article; clinical assessment; clinical evaluation; comparative study; computer analysis; diagnostic accuracy; eye movement; human; limit of quantitation; long term care; nystagmus; priority journal; ambulatory monitoring; devices; dizziness; electronystagmography; equipment design; eye movement; nystagmus; physiology; procedures; signal processing; Eye movements},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access}
}

@ARTICLE{Saeed2019115,
	author = {Saeed, Zafar and Abbasi, Rabeeh Ayaz and Razzak, Imran and Maqbool, Onaiza and Sadaf, Abida and Xu, Guandong},
	title = {Enhanced Heartbeat Graph for emerging event detection on Twitter using time series networks},
	year = {2019},
	journal = {Expert Systems with Applications},
	volume = {136},
	pages = {115 – 132},
	doi = {10.1016/j.eswa.2019.06.005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067630516&doi=10.1016%2fj.eswa.2019.06.005&partnerID=40&md5=80153d18de5d9363909dd62f96978fe8},
	abstract = {With increasing popularity of social media, Twitter has become one of the leading platforms to report events in real-time. Detecting events from Twitter stream requires complex techniques. Event-related trending topics consist of a group of words which successfully detect and identify events. Event detection techniques must be scalable and robust, so that they can deal with the huge volume and noise associated with social media. Existing event detection methods mostly rely on burstiness, mainly the frequency of words and their co-occurrences. However, burstiness sometimes dominates other relevant details in the data which could be equally significant. Besides, the topological and temporal relationships in the data are often ignored. In this work, we propose a novel graph-based approach, called the Enhanced Heartbeat Graph (EHG), which detects events efficiently. EHG suppresses dominating topics in the subsequent data stream, after their first detection. Experimental results on three real-world datasets (i.e., Football Association Challenge Cup Final, Super Tuesday, and the US Election 2012) show superior performance of the proposed approach in comparison to the state-of-the-art techniques. © 2019 Elsevier Ltd},
	author_keywords = {Big data; Dynamic graph; Emerging trends; Event detection; Text stream; Time series network; Twitter},
	keywords = {Big data; Graphic methods; Social networking (online); Time series; Dynamic graph; Emerging trends; Event detection; Text streams; Twitter; Graph theory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Green Open Access}
}@ARTICLE{20161,
	title = {European Conference on Machine Learning, ECML 1989},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9580},
	pages = {1 – 386},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978880690&partnerID=40&md5=cc0f2bb187e0034e0210e959b3a35d0b},
	abstract = {The proceedings contain 21 papers. The special focus in this conference is on Solving Large Scale Learning Tasks. The topics include: Online social networks event detection; detecting events in online social networks; sharing data with guaranteed privacy; distributed support vector machines; knowledge discovery from complex high dimensional data; local pattern detection in attributed graphs; advances in exploratory pattern analytics on ubiquitous data and social media; understanding human mobility with big data; on event detection from spatial time series for urban traffic applications; compressible reparametrization of time-variant linear dynamical systems; detection of local intensity changes in grayscale images with robust methods for time-series analysis; Bayesian ordinal aggregation of peer assessments; collaborative online learning of an action model; application of machine learning concepts without learning; learning statistical relational models for weak supervision in natural language extraction; supervised extraction of usage patterns in different document representations and mining patterns to classify cartified images of Katharina.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2017,
	title = {Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS},
	year = {2017},
	journal = {Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS},
	volume = {2017-December},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172635647&partnerID=40&md5=770cb91a12301b6608ec98b7bcafe8d2},
	abstract = {The proceedings contain 103 papers. The topics discussed include: event description and detection in cyber-physical systems: an ontology-based language and approach; a time series classification method for battery event detection; charge-depleting of the batteries makes smartphones recognizable; concatenating road take me home: indoor navigation without infrastructure support; data collection with privacy preserving in participatory sensing; hierarchical resource distribution network based on mobile edge computing; when user interest meets data quality: a novel user filter scheme for mobile crowd sensing; and high resource utilization auto-scaling algorithms for heterogeneous container configurations.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Souto2016221,
	author = {Souto, Gustavo and Liebig, Thomas},
	title = {On event detection from spatial time series for urban traffic applications},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9580},
	pages = {221 – 233},
	doi = {10.1007/978-3-319-41706-6_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978863276&doi=10.1007%2f978-3-319-41706-6_11&partnerID=40&md5=bd97442025479ae0a876526e589aeaa2},
	abstract = {Since the last decades the availability and granularity of location-based data has been rapidly growing. Besides the proliferation of smartphones and location-based social networks, also crowdsourcing and voluntary geographic data led to highly granular mobility data, maps and street networks. In result, location-aware, smart environments are created. The trend for personal self-optimization and monitoring named by the term ‘quantified self’ will speed-up this ongoing process. The citizens in conjunction with their surrounding smart infrastructure turn into ‘living sensors’ that monitor all aspects of urban living (traffic load, noise, energy consumption, safety and many others). The "Big Data"- based intelligent environments and smart cities require algorithms that process these massive amounts of spatio-temporal data. This article provides a survey on event processing in spatio-temporal data streams with a special focus on urban traffic. © Springer International Publishing Switzerland 2016.},
	keywords = {Artificial intelligence; Energy utilization; Learning systems; Location; Optimization; Event Processing; Intelligent environment; Location-based social networks; Self-optimization; Smart environment; Smart infrastructures; Spatio-temporal data; Spatio-temporal data streams; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Abbes2015338,
	author = {Abbes, Ali Ben and Essid, Houcine and Farah, Imed Riadh and Barra, Vincent},
	title = {Rare events detection in NDVI time-series using Jarque-Bera test},
	year = {2015},
	journal = {International Geoscience and Remote Sensing Symposium (IGARSS)},
	volume = {2015-November},
	pages = {338 – 341},
	doi = {10.1109/IGARSS.2015.7325769},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962509225&doi=10.1109%2fIGARSS.2015.7325769&partnerID=40&md5=1b407aa0c82e5a15a82794cebc23cfc3},
	abstract = {Nowadays, Normalized Difference Vegetation Index (NDVI) time-series has been successfully used in research regarding global environmental change. NDVI time series have proven to be a useful means of indicating drought-related vegetation conditions, due to their real-time coverage across the globe at relatively high spatial resolution. In this paper, we propose a method for detecting rare events in NDVI series. These events are particularly rare and infrequent which increases their complexity of detecting and analyzing them. The proposed method is based on the analysis of the random component by Jarque-Bera test to verify the presence of rare events and obtain their features (time and amplitude). For validation, we have used a database for regions in Northwestern of Tunisia. These data come from MODIS for a period from 18 February 2000 to 17 November 2013 at a spatial resolution of 250 m by 250m. © 2015 IEEE.},
	author_keywords = {decomposition; NDVI; Rare events; Vegetation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Chu2017372,
	author = {Chu, Wen-Sheng and De la Torre, Fernando and Cohn, Jeffrey F. and Messinger, Daniel S.},
	title = {A Branch-and-Bound Framework for Unsupervised Common Event Discovery},
	year = {2017},
	journal = {International Journal of Computer Vision},
	volume = {123},
	number = {3},
	pages = {372 – 391},
	doi = {10.1007/s11263-017-0989-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011835144&doi=10.1007%2fs11263-017-0989-7&partnerID=40&md5=326a134e3bf56f0c65b19a1dbc804100},
	abstract = {Event discovery aims to discover a temporal segment of interest, such as human behavior, actions or activities. Most approaches to event discovery within or between time series use supervised learning. This becomes problematic when relevant event labels are unknown, are difficult to detect, or not all possible combinations of events have been anticipated. To overcome these problems, this paper explores Common Event Discovery (CED), a new problem that aims to discover common events of variable-length segments in an unsupervised manner. A potential solution to CED is searching over all possible pairs of segments, which would incur a prohibitive quartic cost. In this paper, we propose an efficient branch-and-bound (B&B) framework that avoids exhaustive search while guaranteeing a globally optimal solution. To this end, we derive novel bounding functions for various commonality measures and provide extensions to multiple commonality discovery and accelerated search. The B&B framework takes as input any multidimensional signal that can be quantified into histograms. A generalization of the framework can be readily applied to discover events at the same or different times (synchrony and event commonality, respectively). We consider extensions to video search and supervised event detection. The effectiveness of the B&B framework is evaluated in motion capture of deliberate behavior and in video of spontaneous facial behavior in diverse interpersonal contexts: interviews, small groups of young adults, and parent-infant face-to-face interaction. © 2017, Springer Science+Business Media New York.},
	author_keywords = {Bag-of-words; Branch and bound; Common event discovery; Event detection; Global optimization; Human interaction; Synchrony discovery; Unsupervised learning; Video indexing},
	keywords = {Branch and bound method; Global optimization; Indexing (of information); Unsupervised learning; Bag of words; Event detection; Event discoveries; Human interactions; Synchrony discovery; Video indexing; Behavioral research},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access}
}

@ARTICLE{Elgendi2016,
	author = {Elgendi, Mohamed},
	title = {Eventogram: A visual representation of main events in biomedical signals},
	year = {2016},
	journal = {Bioengineering},
	volume = {3},
	number = {4},
	doi = {10.3390/bioengineering3040022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007063742&doi=10.3390%2fbioengineering3040022&partnerID=40&md5=67d72426509f43c5c3ecdab63f226cde},
	abstract = {Biomedical signals carry valuable physiological information and many researchers have difficulty interpreting and analyzing long-term, one-dimensional, quasi-periodic biomedical signals. Traditionally, biomedical signals are analyzed and visualized using periodogram, spectrogram, and wavelet methods. However, these methods do not offer an informative visualization of main events within the processed signal. This paper attempts to provide an event-related framework to overcome the drawbacks of the traditional visualization methods and describe the main events within the biomedical signal in terms of duration and morphology. Electrocardiogram and photoplethysmogram signals are used in the analysis to demonstrate the differences between the traditional visualization methods, and their performance is compared against the proposed method, referred to as the “eventogram” in this paper. The proposed method is based on two event-related moving averages that visualizes the main time-domain events in the processed biomedical signals. The traditional visualization methods were unable to find dominant events in processed signals while the eventogram was able to visualize dominant events in signals in terms of duration and morphology. Moreover, eventogram-based detection algorithms succeeded with detecting main events in different biomedical signals with a sensitivity and positive predictivity >95%. The output of the eventogram captured unique patterns and signatures of physiological events, which could be used to visualize and identify abnormal waveforms in any quasi-periodic signal. © 2016 by the author; licensee MDPI, Basel, Switzerland.},
	author_keywords = {Event detection; Pattern discovery; Quasi-periodic signals; Signal segmentation; Signal transformation; Spatio-temporal analysis; Time-domain representation; Time-series visualization; Waveform recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Dobjan201765,
	author = {Dobjan, Tibor and Antal, Elvira D.},
	title = {Modern feature extraction methods and learning algorithms in the field of industrial acoustic signal processing},
	year = {2017},
	journal = {SISY 2017 - IEEE 15th International Symposium on Intelligent Systems and Informatics, Proceedings},
	pages = {65 – 70},
	doi = {10.1109/SISY.2017.8080589},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040169538&doi=10.1109%2fSISY.2017.8080589&partnerID=40&md5=8175ca78f53f673513273a7e220b9b7d},
	abstract = {Identification of acoustic events is a challanging field of signal processing. Fast identification algorithms would be applicable for real-time event detection in industrial projects. Event detection is usually done by classifying a specific feature of windows of time series. This paper studies the application of the novel skeleton method for feature extraction. We compare it with traditional feature extraction methods on high frequency sampled vibration data, which was measured by a Gleeble 3800 thermo-mechanical physical simulator. Barkhausen noise and other background noises are hardening the analysis. © 2017 IEEE.},
	keywords = {Acoustic noise; Acoustic signal processing; Extraction; Intelligent systems; Signal processing; Vibrations (mechanical); Background noise; Barkhausen noise; Feature extraction methods; High frequency HF; Identification algorithms; Industrial projects; Physical simulator; Thermo-mechanical; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ayachi20161060,
	author = {Ayachi, Fouaz S. and Nguyen, Hung Phuc and Goubault De Brugiere, Etienne and Boissy, Patrick and Duval, Christian},
	title = {The Use of Empirical Mode Decomposition-Based Algorithm and Inertial Measurement Units to Auto-Detect Daily Living Activities of Healthy Adults},
	year = {2016},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	volume = {24},
	number = {10},
	pages = {1060 – 1070},
	doi = {10.1109/TNSRE.2016.2519413},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994059799&doi=10.1109%2fTNSRE.2016.2519413&partnerID=40&md5=682553922393a811b910e6b4ead3722d},
	abstract = {The use of inertial measurement units (IMUs) in motion analysis for clinical purposes is relatively recent. However, the use of such a system in free environment remains sparse. This is in part due the lack of robust algorithms to handle large volumes of data for performance evaluation and patient diagnosis. The present work examines the ability of using empirical mode decomposition and discrete-time detection of events to automatically detect and segment tasks associated with activities of daily living (ADL) using IMUs. Seven healthy older adults (73$\pm$ 4 years old) performed ADL tasks in a simulated apartment during trials of different durations (3, 4, and 5 min). They wore a suit (Synertial-IGS180) comprised of 17-IMUs positioned strategically on body segments to capture full body motion. After a systematic process examining time series of each sensor, it was determined that 6 IMUs were sufficient to detect the nine tasks at hand (such as walking, sit to stand, stand to sit, reaching to the ground to pick or to put down objects on the floor, step over an obstacle and turning). The proposed method automatically identified the proper set of template waveforms associated to ADL tasks based on kinematic data acquired from the selected IMUs. The ground truth on timing of tasks was established by visual segmentation of recordings using the system's software. Despite the variation in the occurrences of the performed tasks (freely moving), the proposed algorithm exhibited high global accuracy under unscripted conditions of motion, for both Se. and Sp. of ${\hbox{97}}\%({\rm N}-{\rm events}=1999)$, using a few features and without learning process. This work will eventually allow for the assessment of mobility performance within the segmented signals, specifically how well the person is moving in his/her environment. © 2001-2011 IEEE.},
	author_keywords = {Assessment; empirical mode decomposition (EMD); event detection; filtering; inertial measurement unit (IMU); mobility; patient monitoring; signal processing; times series analysis},
	keywords = {Carrier mobility; Filtration; Joints (anatomy); Patient monitoring; Units of measurement; Assessment; Empirical Mode Decomposition; Event detection; Inertial measurement unit; Times series; aged; algorithm; Article; daily life activity; decomposition; diagnostic test accuracy study; female; human; human experiment; male; mathematical analysis; metabolic measurement system; motion analysis system; normal human; patient monitoring; sensitivity and specificity; signal processing; Signal processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@CONFERENCE{Jazizadeh2016956,
	author = {Jazizadeh, Farrokh and Wang, Jue},
	title = {Artificial Versus Natural Light Source Identification with Light Intensity Sensors for Energy Monitoring},
	year = {2016},
	journal = {Procedia Engineering},
	volume = {145},
	pages = {956 – 963},
	doi = {10.1016/j.proeng.2016.04.124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999837870&doi=10.1016%2fj.proeng.2016.04.124&partnerID=40&md5=44376e0466707e5db52fa2c77cc6358b},
	abstract = {Studies have shown that increasing the granularity of energy consumption information in buildings could facilitate achieving energy saving objectives. Lighting systems in buildings are one of the main consumers of electricity with a share of approximately (direct and indirect) 23 percent of the total electricity in the US. Direct monitoring of lighting systems is not feasible due to challenges for instrumentation. In this study, we are proposing an approach for monitoring of lighting systems energy consumption by using single light intensity sensors. Load monitoring through light sensors is challenging due to the contribution of natural light in variation of the signal magnitude in the captured time series. Accordingly, we have proposed a new feature in frequency domain that helps us identify artificial light (AL) source type and improve AL event detection. Field experimental study showed the effectiveness of the proposed feature by eliminating all false positives in event detection. © 2016 The Authors.},
	author_keywords = {Building Energy Management; Lighting systems; Load monitoring; Spectral analysis},
	keywords = {Electric load management; Energy conservation; Energy utilization; Feature extraction; Frequency domain analysis; Light sources; Lighting; Lighting fixtures; Spectrum analysis; Sustainable development; Artificial light; Building energy managements; Direct monitoring; Energy monitoring; Frequency domains; Lighting systems; Load monitoring; Source identification; Monitoring},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Sotiriou20161606,
	author = {Sotiriou, Dimitrios and Kopsaftopoulos, Fotis and Fassois, Spilios},
	title = {An Adaptive Time-Series Probabilistic Framework for 4-D Trajectory Conformance Monitoring},
	year = {2016},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	volume = {17},
	number = {6},
	pages = {1606 – 1616},
	doi = {10.1109/TITS.2015.2511024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958613711&doi=10.1109%2fTITS.2015.2511024&partnerID=40&md5=613051c3d06927718963ecb9d8aacd10},
	abstract = {Trajectory conformance monitoring is important for future air traffic control for reasons associated with optimal operation, increased safety, and improved efficiency. In this study, conformance monitoring is considered with respect to preassigned 4-D (space and time) trajectories and their margins (4-D contracts), and an adaptive time-series probabilistic framework is postulated. Two problems are tackled, and proper methods are developed: 1) present conformance monitoring and quality of conformance evaluation via statistical tools, which leads to abnormal event detection; and 2) future conformance monitoring in which conformance is predicted ahead of time allowing for the early initiation of corrective actions. The framework is based on recursive integrated autoregressive modeling of contract deviations alone, with the underlying dynamics and nonstationarity accounted for. An initial assessment of the performance of the framework is based on two simulation scenarios. Through them, present conformance monitoring is shown to lead to quality assessment and the declaration of an alarm immediately following the emergence of an abnormal event. Future conformance monitoring is shown to lead to an early nonconformance alarm, with the lead time shown to be significantly longer than that achieved by a current probabilistic benchmark scheme. © 2016 IEEE.},
	author_keywords = {adaptive models; Conformance monitoring; quality of conformance; time series models; trajectory monitoring},
	keywords = {Air traffic control; Quality control; Statistical mechanics; Time series; Trajectories; Abnormal event detections; Adaptive models; Auto regressive models; Conformance monitoring; Probabilistic framework; Quality assessment; Time series models; Underlying dynamics; Monitoring},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Hegde2015567,
	author = {Hegde, Vinod and Krnjajic, Milovan and Pozdnoukhov, Alexei},
	title = {Unsupervised Event Detection with Infinite Poisson Mixture Model},
	year = {2015},
	journal = {Proceedings - 2015 IEEE International Congress on Big Data, BigData Congress 2015},
	pages = {567 – 575},
	doi = {10.1109/BigDataCongress.2015.88},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959557987&doi=10.1109%2fBigDataCongress.2015.88&partnerID=40&md5=951b8211f8b053671ddc5c853d9b32f8},
	abstract = {Large amount of time series data generated by sensors and Web users is great source of contextual information. Detecting outliers with unusually high values in time series data is crucial for inferring about any events in the real world. In this work, we describe an infinite Poisson mixture model to detect events by identifying outliers in time series of count data. This unsupervised technique estimates the probability densities of count data which have an unknown Poisson mixture while it simultaneously detects outliers in the data. The advantage of our model is that outliers are mapped to mixture components discovered by infinite mixture model and thus inference can be drawn on the different 'types' of outliers and their proportions in the data. This lets us identify and categorize events based on magnitude of outlier data. We have analysed the performance of our model against a well known event detection technique based on Markov Modulated Poisson Process (MMPP) using synthetic and real world data. Results show that our approach to detecting events is more appropriate in analysing periodic count data as compared to the MMPP baseline. The experiments demonstrate that the presented model provides robust, detailed, and interpretable results for the analysis of outliers to detect events. © 2015 IEEE.},
	author_keywords = {event detection; infinite mixture models; outlier detection; time series; unsupervised learning},
	keywords = {Mixtures; Statistics; Time series; Unsupervised learning; Contextual information; Event detection; Markov modulated Poisson process; Mixture components; Mixture model; Outlier Detection; Probability densities; Unsupervised techniques; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shi201636,
	author = {Shi, Feng and Zhou, Yu and Kong, Bing and Xu, Ruifeng},
	title = {Type recognition of financial events by incorporating text and time-series features},
	year = {2016},
	journal = {Proceedings - International Conference on Machine Learning and Cybernetics},
	volume = {1},
	pages = {36 – 42},
	doi = {10.1109/ICMLC.2016.7860874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021075071&doi=10.1109%2fICMLC.2016.7860874&partnerID=40&md5=dbf9965f847b3ed9e75f9b95a1bbc0c9},
	abstract = {The investors in financial market have shown great concerns in the events that may cause fluctuations in the capital market. Traditional event detection and type recognition methods were majorly based on text processing techniques while few research considers the financial time-series features. As we know, there are large amount of financial time-series data available such as stock transaction data. These data may be regarded as the capital market response to specific financial events. By taking these factors into consideration, this paper presents a financial event recognition approach by incorporating text and time-series features. By following the event study method, the influences of specific type of event to stock index are estimated by analyzing the changes of average abnormal returns and average cumulative abnormal returns. In this way, the time-series features related to specific financial event types are obtained. These features are incorporated with text features in a support vector machine based classifier to recognize the types of financial events. The experiment results show that the performance of financial event type recognition is improved by incorporating text and time-series features. © 2016 IEEE.},
	author_keywords = {Event type recognition; Text features; Time-series features},
	keywords = {Commerce; Financial data processing; Financial markets; Investments; Machine learning; Support vector machines; Text processing; Time series; Cumulative abnormal returns; Event study method; Event Types; Financial time series; Recognition methods; Stock transaction; Text feature; Time series features; Character recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Flach2017677,
	author = {Flach, Milan and Gans, Fabian and Brenning, Alexander and Denzler, Joachim and Reichstein, Markus and Rodner, Erik and Bathiany, Sebastian and Bodesheim, Paul and Guanche, Yanira and Sippel, Sebastian and Mahecha, Miguel D.},
	title = {Multivariate anomaly detection for Earth observations: A comparison of algorithms and feature extraction techniques},
	year = {2017},
	journal = {Earth System Dynamics},
	volume = {8},
	number = {3},
	pages = {677 – 696},
	doi = {10.5194/esd-8-677-2017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027365144&doi=10.5194%2fesd-8-677-2017&partnerID=40&md5=65dc534ad7a5fc5fd5aa7c1f285f8695},
	abstract = {Today, many processes at the Earth's surface are constantly monitored by multiple data streams. These observations have become central to advancing our understanding of vegetation dynamics in response to climate or land use change. Another set of important applications is monitoring effects of extreme climatic events, other disturbances such as fires, or abrupt land transitions. One important methodological question is how to reliably detect anomalies in an automated and generic way within multivariate data streams, which typically vary seasonally and are interconnected across variables. Although many algorithms have been proposed for detecting anomalies in multivariate data, only a few have been investigated in the context of Earth system science applications. In this study, we systematically combine and compare feature extraction and anomaly detection algorithms for detecting anomalous events. Our aim is to identify suitable workflows for automatically detecting anomalous patterns in multivariate Earth system data streams. We rely on artificial data that mimic typical properties and anomalies in multivariate spatiotemporal Earth observations like sudden changes in basic characteristics of time series such as the sample mean, the variance, changes in the cycle amplitude, and trends. This artificial experiment is needed as there is no "gold standard" for the identification of anomalies in real Earth observations. Our results show that a well-chosen feature extraction step (e.g., subtracting seasonal cycles, or dimensionality reduction) is more important than the choice of a particular anomaly detection algorithm. Nevertheless, we identify three detection algorithms (k-nearest neighbors mean distance, kernel density estimation, a recurrence approach) and their combinations (ensembles) that outperform other multivariate approaches as well as univariate extreme-event detection methods. Our results therefore provide an effective workflow to automatically detect anomalies in Earth system science data. © Author(s) 2017.},
	keywords = {Climate change; Data communication systems; Extraction; Land use; Nearest neighbor search; Observatories; Signal detection; Anomaly-detection algorithms; Basic characteristics; Dimensionality reduction; Earth system science; Feature extraction techniques; Kernel Density Estimation; Multiple data streams; Multivariate approach; algorithm; climate effect; multivariate analysis; pattern recognition; spatiotemporal analysis; vegetation dynamics; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Wu20163,
	author = {Wu, Shaojiang and Wang, Yibo and Zhan, Yi and Chang, Xu},
	title = {Automatic microseismic event detection by band-limited phase-only correlation},
	year = {2016},
	journal = {Physics of the Earth and Planetary Interiors},
	volume = {261},
	pages = {3 – 16},
	doi = {10.1016/j.pepi.2016.09.005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028245504&doi=10.1016%2fj.pepi.2016.09.005&partnerID=40&md5=086160017ac4a8cbece25d11c096b54f},
	abstract = {Identification and detection of microseismic events is a significant issue in source locations and source mechanism analysis. The number of the records is notably large, especially in the case of some real-time monitoring, and while the majority of microseismic events are highly weak and sparse, automatic algorithms are indispensable. In this study, we introduce an effective method for the identification and detection of microseismic events by judging whether the P-wave phase exists in a local segment from a single three-component microseismic records. The new judging algorithm consists primarily of the following key steps: 1) transform the waveform time series into time-varying spectral representations using the S-transform; 2) calculate the similarity of the frequency content in the time-frequency domain using the phase-only correlation function; and 3) identify the P-phase by the combination analysis between any two components. The proposed algorithm is compared to a similar approach using the cross-correlation in the time domain between any two components and later tested with synthetic microseismic datasets and real field-recorded datasets. The results indicate that the proposed algorithm is able to distinguish similar and dissimilar waveforms, even for low signal noise ratio and emergent events, which is important for accurate and rapid selection of microseismic events from a large number of records. This method can be applied to other geophysical analyses based on the waveform data. © 2016 Elsevier B.V.},
	author_keywords = {Event detected; Microsismic; Phase-only correlation},
	keywords = {Frequency domain analysis; Mathematical transformations; Seismic waves; Seismology; Time domain analysis; Time series analysis; Automatic algorithms; Event detected; Geophysical analysis; Microsismic; Phase-only correlation; Real time monitoring; Spectral representations; Time frequency domain; algorithm; data set; detection method; identification method; microearthquake; P-wave; S-wave; transform; waveform analysis; Microseismic monitoring},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@ARTICLE{Liu2015109,
	author = {Liu, Shuming and Smith, Kate and Che, Han},
	title = {A multivariate based event detection method and performance comparison with two baseline methods},
	year = {2015},
	journal = {Water Research},
	volume = {80},
	pages = {109 – 118},
	doi = {10.1016/j.watres.2015.05.013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929415373&doi=10.1016%2fj.watres.2015.05.013&partnerID=40&md5=31eac2ee07026b1e5a89c541d89e4170},
	abstract = {Early warning systems have been widely deployed to protect water systems from accidental and intentional contamination events. Conventional detection algorithms are often criticized for having high false positive rates and low true positive rates. This mainly stems from the inability of these methods to determine whether variation in sensor measurements is caused by equipment noise or the presence of contamination. This paper presents a new detection method that identifies the existence of contamination by comparing Euclidean distances of correlation indicators, which are derived from the correlation coefficients of multiple water quality sensors. The performance of the proposed method was evaluated using data from a contaminant injection experiment and compared with two baseline detection methods. The results show that the proposed method can differentiate between fluctuations caused by equipment noise and those due to the presence of contamination. It yielded higher possibility of detection and a lower false alarm rate than the two baseline methods. With optimized parameter values, the proposed method can correctly detect 95% of all contamination events with a 2% false alarm rate. © 2015 Elsevier Ltd.},
	author_keywords = {Contaminant classification; Conventional sensor; Early warning system; Euclidean distance; Pearson correlation; Water quality},
	keywords = {Algorithms; Computer Systems; Environmental Monitoring; Multivariate Analysis; Reproducibility of Results; Water Pollutants, Chemical; Water Pollution, Chemical; Water Quality; Water Supply; Alarm systems; Correlation methods; Errors; Image resolution; Water quality; water pollutant; Baseline methods; Contaminant classification; Contamination events; Conventional sensors; Detection methods; Early Warning System; Euclidean distance; Events detection; False alarm rate; Pearson correlation; alarm signal; algorithm; baseline conditions; detection method; early warning system; multivariate analysis; optimization; performance assessment; sensor; water pollution; water quality; Article; correlation coefficient; data processing; intermethod comparison; linear prediction filter; multivariate euclidean distance; priority journal; receiver operating characteristic; sensitivity and specificity; sensor; time series analysis; turbidity; water analysis; water contamination; water quality; water supply; algorithm; analysis; comparative study; computer system; environmental monitoring; multivariate analysis; prevention and control; procedures; reproducibility; standards; water pollutant; water pollution; water quality; Contamination},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28}
}

@CONFERENCE{Healy201555,
	author = {Healy, Philip and Hunt, Graham and Kilroy, Steven and Lynn, Theo and Morrison, John P. and Venkatagiri, Shankar},
	title = {Evaluation of peak detection algorithms for social media event detection},
	year = {2015},
	journal = {Proceedings - 10th International Workshop on Semantic and Social Media Adaptation and Personalization, SMAP 2015},
	pages = {55 – 60},
	doi = {10.1109/SMAP.2015.7370090},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964089198&doi=10.1109%2fSMAP.2015.7370090&partnerID=40&md5=e3822560b2c44969515d0839eaf4b548},
	abstract = {We evaluate the effectiveness of three peak detection algorithms when applied to collection of social media datasets. Each dataset is composed of a year's worth of tweets relating to a topic. The datasets were converted to time series composed of hourly tweet volumes. The objective of the analysis was to identify abnormal surges of communication, which are taken to be representative of the occurrence of events relevant to the topic under consideration. The ground truth was established by manually tagging the time series in order to identify peaks apparent to a human operator. Candidate algorithms were then evaluated in terms of the precision, recall, and F± scores obtained when their output was compared to the manually identified peaks. A general-purpose algorithm is found to perform reasonably well, but seasonality in social media data limits the effectiveness of applying simple algorithms without filtering. © 2015 IEEE.},
	author_keywords = {Analytics; Event Detection; Peak Detection; Social Media; Spike Detection; Twitter},
	keywords = {Semantics; Signal detection; Social networking (online); Time series; Analytics; Event detection; Peak detection; Social media; Spike detection; Twitter; Algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{20171,
	title = {International Conference on Cross-Cultural Decision Making, CCDM 2016},
	year = {2017},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {480},
	pages = {1 – 356},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986188696&partnerID=40&md5=1a625a47badb19c9d7d11cb4bf8ead35},
	abstract = {The proceedings contain 28 papers. The special focus in this conference is on Dynamic PMESII Modeling in Complex Environments. The topics include: Expeditionary modeling for population-centric operations in megacities; time-series analysis of blog and metaphor dynamics for event detection; modeling causal relationships in sociocultural systems using ensemble methods; difference analysis of impression on Japan from Chinese students with different education stages; dynamics of national culture and employee characteristics on organizational commitment in retail banks in ghana; cross-cultural competence and functional diversity in business negotiations; investigation of cultural bias using physiological metrics; difference of adaptation process to comfort and discomfort stimulus when presented all together or intermittently; evaluating automatic learning of structure for event extraction; scenario-based practical exercises to train and assess general cross-cultural competence for special operations forces; toward culturally-aware, next generation learning ecosystems; investigating cross-cultural differences in trust levels of automotive automation; evaluating instructor configurability for adaptive training; a method for creating realistic and individually varied cultural avatars; the preference of using social media by different attachment styles for managing romantic relation; considering culture in contemporary military interventions; development of a competency model for civil-military teaming; a planning tool for interaction with influential actors based on paraconsistent logic; the conundrum of verification and validation of social science-based models redux; socio-cultural modeling and dynamic decision making; examining the, ideological, sociopolitical, and contextual factors underlying the appeal of extremism and a statistical approach to the subnational geolocation of event data.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Caillault20171,
	author = {Caillault, Emilie Poisson and Lefebvre, Alain},
	title = {Towards Chl-a bloom understanding by EM-based unsupervised event detection},
	year = {2017},
	journal = {OCEANS 2017 - Aberdeen},
	volume = {2017-October},
	pages = {1 – 5},
	doi = {10.1109/OCEANSE.2017.8084597},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044661087&doi=10.1109%2fOCEANSE.2017.8084597&partnerID=40&md5=6cbea65e5404faa72305faace2bad6cc},
	abstract = {Marine water quality monitoring and subsequent management require to know when a specific event like harmful algae bloom may occur and which environmental conditions and pressures lead to this event. So, event detection and its dynamic understanding are crucial to adapt strategy. An algorithm is proposed to identify curves mixture and their dynamics features - initiation, duration, peaks and ends of the event. The approach is fully unsupervised, it requires no tuning parameters and is based on Expectation Maximization process to estimate the most robust mixture according to fixed criteria. A complete framework is proposed to deal with a univariate time series with missing data. The approach is applied on Chlorophyll-a series collected weekly since 1989. Chlorophyll-a is a proxy of the phytoplankton biomass. The results are promising according to the phytoplankton composition knowledge, collected at lower frequency, and allowing to discuss about the annual variability of phytoplankton dynamics. © 2017 IEEE.},
	author_keywords = {Chlorophyll-a; Event detection; Expectation-Maximisation; Phaeocystis; Phenology; Time series},
	keywords = {Maximum principle; Mixtures; Phytoplankton; Time series; Water quality; Chlorophyll a; Event detection; Expectation-maximisation; Phaeocystis; Phenology; Chlorophyll},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Brindha20171,
	author = {Brindha, N. and Visalakshi, P.},
	title = {Bridging semantic gap between high-level and low-level features in content-based video retrieval using multi-stage ESN–SVM classifier},
	year = {2017},
	journal = {Sadhana - Academy Proceedings in Engineering Sciences},
	volume = {42},
	number = {1},
	pages = {1 – 10},
	doi = {10.1007/s12046-016-0574-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006784336&doi=10.1007%2fs12046-016-0574-8&partnerID=40&md5=22634095b18a2cda84f4518937e4a7c7},
	abstract = {Content-based video retrieval system aims at assisting a user to retrieve targeted video sequence in a large database. Most of the search engines use textual annotations to retrieve videos. These types of engines offer a low-level abstraction while the user seeks high-level semantics. Bridging this type of semantic gap in video retrieval remains an important challenge. In this paper, colour, texture and shapes are considered to be low-level features and motion is a high-level feature. Colour histograms convert the RGB colour space into YcbCr and extract hue and saturation values from frames. After colour extraction, filter mask is applied and gradient value is computed. Gradient and threshold values are compared to draw the edge map. Edges are smoothed for sharpening to remove the unnecessary connected components. These diverse shapes are then extracted and stored in shape feature vectors. Finally, an SVM classifier is used for classification of low-level features. For high-level features, depth images are extracted for motion feature identification and classification is done via echo state neural networks (ESN). ESN are a supervised learning technique and follow the principle of recurrent neural networks. ESN are well known for time series classification and also proved their effective performance in gesture detection. By combining the existing algorithms, a high-performance multimedia event detection system is constructed. The effectiveness and efficiency of proposed event detection mechanism is validated using MSR 3D action pair dataset. Experimental results show that the detection accuracy of proposed combination is better than those of other algorithms © 2016, Indian Academy of Sciences.},
	author_keywords = {Classification; ESN; feature selection; spatio-temporal structure; SVM},
	keywords = {Color; Feature extraction; Recurrent neural networks; Search engines; Semantics; Support vector machines; Textures; Content-based video retrieval; Content-based video retrieval systems; Echo state neural networks; Effective performance; Effectiveness and efficiencies; Multimedia event detections; Spatio-temporal structures; Time series classifications; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Bronze Open Access}
}

@ARTICLE{Cui2016257,
	author = {Cui, Lishan and Zhang, Xiuzhen and Zhou, Xiangmin and Salim, Flora},
	title = {Topical event detection on twitter},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9877 LNCS},
	pages = {257 – 268},
	doi = {10.1007/978-3-319-46922-5_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990020604&doi=10.1007%2f978-3-319-46922-5_20&partnerID=40&md5=01c6fbd9a83486ff1a93d04969fa741a},
	abstract = {Event detection on Twitter has attracted active research. Although existing work considers the semantic topic structure of documents for event detection, the topic dynamics and the semantic consistency are under-investigated. In this paper, we study the problem of topical event detection in tweet streams. We define topical events as the bursty occurrences of semantically consistent topics. We decompose the problem of topical event detection into two components: (1) We address the issue of the semantic incoherence of the evolution of topics. We propose to improve topic modelling to filter out semantically inconsistent dynamic topics. (2) We propose to perform burst detection on the time series of dynamic topics to detect bursty occurrences. We apply our proposed techniques to the real world application by detecting topical events in public transport tweets. Experiments demonstrate that our approach can detect the newsworthy events with high success rate. © Springer International Publishing AG 2016.},
	author_keywords = {Burst detection; Dynamic topic modeling; Event detection; Topic mutation},
	keywords = {Semantics; Social networking (online); Burst detection; Dynamic topic models; Event detection; Public transport; Semantic consistency; Topic mutation; Topic structures; Two-component; Database systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Ghosh20163985,
	author = {Ghosh, Pradipto},
	title = {Space event detection via robust time series forecasting},
	year = {2016},
	journal = {Advances in the Astronautical Sciences},
	volume = {158},
	pages = {3985 – 4002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007396722&partnerID=40&md5=6864169517f553298e3624c18cb4c62a},
	abstract = {The ability to detect sudden and unexpected changes in the ephemerides of tracked space objects is a crucial feature of space event monitoring systems. These changes may arise from actual space events such as satellite maneuvers or collisions, from cross-tagging of space objects as might occur during a fly-by, or even from inadvertently introduced defects in the orbit determination (OD) workflow. Utilizing robust time series forecasting techniques, this paper introduces a new method for detecting sudden changes in the ephemeris of a tracked object. Test cases drawn from known space events demonstrate that the software implementation of this method is able to flag each sequentially supplied orbitdetermined state as in- or out-of-family depending on whether the state is statistically typical relative to a configurable look-back interval.},
	keywords = {Orbits; Software testing; Space flight; Event detection; Event monitoring; Orbit determination; Software implementation; Space objects; Sudden change; Time series forecasting; Tracked objects; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Loureiro2016242,
	author = {Loureiro, Dália and Amado, Conceição and Martins, André and Vitorino, Diogo and Mamade, Aisha and Coelho, Sérgio Teixeira},
	title = {Water distribution systems flow monitoring and anomalous event detection: A practical approach},
	year = {2016},
	journal = {Urban Water Journal},
	volume = {13},
	number = {3},
	pages = {242 – 252},
	doi = {10.1080/1573062X.2014.988733},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955714922&doi=10.1080%2f1573062X.2014.988733&partnerID=40&md5=f16db0bf8887ad59518a42c17ef8e533},
	abstract = {Methods to detect outliers in network flow measurements that may be due to pipe bursts or unusual consumptions are fundamental to improve water distribution system on-line operation and management, and to ensure reliable historical data for sustainable planning and design of these systems. To detect and classify anomalous events in flow data from district metering areas a four-step methodology was adopted, implemented and tested: i) data acquisition, ii) data validation and normalization, iii) anomalous observation detection, iv) anomalous event detection and characterization. This approach is based on the renewed concept of outlier regions and depends on a reduced number of configuration parameters: the number of past observations, the true positive rate and the false positive rate. Results indicate that this approach is flexible and applicable to the detection of different types of events (e.g., pipe burst, unusual consumption) and to different flow time series (e.g., instantaneous, minimum night flow). © 2015 Taylor & Francis.},
	author_keywords = {flow measurement; flow patterns; outliers; pipe burst; real water losses; water distribution systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 68}
}

@ARTICLE{Pełech-Pilichowski2015555,
	author = {Pełech-Pilichowski, Tomasz and Duda, Jan T.},
	title = {A two-level detector of short-term unique changes in time series based on a similarity method},
	year = {2015},
	journal = {Expert Systems},
	volume = {32},
	number = {4},
	pages = {555 – 561},
	doi = {10.1111/exsy.629},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939447009&doi=10.1111%2fexsy.629&partnerID=40&md5=5efed40956bea67be3214afaa75f1e87},
	abstract = {In the paper, a novel two-level algorithm of time-series change detection is presented. In the first level, to identify non-stationary sequences in a processed signal, preliminary detection of events is performed with a short-term prediction comparison. In the second stage, to confirm the changes detected in the first level, a similarity method aimed at identification of unique changes is employed. The detection of changes in a non-stationary time series is discussed, implemented algorithms are described and the results produced on a sample four financial time series are shown. General conditions for implementing the proposed algorithm as an immune-like event detector are discussed. © 2012 Blackwell Publishing Ltd.},
	author_keywords = {distance-based detectors; immune-like event detection; signal analysis; time-series prediction},
	keywords = {Financial data processing; Signal analysis; Signal detection; Time series; Detection of changes; Distance-based; Event detection; Financial time series; Level algorithms; Non-stationary time series; Short term prediction; Time series prediction; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Kato2018251,
	author = {Kato, Shinya and Amagata, Daichi and Nishio, Shunya and Hara, Takahiro},
	title = {Monitoring Range Motif on Streaming Time-Series},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11029 LNCS},
	pages = {251 – 266},
	doi = {10.1007/978-3-319-98809-2_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052098391&doi=10.1007%2f978-3-319-98809-2_16&partnerID=40&md5=d24034b893b19915dd3c97e672ce2d40},
	abstract = {Recent IoT-based applications generate time-series in a streaming fashion, and they often require techniques that enable environmental monitoring and event detection from generated time-series. Discovering a range motif, which is a subsequence that repetitively appears the most in a time-series, is a promising approach for satisfying such a requirement. This paper tackles the problem of monitoring a range motif of a streaming time-series under a count-based sliding-window setting. Whenever a window slides, a new subsequence is generated and the oldest subsequence is removed. A straightforward solution for monitoring a range motif is to scan all subsequences in the window while computing their occurring counts measured by a similarity function. Because the main bottleneck is similarity computation, this solution is not efficient. We therefore propose an efficient algorithm, namely SRMM. SRMM is simple and its time complexity basically depends only on the occurring counts of the removed and generated subsequences. Our experiments using four real datasets demonstrate that SRMM scales well and shows better performance than a baseline. © 2018, Springer Nature Switzerland AG.},
	author_keywords = {Motif monitoring; Streaming time-series},
	keywords = {Expert systems; Environmental Monitoring; Event detection; Real data sets; Similarity computation; Similarity functions; Sliding Window; Time complexity; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Xu2016,
	author = {Xu, Ren and Jiang, Ning and Mrachacz-Kersting, Natalie and Dremstrup, Kim and Farina, Dario},
	title = {Factors of influence on the performance of a short-latency non-invasive brain switch: Evidence in healthy individuals and implication for motor function rehabilitation},
	year = {2016},
	journal = {Frontiers in Neuroscience},
	volume = {9},
	number = {JAN},
	doi = {10.3389/fnins.2015.00527},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958045740&doi=10.3389%2ffnins.2015.00527&partnerID=40&md5=1eb4c517f07c19739ece277465c0e15d},
	abstract = {Brain-computer interfacing (BCI) has recently been applied as a rehabilitation approach for patients with motor disorders, such as stroke. In these closed-loop applications, a brain switch detects the motor intention from brain signals, e.g., scalp EEG, and triggers a neuroprosthetic device, either to deliver sensory feedback or to mimic real movements, thus re-establishing the compromised sensory-motor control loop and promoting neural plasticity. In this context, single trial detection of motor intention with short latency is a prerequisite. The performance of the event detection from EEG recordings is mainly determined by three factors: the type of motor imagery (e.g., repetitive, ballistic), the frequency band (or signal modality) used for discrimination (e.g., alpha, beta, gamma, and MRCP, i.e., movement-related cortical potential), and the processing technique (e.g., time-series analysis, sub-band power estimation). In this study, we investigated single trial EEG traces during movement imagination on healthy individuals, and provided a comprehensive analysis of the performance of a short-latency brain switch when varying these three factors. The morphological investigation showed a cross-subject consistency of a prolonged negative phase in MRCP, and a delayed beta rebound in sensory-motor rhythms during repetitive tasks. The detection performance had the greatest accuracy when using ballistic MRCP with time-series analysis. In this case, the true positive rate (TPR) was ~70% for a detection latency of ~200 ms. The results presented here are of practical relevance for designing BCI systems for motor function rehabilitation. © 2016 Xu, Jiang, Mrachacz-Kersting, Dremstrup and Farina.},
	author_keywords = {Ballistic and repetitive task; Brain-computer interface; Motor intention detection; Movement-related cortical potential; Sensory-motor rhythm},
	keywords = {brain; controlled study; electroencephalogram; human; human experiment; imagery; imagination; motor performance; normal human; rebound; rehabilitation; rhythm; time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Cheng201615101,
	author = {Cheng, Kai-Wen and Chen, Yie-Tarng and Fang, Wen-Hsien},
	title = {An efficient subsequence search for video anomaly detection and localization},
	year = {2016},
	journal = {Multimedia Tools and Applications},
	volume = {75},
	number = {22},
	pages = {15101 – 15122},
	doi = {10.1007/s11042-015-2453-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921871703&doi=10.1007%2fs11042-015-2453-4&partnerID=40&md5=583cacf7c684ca274021c13f6f8b7838},
	abstract = {This paper presents a novel framework for anomaly event detection and localization in crowded scenes. For anomaly detection, one-class support vector machine with Bayesian derivation is applied to detect unusual events. We also propose a novel event representation, called subsequence, which refers to a time series of spatial windows in proximity. Unlike recent works encoded an event with a 3D bounding box which may contain irrelevant information, e.g. background, a subsequence can concisely capture the unstructured property of an event. To efficiently locate anomalous subsequences in a video space, we propose the maximum subsequence search. The proposed search algorithm integrates local anomaly scores into a global consistent detection so that the start and end of an abnormal event can be determined under false and missing detections. Experimental results on two public datasets show that our method is robust to the illumination change and achieve at least 80% localization rate which approximately doubles the accuracy of recent works. This study concludes that anomaly localization is crucial in finding abnormal events. © 2015, Springer Science+Business Media New York.},
	author_keywords = {Anomaly detection; Localization; Subsequence; Video surveillance},
	keywords = {Image retrieval; Image segmentation; Anomaly detection; Anomaly localizations; Consistent detections; Event representations; Localization; One-class support vector machine; Subsequence; Video surveillance; Security systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Cassady2017347,
	author = {Cassady, Colin and Lin, Fandi and Molinari, Thomas and Alvarado, Rafael and Wang, Ke},
	title = {Joint sentiment models for event detection and latent cultural structure assessment in nationalist text},
	year = {2017},
	journal = {2017 Systems and Information Engineering Design Symposium, SIEDS 2017},
	pages = {347 – 352},
	doi = {10.1109/SIEDS.2017.7937744},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025580242&doi=10.1109%2fSIEDS.2017.7937744&partnerID=40&md5=019ab37ac8abcd09895a260592a579b0},
	abstract = {Increased interaction among distinct perspectives can lead to increased conflict. The multiplicity of available data can alleviate this burden by offering an informed avenue for comprehension. Parsing these data sources for relevant information is a time intensive and academically challenging task. Our research looks to explore the practicality of parsing these sources of data by attempting to surface latent cultural structures from organized texts. By analyzing sources that heavily rely on nationalistic subtexts, our research looks to find non-obvious sentiment on latent cultural events and topics that would typically require dedicated research to discover and dissect. The two data sources this work considers are nationalist journalistic efforts: An Phoblacht and TamilNet. We explore different paradigms for latent variable discovery in textual data, including topic modeling and word embedding, and synthesize them with sentiment analysis to produce a composite model for discovering and classifying unseen cultural context within the text. We pay additional consideration to evaluating how these composite models shift over time, and what implications this holds for identifying patterns of reaction for these populations. Our exploratory results show predicted latent cultural structures within the text, while our time series analysis indicates several outliers in the usage of language that indicate potential latent cultural perspectives. © 2017 IEEE.},
	author_keywords = {Event Detection; Joint Sentiment Models; Nationalist Discourse; Natural Language Processing},
	keywords = {Data mining; Natural language processing systems; Time series analysis; Composite modeling; Composite models; Cultural context; Cultural events; Event detection; Latent variable; Nationalist Discourse; Sentiment analysis; Structural design},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sangnier20163432,
	author = {Sangnier, Maxime and Gauthier, Jerome and Rakotomamonjy, Alain},
	title = {Early and reliable event detection using proximity space representation},
	year = {2016},
	journal = {33rd International Conference on Machine Learning, ICML 2016},
	volume = {5},
	pages = {3432 – 3441},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998636444&partnerID=40&md5=192bdd9ce89bcf0cd48425944fe13298},
	abstract = {Let us consider a specific action or situation (called event) that takes place within a time se-ries. The objective in early detection is to build a decision function that is able to go off as soon as possible from the onset of an occurrence of this event. This implies making a decision with an incomplete information. This paper proposes a novel framework that i) guarantees that a de-tection made with a partial observation will also occur at full observation of the time-series; ii) incorporates in a consistent manner the lack of knowledge about the minimal amount of infor-mation needed to make a decision. The proposed detector is based on mapping the temporal sequences to a landmarking space thanks to appropriately designed similarity functions. As a by-product, the framework benefits from a scalable training algorithm and a theoretical guarantee concerning its generalization ability. We also discuss an important improvement of our framework in which decision function can still be made reliable while being more expressive. Our experimental studies provide compelling results on toy data, presenting the trade-off that occurs when aiming at accuracy, earliness and reliability. Results on real physiological and video datasets show that our proposed approach is as accurate and early as state-of-the-art algorithm, while ensuring reliability and being far more efficient to learn.copyright © 2016 by the author(s).},
	keywords = {Artificial intelligence; Economic and social effects; Learning systems; Decision functions; Generalization ability; Incomplete information; Partial observation; Similarity functions; State-of-the-art algorithms; Theoretical guarantees; Training algorithms; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{2017,
	title = {ACM International Conference Proceeding Series},
	year = {2017},
	journal = {ACM International Conference Proceeding Series},
	volume = {Part F129475},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028315786&partnerID=40&md5=0de824cc2ae18fe50be5dcb2e37d6824},
	abstract = {The proceedings contain 35 papers. The topics discussed include: towards easier visualization of linked data for lay users; large-scale storage and query processing for semantic sensor data; exploring lurking behaviors in online social networks; knowledge extraction from on-line open source bug tracking systems to predict bug-fixing time; a time series classification approach to game Bot detection; evolutionary mining of relaxed dependencies from big data collections; HERMEVENT: a news collection for emerging-event detection; querying and searching the deep web; on the SPARQL metamodeling semantics entailment regime for OWL 2 QL ontologies; semantic technology for open data publishing; efficient top-k shortest path query processing in sparse graph databases; mitigating linked data quality issues in knowledge-intense information extraction methods; analysis of semantic URLs to support automated linking of structured data on the web; managing road safety through the use of linked data and heat maps; an extended spreading activation technique for hashtag recommendation in microblogging platforms; a real-time twitter sentiment analysis using an unsupervised method; and an innovative majority voting mechanism in interactive social network clustering.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Koepcke2016,
	author = {Koepcke, Lena and Ashida, Go and Kretzberg, Jutta},
	title = {Single and multiple change point detection in spike trains: Comparison of different CUSUM methods},
	year = {2016},
	journal = {Frontiers in Systems Neuroscience},
	volume = {10},
	number = {JUN},
	doi = {10.3389/fnsys.2016.00051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989284843&doi=10.3389%2ffnsys.2016.00051&partnerID=40&md5=abcabd3bf0cfa10ea8eb9be685bd72fe},
	abstract = {In a natural environment, sensory systems are faced with ever-changing stimuli that can occur, disappear or change their properties at any time. For the animal to react adequately the sensory systems must be able to detect changes in external stimuli based on its neuronal responses. Since the nervous system has no prior knowledge of the stimulus timing, changes in stimulus need to be inferred from the changes in neuronal activity, in particular increase or decrease of the spike rate, its variability, and shifted response latencies. From a mathematical point of view, this problem can be rephrased as detecting changes of statistical properties in a time series. In neuroscience, the CUSUM (cumulative sum) method has been applied to recorded neuronal responses for detecting a single stimulus change. Here, we investigate the applicability of the CUSUM approach for detecting single as well as multiple stimulus changes that induce increases or decreases in neuronal activity. Like the nervous system, our algorithm relies exclusively on previous neuronal population activities, without using knowledge about the timing or number of external stimulus changes. We apply our change point detection methods to experimental data obtained by multi-electrode recordings from turtle retinal ganglion cells, which react to changes in light stimulation with a range of typical neuronal activity patterns. We systematically examine how variations of mathematical assumptions (Poisson, Gaussian, and Gamma distributions) used for the algorithms may affect the detection of an unknown number of stimulus changes in our data and compare these CUSUM methods with the standard Rate Change method. Our results suggest which versions of the CUSUM algorithm could be useful for different types of specific data sets. © 2016 Koepcke, Ashida and Kretzberg.},
	author_keywords = {Event detection; Moving average; Neural coding; Rate change; Rate coding; Response latency; Signal detection; Spike train analysis},
	keywords = {algorithm; Article; clinical evaluation; cluster analysis; comparative study; electrode; mathematical analysis; muscle sympathetic nerve activity; nerve cell membrane; performance; process optimization; sensory system examination; sequence analysis; spike wave; stimulation; stochastic model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Goode201717,
	author = {Goode, Brian J. and Reyes, Juan Ignacio M. and Pardo-Yepez, Daniela R. and Canale, Gabriel L. and Tong, Richard M. and Mares, David and Roan, Michael and Ramakrishnan, Naren},
	title = {Time-series analysis of blog and metaphor dynamics for event detection},
	year = {2017},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {480},
	pages = {17 – 27},
	doi = {10.1007/978-3-319-41636-6_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986186183&doi=10.1007%2f978-3-319-41636-6_2&partnerID=40&md5=9b34b16c0b5a396793fdc105b6cab0cb},
	abstract = {Open source indicators (OSI) like social media are useful for detecting and forecasting the onset and progression of political events and mass movements such as elections and civil unrest. Recent work has led us to analyze metaphor usage in Latin American blogs to model such events. In addition to being rich in metaphorical usage, these data sources are heterogeneous with respect to their time-series behavior in terms of publication frequency and metaphor occurrence that make relative comparisons across sources difficult. We hypothesize that understanding these non-normal behaviors is a compulsory step toward improving analysis and forecasting ability. In this work, we discuss our blog data set in detail, and dissect the data along several key characteristics such as blog publication frequency, length, and metaphor usage. In particular, we focus on occurrence clustering: modeling variations in the incidence of both metaphors and blogs over time. We describe these variations in terms of the shape parameters of distributions estimated using maximum likelihood methods. We conclude that although there may be no “characteristic” behavior in the heterogeneity of the sources, we can form groups of blogs with similar behaviors to improve detection ability. © Springer International Publishing Switzerland 2017.},
	author_keywords = {Metaphor; Open source indicators; Temporal clustering},
	keywords = {Blogs; Decision making; Internet; Maximum likelihood; Social networking (online); Detection ability; Forecasting ability; Key characteristics; Maximum likelihood methods; Metaphor; Open sources; Political events; Temporal clustering; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Weber20181363,
	author = {Weber, Samuel and Faillettaz, Jérome and Meyer, Matthias and Beutel, Jan and Vieli, Andreas},
	title = {Acoustic and microseismic characterization in steep bedrock permafrost on matterhorn (CH)},
	year = {2018},
	journal = {Journal of Geophysical Research: Earth Surface},
	volume = {123},
	number = {6},
	pages = {1363 – 1385},
	doi = {10.1029/2018JF004615},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052894310&doi=10.1029%2f2018JF004615&partnerID=40&md5=c71d692dc46df442f6db396e07852254},
	abstract = {Understanding of processes and factors influencing slope stability is essential for assessing the stability of potentially hazardous slopes. Passive monitoring of acoustic emissions and microseismology provides subsurface information on fracturing (timing and identification of the mechanism) and therefore complement surface displacement data. This study investigates for the first time acoustic and microseismic signals generated in steep, fractured bedrock permafrost, covering the broad frequency range of 1 - 105 Hz. The analysis of artificial forcing experiments using a rebound hammer in a controlled setting led to two major findings: First, statistically insignificant cross correlation between signals indicates that waveforms change strongly with propagation distance. Second, a significant amplification is found in the frequency band 33-67 Hz. This finding is strongly supported by evidence from artificial rockfall events and more importantly by naturally occurring fracture events identified in fracture displacement data. Thus, filtering this frequency band enables enhanced detection of microseismic events relevant for slope stability assessment. The analysis of 2-year time series in this frequency band further suggests that the detected energy rate baseline of all automatically triggered events using the STA/LTA algorithm is not sensitive to temperature forcing, an observation of primary importance for long-term data collection, analysis, and interpretation. The event detection in the established frequency band is not only improved but also not affected by the short- and long-term temperature changes in such a rapidly changing environment. © 2018. American Geophysical Union. All rights reserved.},
	keywords = {acoustic method; bedrock; displacement; permafrost; rockfall; seismology; slope stability; stability analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Green Open Access}
}

@ARTICLE{Chen201850,
	author = {Chen, Chao and Terejanu, Gabriel},
	title = {Sub-event detection on twitter network},
	year = {2018},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {519},
	pages = {50 – 60},
	doi = {10.1007/978-3-319-92007-8_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049555921&doi=10.1007%2f978-3-319-92007-8_5&partnerID=40&md5=6f5c3d9de846350adf677c14bbf27787},
	abstract = {This work addresses the online detection of sub-events using Twitter stream data. We formulate the process of sub-event identification as an outlier detection problem using three statistical methods: Kalman Filter, Gaussian Process, and Probabilistic Principal Component Analysis. These methods are used to construct the probability distribution of percentage change in the number of tweets. Outliers are identified as future observations that do not fit these predicted probability distributions. Five real-world case studies are investigated to test the effectiveness of the methods. Finally, we discuss the limitations of the proposed frame-work and provide future directions for improvement. © IFIP International Federation for Information Processing 2018 Published by Springer International Publishing AG 2018. All Rights Reserved.},
	author_keywords = {Outlier detection; Social media mining; Time-series analysis},
	keywords = {Artificial intelligence; Data handling; Filtration; Principal component analysis; Social networking (online); Statistics; Time series analysis; Case-studies; Future observations; Gaussian Processes; On-line detection; Outlier Detection; Probabilistic principal component analysis; Social media minings; Twitter networks; Probability distributions},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Mao2017,
	author = {Mao, Yingchi and Qi, Hai and Ping, Ping and Li, Xiaofang},
	title = {Contamination event detection with multivariate time-series data in agricultural water monitoring},
	year = {2017},
	journal = {Sensors (Switzerland)},
	volume = {17},
	number = {12},
	doi = {10.3390/s17122806},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037523264&doi=10.3390%2fs17122806&partnerID=40&md5=add016aa95dadfb83daac031269a35f2},
	abstract = {Time series data of multiple water quality parameters are obtained from the water sensor networks deployed in the agricultural water supply network. The accurate and efficient detection and warning of contamination events to prevent pollution from spreading is one of the most important issues when pollution occurs. In order to comprehensively reduce the event detection deviation, a spatial–temporal-based event detection approach with multivariate time-series data for water quality monitoring (M-STED) was proposed. The M-STED approach includes three parts. The first part is that M-STED adopts a Rule K algorithm to select backbone nodes as the nodes in the CDS, and forward the sensed data of multiple water parameters. The second part is to determine the state of each backbone node with back propagation neural network models and the sequential Bayesian analysis in the current timestamp. The third part is to establish a spatial model with Bayesian networks to estimate the state of the backbones in the next timestamp and trace the “outlier” node to its neighborhoods to detect a contamination event. The experimental results indicate that the average detection rate is more than 80% with M-STED and the false detection rate is lower than 9%, respectively. The M-STED approach can improve the rate of detection by about 40% and reduce the false alarm rate by about 45%, compared with the event detection with a single water parameter algorithm, S-STED. Moreover, the proposed M-STED can exhibit better performance in terms of detection delay and scalability. © 2017 by the author. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Back propagation model; Connected dominating set; Event detection; Multivariate water quality parameters; Spatial-temporal model; Timeseries data; Water supply network},
	keywords = {Bayes Theorem; Environmental Monitoring; Water; Water Pollutants, Chemical; Water Quality; Water Supply; Ad hoc networks; Agriculture; Backpropagation; Bayesian networks; Monitoring; Neural networks; Parameter estimation; Pollution; Sensor networks; Time series; Water distribution systems; Water quality; Water supply; water; Connected Dominating Set; Event detection; Spatial temporal model; Time-series data; Water quality parameters; Water supply networks; Bayes theorem; environmental monitoring; water pollutant; water quality; water supply; Pollution detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhu2017560,
	author = {Zhu, Xi and Guo, Diansheng},
	title = {Urban event detection with big data of taxi OD trips: A time series decomposition approach},
	year = {2017},
	journal = {Transactions in GIS},
	volume = {21},
	number = {3},
	pages = {560 – 574},
	doi = {10.1111/tgis.12288},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021104491&doi=10.1111%2ftgis.12288&partnerID=40&md5=9c17210377d0be1d027bcc16efdb4e65},
	abstract = {Big urban mobility data, such as taxi trips, cell phone records, and geo-social media check-ins, offer great opportunities for analyzing the dynamics, events, and spatiotemporal trends of the urban social landscape. In this article, we present a new approach to the detection of urban events based on location-specific time series decomposition and outlier detection. The approach first extracts long-term temporal trends and seasonal periodicity patterns. Events are defined as anomalies that deviate significantly from the prediction with the discovered temporal patterns, i.e., trend and periodicity. Specifically, we adopt the STL approach, i.e., seasonal and trend decomposition using LOESS (locally weighted scatterplot smoothing), to decompose the time series for each location into three components: long-term trend, seasonal periodicity, and the remainder. Events are extracted from the remainder component for each location with an outlier detection method. We analyze over a billion taxi trips for over seven years in Manhattan (New York City) to detect and map urban events at different temporal resolutions. Results show that the approach is effective and robust in detecting events and revealing urban dynamics with both holistic understandings and location-specific interpretations. © 2017 John Wiley & Sons Ltd},
	keywords = {Kansas; Manhattan; United States; Big data; Data handling; Taxicabs; Time series; Cell phone; Decomposition approach; Dynamic events; Events detection; Mobility datum; Outlier Detection; Social media; Temporal trends; Time series decomposition; Urban mobility; data set; decomposition analysis; periodicity; spatial variation; temporal variation; time series analysis; urban area; Location},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@ARTICLE{Ayachi2016442,
	author = {Ayachi, Fouaz S. and Nguyen, Hung P. and Lavigne-Pelletier, Catherine and Goubault, Etienne and Boissy, Patrick and Duval, Christian},
	title = {Wavelet-based algorithm for auto-detection of daily living activities of older adults captured by multiple inertial measurement units (IMUs)},
	year = {2016},
	journal = {Physiological Measurement},
	volume = {37},
	number = {3},
	pages = {442 – 461},
	doi = {10.1088/0967-3334/37/3/442},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961196606&doi=10.1088%2f0967-3334%2f37%2f3%2f442&partnerID=40&md5=981e0e8ecbaf3580d8531ae748814eec},
	abstract = {A recent trend in human motion capture is the use of inertial measurement units (IMUs) for monitoring and performance evaluation of mobility in the natural living environment. Although the use of such systems have grown significantly, the development of methods and algorithms to process IMU data for clinical purposes is still limited. The aim of this work is to develop algorithms based on wavelet transform and discrete-time detection of events for the automatic segmentation of tasks related activities of daily living (ADL) from body worn IMUs. Seven healthy older adults (73 ± 4 years old) performed 10 ADL tasks in a simulated apartment during trials of different durations (3, 4, and 5 min). They wore a suit (Synertial UK Ltd IGS-180) comprised of 17 IMUs positioned strategically on body segments to capture full body motion. The proposed method automatically detected the number of template waveforms (representing each movement separately) using discrete wavelet transform (DWT) and discrete-time detection of events based on angular velocity, linear acceleration and 3D orientation data of pertinent IMUs. The sensitivity (Se.) and specificity (Sp.) of detection for the proposed method was established using time stamps of10tasks obtained from visual segmentation of each trial using the video records and the avatar provided by the system's software. At first, we identified six pertinent sensors that were strongly associated to different activities (at most two sensors/task) that allowed detection of tasks with high accuracy. The proposed algorithm exhibited significant global accuracy (N events = 1999, Se. = 97.5%, Sp. = 94%), despite the variation in the occurrences of the performed tasks (free living). The Se. varied from 94% to 100% for all the detected ADL tasks and Sp. ranged from 90% to 100% with the worst Sp. = 85 and 87% for Release-mid (reaching for object held just beyond reach at chest height) and Turning-Left tasks, respectively. This study demonstrated that DWT in conjunction with a nonlinear transform and auto-adaptive thresholding process for decision rules are highly efficient in detecting and segmenting tasks performed during free-living activities. This study also helped to determine the optimal number of sensors, and their location to detect such activities. This work lays the foundation for the automatic assessment of mobility performance within the segmented signals, as well as potentially helps differentiate populations based on their mobility patterns and symptomatology. © 2016 Institute of Physics and Engineering in Medicine.},
	author_keywords = {event detection; IMU; mobility; patient monitoring; signal processing; time series analysis; wavelet},
	keywords = {Accelerometry; Activities of Daily Living; Aged; Algorithms; Female; Humans; Male; Task Performance and Analysis; Walking; Wavelet Analysis; Discrete wavelet transforms; Image segmentation; Patient monitoring; Signal reconstruction; Wearable sensors; Activities of Daily Living; Discrete time; Events detection; Inertial measurements units; Mobility; Older adults; Signal-processing; Time detection; Time-series analysis; Wavelet; accelerometry; aged; algorithm; daily life activity; devices; female; human; male; physiology; task performance; walking; wavelet analysis; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Cordova2017,
	author = {Cordova, Jose and Arghandeh, Reza and Zhou, Yuxun and Wesolowski, Sergiusz and Wu, Wei and Matthias, Stifter},
	title = {Shape-based data analysis for event classification in power systems},
	year = {2017},
	journal = {2017 IEEE Manchester PowerTech, Powertech 2017},
	doi = {10.1109/PTC.2017.7980950},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034760666&doi=10.1109%2fPTC.2017.7980950&partnerID=40&md5=c39cc78da9756a80ac17e5a139d80ecc},
	abstract = {Fault classification in power systems is a challenging and complex task as the variety and variability of the electrical parameters of the various network components in spatial and temporal scales. The majority of machine learning methods for event detection require the labeled data sets or examples of previous events. However, the recorded event data happen in different locations, time and system conditions. Therefore, they are not aligned time-series which introduce more challenges for feature selection and signal processing. To perform better feature selection for time-series measurements, shape-based methods along with time alignment (also called registration) are needed. This paper presents the Fisher-Rao Registration Method (FRMM) as a solution for the alignment of different time signals. Amplitude and phase components resulting from the Fisher-Rao registration method provide a means for implementing a hierarchical clustering analysis classifying different fault events by type. The algorithm was tested with the IEEE 13-nodes test feeder simulated in RSCAD environment with over 1500 different fault events presenting an average prediction rate of 98%. © 2017 IEEE.},
	author_keywords = {Data Mining; Event Detection; Feature Selection; Power Distribution Networks; Shape-based Data Analysis},
	keywords = {Data handling; Data mining; Information analysis; Learning systems; Signal processing; Time series; Electrical parameter; Event detection; Fault classification; Hierarchical clustering analysis; Machine learning methods; Power distribution network; Shape based; Spatial and temporal scale; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Blank201593,
	author = {Blank, Peter and Hoßbach, Julian and Schuldhaus, Dominik and Eskofier, Bjoern M.},
	title = {Sensor-based stroke detection and stroke type classification in table tennis},
	year = {2015},
	journal = {ISWC 2015 - Proceedings of the 2015 ACM International Symposium on Wearable Computers},
	pages = {93 – 100},
	doi = {10.1145/2802083.2802087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960350415&doi=10.1145%2f2802083.2802087&partnerID=40&md5=efe3cc049cba8989fcba4dc642601907},
	abstract = {In this paper we present a sensor-based table tennis stroke detection and classification system. We attached inertial sensors to table tennis rackets and collected data of 8 different basic stroke types from 10 amateur and professional players. Firstly, single strokes were detected by a event detection algorithm. Secondly, features were computed and used as input for stroke type classification. Multiple classifiers were compared regarding classification rates and computational effort. The overall sensitivity of the stroke detection was 95.7% and the best classifier reached a classification rate of 96.7%. Therefore, our presented approach is able to detect table tennis strokes in time-series data and to classify each stroke into correct stroke type categories. The system has the potential to be implemented as an embedded real-time application for other racket sports, to analyze training exercises and competitions, to present match statistics or to support the athletes' training progress. To our knowledge, this is the first paper that addresses a wearable support system for table tennis, and our future work aims at using the presented results to build a complete match analysis system for this sport. © Copyright 2015 ACM.},
	author_keywords = {Inertial sensors; Movement analysis; Stroke detection and classification; Table tennis},
	keywords = {Inertial navigation systems; Wearable computers; Wearable technology; Classification system; Embedded real-time applications; Event detection algorithm; Inertial sensor; Movement analysis; Stroke detection; Table-tennis; Type classifications; Sports},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 59}
}

@ARTICLE{Soulard2016,
	author = {Soulard, Christopher E. and Albano, Christine M. and Villarreal, Miguel L. and Walker, Jessica J.},
	title = {Continuous 1985-2012 Landsat monitoring to assess fire effects on meadows in Yosemite National Park, California},
	year = {2016},
	journal = {Remote Sensing},
	volume = {8},
	number = {5},
	doi = {10.3390/rs8050371},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971419995&doi=10.3390%2frs8050371&partnerID=40&md5=45ed2adb7bc4a886610c9c59e6cbdb23},
	abstract = {To assess how montane meadow vegetation recovered after a wildfire that occurred in Yosemite National Park, CA in 1996, Google Earth Engine image processing was applied to leverage the entire Landsat Thematic Mapper archive from 1985 to 2012. Vegetation greenness (normalized difference vegetation index (NDVI)) was summarized every 16 days across the 28-year Landsat time series for 26 meadows. Disturbance event detection was hindered by the subtle influence of low-severity fire on meadow vegetation. A hard break (August 1996) was identified corresponding to the Ackerson Fire, and monthly composites were used to compare NDVI values and NDVI trends within burned and unburned meadows before, immediately after, and continuously for more than a decade following the fire date. Results indicate that NDVI values were significantly lower at 95% confidence level for burned meadows following the fire date, yet not significantly lower at 95% confidence level in the unburned meadows. Burned meadows continued to exhibit lower monthly NDVI in the dormant season through 2012. Over the entire monitoring period, the negative-trending, dormant season NDVI slopes in the burned meadows were also significantly lower than unburned meadows at 90% confidence level. Lower than average NDVI values and slopes in the dormant season compared to unburned meadows, coupled with photographic evidence, strongly suggest that evergreen vegetation was removed from the periphery of some meadows after the fire. These analyses provide insight into how satellite imagery can be used to monitor low-severity fire effects on meadow vegetation. © 2016 by the authors.},
	author_keywords = {Google Earth Engine; Landsat; Meadow; NDVI; Sierra Nevada; Vegetation change; Wildfire; Yosemite},
	keywords = {Engines; Forestry; Image processing; Satellite imagery; Vegetation; Google earths; LANDSAT; Meadow; NDVI; Sierra Nevada; Vegetation change; Wildfire; Yosemite; Fires},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Vaezi20151896,
	author = {Vaezi, Yoones and van der Baan, Mirko},
	title = {Comparison of the STA/LTA and power spectral density methods for microseismic event detection},
	year = {2015},
	journal = {Geophysical Journal International},
	volume = {203},
	number = {3},
	pages = {1896 – 1908},
	doi = {10.1093/gji/ggv419},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949256576&doi=10.1093%2fgji%2fggv419&partnerID=40&md5=357b4f33705805900c9224bd3a49bf56},
	abstract = {Robust event detection and picking is a prerequisite for reliable (micro-) seismic interpretations. Detection ofweak events is a common challenge among various available event detection algorithms. In this paper we compare the performance of two event detection methods, the short-term average/long-term average (STA/LTA) method, which is the most commonly used technique in industry, and a newly introduced method that is based on the power spectral density (PSD) measurements. We have applied both techniques to a 1-hr long segment of the vertical component of some raw continuous data recorded at a borehole geophone in a hydraulic fracturing experiment. The PSD technique outperforms the STA/LTA technique by detecting a higher number of weak events while keeping the number of false alarms at a reasonable level. The time-frequency representations obtained through the PSD method can also help define a more suitable bandpass filter which is usually required for the STA/LTA method. The method offers thus much promise for automated event detection in industrial, local, regional and global seismological data sets. © The Authors 2015.},
	author_keywords = {Fourier analysis; Time-series analysis},
	keywords = {Bandpass filters; Fourier analysis; Fourier series; Seismology; Spectral density; Time series analysis; Event detection algorithm; Microseismic events; Number of false alarms; Power spectral densities (PSD); Power spectral density method; Seismic interpretation; Time-frequency representations; Vertical component; algorithm; borehole; comparative study; detection method; geophone; hydraulic fracture; seismicity; seismology; time series analysis; Power spectral density},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 79; All Open Access, Bronze Open Access}
}

@CONFERENCE{Schubert2016,
	author = {Schubert, Erich and Weiler, Michael and Kriegel, Hans-Peter},
	title = {SPOTHOT: Scalable detection of geo-spatial events in large textual streams},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {18-20-July-2016},
	doi = {10.1145/2949689.2949699},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982095606&doi=10.1145%2f2949689.2949699&partnerID=40&md5=ce69746f1b4967f83807433e948ec7c1},
	abstract = {The analysis of social media data poses several challenges: first of all, the data sets are very large, secondly they change constantly, and third they are heterogeneous, consisting of text, images, geographic locations and social connections. In this article, we focus on detecting events consisting of text and location information, and introduce an analysis method that is scalable both with respect to volume and velocity. We also address the problems arising from differences in adoption of social media across cultures, languages, and countries in our event detection by efficient normalization. We introduce an algorithm capable of processing vast amounts of data using a scalable online approach based on the SigniTrend event detection system, which is able to identify unusual geo-textual patterns in the data stream without requiring the user to specify any constraints in advance, such as hashtags to track: In contrast to earlier work, we are able to monitor every word at every location with just a fixed amount of memory, compare the values to statistics from earlier data and immediately report significant deviations with minimal delay. Thus, this algorithm is capable of reporting "Breaking News" in real-time. Location is modeled using unsupervised geometric discretization and supervised administrative hierarchies, which permits detecting events at city, regional, and global levels at the same time. The usefulness of the approach is demonstrated using several real-world example use cases using Twitter data. © 2016 ACM.},
	author_keywords = {anomaly detection; bursty topic detection; change detection; geo-social media; Local event detection; online control charts; rich geo-spatial data; scalable realtime data analysis; streaming algorithm; time-series analysis; trend detection},
	keywords = {Information retrieval systems; Location; Management information systems; Media streaming; Signal detection; Social networking (online); Anomaly detection; Bursty topics; Change detection; Event detection; Geo-spatial data; On-line controls; Real-time data; Social media; Streaming algorithm; Trend detection; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Sarkar20155818,
	author = {Sarkar, Soumalya and Damarla, Thyagaraju and Ray, Asok},
	title = {Real-time activity recognition from seismic signature via multi-scale symbolic time series analysis (MSTSA)},
	year = {2015},
	journal = {Proceedings of the American Control Conference},
	volume = {2015-July},
	pages = {5818 – 5823},
	doi = {10.1109/ACC.2015.7172251},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940915411&doi=10.1109%2fACC.2015.7172251&partnerID=40&md5=f5a4fe2815f7a1c6015f7916cfc61a8f},
	abstract = {Reliability of unattended ground sensors (UGS) to detect and classify different activities (e.g., walking and digging) is often limited by high false alarm rates, possibly due to the lack of robustness of the underlying algorithms in different environmental conditions (e.g., soil types and moisture contents for seismic sensors), inability to model large variations in the signature of a single activity and limitations of on-board computation. In this regard, a fast and robust multi-scale symbolic time series analysis (MSTSA) framework has been formulated to detect and classify human activities from seismic signatures. The building block of the proposed framework is built upon the concept of applying the short-length symbolic time-series online classifier (SSTOC) via Dirichlet-Compound-Multinomial model (DCM) construction. The algorithm operates on symbol sequences that are generated from seismic time-series and intermediate event class time-series at different time scales. These building blocks, with different window sizes, are cascaded in multiple layers for event detection and activity classification. A variety of experiments have been conducted in the field, which include realistic scenarios of different types of walking/digging. The results of experiments show that an accuracy of more than 90% and a false alarm of around 5% can be achieved in real time for activity detection and recognition. © 2015 American Automatic Control Council.},
	author_keywords = {Activity Recognition; Multi-scale Time-series Analysis; Pattern Classification; Symbolic Dynamic Filtering; Unattended Ground Sensors},
	keywords = {Errors; Harmonic analysis; Pattern recognition; Seismology; Unattended sensors; Activity classifications; Activity recognition; Different time scale; Environmental conditions; Real-time activity recognition; Symbolic Dynamic Filtering; Symbolic time series analysis; Unattended ground sensors; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{20161,
	title = {27th Australasian Database Conference on Databases Theory and Applications, ADC 2016},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9877 LNCS},
	pages = {1 – 485},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990052937&partnerID=40&md5=484824bd5d85dc62614789b39bc889bc},
	abstract = {The proceedings contain 44 papers. The special focus in this conference is on Social Network, Graphs, Spatial Database, Uncertain Data, Trajectory, Data Mining, Analytics and Miscellaneous. The topics include: Finding influencers in temporal social networks using intervention analysis; comprehensive graph and content feature based user profiling; efficient maximum closeness centrality group identification; continuous maximum visibility query for a moving target; a sketch-first approach for Finding TSP; finding least on-road travel time on road network; an automated tool for building Smartphone indoor navigation system from autocad files; integration of probabilistic information; top-k dominance range-based uncertain queries; adapting ELM to time series classification; prescriptive analytics for big data; topical event detection on twitter; automatic labelling of topics via analysis of user summaries; exploring data mining techniques in medical data streams; virtual samples construction using image-block-stretching for face recognition; effective order preserving estimation method; optimising queue-based semi-stream joins by introducing a queue of frequent pages; exploiting hierarchies for efficient detection of completeness in stream data; a system for efficient processing distance-aware influence maximization; linking news and tweets; classifier hub for imbalanced financial data and an interactive tool for provenance-aware regular path queries on RDF graphs.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang2017624,
	author = {Wang, Kexin and Wei, Yuan and Hou, DIbo and Huang, Pingjie and Yu, Jie and Zhang, Guangxin},
	title = {Contamination Event Detection Method Based on the Longest Common Subsequence Analysis Using Multiple Water Quality Parameters},
	year = {2017},
	journal = {World Environmental and Water Resources Congress 2017: Hydraulics and Waterways and Water Distribution Systems Analysis - Selected Papers from the World Environmental and Water Resources Congress 2017},
	pages = {624 – 636},
	doi = {10.1061/9780784480625.059},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021413516&doi=10.1061%2f9780784480625.059&partnerID=40&md5=60401b98fb9ab62298fe0b921f2d4692},
	abstract = {As the irreplaceable natural resource, water plays an important part in human life. It's necessary to establish of a set of water quality early warning system which can quickly and accurately identify contamination. The existing anomaly detection methods are either simple fusion of abnormal judgment results from single index, or correlation analysis of multiple parameters at the cost of high time complexity. Aimed to solve these problems, this paper describes a multivariate correlation analysis method based on the longest common subsequence (LCSS) analysis combined with Dempster-Shafer (D-S) evidence theory. The proposed method utilizes adaptive sliding window scale to acquire water quality parameter time sequence, LCSS to describe similarity between different water quality series fluctuation, and D-S evidence theory to calculate abnormal probabilities. The ROC curve is introduced to verify the algorithm performance. Tested by data from the laboratory contaminant injection experiment, this approach shows nice ability in dealing with time series deformation problem rapidly, which to a certain extent can improve the reliability of multi-index correlation degree analysis, and ultimately reduce the abnormal water contamination event detection false alarm rate. © ASCE.},
	keywords = {Contamination; Correlation methods; Multivariant analysis; Pollution detection; Quality control; Reliability analysis; Systems analysis; Time series analysis; Water injection; Water pollution; Water quality; Water supply systems; Adaptive sliding windows; Algorithm performance; Anomaly detection methods; Deformation problems; Dempster-Shafer evidence theory; Longest common subsequences; Multivariate correlation; Water quality parameters; Water resources},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Efros201784,
	author = {Efros, Pavel and Buchmann, Erik and Englhardt, Adrian and Böhm, Klemens},
	title = {How to Quantify the Impact of Lossy Transformations on Event Detection},
	year = {2017},
	journal = {Big Data Research},
	volume = {9},
	pages = {84 – 97},
	doi = {10.1016/j.bdr.2017.02.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019476481&doi=10.1016%2fj.bdr.2017.02.001&partnerID=40&md5=cc22dced25f2ba26e0a416941c117df3},
	abstract = {To ease the proliferation of big data, it frequently is transformed, be it by compression, be it by anonymization. Such transformations however modify characteristics of the data. In the case of time series, important characteristics are the occurrence of certain changes or patterns in the data, also referred to as events. Clearly, the less transformations modify events, the better for subsequent analyses. More specifically, the severity of those modifications depends on the application scenario, and quantifying it is far from trivial. In this paper, we propose MILTON, a flexible and robust Measure for quantifying the Impact of Lossy Transformations on subsequent event detectiON. MILTON is applicable to any lossy transformation technique on time-series data and to any general-purpose event-detection approach. We have evaluated it with several real-world use cases. Our evaluation shows that MILTON allows to quantify the impact of lossy transformations and to choose the best one from a class of transformation techniques for a given application scenario. © 2017 Elsevier Inc.},
	author_keywords = {Change detection; Event detection; Lossy transformations; Time series},
	keywords = {Big data; Metadata; Anonymization; Application scenario; Change detection; Detection approach; Events detection; Lossy transformation; Robust measures; Time-series data; Times series; Transformation techniques; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Prasad2018,
	author = {Prasad, Lakshman},
	title = {Multiscale graph-based framework for efficient multi-sensor integration and event detection},
	year = {2018},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {10646},
	doi = {10.1117/12.2304288},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049218882&doi=10.1117%2f12.2304288&partnerID=40&md5=f13da5ea9248ae5978f8197b156e30c3},
	abstract = {We present a general framework for integrating disparate sensors to dynamically detect events. Events are often observed as multiple, asynchronous, disparate sensors' activations in time. The challenge is to reconcile them to infer that a process of interest is underway or has occurred. We abstractly model each sensor as a value-attributed time interval over which it takes values that are relevant to a known process of interest. Process knowledge is incorporated in the detection scheme by defining sensor neighborhood intervals that overlap with temporally neighboring sensor neighborhood intervals in the process. The sensor neighborhoods are represented as nodes of an interval graph, with edges between nodes of overlapping sensor neighborhoods. Sensor activity is then interpreted via this process model by constructing an interval graph time series, for relevant sensor types and process-driven neighborhoods, and looking for subgraphs that match those of the process model graph. A time series that dynamically records the number of sensor neighborhoods overlapping at any given time is used to detect temporal regions of high sensor activity indicative of an event. Multiscale analysis of this time series reveals peaks over different time scales. The peaks are then used to efficiently triage underlying interval subgraphs of sensor activity to examine them for relational patterns similar to the process model graph of interest. Thus, our framework synergistically uses relational as well as scale information to dynamically and efficiently triage sensors related to a process. Multiple processes of interest may be efficiently detected and tracked in parallel using this approach. © 2018 SPIE.},
	author_keywords = {Event detection; feature extraction; graph representation; interval graph; Multi-sensor; multiscale analysis},
	keywords = {Feature extraction; Graphic methods; Signal processing; Time series; Time series analysis; Event detection; Graph representation; Interval graph; Multi scale analysis; Multi sensor; Graph theory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Szczurek2017229,
	author = {Szczurek, Anadrzej and Maciejewska, Monika},
	title = {Detection of occupancy events from indoor air monitoring data},
	year = {2017},
	journal = {Proceedings - 2016 3rd International Conference on Mathematics and Computers in Sciences and in Industry, MCSI 2016},
	pages = {229 – 234},
	doi = {10.1109/MCSI.2016.47},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014183675&doi=10.1109%2fMCSI.2016.47&partnerID=40&md5=a6b25a75a5aa622819e675e4891acfa1},
	abstract = {In recent years, there has been observed an increase of interest in maintaining proper air quality in spaces occupied by people. Various strategies offer to provide the relevant information. In this work we consider attaining it on the basis of indoor air behavior episodes, which are evident from observations or measurements made over a period of time. Initially we focused on the automatic detection of events, which are building blocks of episodes. Events were defined as circumstances when indoor air remained under a fixed influence e.g. from a particular combination of factors affecting it. To reach the objective we applied change point analysis to the time series of a selected indoor air parameter, which was monitored in a continuous manner. There were examined two algorithms of change point detection coupled with the refining criteria, proposed using the domain knowledge. It was demonstrated that change point analysis of CO2 concentration time series allows to distinguish events associated with building use by occupants. ©2016 IEEE.},
	author_keywords = {Carbon dioxide; Change point analysis; Event detection; Indoor air; Time series},
	keywords = {Air quality; Carbon; Carbon dioxide; Time series; Automatic Detection; Building blockes; Change point detection; Change-point analysis; CO2 concentration; Domain knowledge; Event detection; Indoor air; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Buntain2016366,
	author = {Buntain, Cody and Lin, Jimmy and Golbeck, Jennifer},
	title = {Discovering key moments in social media streams},
	year = {2016},
	journal = {2016 13th IEEE Annual Consumer Communications and Networking Conference, CCNC 2016},
	pages = {366 – 374},
	doi = {10.1109/CCNC.2016.7444808},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966667428&doi=10.1109%2fCCNC.2016.7444808&partnerID=40&md5=eec8ece52c97967f1eeb7a7ef4623fd6},
	abstract = {This paper introduces a general technique, called LABurst, for identifying key moments, or moments of high impact, in social media streams without the need for domain-specific information or seed keywords. We leverage machine learning to model temporal patterns around bursts in Twitter's unfiltered public sample stream and build a classifier to identify tokens experiencing these bursts. We show LABurst performs competitively with existing burst detection techniques while simultaneously providing insight into and detection of unanticipated moments. To demonstrate our approach's potential, we compare two baseline event-detection algorithms with our language-agnostic algorithm to detect key moments across three major sporting competitions: 2013 World Series, 2014 Super Bowl, and 2014 World Cup. Our results show LABurst outperforms a time series analysis baseline and is competitive with a domain-specific baseline even though we operate without any domain knowledge. We then go further by transferring LABurst's models learned in the sports domain to the task of identifying earthquakes in Japan and show our method detects large spikes in earthquake-related tokens within two minutes of the actual event. © 2016 IEEE.},
	keywords = {Artificial intelligence; Earthquakes; Geophysics; Learning systems; Media streaming; Telecommunication industry; Time series analysis; Burst detection; Domain knowledge; Domain specific; Domain-specific information; Event detection algorithm; High impact; Sporting competition; Temporal pattern; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@CONFERENCE{Cui2015,
	author = {Cui, Mingjian and Zhang, Jie and Florita, Anthony R. and Hodge, Bri-Mathias and Ke, Deping and Sun, Yuanzhang},
	title = {An optimized swinging door algorithm for wind power ramp event detection},
	year = {2015},
	journal = {IEEE Power and Energy Society General Meeting},
	volume = {2015-September},
	doi = {10.1109/PESGM.2015.7286272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956866160&doi=10.1109%2fPESGM.2015.7286272&partnerID=40&md5=67a3e37de102863ed58d991b70d391b6},
	abstract = {Significant wind power ramp events (WPREs) are those that influence the integration of wind power, and they are a concern to the continued reliable operation of the power grid. As wind power penetration has increased in recent years, so has the importance of wind power ramps. In this paper, an optimized swinging door algorithm (SDA) is developed to improve ramp detection performance. Wind power time series data are segmented by the original SDA, and then all significant ramps are detected and merged through a dynamic programming algorithm. An application of the optimized SDA is provided to ascertain the optimal parameter of the original SDA. Measured wind power data from the Electric Reliability Council of Texas (ERCOT) are used to evaluate the proposed optimized SDA. Results show that the proposed optimized SDA method provided better performance than the L1-Ramp Detect with Sliding Window (L1-SW) method but with significantly less (almost 1,400 seconds less) computational requirements, and it was also used as a baseline to determine the optimal value of the tunable parameter in the original SDA for ramp detection. © 2015 IEEE.},
	author_keywords = {Dynamic programming; ERCOT; sliding window; swinging door algorithm; wind power ramp events},
	keywords = {Algorithms; Wind power; Computational requirements; Dynamic programming algorithm; Electric reliability council of texas; ERCOT; Ramp events; Sliding Window; Swinging door algorithms; Wind power penetration; Dynamic programming},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@ARTICLE{Ni20171623,
	author = {Ni, Ming and He, Qing and Gao, Jing},
	title = {Forecasting the Subway Passenger Flow under Event Occurrences with Social Media},
	year = {2017},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	volume = {18},
	number = {6},
	pages = {1623 – 1632},
	doi = {10.1109/TITS.2016.2611644},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991030419&doi=10.1109%2fTITS.2016.2611644&partnerID=40&md5=7be27e5599c79f2bc5419648900c5f9a},
	abstract = {Subway passenger flow prediction is strategically important in metro transit system management. The prediction under event occurrences turns into a very challenging task. In this paper, we adopt a new kind of data source - social media - to tackle this challenge. We develop a systematic approach to examine social media activities and sense event occurrences. Our initial analysis demonstrates that there exists a moderate positive correlation between passenger flow and the rates of social media posts. This finding motivates us to develop a novel approach for improved flow forecast. We first develop a hashtag-based event detection algorithm. Furthermore, we propose a parametric and convex optimization-based approach, called optimization and prediction with hybrid loss function (OPL), to fuse the linear regression and the results of seasonal autoregressive integrated moving average (SARIMA) model jointly. The OPL hybrid model takes advantage of the unique strengths of linear correlation in social media features and SARIMA model in time series prediction. Experiments on events nearby a subway station show that OPL reports the best forecasting performance compared with other state-of-the-art techniques. In addition, an ensemble model is developed to leverage the weighted results from OPL and support vector machine regression together. As a result, the prediction accuracy and the robustness further increase. © 2000-2011 IEEE.},
	author_keywords = {event identification; Social media; social sensing; subway passenger flow prediction; transit ridership},
	keywords = {Convex optimization; Image retrieval; Railroads; Social networking (online); Subway stations; Subways; Transportation; Event detection algorithm; Forecasting performance; Passenger flow predictions; Positive correlations; Seasonal autoregressive integrated moving averages; State-of-the-art techniques; Support vector machine regressions; Time series prediction; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 148}
}

@ARTICLE{Wang2017172,
	author = {Wang, Zijun and Zhao, Boming},
	title = {Automatic event detection and picking of P, S seismic phases for earthquake early warning and application for the 2008 Wenchuan earthquake},
	year = {2017},
	journal = {Soil Dynamics and Earthquake Engineering},
	volume = {97},
	pages = {172 – 181},
	doi = {10.1016/j.soildyn.2017.03.017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015658654&doi=10.1016%2fj.soildyn.2017.03.017&partnerID=40&md5=472f9a5686c48f43db85eb48f208a9ff},
	abstract = {We proposed a set of high-precision combination algorithms to detect and pick seismic phases for the earthquake early warning (EEW). First by the polarisation analysis of the three-component seismograms, we developed two filters to separate P and S waves for each record through a sliding time window. Then based on the short term average/long term average characteristic function on the polarised traces, an amplification coefficient, in terms of δ, was introduced to be multiplied by the original ratio to sensitively reflect the changes of signals’ amplitude and frequency, where a better detection of the phase arrival was achieved. Next according to the preliminary detections, we used the Akaike information criteria function combined with the higher order statistics to refine the signal and lock on the arrival time with a higher degree of accuracy. We tested our techniques to the main-shock and aftershocks of the Ms 8.0 Wenchuan earthquake, where hundreds of three-component acceleration records over magnitudes of Ms 5.0 were treated. In comparison to the analyst picks, the results of the proposed detection algorithms were shown to perform well and can be applied for the early warning of impending earthquakes occurred with diverse focal mechanisms, complicated propagation process and site effects. © 2017 Elsevier Ltd},
	author_keywords = {Body waves; Earthquake early warning; Phase detection; Time-series analysis; Wenchuan earthquake},
	keywords = {Earthquake effects; Geophysics; Higher order statistics; Seismology; Shear waves; Signal detection; Time series analysis; 2008 wenchuan earthquakes; Akaike information criterion; Amplification coefficient; Body waves; Characteristic functions; Earthquake early warning; Phase detection; Wenchuan Earthquake; aftershock; Akaike information criterion; body wave; early warning system; focal mechanism; P-wave; S-wave; seismogram; Sichuan earthquake 2008; time series analysis; Earthquakes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@ARTICLE{Reynen20171394,
	author = {Reynen, Andrew and Audet, Pascal},
	title = {Supervised machine learning on a network scale: Application to seismic event classification and detection},
	year = {2017},
	journal = {Geophysical Journal International},
	volume = {210},
	number = {3},
	pages = {1394 – 1409},
	doi = {10.1093/gji/ggx238},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023752534&doi=10.1093%2fgji%2fggx238&partnerID=40&md5=60e191ee56cea249b17b5b6f013aa5ea},
	abstract = {A new method using a machine learning technique is applied to event classification anddetection at seismic networks. This method is applicable to a variety of network sizes andsettings. The algorithm makes use of a small catalogue of known observations across theentire network. Two attributes, the polarization and frequency content, are used as input toregression. These attributes are extracted at predicted arrival times for P and Swaves using onlyan approximate velocity model, as attributes are calculated over large time spans. This methodof waveformcharacterization is shown to be able to distinguish between blasts and earthquakeswith 99 per cent accuracy using a network of 13 stations located in Southern California. Thecombination of machine learning with generalized waveform features is further applied toevent detection in Oklahoma, United States. The event detection algorithm makes use of apair of unique seismic phases to locate events, with a precision directly related to the samplingrate of the generalized waveform features. Over a week of data from 30 stations in Oklahoma,United States are used to automatically detect 25 times more events than the catalogue ofthe local geological survey, with a false detection rate of less than 2 per cent. This methodprovides a highly confident way of detecting and locating events. Furthermore, a large numberof seismic events can be automatically detected with low false alarm, allowing for a largerautomatic event catalogue with a high degree of trust. © The Authors 2017. Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Computational seismology; Numerical approximations and analysis; Time-series analysis},
	keywords = {California; Oklahoma [United States]; United States; Artificial intelligence; Education; Learning systems; Seismology; Time series analysis; Computational seismologies; Event classification; Event detection algorithm; Frequency contents; Machine learning techniques; Numerical approximations and analysis; Southern California; Supervised machine learning; algorithm; arrival time; classification; detection method; earthquake catalogue; earthquake event; machine learning; P-wave; S-wave; seismology; time series analysis; waveform analysis; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 56}
}

@CONFERENCE{Lesti2017,
	author = {Lesti, Gordon and Spiegel, Stephan},
	title = {A sliding window filter for time series streams},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {1958},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033700657&partnerID=40&md5=1adf7d4691b58873698fad0f1088c558},
	abstract = {The ever increasing number of sensor-equipped devices comes along with a growing need for data analysis techniques that are able to process time series streams in an online fashion. Although many sensor-equipped devices produce never-ending data streams, most real-world applications merely require high-level information about the presence or absence of certain events that correspond to temporal patterns. Since online event detection is usually computational demanding, we propose a sliding window filter that decreases the time/space complexity and, therefore, allows edge computing on devices with only few resources. Our evaluation for online gesture recognition shows that the developed filtering approach does not only reduce the number of expensive dissimilarity comparison, but also maintains high precision.},
	author_keywords = {Computational Complexity; Internet of Things; Online Event Detection; Sliding Window Technique; Time Series Streams},
	keywords = {Bandpass filters; Computational complexity; Internet of things; Learning systems; Time series; Data analysis techniques; Edge computing; High-level information; On-line fashion; Online event detection; Sliding window techniques; Temporal pattern; Time/space complexity; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wagner20171866,
	author = {Wagner, F. and Tryggvason, A. and Roberts, R. and Lund, B. and Gudmundsson, Ó.},
	title = {Automatic seismic event detection using migration and stacking: A performance and parameter study in Hengill, southwest Iceland},
	year = {2017},
	journal = {Geophysical Journal International},
	volume = {209},
	number = {3},
	pages = {1866 – 1877},
	doi = {10.1093/gji/ggx127},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039960281&doi=10.1093%2fgji%2fggx127&partnerID=40&md5=20cb27b068f1cd669aad584ba0ab2c06},
	abstract = {We investigate the performance of a seismic event detection algorithm using migration and stacking of seismic traces. The focus lies on determining optimal data dependent detection parameters for a data set from a temporary network in the volcanically active Hengill area, southwest Iceland. We test variations of the short-term average to long-term average and Kurtosis functions, calculated from filtered seismic traces, as input data. With optimal detection parameters, our algorithm identified 94 per cent (219 events) of the events detected by the South Iceland Lowlands (SIL) system, that is, the automatic system routinely used on Iceland, as well as a further 209 events, previously missed. The assessed number of incorrect (false) detections was 25 per cent for our algorithm, which was considerably better than that from SIL (40 per cent). Empirical tests show that well-functioning processing parameters can be effectively selected based on analysis of small, representative subsections of data. Our migration approach is more computationally expensive than some alternatives, but not prohibitively so, and it appears well suited to analysis of large swarms of low magnitude events with interevent times on the order of seconds. It is, therefore, an attractive, practical tool for monitoring of natural or anthropogenic seismicity related to, for example, volcanoes, drilling or fluid injection. © The Authors 2017.},
	author_keywords = {Induced seismicity; Numerical solutions; Time-series analysis; Volcano seismology},
	keywords = {Hengill; Iceland; South Iceland Seismic Zone; Induced Seismicity; Time series analysis; Volcanoes; Automatic systems; Fluid injections; Numerical solution; Optimal detection; Parameter studies; Processing parameters; Temporary networks; Volcano seismology; algorithm; earthquake magnitude; earthquake swarm; induced seismicity; seismic data; seismic migration; seismology; stacking; volcano; Seismology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Gosztolya2016232,
	author = {Gosztolya, Gábor},
	title = {Detecting laughter and filler events by time series smoothing with genetic algorithms},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9811 LNCS},
	pages = {232 – 239},
	doi = {10.1007/978-3-319-43958-7_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984791454&doi=10.1007%2f978-3-319-43958-7_27&partnerID=40&md5=65ac3cfb43da10540e452bc6457ee731},
	abstract = {Social signal detection, where the aim is to identify vocalizations like laughter and filler events (sounds like “eh”, “er”, etc.) is a popular task in the area of computational paralinguistics, a subfield of speech technology. Recent studies have shown that besides applying state-of-the-art machine learning methods, it is worth making use of the contextual information and adjusting the frame-level scores based on the local neighbourhood. In this study we apply a weighted average time series smoothing filter for laughter and filler event identification, and set the weights using genetic algorithms. Our results indicate that this is a viable way of improving the Area Under the Curve (AUC) scores: our resulting scores are much better than the accuracy of the raw likelihoods produced by both AdaBoost.MH and DNN, and we also significantly outperform standard time series filters as well. © Springer International Publishing Switzerland 2016.},
	author_keywords = {Genetic algorithms; Laughter and filler event detection; Social signals; Time series filter},
	keywords = {Algorithms; Artificial intelligence; Fillers; Genetic algorithms; Learning systems; Time series; Area under the curves; Contextual information; Event detection; Event identification; Smoothing filters; Social signals; State-of-the-art machine learning methods; Weighted averages; Signal detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Li2016658,
	author = {Li, Ruonan and Liu, Shuming and Smith, Kate and Che, Han},
	title = {A canonical correlation analysis based method for contamination event detection in water sources},
	year = {2016},
	journal = {Environmental Science: Processes and Impacts},
	volume = {18},
	number = {6},
	pages = {658 – 666},
	doi = {10.1039/c6em00108d},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975316851&doi=10.1039%2fc6em00108d&partnerID=40&md5=b2c837ed63cb2e9c8a835a743556fd85},
	abstract = {In this study, a general framework integrating a data-driven estimation model is employed for contamination event detection in water sources. Sequential canonical correlation coefficients are updated in the model using multivariate water quality time series. The proposed method utilizes canonical correlation analysis for studying the interplay between two sets of water quality parameters. The model is assessed by precision, recall and F-measure. The proposed method is tested using data from a laboratory contaminant injection experiment. The proposed method could detect a contamination event 1 minute after the introduction of 1.600 mg l-1 acrylamide solution. With optimized parameter values, the proposed method can correctly detect 97.50% of all contamination events with no false alarms. The robustness of the proposed method can be explained using the Bauer-Fike theorem. © 2016 The Royal Society of Chemistry.},
	keywords = {Environmental Monitoring; Models, Statistical; Water; Water Pollutants, Chemical; Water Pollution, Chemical; Water Quality; Water Supply; acrylamide; nitrate; nitrogen; phosphate; water; water pollutant; Article; conductance; correlation analysis; correlation coefficient; multivariate analysis; pH; priority journal; time series analysis; turbidity; uncertainty; water analysis; water contamination; water quality; water supply; water temperature; analysis; chemistry; environmental monitoring; procedures; statistical model; water pollutant; water pollution; water quality},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Singh201756,
	author = {Singh, Gurdit and Bansal, Divya and Sofat, Sanjeev},
	title = {A smartphone based technique to monitor driving behavior using DTW and crowdsensing},
	year = {2017},
	journal = {Pervasive and Mobile Computing},
	volume = {40},
	pages = {56 – 70},
	doi = {10.1016/j.pmcj.2017.06.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020902179&doi=10.1016%2fj.pmcj.2017.06.003&partnerID=40&md5=232a0978354a4b4d6d10f9d92137f56c},
	abstract = {Safety issues while driving in smart cities are considered to be top-notch priority in contrast to traveling. Today's fast paced society, often leads to accidents. In order to reduce the road accidents, one key area of research is monitoring the driving behavior of drivers. Understanding the driver behavior is an essential component in Intelligent Driver Assistance Systems. One of potential cause of traffic fatalities is aggressive driving behavior. However, drivers are not fully aware of their aggressive actions. So, in order to increase awareness and to promote driver safety, a novel system has been proposed. In this work, we focus on DTW based event detection technique, which have not been researched in motion sensors based time series data to a great extent. Our motivation is to improve the classification accuracy to detect sudden braking and aggressive driving behaviors using sensory data collected from smartphone. A very significant feature of DTW is to be able to automatically cope with time deformations and different speeds associated with time-dependent data which makes it suitable for our chosen application where data might get affected due to factors such as: high variability in road and vehicle conditions, heterogeneous smartphone sensors, etc. Our technique is novel as it uses fusion of sensors to enhance detection accuracy. The experimental results show that proposed algorithm outperforms the existing machine learning and threshold-based techniques with 100% detection rate of braking events and 97% & 86.67% detection rate of normal left & right turns and aggressive left & right turns respectively. © 2017 Elsevier B.V.},
	author_keywords = {Driving behavior; Dynamic Time Warping (DTW); Global Positioning System (GPS); Intelligent Transportation Systems (ITS); Sensor fusion; Smartphone},
	keywords = {Automobile drivers; Global positioning system; Highway accidents; Highway traffic control; Intelligent systems; Intelligent vehicle highway systems; Learning systems; Roads and streets; Smartphones; Aggressive driving behaviors; Classification accuracy; Driving behavior; Dynamic time warping; Intelligent driver assistance systems; Intelligent transportation systems; Sensor fusion; Time-dependent data; Behavioral research},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 50}
}

@CONFERENCE{Hallac2015387,
	author = {Hallac, David and Leskovec, Jure and Boyd, Stephen},
	title = {Network lasso: Clustering and optimization in large graphs},
	year = {2015},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	volume = {2015-August},
	pages = {387 – 396},
	doi = {10.1145/2783258.2783313},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954186214&doi=10.1145%2f2783258.2783313&partnerID=40&md5=c52088f6cbb0a69b36e81e83234b2845},
	abstract = {Convex optimization is an essential tool for modern data analysis, as it provides a framework to formulate and solve many problems in machine learning and data mining. However, general convex optimization solvers do not scale well, and scalable solvers are often specialized to only work on a narrow class of problems. Therefore, there is a need for simple, scalable algorithms that can solve many common optimization problems. In this paper, we introduce the network lasso, a generalization of the group lasso to a network setting that allows for simultaneous clustering and optimization on graphs. We develop an algorithm based on the Alternating Direction Method of Multipliers (ADMM) to solve this problem in a distributed and scalable manner, which allows for guaranteed global convergence even on large graphs. We also examine a non-convex extension of this approach. We then demonstrate that many types of problems can be expressed in our framework. We focus on three in particular - binary classification, predicting housing prices, and event detection in time series data - comparing the network lasso to baseline approaches and showing that it is both a fast and accurate method of solving large optimization problems.},
	author_keywords = {ADMM; Convex optimization; Network lasso},
	keywords = {Artificial intelligence; Convex optimization; Data mining; Housing; Learning systems; Optimization; ADMM; Alternating direction method of multipliers; Binary classification; Global conver-gence; Optimization problems; Optimization solvers; Scalable algorithms; Time-series data; Problem solving},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 181; All Open Access, Green Open Access}
}

@ARTICLE{Zhang20168799,
	author = {Zhang, Xinfeng and Yang, Su and Tang, Yuan Yan and Zhang, Weishan},
	title = {A thermodynamics-inspired feature for anomaly detection on crowd motions in surveillance videos},
	year = {2016},
	journal = {Multimedia Tools and Applications},
	volume = {75},
	number = {14},
	pages = {8799 – 8826},
	doi = {10.1007/s11042-015-3101-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949960069&doi=10.1007%2fs11042-015-3101-8&partnerID=40&md5=f2918fb69d39c4391831f9a9b9730a32},
	abstract = {Identification of abnormal behaviors in surveillance videos of crowds plays an important role in public security monitoring. However, detecting abnormal crowd behaviors is challenging in that movements of individuals are usually random and unpredictable, and the occlusions caused by over-crowding make the task more difficult. In this paper, we introduce thermodynamic micro-statistics theory to detect and localize abnormal behaviors in crowded scenes based on Boltzmann Entropy. For this purpose, the scene of interest is modeled as moving particles turned out from a general optical flow algorithm. The particles are grouped into a set of prototypes according to their speeds and directions of moving, and a histogram is established to figure out how the particles distribute over the prototypes. Here, Boltzmann Entropy is computed from the histogram for each video clip to characterize the chaos degree of crowd motion. By means of such feature extraction, the crowd motion patterns can be represented as a time series. We find that when most people behave anomaly in an area under surveillance, the corresponding entropy value will increase remarkably in comparison with those of normal cases. This motives us to make use of Boltzmann Entropy to distinguish the collective behaviors of people under emergent circumstances from their normal behaviors by evaluating how significantly the current feature value fits into the Gaussian model of normal cases. We validate our method extensively for anomaly detection and localization. The experimental results show promising performance compared with the state of the art methods. © Springer Science+Business Media New York 2015.},
	author_keywords = {Abnormal event detection; Anomaly detection; Boltzmann Entropy; Collective behavior; Crowd},
	keywords = {Entropy; Feature extraction; Graphic methods; Monitoring; Motion analysis; Security systems; Abnormal event detections; Anomaly detection; Boltzmann entropy; Collective behavior; Crowd; Behavioral research},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@CONFERENCE{Alkhamees20171882,
	author = {Alkhamees, Nora and Fasli, Maria},
	title = {Event detection from time-series streams using directional change and dynamic thresholds},
	year = {2017},
	journal = {Proceedings - 2017 IEEE International Conference on Big Data, Big Data 2017},
	volume = {2018-January},
	pages = {1882 – 1891},
	doi = {10.1109/BigData.2017.8258133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047794934&doi=10.1109%2fBigData.2017.8258133&partnerID=40&md5=fd20a2c00aa8046ae4940d5354d4fb0d},
	abstract = {Event Detection from data streams is challenging due to the characteristics of such streams, where data elements arrive in real-time and at high velocity, as well as being streams of unbounded size, even more it is not possible to backtrack over the past arrived data elements or review and keep track of the entire history. Financial time-series streams are a source of financial data (tick data) at fine time scales. In this research, we aim to detect events occurring within time-series streams, and our approach utilises the Directional Change Approach, which summarizes price movements based on a given threshold to detect events. In this paper, we propose a dynamic threshold definition method to be used for detecting the directional change events. The threshold is calculated on a daily basis based on previous day price transitions and the current day opening price. An experiment was run for more than 30 weeks to detect the occurring directional change events on a time-series stream, with one minute data flow levels (one minute frequency) to test our threshold definition method against different fixed threshold values. The detected events were evaluated against news headlines published regarding the studied share on the same day the event was found. The results revealed that a daily dynamic calculated threshold more accurately detected events than different static fixed threshold values. © 2017 IEEE.},
	keywords = {Big data; Financial data processing; Definition method; Directional changes; Dynamic threshold; Event detection; Financial data; Financial time series; Fixed threshold; Price movement; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Bernardi20152019,
	author = {Bernardi, F. and Lomax, A. and Michelini, A. and Lauciani, V. and Piatanesi, A. and Lorito, S.},
	title = {Appraising the Early-est earthquake monitoring system for tsunami alerting at the Italian Candidate Tsunami Service Provider},
	year = {2015},
	journal = {Natural Hazards and Earth System Sciences},
	volume = {15},
	number = {9},
	pages = {2019 – 2036},
	doi = {10.5194/nhess-15-2019-2015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941368648&doi=10.5194%2fnhess-15-2019-2015&partnerID=40&md5=137c1f5a6c2a89970f8a04eba5e6bf01},
	abstract = {In this paper we present and discuss the performance of the procedure for earthquake location and characterization implemented in the Italian Candidate Tsunami Service Provider at the Istituto Nazionale di Geofisica e Vulcanologia (INGV) in Rome. Following the ICG/NEAMTWS guidelines, the first tsunami warning messages are based only on seismic information, i.e., epicenter location, hypocenter depth, and magnitude, which are automatically computed by the software Early-est. Early-est is a package for rapid location and seismic/tsunamigenic characterization of earthquakes. The Early-est software package operates using offline-event or continuous-real-time seismic waveform data to perform trace processing and picking, and, at a regular report interval, phase association, event detection, hypocenter location, and event characterization. Early-est also provides mb, Mwp, and Mwpd magnitude estimations. mb magnitudes are preferred for events with Mwp ≲ 5.8, while Mwpd estimations are valid for events with Mwp ≳ 7.2. In this paper we present the earthquake parameters computed by Early-est between the beginning of March 2012 and the end of December 2014 on a global scale for events with magnitude M ≥ 5.5, and we also present the detection timeline. We compare the earthquake parameters automatically computed by Early-est with the same parameters listed in reference catalogs. Such reference catalogs are manually revised/verified by scientists. The goal of this work is to test the accuracy and reliability of the fully automatic locations provided by Early-est. In our analysis, the epicenter location, hypocenter depth and magnitude parameters do not differ significantly from the values in the reference catalogs. Both mb and Mwp magnitudes show differences to the reference catalogs. We thus derived correction functions in order to minimize the differences and correct biases between our values and the ones from the reference catalogs. Correction of the Mwp distance dependency is particularly relevant, since this magnitude refers to the larger and probably tsunamigenic earthquakes. Mwp values at stations with epicentral distance Δ≲ 30° are significantly overestimated with respect to the CMT-global solutions, whereas Mwp values at stations with epicentral distance &Delta; ≳ 90° are slightly underestimated. After applying such distance correction the Mwp provided by Early-est differs from CMT-global catalog values of about &delta; Mwp 0.0 ∓ 0.2. Early-est continuously acquires time-series data and updates the earthquake source parameters. Our analysis shows that the epicenter coordinates and the magnitude values converge within less than 10 min (5 min in the Mediterranean region) toward the stable values. Our analysis shows that we can compute Mwp magnitudes that do not display short epicentral distance dependency overestimation, and we can provide robust and reliable earthquake source parameters to compile tsunami warning messages within less than 15 min after the event origin time.},
	keywords = {Italy; Lazio; Mediterranean Region; Roma [Lazio]; Rome; earthquake catalogue; earthquake epicenter; earthquake hypocenter; earthquake magnitude; monitoring system; performance assessment; seismic wave; source parameters; tsunami},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Cai20152884,
	author = {Cai, Rui-Chu and Xie, Wei-Hao and Hao, Zhi-Feng and Wang, Li-Juan and Wen, Wen},
	title = {Abnormal crowd detection based on multi-scale recurrent neural network},
	year = {2015},
	journal = {Ruan Jian Xue Bao/Journal of Software},
	volume = {26},
	number = {11},
	pages = {2884 – 2896},
	doi = {10.13328/j.cnki.jos.004893},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948157942&doi=10.13328%2fj.cnki.jos.004893&partnerID=40&md5=f1f4125427223bb7c337d31d19e81397},
	abstract = {Because of the great variations of crowd density and crowd dynamics, as well as the existence of many shelters in scenes, the abnormal crowd event detection and localization are still challenging problems and hot topics of the crowd scene analysis. Based on the spatial-temporal modeling of the crowd scene, this paper proposes an abnormal crowd event detection and localization approach based on multi-scale recurrent neural network. Firstly, the crowd scenes are split into grids and presented using multi-scale histogram of optical flow (MHOF). Then, different grids are connected to obtain a global time series model of the crowd scene. Finally, a multi-scale recurrent neural network is devised to detect and locate the abnormal event on the time series model of the crowd scene. In the multi-scale recurrent neural network, the multi-scale hidden layers are used to model the spatial relation among different scale neighbors, and the feedback loops are used to catch the temporal relation. Extensive experiments demonstrate the effectiveness of the presented approach. © Copyright 2015, Institute of Software, the Chinese Academy of Sciences. All rights reserved.},
	author_keywords = {Abnormal crowd event detection; Multi-scale; Recurrent neural network; Video surveillance},
	keywords = {Multilayer neural networks; Security systems; Time series; Crowd detection; Event detection; Multi-scale; Spatial relations; Spatial temporal model; Temporal relation; Time series modeling; Video surveillance; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Huang201750,
	author = {Huang, Weijing and Wang, Tengjiao and Chen, Wei and Wang, Yazhou},
	title = {Category-Level transfer learning from knowledge base to microblog stream for accurate event detection},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10177 LNCS},
	pages = {50 – 67},
	doi = {10.1007/978-3-319-55753-3_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028448424&doi=10.1007%2f978-3-319-55753-3_4&partnerID=40&md5=12a8289b07b737544f1ba1ad1b5286f7},
	abstract = {Many Web applications need the accurate event detection technique on microblog stream. But the accuracy of existing methods is still challenged by microblog’s short length and high noise. We develop a novel category-level transfer learning method TransDetector to deal with the task. TransDetector bases on two facts, that microblog is short but can be enriched by knowledge base semantically with transfer learning; and events can be detected more accurately on microblogs with richer semantics. The following contributions are made in TransDetector. (1) We propose a structure-guided category-level topics extraction method, which exploits the knowledge base’s hierarchical structure to extract categories’ highly correlated topics. (2)We develop a probabilistic model CTrans-LDA for category-level transfer learning, which utilizes the word co-occurrences and transfers the knowledge base’s category-level topics into microblogs. (3) Events are detected accurately on categorylevel word time series, due to richer semantics and less noise. (4) Experiment verifies the quality of category-level topics extracted from knowledge base, and the further study on the benchmark Edinburgh twitter corpus validates the effectiveness of our proposed transfer learning method for event detection. TransDetector achieves high accuracy, promoting the precision by 9% without sacrificing the recall rate. © Springer International Publishing AG 2017.},
	author_keywords = {Event detection; Knowledge base; Microblog stream; Transfer learning},
	keywords = {Benchmarking; Data mining; Database systems; Learning systems; Semantics; Event detection; Hierarchical structures; Knowledge base; Micro-blog; Probabilistic modeling; Transfer learning; Transfer learning methods; Word co-occurrence; Knowledge based systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Li201752,
	author = {Li, Jiangfeng and Liao, Zhenyu and Zhang, Chenxi and Wang, Jing},
	title = {Event detection on online videos using crowdsourced time-sync comment},
	year = {2017},
	journal = {Proceedings - 2016 7th International Conference on Cloud Computing and Big Data, CCBD 2016},
	pages = {52 – 57},
	doi = {10.1109/CCBD.2016.021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027461715&doi=10.1109%2fCCBD.2016.021&partnerID=40&md5=4e5d337f3d4a6681a1175d4c85ccbe0f},
	abstract = {In recent years, more and more people are like to watch videos online because of its convenience and social features. Due to the limit of entertainment time, there is a new requirement that people prefer to watch some hot video segments rather than an entire video. However, it is a quite time-consuming work to extract the highlight segments in videos manually because the number of videos uploaded to the internet is huge. In this paper, we propose a model of event detection on videos using Time-Sync comments provided by online users. In the model, three features of Time-Sync comments are extracted firstly. Then, user behavior relevance in time series are analyzed to find the video shots that people are interested in most. Metric and its optimization to score video shots for event detection are introduced lastly. Experiments on several movies shows that the events detected by our method coincide with the highlights in the movies. Experiments on movies show that the events detected by our method coincide with the highlights in the movies. © 2016 IEEE.},
	author_keywords = {Crowdsource; Event detection; Time-Sync Comments; Topic model},
	keywords = {Behavioral research; Cloud computing; Crowdsourcing; Motion pictures; Video signal processing; Watches; Event detection; Online users; Online video; Time-Sync Comments; Topic Modeling; User behaviors; Video segments; Video shots; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Fan2016155,
	author = {Fan, Ya Ju and Kamath, Chandrika},
	title = {Detecting ramp events in wind energy generation using affinity evaluation on weather data},
	year = {2016},
	journal = {Statistical Analysis and Data Mining},
	volume = {9},
	number = {3},
	pages = {155 – 173},
	doi = {10.1002/sam.11308},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969820392&doi=10.1002%2fsam.11308&partnerID=40&md5=7005e5341c56ee7cf77839f5b151568f},
	abstract = {Ramp events, which are significant changes in wind generation over a short interval, make it difficult to schedule wind energy on the power grid. Predicting the occurrences of these events can help control room operators ensure that the load and generation on the power grid are in balance at all times. In this paper, we focus on predicting up-ramp events, which are large increases in generation in a short time interval. We propose a novel detection algorithm that uses historical data to detect incoming pre-ramp events, which are defined as the part of the time series that occurs before ramp events. Using wind energy generation data from Bonneville Power Administration in the mid-Columbia Basin region, and weather data from the nearby meteorological towers, we define the concept of affinity of weather data to the preramp events. This is used to identify important weather variables and predict the pre-ramp events. A comparison of our approach with traditional feature selection and classification methods indicates that our method identifies a similar set of features as important and gives better detection accuracy. © 2016 Wiley Periodicals, Inc. Statistical Analysis and Data Mining: The ASA Data Science Journal, 2016 © 2016 Wiley Periodicals, Inc..},
	author_keywords = {Event detection; Optimization models; Sensor streams},
	keywords = {Data mining; Electric power system control; Forecasting; Meteorological instruments; Meteorology; Optimization; Wind power; Bonneville power administrations; Control room operators; Event detection; Feature selection and classification; Meteorological tower; Optimization models; Short time intervals; Wind energy generation; Electric power transmission networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Zhang2016666,
	author = {Zhang, Yuanxun and Debroy, Saptarshi and Calyam, Prasad},
	title = {Network-Wide Anomaly Event Detection and Diagnosis with perfSONAR},
	year = {2016},
	journal = {IEEE Transactions on Network and Service Management},
	volume = {13},
	number = {3},
	pages = {666 – 680},
	doi = {10.1109/TNSM.2016.2546943},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991327536&doi=10.1109%2fTNSM.2016.2546943&partnerID=40&md5=282e110bec393bd20dd8d4ff1cf7c827},
	abstract = {High-performance computing (HPC) environments supporting data-intensive applications need multidomain network performance measurements from open frameworks such as perfSONAR. Detected network-wide correlated anomaly events that impact data throughput performance need to be quickly and accurately notified along with a root-cause analysis for remediation. In this paper, we present a novel network anomaly events detection and diagnosis scheme for network-wide visibility that improves accuracy of root-cause analysis. We address analysis limitations in cases where there is absence of complete network topology information, and when measurement probes are mis-calibrated leading to erroneous diagnosis. Our proposed scheme fuses perfSONAR time-series path measurements data from multiple domains using principal component analysis (PCA) to transform data for accurate correlated and uncorrelated anomaly events detection. We quantify the certainty of such detection using a measurement data sanity checking that involves: 1) measurement data reputation analysis to qualify the measurement samples and 2) filter framework to prune potentially misleading samples. Lastly, using actual perfSONAR one-way delay measurement traces, we show our proposed scheme's effectiveness in diagnosing the root-cause of critical network performance anomaly events. © 2016 IEEE.},
	author_keywords = {Anomaly Event Detection; Multi-domain Network Performance Monitoring; Root-cause Diagnosis Certainty},
	keywords = {Network performance; Time series analysis; Data-intensive application; Event detection; High performance computing (HPC); Multidomain networks; Network anomalies; One way delay measurements; Root cause; Root cause analysis; Principal component analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@BOOK{Cox20171437,
	author = {Cox, Louis Anthony},
	title = {Quantifying and reducing uncertainty about causality in improving public health and safety},
	year = {2017},
	journal = {Handbook of Uncertainty Quantification},
	pages = {1437 – 1499},
	doi = {10.1007/978-3-319-12385-1_71},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034765497&doi=10.1007%2f978-3-319-12385-1_71&partnerID=40&md5=d100b9f04328067af9bb1759e718c129},
	abstract = {Effectively managing uncertain health, safety, and environmental risks requires quantitative methods for quantifying uncertain risks, answering the following questions about them, and characterizing uncertainties about the answers: *Event detection: What has changed recently in disease patterns or other adverse outcomes, by how much, when? *Consequence prediction: What are the implications for what will probably happen next if different actions (or no new actions) are taken? *Risk attribution: What is causing current undesirable outcomes? Does a specific exposure harm human health, and, if so, who is at greatest risk and under what conditions? *Response modeling: What combinations of factors affect health outcomes, and how strongly? How would risks change if one or more of these factors were changed? *Decision making: What actions or interventions will most effectively reduce uncertain health risks? *Retrospective evaluation and accountability: How much difference have exposure reductions actually made in reducing adverse health outcomes? These are all causal questions. They are about the uncertain causal relations between causes, such as exposures, and consequences, such as adverse health outcomes. This chapter reviews advances in quantitative methods for answering them. It recommends integrated application of these advances, which might collectively be called causal analytics, to better assess and manage uncertain risks. It discusses uncertainty quantification and reduction techniques for causal modeling that can help to predict the probable consequences of different policy choices and how to optimize decisions. Methods of causal analytics, including change-point analysis, quasi-experimental studies, causal graph modeling, Bayesian Networks and influence diagrams, Granger causality and transfer entropy methods for time series, and adaptive learning algorithms provide a rich toolkit for using data to assess and improve the performance of risk management efforts by actively discovering what works well and what does not.},
	author_keywords = {Adaptive learning; Bayesian networks (BN); Causal analytics; Causal graph; Causal laws; Change-point analysis (CPA); Counterfactual; DAG model; Directed acyclic graph (DAG); Dynamic bayesian networks (DBN); Ensemble learning algorithms; Evaluation analytics; Granger causality; Influence diagram (ID); Interrupted time series analysis; Intervention analysis; Learning analytics; Marginal structural model (MSM); Model ensembles; Multi-agent influence diagram (MAID); Path analysis; Predictive analytics; Prescriptive analytics; Propensity score; Quasi-experiments (QEs); Simulation; Structural equations model (SEM); Structure discovery; Transfer entropy; Uncertainty analytics},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Andor201742,
	author = {Andor, György and Bohák, András},
	title = {Identifying events in financial time series – A new approach with bipower variation},
	year = {2017},
	journal = {Finance Research Letters},
	volume = {22},
	pages = {42 – 48},
	doi = {10.1016/j.frl.2016.11.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022021162&doi=10.1016%2fj.frl.2016.11.003&partnerID=40&md5=e3c562dcb7628e4a735dd87d9c1286e0},
	abstract = {We present a statistical test to identify significant events in financial price time series. In contrast to “jumps,” we define “events” as non-instantaneous, but nevertheless unusually fast and large, price changes. We show that non-parametric tests perform badly in detecting events so defined. We propose a new approach to explore the dependence of jump detection statistics on the sampling method used and find that our method improves the event detection rate of the standard test by a factor of three. © 2016 Elsevier Inc.},
	author_keywords = {Bipower variation; Event detection; Jump detection; Realized volatility},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Kolchyna2017323,
	author = {Kolchyna, Olga and Souza, Tharsis T.P. and Treleaven, Philip C. and Aste, Tomaso},
	title = {A framework for Twitter events detection, differentiation and its application for retail brands},
	year = {2017},
	journal = {FTC 2016 - Proceedings of Future Technologies Conference},
	pages = {323 – 331},
	doi = {10.1109/FTC.2016.7821630},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013666523&doi=10.1109%2fFTC.2016.7821630&partnerID=40&md5=856f06a0ae7089ca4d991161ed517c7b},
	abstract = {We propose a framework for Twitter events detection, differentiation and quantification of their significance for predicting spikes in sales. In previous approaches, the differentiation between Twitter events has mainly been done based on spatial, temporal or topic information. We suggest a novel approach that performs clustering of Twitter events based on their shapes (taking into account growth and relaxation signatures). Our study provides empirical evidence that through events differentiation based on their shape one can clearly identify clusters of Twitter events that contain more information about future sales than the non-clustered Twitter signal. We also propose a method for automatic identification of the optimum event window, solving a task of window selection, which is a common problem in the event study field. The framework described in this paper was tested on a large-scale dataset of 150 million Tweets and sales data of 75 brands, and can be applied to the analysis of time series from other domains. © 2016 IEEE.},
	author_keywords = {Anomaly detection; clustering; event detection; event study; social media; spikes; Twitter},
	keywords = {Automation; Sales; Time series analysis; Anomaly detection; clustering; Event detection; Event studies; Social media; spikes; Twitter; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Leite2018330,
	author = {Leite, Roger A. and Gschwandtner, Theresia and Miksch, Silvia and Kriglstein, Simone and Pohl, Margit and Gstrein, Erich and Kuntner, Johannes},
	title = {EVA: Visual Analytics to Identify Fraudulent Events},
	year = {2018},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	volume = {24},
	number = {1},
	pages = {330 – 339},
	doi = {10.1109/TVCG.2017.2744758},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029162938&doi=10.1109%2fTVCG.2017.2744758&partnerID=40&md5=f35e9515d00e32566ce22d4dc3403d9a},
	abstract = {Financial institutions are interested in ensuring security and quality for their customers. Banks, for instance, need to identify and stop harmful transactions in a timely manner. In order to detect fraudulent operations, data mining techniques and customer profile analysis are commonly used. However, these approaches are not supported by Visual Analytics techniques yet. Visual Analytics techniques have potential to considerably enhance the knowledge discovery process and increase the detection and prediction accuracy of financial fraud detection systems. Thus, we propose EVA, a Visual Analytics approach for supporting fraud investigation, fine-tuning fraud detection algorithms, and thus, reducing false positive alarms. © 1995-2012 IEEE.},
	author_keywords = {Business and Finance Visualization; Financial Fraud Detection; Time Series Data; Visual Knowledge Discovery},
	keywords = {Crime; Data mining; Data visualization; Finance; Complexity theory; Event detection; Financial fraud detections; Time-series data; Visual analytics; Visual knowledge discovery; Visualization},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45}
}

@CONFERENCE{Mounce2017,
	author = {Mounce, S.R. and Fargus, A. and Weeks, M. and Young, J. and Ejimbe, D. and Goya, E. and Holburn, M. and Jackson, T. and Boxall, J.B.},
	title = {Online advanced uncertain reasoning architecture with binomial event discriminator system for novelty detection in smart water networks},
	year = {2017},
	journal = {CCWI 2017 - 15th International Conference on Computing and Control for the Water Industry},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091596172&partnerID=40&md5=322e650678bf3047dbb0b68a96fc1079},
	abstract = {Minimising the loss of treated water from water supply systems due to bursts is an ongoing issue for water service providers around the world. Sensor technology and the 'big data' they generate combined with machine learning based analytics are providing an opportunity for automated event detection. AURA-Alert has been developed as an online (Software as a Service) system which automates the training data selection (by selecting data with acceptable Match Strength and with regular retraining). The addition of a Binomial Event Discriminator service can produce alerts based on windows of thresholded match distances. A pilot deployment on over 200 live data streams in the cloud has been deployed as part of the SmartWater4Europe project. Examples of analysis for real events are presented. For a historic subset of eight data streams over a three month period up to 58% of bursts were detected (depending on window used for evaluation). It is concluded that the system is an effective and viable tool for novelty detection for water network time series data with potential for wider applicability. Key strengths include lack of per site configuration, data-driven self-learning (from periods of normality), real-time, high scalability and full automation of model retraining. © 2020 CCWI 2017 - 15th International Conference on Computing and Control for the Water Industry. All rights reserved.},
	author_keywords = {Burst detection; Data driven; Neural networks; Online; Smart water networks},
	keywords = {Advanced Analytics; Computer architecture; Discriminators; Learning systems; Software as a service (SaaS); Uncertainty analysis; Water supply; Water supply systems; Water treatment; Advanced uncertain reasoning architectures; Event detection; High scalabilities; Novelty detection; Sensor technologies; Time-series data; Water networks; Water service; Data streams},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Chang2016,
	author = {Chang, C.X. and Wu, W.S. and Wang, W.Y.},
	title = {Automatic microseismic events detection by phase-only correlation},
	year = {2016},
	journal = {78th EAGE Conference and Exhibition 2016: Efficient Use of Technology - Unlocking Potential},
	doi = {10.3997/2214-4609.201600721},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086690239&doi=10.3997%2f2214-4609.201600721&partnerID=40&md5=23165b3ee3cb512fd45cbfc38fd126e5},
	abstract = {Identification and detection of the microseismic events is significant issue in source locations and source mechanism analysis. And due to the large amount of microseismic records and need for rapid field analysis and monitoring, the automatic algorithms are more indispensable. In this study, we introduce an effective method for the identification and detecting of the microseismic events by judging if there is a P-wave phase in local segment from single three-component microseismic records. The new judging algorithm mainly contains following key steps: 1), transform the waveform time series into time-varying spectral representations; 2), detect the similarity of the frequency content in the time-frequency domain using the phase-only correlation function; 3), identify the P-phase by the combination analysis of three-component records. The proposed algorithm is compared to the traditional 1D crosscorrelation of the raw waveform, with a synthetic microseismic datasets and a real field-recorded datasets. The results show that the new algorithm is stable to distinguish the similar waveforms and dissimilar waveforms even for low SNR and emergent events, which is meaningful to select the microseismic events out of a large amount of records accurately and rapidly. It can be applied to some other geophysical analyses based on the waveform data.},
	keywords = {Frequency domain analysis; Seismic waves; Seismology; Time series analysis; Automatic algorithms; Combination analysis; Frequency contents; Geophysical analysis; Microseismic events; Phase-only correlation; Spectral representations; Time frequency domain; Microseismic monitoring},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lavand2016,
	author = {Lavand, S.A. and Gajjar, G.R. and Soman, S.A. and Gajbhiye, R.},
	title = {Mining spatial frequency time series data for event detection in power systems},
	year = {2016},
	journal = {IET Conference Publications},
	volume = {2016},
	number = {CP671},
	doi = {10.1049/cp.2016.0083},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997610728&doi=10.1049%2fcp.2016.0083&partnerID=40&md5=444a4724d37209fd10e26c7c7ffacaad},
	abstract = {In this paper we address the question of automatic event detection and classification. The method proposed can be applied to both, real time streaming data and data stored in a historian. The scheme can classify the type of disturbance as well as identify the time instance of the disturbance. Thus, it will improve the post disturbance analysis. Frequency is a common signal in power system which responds to major power system disturbance like faults, load and generation tripping. A desirable feature of this signal is that under normal condition it is stationary. As such we propose a two step event detection scheme using time series of wide area frequency measurements e.g. from PMUs. We present case studies using historian PMU data from different locations.},
	author_keywords = {Auto event detection; Hodrick-prescott filter; Power swings; Principal component analysis; WAMS},
	keywords = {Electric power system measurement; Filtration; History; Principal component analysis; Time series; Desirable features; Disturbance analysis; Event detection; Frequency measurements; Hodrick-prescott filters; Power swings; Power system disturbances; Real time streaming; Electric power system protection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Hayama20181,
	author = {Hayama, Tessai},
	title = {Detecting TV program highlight scenes using twitter data classified by twitter user behavior},
	year = {2018},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {685},
	pages = {1 – 13},
	doi = {10.1007/978-3-319-70019-9_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037845276&doi=10.1007%2f978-3-319-70019-9_1&partnerID=40&md5=79b496a6de57792042e20014b9ff0427},
	abstract = {This paper presents a novel TV event detection method for automatically generating TV program digests by using Twitter data. Previous studies of TV program digest generation based on Twitter data have developed TV event detection methods that analyze the frequency time series of tweets that users made while watching a given TV program; however, in most of the previous studies, differences in how Twitter is used, e.g., sharing information versus conversing, have not been taken into consideration. Since these different types of Twitter data are lumped together into one category, it is difficult to detect highlight scenes of TV programs and correctly extract their content from the Twitter data. Therefore, this paper presents a highlight scene detection method to automatically generate TV program digests for TV programs based on Twitter data classified by Twitter user behavior. To confirm the effectiveness of the proposed method, experiments using a TV soccer program were conducted. © Springer International Publishing AG 2018.},
	author_keywords = {Highlight-scene detection; Text analysis; TV digest; Twitter data},
	keywords = {Behavioral research; Event detection; Scene detection; Sharing information; Text analysis; TV programs; Twitter data; User behaviors; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wei20161402,
	author = {Wei, Yuan and Feng, Tian-Heng and Huang, Ping-Jie and Hou, Di-Bo and Zhang, Guang-Xin},
	title = {Contamination event detection method based on dynamic correlation analysis of multiple water quality parameters},
	year = {2016},
	journal = {Zhejiang Daxue Xuebao (Gongxue Ban)/Journal of Zhejiang University (Engineering Science)},
	volume = {50},
	number = {7},
	pages = {1402 – 1409},
	doi = {10.3785/j.issn.1008-973X.2016.07.025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979529730&doi=10.3785%2fj.issn.1008-973X.2016.07.025&partnerID=40&md5=ec7394b95b885b2ddcbb9b0e782b1ace},
	abstract = {A multivariate correlation analysis method was proposed by exploring the internal correlation within conventional water quality parameters before and after the occurrence of contamination event in order to improve the performance of the existing water quality anomaly detection methods. The dynamic distance between each two monitored parameters was calculated to define the fluctuation correlation of the two time series by using the dynamic time warping (DTW) method. The correlation coefficient was fused with univariate basic abnormal probability based on D-S evidence theory in order to obtain the fused probability. The synthesis alarm decision was made by comparing the fused probability with the threshold. The proposed method was tested with experimental monitoring data collected from the laboratory pipeline system. Different concentrations of copper sulfate and potassium ferricyanide were separately injected into the pipeline system. Eight conventional monitoring parameters were measured by sensors installed along the pipeline. The collected monitoring data was applied to correlation analysis and probability fusion based on the proposed method. The ROC analysis was introduced to verify the performance and validity of the techniques. © 2016, Zhejiang University Press. All right reserved.},
	author_keywords = {Conventional water parameter; Correlation analysis; Data fusion; Dynamic time warping; Time series analysis; Water quality event detection},
	keywords = {Correlation methods; Data fusion; Monitoring; Multivariant analysis; Pipelines; Piping systems; Pollution detection; Probability; Time series analysis; Water pipelines; Water quality; Anomaly detection methods; Correlation analysis; Correlation coefficient; Dynamic time warping; Event detection; Multivariate correlation; Water parameters; Water quality parameters; Quality control},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Naamnih2018390,
	author = {Naamnih, Jad and Ostfeld, Avi},
	title = {A Time Varying Minimum Volume Ellipsoid (MVE) Method for Water Distribution Systems Event Detection},
	year = {2018},
	journal = {World Environmental and Water Resources Congress 2018: Hydraulics and Waterways, Water Distribution Systems Analysis, and Smart Water - Selected Papers from the World Environmental and Water Resources Congress 2018},
	pages = {390 – 399},
	doi = {10.1061/9780784481424.041},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048870893&doi=10.1061%2f9780784481424.041&partnerID=40&md5=7a75573a951683784730877ad3ea94f0},
	abstract = {Water distribution systems are particularly vulnerable infrastructure systems as they comprise numerous exposed elements which can be deliberately infiltrated or may malfunction. Faults in pump operation, errors in sensors, power outages, cyber-attacks, contamination intrusions, and other abnormal complications harm water distribution systems operation in various ways. Therefore, implementing reliable events detection mechanisms in drinking water systems is vital for ensuring societal welfare. As such, the ability to rapidly detect such occurrences (and their origin) is a foremost objective. In this study a model for detecting abnormal events in water distribution systems using a minimum volume ellipsoid (MVE), adapted through time, is developed and demonstrated. A preliminary step to the ellipsoid finding is the clustering of different observation groups. It may be inaccurate to apply all observations in the same ellipsoid, as there are routine changes in water parameters. Applying some seasonal adjustments for example, is essential. Pattern recognition can help characterize typical behaviors of a time series. For example, water temperature rises in 2-3 degrees around 10 am, or increases in chloramine concentration don't last more than 10 minutes. Such characteristics may help define more appropriate ellipsoids for each time step thus generate a more sensitive model. The proposed method repeatedly constructs an MVE and modifies its structure according to new measurements and recorded events. The method is demonstrated on an example application through base runs and sensitivity analyses using hourly consumptions, flows, and pressures. © 2018 American Society of Civil Engineers.},
	keywords = {Hydraulics; Network security; Outages; Pattern recognition; Potable water; Sensitivity analysis; Systems analysis; Water distribution systems; Drinking water systems; Event detection; Events detection; Infrastructure systems; Minimum volume ellipsoids; Seasonal adjustments; Water parameters; Water temperatures; Water resources},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xu2017487,
	author = {Xu, Wei and Liu, Lingyu and Shang, Wei},
	title = {Leveraging cross-media analytics to detect events and mine opinions for emergency management},
	year = {2017},
	journal = {Online Information Review},
	volume = {41},
	number = {4},
	pages = {487 – 506},
	doi = {10.1108/OIR-08-2015-0286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027462146&doi=10.1108%2fOIR-08-2015-0286&partnerID=40&md5=2ab3e800ea4c62f4ce3b032c642a8357},
	abstract = {Purpose: Timely detection of emergency events and effective tracking of corresponding public opinions are critical in emergency management. As media are immediate sources of information on emergencies, the purpose of this paper is to propose cross-media analytics to detect and track emergency events and provide decision support for government and emergency management departments. Design/methodology/approach: In this paper, a novel emergency event detection and opinion mining method is proposed for emergency management using cross-media analytics. In the proposed approach, an event detection module is constructed to discover emergency events based on cross-media analytics, and after the detected event is confirmed as an emergency event, an opinion mining module is used to analyze public sentiments and then generate public sentiment time series for early warning via a semantic expansion technique. Findings: Empirical results indicate that a specific emergency can be detected and that public opinion can be tracked effectively and efficiently using cross-media analytics. In addition, the proposed system can be used for decision support and real-time response for government and emergency management departments. Research limitations/implications: This paper takes full advantage of cross-media information and proposes novel emergency event detection and opinion mining methods for emergency management using cross-media analytics. The empirical analysis results illustrate the efficiency of the proposed method. Practical implications: The proposed method can be applied for detection of emergency events and tracking of public opinions for emergency decision support and governmental real-time response. Originality/value: This research work contributes to the design of a decision support system for emergency event detection and opinion mining. In the proposed approaches, emergency events are detected by leveraging cross-media analytics, and public sentiments are measured using an auto-expansion of the domain dictionary in the field of emergency management to eliminate the misclassification of the general dictionary and to make the quantization more accurate. © Emerald Publishing Limited.},
	author_keywords = {Cross-media analytics; Emergence management; Event detection; Opinion mining; Semantic expansion},
	keywords = {Artificial intelligence; Civil defense; Data mining; Decision making; Decision support systems; Disasters; Industrial management; Mining; Risk management; Semantics; Social aspects; Cross-media; Design/methodology/approach; Emergency decision support; Emergency management; Event detection; Opinion mining; Semantic expansion; Sources of informations; decision support system; emergency; government; mining; public opinion; time series analysis; Emergency services},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Dao20152690,
	author = {Dao, Minh-Son and Zettsu, Koji and Pongpaichet, Siripen and Jalali, Laleh and Jain, Ramesh},
	title = {Exploring spatio-temporal-theme correlation between physical and social streaming data for event detection and pattern interpretation from heterogeneous sensors},
	year = {2015},
	journal = {Proceedings - 2015 IEEE International Conference on Big Data, IEEE Big Data 2015},
	pages = {2690 – 2699},
	doi = {10.1109/BigData.2015.7364069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963756618&doi=10.1109%2fBigData.2015.7364069&partnerID=40&md5=6b5ee58fce82b279e21a7e358e31d129},
	abstract = {In this paper, we introduce a new method that explores spatio-temporal-theme correlations between physical and social streaming data for event detection and pattern interpretation from heterogeneous sensors. Particularly, we employ a basic two-phase framework in pattern recognition (i.e. feature extraction and detection) with the novel improvement that concerns the use of semantic information acquired from social sensors to automatically label the low-level features extracted from physical sensors. Moreover, by symbolizing the trend component of time-series data, the proposed method has an ability to interpret event's patterns to help users get insights of how events happen. Differentiating from conventional supervised learning methods whose training data are labeled manually and in an off-line mode, the proposed method can collect labels for training data automatically and in an on-line mode. Moreover, after running for a certain time, a training stage can run parallel with the detecting stage when an event model is totally built. After that, the training stage continues learning to increase the accuracy of the event model by nonstop collecting new samples with labels from streaming data. The problem of environmental factors and particularly air pollution impacts on asthma exacerbation is considered for evaluating the proposed method. The experimental results show that the proposed method can probably detect the prevalence of asthma risks in a specific spatio-temporal context as well as help users understand how a change in the surrounding environment (e.g. weather condition and air pollution) can influence their health (e.g. asthma attack) by interpreting detected event's patterns. © 2015 IEEE.},
	author_keywords = {Data Mining; Event Detection; Health Care; Pattern Interpretation; Spatio-Temporal-Theme Correlation},
	keywords = {Air pollution; Data mining; Diseases; Feature extraction; Health care; Health risks; Pattern recognition; Pollution; Semantics; Air pollution impact; Environmental factors; Event detection; Heterogeneous sensors; Pattern Interpretation; Spatio temporal; Supervised learning methods; Surrounding environment; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Crochemore20171573,
	author = {Crochemore, Louise and Ramos, Maria-Helena and Pappenberger, Florian and Perrin, Charles},
	title = {Seasonal streamflow forecasting by conditioning climatology with precipitation indices},
	year = {2017},
	journal = {Hydrology and Earth System Sciences},
	volume = {21},
	number = {3},
	pages = {1573 – 1591},
	doi = {10.5194/hess-21-1573-2017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015438450&doi=10.5194%2fhess-21-1573-2017&partnerID=40&md5=cd519fbb87565d46a8d00d6bf28835e9},
	abstract = {Many fields, such as drought-risk assessment or reservoir management, can benefit from long-range streamflow forecasts. Climatology has long been used in long-range streamflow forecasting. Conditioning methods have been proposed to select or weight relevant historical time series from climatology. They are often based on general circulation model (GCM) outputs that are specific to the forecast date due to the initialisation of GCMs on current conditions. This study investigates the impact of conditioning methods on the performance of seasonal streamflow forecasts. Four conditioning statistics based on seasonal forecasts of cumulative precipitation and the standardised precipitation index were used to select relevant traces within historical streamflows and precipitation respectively. This resulted in eight conditioned streamflow forecast scenarios. These scenarios were compared to the climatology of historical streamflows, the ensemble streamflow prediction approach and the streamflow forecasts obtained from ECMWF System 4 precipitation forecasts. The impact of conditioning was assessed in terms of forecast sharpness (spread), reliability, overall performance and low-flow event detection. Results showed that conditioning past observations on seasonal precipitation indices generally improves forecast sharpness, but may reduce reliability, with respect to climatology. Conversely, conditioned ensembles were more reliable but less sharp than streamflow forecasts derived from System 4 precipitation. Forecast attributes from conditioned and unconditioned ensembles are illustrated for a case of drought-risk forecasting: the 2003 drought in France. In the case of low-flow forecasting, conditioning results in ensembles that can better assess weekly deficit volumes and durations over a wider range of lead times. © Author(s) 2017.},
	keywords = {France; Climatology; Drought; Reservoir management; Risk assessment; Stream flow; Weather forecasting; Cumulative precipitation; General circulation model; Precipitation forecast; Precipitation indices; Seasonal precipitations; Streamflow forecast; Streamflow forecasting; Streamflow prediction; climatology; drought; forecasting method; general circulation model; low flow; precipitation assessment; seasonality; streamflow; Forecasting},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{20161,
	title = {15th International Symposium on Advances in Intelligent Data Analysis, IDA 2016},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9897 LNCS},
	pages = {1 – 403},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990050953&partnerID=40&md5=0f2fa94917877739fd4b08cf1ed2a403},
	abstract = {The proceedings contain 36 papers. The special focus in this conference is on Advances in Intelligent Data Analysis. The topics include: A practical language modeling approach for time series classification; ranking accuracy for Logistic-GEE models; the morality machine; tracking moral values in tweets; a hybrid approach for probabilistic relational models structure learning; on the impact of data set size in transfer learning using deep neural networks; obtaining shape descriptors from a concave hull-based clustering algorithm; visual perception of discriminative landmarks in classified time series; spotting the diffusion of new psychoactive substances over the internet; feature selection issues in long-term travel time prediction; online semi-supervised learning for multi-target regression in data streams using AMRules; a toolkit for analysis of deep learning experiments; the optimistic method for model estimation; learning from the news; predicting entity popularity on twitter; estimating sequence similarity from read sets for clustering sequencing data; widened learning of Bayesian network classifiers; vote buying detection via independent component analysis; a framework for interpolating scattered data using space-filling curves; privacy-awareness of distributed data clustering algorithms revisited; bi-stochastic matrix approximation framework for data co-clustering; sequential cost-sensitive feature acquisition; anomaly detection and explanation in dynamic graphs; similarity based hierarchical clustering with an application to text collections; determining data relevance using semantic types and graphical interpretation cues and stability evaluation of event detection techniques for twitter.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Batal2016115,
	author = {Batal, Iyad and Cooper, Gregory F. and Fradkin, Dmitriy and Harrison, James and Moerchen, Fabian and Hauskrecht, Milos},
	title = {An efficient pattern mining approach for event detection in multivariate temporal data},
	year = {2016},
	journal = {Knowledge and Information Systems},
	volume = {46},
	number = {1},
	pages = {115 – 150},
	doi = {10.1007/s10115-015-0819-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952717438&doi=10.1007%2fs10115-015-0819-6&partnerID=40&md5=78f0159be98afdec9917f8af2326af8e},
	abstract = {This work proposes a pattern mining approach to learn event detection models from complex multivariate temporal data, such as electronic health records. We present recent temporal pattern mining, a novel approach for efficiently finding predictive patterns for event detection problems. This approach first converts the time series data into time-interval sequences of temporal abstractions. It then constructs more complex time-interval patterns backward in time using temporal operators. We also present the minimal predictive recent temporal patterns framework for selecting a small set of predictive and non-spurious patterns. We apply our methods for predicting adverse medical events in real-world clinical data. The results demonstrate the benefits of our methods in learning accurate event detection models, which is a key step for developing intelligent patient monitoring and decision support systems. © 2015, Springer-Verlag London.},
	author_keywords = {Electronic health records; Event detection; Recent temporal patterns; Temporal abstractions; Temporal data mining; Time-interval patterns},
	keywords = {Decision support systems; Patient monitoring; Pattern recognition; Records management; Electronic health record; Event detection; Temporal abstraction; Temporal data mining; Temporal pattern; Time-interval patterns; Data mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Green Open Access}
}

@CONFERENCE{Szczurek2017,
	author = {Szczurek, Andrzej and Maciejewska, Monika and Uchroński, Mariusz},
	title = {Detection of comfortable temperature based on thermal events detection indoors},
	year = {2017},
	journal = {E3S Web of Conferences},
	volume = {22},
	doi = {10.1051/e3sconf/20172200172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034451210&doi=10.1051%2fe3sconf%2f20172200172&partnerID=40&md5=5760c545014f4fca82dee0f5ed4ef0d7},
	abstract = {This work focussed on thermal comfort as the basis to control indoor conditions. Its objective is a method to determine thermal preferences of office occupants. The method is based on detection of thermal events. They occur when indoor conditions are under control of occupants. Thermal events are associated with the use of local heating/cooling sources which have user-adjustable settings. The detection is based on Fourier analysis of indoor temperature time series. The relevant data is collected by temperature sensor. We achieved thermal events recognition rate of 86 %. Conditions when indoor conditions were beyond control were detected with 95.6 % success rate. Using experimental data it was demonstrated that the method allows to reproduce key elements of temperature statistics associated with conditions when occupants are in control of thermal comfort. © The Authors, published by EDP Sciences, 2017.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kapucu2016,
	author = {Kapucu, Fikret E. and Välkki, Inkeri and Mikkonen, Jarno E. and Leone, Chiara and Lenk, Kerstin and Tanskanen, Jarno M. A. and Hyttinen, Jari A. K.},
	title = {Spectral entropy based neuronal network synchronization analysis based on microelectrode array measurements},
	year = {2016},
	journal = {Frontiers in Computational Neuroscience},
	volume = {10},
	number = {OCT},
	doi = {10.3389/fncom.2016.00112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053361647&doi=10.3389%2ffncom.2016.00112&partnerID=40&md5=3d03b3e70016edc1dd9ee6c4d0332df8},
	abstract = {Synchrony and asynchrony are essential aspects of the functioning of interconnected neuronal cells and networks. New information on neuronal synchronization can be expected to aid in understanding these systems. Synchronization provides insight in the functional connectivity and the spatial distribution of the information processing in the networks. Synchronization is generally studied with time domain analysis of neuronal events, or using direct frequency spectrum analysis, e.g., in specific frequency bands. However, these methods have their pitfalls. Thus, we have previously proposed a method to analyze temporal changes in the complexity of the frequency of signals originating from different network regions. The method is based on the correlation of time varying spectral entropies (SEs). SE assesses the regularity, or complexity, of a time series by quantifying the uniformity of the frequency spectrum distribution. It has been previously employed, e.g., in electroencephalogram analysis. Here, we revisit our correlated spectral entropy method (CorSE), providing evidence of its justification, usability, and benefits. Here, CorSE is assessed with simulations and in vitro microelectrode array (MEA) data. CorSE is first demonstrated with a specifically tailored toy simulation to illustrate how it can identify synchronized populations. To provide a form of validation, the method was tested with simulated data from integrate-and-fire model based computational neuronal networks. To demonstrate the analysis of real data, CorSE was applied on in vitro MEA data measured from rat cortical cell cultures, and the results were compared with three known event based synchronization measures. Finally, we show the usability by tracking the development of networks in dissociated mouse cortical cell cultures. The results show that temporal correlations in frequency spectrum distributions reflect the network relations of neuronal populations. In the simulated data, CorSE unraveled the synchronizations. With the real in vitro MEA data, CorSE produced biologically plausible results. Since CorSE analyses continuous data, it is not affected by possibly poor spike or other event detection quality. We conclude that CorSE can reveal neuronal network synchronization based on in vitro MEA field potential measurements. CorSE is expected to be equally applicable also in the analysis of corresponding in vivo and ex vivo data analysis. © 2016 Kapucu, Välkki, Mikkonen, Leone, Lenk, Tanskanen and Hyttinen.},
	author_keywords = {Correlation; Developing neuronal networks; MEA; Microelectrode array; Mouse cortical cells; Rat cortical cells; Spectral entropy; Synchronization},
	keywords = {Cell culture; Cells; Complex networks; Correlation methods; Frequency domain analysis; Microelectrodes; Neurons; Rats; Spectroscopy; Spectrum analysis; Synchronization; Time domain analysis; Cortical cells; Electroencephalogram analysis; Event-based synchronization; Frequency spectrum analysis; Integrate-and-fire model; Microelectrode array; Neuronal networks; Spectral entropy; action potential amplitude; animal cell; Article; connectome; controlled study; correlated spectral entropy; cortical synchronization; entropy; firing rate; in vitro study; local field potential; microelectrode; mouse; nerve cell membrane potential; nerve cell network; nonhuman; oscillation; rat; signal noise ratio; spectroscopy; spike wave; validation process; Neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Krumm2015,
	author = {Krumm, John and Horvitz, Eric},
	title = {Eyewitness: Identifying local events via space-time signals in Twitter feeds},
	year = {2015},
	journal = {GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems},
	volume = {03-06-November-2015},
	doi = {10.1145/2820783.2820801},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961198026&doi=10.1145%2f2820783.2820801&partnerID=40&md5=c24f1722ddbf3ed5a25c37ec20dd498e},
	abstract = {We present a methodology for automatically extracting and summarizing reports of significant local events from large-scale Twitter feeds. While previous work has relied on an analysis of tweet text to identify local events, we show how to reliably detect events using only time series analysis of geotagged tweet volumes from localized regions. The algorithm sweeps through different spatial and temporal resolutions and finds events as anomalous spikes in the rate of geotagged tweets. We applied the approach to a corpus of over 733 million geotagged tweets. Using a panel of 103 crowdsourced judges who tagged 2400 detected events, we achieved a local event detection precision of 70%. Using these judged events as ground truth, a decision tree classifier was able to raise the detection precision to 93%. © 2015 ACM.},
	author_keywords = {Local events; Microblog; Twitter},
	keywords = {Decision trees; Geographic information systems; Information systems; Social networking (online); Decision tree classifiers; Detection precision; Event detection; Local events; Micro-blog; Space-time signals; Spatial and temporal resolutions; Twitter; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49}
}

@ARTICLE{Saeed2018534,
	author = {Saeed, Zafar and Abbasi, Rabeeh Ayaz and Sadaf, Abida and Razzak, Muhammad Imran and Xu, Guandong},
	title = {Text stream to temporal network - A dynamic heartbeat graph to detect emerging events on twitter},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10938 LNAI},
	pages = {534 – 545},
	doi = {10.1007/978-3-319-93037-4_42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049376201&doi=10.1007%2f978-3-319-93037-4_42&partnerID=40&md5=5eed73ed262b9098f1494fdf3fe8d182},
	abstract = {Huge mounds of data are generated every second on the Internet. People around the globe publish and share information related to real-world events they experience every day. This provides a valuable opportunity to analyze the content of this information to detect real-world happenings, however, it is quite challenging task. In this work, we propose a novel graph-based approach named the Dynamic Heartbeat Graph (DHG) that not only detects the events at an early stage, but also suppresses them in the upcoming adjacent data stream in order to highlight new emerging events. This characteristic makes the proposed method interesting and efficient in finding emerging events and related topics. The experiment results on real-world datasets (i.e. FA Cup Final and Super Tuesday 2012) show a considerable improvement in most cases, while time complexity remains very attractive. © 2018, Springer International Publishing AG, part of Springer Nature.},
	author_keywords = {Big data; Dynamic graph; Emerging trend; Event detection; Text stream; Time series analysis},
	keywords = {Data mining; Graphic methods; Time series analysis; Dynamic graph; Emerging trends; Event detection; Graph-based; Real-world datasets; Temporal networks; Text streams; Time complexity; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Green Open Access}
}

@ARTICLE{Patri2016461,
	author = {Patri, Om Prasad and Panangadan, Anand V. and Sorathia, Vikrambhai S. and Prasanna, Viktor K.},
	title = {Sensors to Events: Semantic Modeling and Recognition of Events from Data Streams},
	year = {2016},
	journal = {International Journal of Semantic Computing},
	volume = {10},
	number = {4},
	pages = {461 – 501},
	doi = {10.1142/S1793351X16400171},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048543122&doi=10.1142%2fS1793351X16400171&partnerID=40&md5=58c0286d5bec08505694e861f7453d88},
	abstract = {Detecting and responding to real-world events is an integral part of any enterprise or organization, but Semantic Computing has been largely underutilized for complex event processing (CEP) applications. A primary reason for this gap is the difference in the level of abstraction between the high-level semantic models for events and the low-level raw data values received from sensor data streams. In this work, we investigate the need for Semantic Computing in various aspects of CEP, and intend to bridge this gap by utilizing recent advances in time series analytics and machine learning. We build upon the Process-oriented Event Model, which provides a formal approach to model real-world objects and events, and specifies the process of moving from sensors to events. We extend this model to facilitate Semantic Computing and time series data mining directly over the sensor data, which provides the advantage of automatically learning the required background knowledge without domain expertise. We illustrate the expressive power of our model in case studies from diverse applications, with particular emphasis on non-intrusive load monitoring in smart energy grids. We also demonstrate that this powerful semantic representation is still highly accurate and performs at par with existing approaches for event detection and classification. © 2016 World Scientific Publishing Company.},
	author_keywords = {event ontology; Event stream processing; information integration; non-intrusive load monitoring; temporal pattern mining; time series shapelets},
	keywords = {Data mining; Semantics; Time series; Event ontology; Event stream processing; Information integration; Nonintrusive load monitoring; Shapelets; Temporal pattern minings; Learning systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Zhang2017157,
	author = {Zhang, Ruibin and Yang, Chi and Pang, Shaoning and Sarrafzadeh, Hossein},
	title = {UnitecDEAMP: Flow feature profiling for malicious events identification in darknet space},
	year = {2017},
	journal = {Communications in Computer and Information Science},
	volume = {719},
	pages = {157 – 168},
	doi = {10.1007/978-981-10-5421-1_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022221371&doi=10.1007%2f978-981-10-5421-1_13&partnerID=40&md5=edd02a504d3a3cfa9993b7e822bf385f},
	abstract = {This paper proposes a traffic decomposition approach called UnitecDEAMP based on flow feature profiling to distinct groups of significant malicious events from background noise in massive historical darknet traffic. Specifically, we segment and extract traffic flows from captured darknet data, categorize the flows according to sets of criteria derived from our traffic behavior assessments. Those criteria will be validated through the followed correlation analysis to guarantee that any redundant criteria be eliminated. Significant events are appraised by combined criteria filtering, including significance regarding volume, significance in terms of time series occurrence and significance regarding variation. To demonstrate the effectiveness of our UnitecDEAMP, real world darknet traffic data sets with twelve months are used for conducting our empirical study. The experimental results show that UnitecDEAMP can effectively select the most significant malicious events. © Springer Nature Singapore Pte Ltd. 2017.},
	author_keywords = {Cyber threats; Darknet traffic analysis; Flow feature profiling; Malicious event detection; Malicious traffic flow identification},
	keywords = {Security of data; Cyber threats; Event detection; Flow features; Malicious traffic; Traffic analysis; Traffic surveys},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Barz20171,
	author = {Barz, Bjorn and Garcia, Yanira Guanche and Rodner, Erik and Denzler, Joachim},
	title = {Maximally divergent intervals for extreme weather event detection},
	year = {2017},
	journal = {OCEANS 2017 - Aberdeen},
	volume = {2017-October},
	pages = {1 – 9},
	doi = {10.1109/OCEANSE.2017.8084569},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044601925&doi=10.1109%2fOCEANSE.2017.8084569&partnerID=40&md5=b3d8520d7a565475070b46435f1c3e17},
	abstract = {We approach the task of detecting anomalous or extreme events in multivariate spatio-temporal climate data using an unsupervised machine learning algorithm for detection of anomalous intervals in time-series. In contrast to many existing algorithms for outlier and anomaly detection, our method does not search for point-wise anomalies, but for contiguous anomalous intervals. We demonstrate the suitability of our approach through numerous experiments on climate data, including detection of hurricanes, North Sea storms, and low-pressure fields. © 2017 IEEE.},
	keywords = {Learning systems; Anomalous intervals; Anomaly detection; Climate data; Extreme events; Extreme weather events; Low pressures; Spatio temporal; Unsupervised machine learning; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Shahriar2015,
	author = {Shahriar, Md. Sumon and Smith, Daniel and Rahman, Ashfaqur and Henry, Dave and Bishop-Hurley, Greg and Rawnsley, Richard and Freeman, Mark and Hills, James},
	title = {Heat event detection in dairy cows with collar sensors: An unsupervised machine learning approach},
	year = {2015},
	journal = {2015 IEEE SENSORS - Proceedings},
	doi = {10.1109/ICSENS.2015.7370528},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963596899&doi=10.1109%2fICSENS.2015.7370528&partnerID=40&md5=14836f0172d1a65e4ababfb32f172f83},
	abstract = {The detection of heat (estrus) events in pasture-based dairy cows fitted with on-animal sensors was investigated using an unsupervised learning. Accelerometer data from the cow collar sensors were used in this approach where the aim was to identify increased activity level (restlessness, increased walking for mating) and to find association with recorded heat events. High dimensional time series data from accelerometers were first segmented in windows followed by feature extractions. The extracted features are standard deviation, amplitude, energy and Fast Fourier Transform (FFT). K-means clustering algorithm was then applied across the windows for grouping. The groups were labeled in terms of activity intensities: high, medium and low. An activity index level (AIxL) was derived from the activity intensity labels. We compared the AIxL with recorded heat events and observed significant associations between the increased activities through high AIxL values and the observed heat events. © 2015 IEEE.},
	keywords = {Accelerometers; Artificial intelligence; Fast Fourier transforms; Learning systems; Accelerometer data; Activity intensities; Activity levels; High-dimensional; K-Means clustering algorithm; Standard deviation; Time-series data; Unsupervised machine learning; Clustering algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Kužnar2017,
	author = {Kužnar, Damjan and Piltaver, Rok and Gradišek, Anton and Gams, Matjaž and Luštrek, Mitja},
	title = {An intelligent system to monitor refrigeration devices},
	year = {2017},
	journal = {Expert Systems},
	volume = {34},
	number = {5},
	doi = {10.1111/exsy.12199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023621330&doi=10.1111%2fexsy.12199&partnerID=40&md5=383318bec29634f71d8f2d8d8204278d},
	abstract = {Refrigeration systems have been a vital component of our lives for more than a century. Apart from storing food, they are used to store sensitive goods such as pharmaceutical products or reactive chemicals. The deterioration of the refrigeration system performance due to aging or malfunction directly affects the quality of stored goods. Therefore, an early detection of deviation in performance is an important task. This paper presents a system that monitors operation of refrigeration devices and alerts the user to possible irregularities in the operation run. The emphasis is on recognition of gradual changes of performance that indicate upcoming hardware problems. The system consists of 2 modules: human-defined expert rules and machine learning. The machine-learning module learns to recognize abnormal behaviour of devices automatically. Furthermore, it can distinguish between different abnormal events and allow the user to classify some of the types as normal, so that they not longer raise an alarm. The machine learning was evaluated by comparing its recognition of abnormal events and classification accuracy of such events to the performance of a human operator. The system can in principle be adapted to any electronic device that periodically applies some system for sustaining a predefined quality (e.g., temperature). Copyright © 2017 John Wiley & Sons, Ltd.},
	author_keywords = {event classification; event detection; intelligent systems; machine learning; refrigeration devices; time series},
	keywords = {Artificial intelligence; Chemical contamination; Education; Electron devices; Intelligent systems; Learning systems; Refrigeration; Time series; Abnormal behaviours; Classification accuracy; Event classification; Event detection; Machine learning module; Pharmaceutical products; Refrigeration devices; Refrigeration system; Monitoring},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Patri2016430,
	author = {Patri, Om Prasad},
	title = {Doctoral symposium: Modeling and recognition of events from multidimensional data},
	year = {2016},
	journal = {DEBS 2016 - Proceedings of the 10th ACM International Conference on Distributed and Event-Based Systems},
	pages = {430 – 433},
	doi = {10.1145/2933267.2933434},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978698100&doi=10.1145%2f2933267.2933434&partnerID=40&md5=fb4ed24f5232ae7b282afed277894b2a},
	abstract = {The recent rise in scale of sensors has led to the need for faster processing of events from multiple sensor data streams in a variety of real-world applications. We need an approach to model realworld entities and their interrelationships, and specify the process of moving from sensor data streams to event detection to eventbased goal planning. Recent advances in analysis of temporal data, such as time series shapelets, provide methods for identifying these discriminative events for classification. In this dissertation, I make connections between event processing and time series data mining as part of a comprehensive event detection and representation framework. © 2016 ACM.},
	author_keywords = {Event model; Feature selection; Multivariate time series classification; Sensor data mining; Shapelets},
	keywords = {Classification (of information); Data communication systems; Feature extraction; Software architecture; Time series; Time series analysis; Event model; Modeling and recognition; Multidimensional data; Multivariate time series classifications; Real-world entities; Sensor-data mining; Shapelets; Time series data mining; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Mao2017321,
	author = {Mao, Yingchi and Qi, Hai and Chen, Xiaoli and Li, Xiaofang},
	title = {Event Detection with Multivariate Water Parameters in the Water Monitoring Applications},
	year = {2017},
	journal = {Proceedings - 4th IEEE International Conference on Cyber Security and Cloud Computing, CSCloud 2017 and 3rd IEEE International Conference of Scalable and Smart Cloud, SSC 2017},
	pages = {321 – 326},
	doi = {10.1109/CSCloud.2017.67},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028689201&doi=10.1109%2fCSCloud.2017.67&partnerID=40&md5=caa57dc3ffb9ae52eff5df7e3fe11be5},
	abstract = {The real-time time series data of multiple water quality parameters are obtained from the water sensor networks deployed in the water supply network. The accurate and efficient detection and warning of contamination events to prevent pollution from spreading is one of the most important issues when the pollution occurs. In order to comprehensively reduce the event detection deviation, a Temporal Abnormal Event Detection Algorithm for Multivariate time series data (M-TAEDA) was proposed. In M-TAEDA, first, Back Propagation neural network models are adopted to analyze the time series data of multiple water quality parameters and calculate the possible outliers. Then, M-TAEDA algorithm determines the potential contamination events through Bayesian sequential analysis to estimate the probability of a contamination event. Finally, it can make decision based on the multiple event probabilities fusion in the water supply system. The experimental results indicate that the proposed M-TAEDA algorithm can obtain the 90% accuracy with BP neural network model and improve the rate of detection about 40% and reduce the false alarm rate about 45%, compared with the temporal event detection of Single Variate Temporal Abnormal Event Detection Algorithm (S-TAEDA). © 2017 IEEE.},
	author_keywords = {back propagation model; event detction; multivariate water quality parameters; time-series data; water supply network},
	keywords = {Backpropagation; Cloud computing; Data flow analysis; Neural networks; Pollution; Sensor networks; Signal detection; Time series; Water quality; Water supply; Water supply systems; Abnormal event detections; Back propagation neural networks; BP neural network model; event detction; Multivariate time series; Time-series data; Water quality parameters; Water supply networks; Water distribution systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Arnold2017,
	author = {Arnold, Daniel B. and Roberts, Ciaran and Ardakanian, Omid and Stewart, Emma M.},
	title = {Synchrophasor data analytics in distribution grids},
	year = {2017},
	journal = {2017 IEEE Power and Energy Society Innovative Smart Grid Technologies Conference, ISGT 2017},
	doi = {10.1109/ISGT.2017.8085979},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036589853&doi=10.1109%2fISGT.2017.8085979&partnerID=40&md5=bf0d88d88c1e1055adb9cbe6353170b7},
	abstract = {The deployment of high-fidelity, high-resolution sensors in distribution systems will play a key role in enabling increased resiliency and reliability in the face of a changing generation landscape. In order to leverage the full potential of such a rich dataset, it is necessary to develop an analytics framework capable of both detecting and analyzing patterns within events of interest. This work details the foundation of such an infrastructure. Here, we present an algorithm for detecting events, in the form of edges in voltage magnitude time series data, and an approach for clustering sets of events to reveal unique features that distinguish different events from one another (e.g. capacitor bank switching from transformer tap changes). We test the proposed infrastructure on distribution synchrophasor data obtained from a utility in California over a one week period. Our results indicate that event detection and clustering of archived data reveals features unique to the operation of voltage regulation equipment. The chosen data set particularly highlights the value of the derivative of the localized voltage angle as a distinguishing feature. © 2017 IEEE.},
	keywords = {Electric power transmission networks; Feature extraction; Random access storage; Voltage regulators; Capacitor bank switching; Distribution grid; Distribution systems; High resolution sensors; Synchrophasor datum; Time-series data; Transformer taps; Voltage magnitude; Smart power grids},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@ARTICLE{Nazif2016,
	author = {Nazif, Amina and Mohammed, Nurul Izma and Malakahmad, Amirhossein and Abualqumboz, Motasem S.},
	title = {Application of Step Wise Regression Analysis in Predicting Future Particulate Matter Concentration Episode},
	year = {2016},
	journal = {Water, Air, and Soil Pollution},
	volume = {227},
	number = {4},
	doi = {10.1007/s11270-016-2823-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962304986&doi=10.1007%2fs11270-016-2823-1&partnerID=40&md5=0ce88e2e8f91372c1eab4a1ada562ac5},
	abstract = {Particulate matter is an air pollutant that has resulted in tremendous health effects to the exposed populace. Air quality forecasting is an established process where air pollutants particularly, particulate matter (PM10) concentration is predicted in advance, so that adequate measures are implemented to reduce the health effect of PM10 to the barest level. The present study used daily average PM10 concentration and meteorological parameters (temperature, humidity, wind speed and wind direction) for 5 years (2006-2010) from three industrial air quality monitoring stations in Malaysia (Balok Baru, Tasek and Paka). Time series plot was used to assess PM10 pollution trend in the industrial areas. Additionally, step wise regression (SWR) analysis was used to predict next day PM10 concentrations for the three industrial areas. The SWR method was compared with a persistence model to assess its predictive capabilities. The results for the trend analysis showed that, Balok Baru (BB) had higher PM10 concentration levels, having high values in 2006, 2007 and 2009. These values were higher than the Malaysian Ambient Air Quality Guideline (MAAQG) of 150 μg/m3. Subsequently, the other two industrial areas Tasek (TK) and Paka (PK) had no record of violating the MAAQG. The results for the SWR analysis had significant R 2 values of 0.64, 0.66 and 0.60, respectively. The model performance results for variance inflation factor (VIF) were less than 5 and Durbin-Watson test (DW) had value of 2 for each of the study areas, which were significant. The comparative analysis between SWR and persistence model showed that the SWR had better capabilities, having lower errors for the BB, TK and PK areas. Using root mean square error (RMSE), the results showed error differences of 7, 12 and 16 %, and higher predictability using index of agreement (IA), having a difference of 17, 19 and 16 % for BB, TK, and PK areas, respectively. The results showed that SWR can be used in predicting PM10 next day average concentration, while the extreme event detection results showed that 100 μg/m3 were better detected than the 150 μg/m3 bench marked levels. © 2016 Springer International Publishing Switzerland.},
	author_keywords = {Air pollution; Daily average forecast; Particulate matter; Persistence model; Step wise regression analysis},
	keywords = {Malaysia; Guibourtia demeusei; Air quality; Errors; Forecasting; Mean square error; Pollution; Regression analysis; Wind; Air quality forecasting; Air quality monitoring stations; Meteorological parameters; Particulate Matter; Persistence models; Predictive capabilities; Root mean square errors; Stepwise regression; air quality; atmospheric pollution; concentration (composition); meteorology; particulate matter; prediction; regression analysis; air quality; ambient air; error; genetic polymorphism; humidity; industrial area; Malaysia; meteorology; model; monitoring; particulate matter; practice guideline; regression analysis; statistical model; time series analysis; velocity; Air pollution},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Green Open Access}
}

@ARTICLE{Daoud2018129,
	author = {Daoud, Daoud M.},
	title = {Detecting and ranking events in Twitter using diversity analysis},
	year = {2018},
	journal = {International Journal of Business Intelligence and Data Mining},
	volume = {13},
	number = {1-3},
	pages = {129 – 146},
	doi = {10.1504/IJBIDM.2017.10003611},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038432753&doi=10.1504%2fIJBIDM.2017.10003611&partnerID=40&md5=068ec286d89f7482a657638a79de7626},
	abstract = {In Twitter and in other social media channels, detecting events is very important and has many applications. However, this task is very challenging because of the huge number of tweets that are posted every minute and the massive scale of the spamming activities. In this paper, we present an innovative approach for detecting events using data posted to Twitter. The proposed approach is based on the concept of user’s attention by quantitatively modelling the diversity of hashtags using Shannon’s index. Our method records the diversity values on an hourly basis time-series. Using statistical techniques, the method locates the intervals having diversity values that fall outside the range of forecasted ones (normal state). We also present the labelling and ranking techniques that are implemented in this research. Experimental results on a dataset consisting of 15 million Arabic tweets show that our proposed approach can effectively detect real-world events in Twitter. Copyright © 2018 Inderscience Enterprises Ltd.},
	author_keywords = {Arabic; Diversity index; Event detection; Events labelling; Events ranking; Hashtags; Social media; Time-series analysis; Twitter; Z-score},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access}
}

@ARTICLE{Yusuf201515,
	author = {Yusuf, Syed A. and Brown, David J. and Mackinnon, Alan},
	title = {Application of acoustic directional data for audio event recognition via HMM/CRF in perimeter surveillance systems},
	year = {2015},
	journal = {Robotics and Autonomous Systems},
	volume = {72},
	pages = {15 – 28},
	doi = {10.1016/j.robot.2015.04.004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937523079&doi=10.1016%2fj.robot.2015.04.004&partnerID=40&md5=118fb9b3726f3b368b53b2b6f279e48a},
	abstract = {Audio event detection (AED) and recognition is a signal processing and analysis domain used in a wide range of applications including surveillance, home automation and behavioral assessment. The field presents numerous challenges to the current state-of-the-art due to its highly nonlinear nature. High false alarm rates (FARs) in such applications particularly limit the capabilities of vision-based perimeter monitoring systems by inducing high operator dependence. On the other hand, conventional fence-based vibration detectors and pressure-driven "taut wires" offer high sensitivity at the cost of a high FAR due to debris, animals and weather. This work reports an audio event identification methodology implemented as a test-bed system for a surveillance application to reduce FAR, maximize blind-spot coverage and improve audio event classification accuracy. The first phase utilizes a nonlinear autoregressive classifier to locate and classify discrete audio events via an exogenous sound direction variable to improve classifier confidence. The second phase implements a time-series-based system to recognize various audio activity groups from nominal everyday sound events such as traffic and muffled speech. The discretely labeled data is thus trained with HMM and Conditional Random Field classifiers and reports a substantial improvement in classification accuracies of indoor human activities. © 2015 Elsevier B.V. All rights reserved.},
	author_keywords = {Artificial intelligence; Audio event detection; Automation; Conditional Random Fields; Hidden Markov models; Machine learning; Robotics},
	keywords = {Agricultural robots; Alarm systems; Artificial intelligence; Audio systems; Automation; Hidden Markov models; Image segmentation; Learning systems; Monitoring; Robotics; Audio event detection; Behavioral assessment; Classification accuracy; Conditional random field; Operator dependence; Perimeter surveillances; Surveillance applications; Vibration detectors; Audio acoustics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Bronze Open Access}
}

@ARTICLE{20161,
	title = {17th International Conference on Web-Age Information Management, WAIM 2016},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9659},
	pages = {1 – 551},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976611087&partnerID=40&md5=bbf4f736c70e0a501adf4a3396c6ddb9},
	abstract = {The proceedings contain 45 papers. The special focus in this conference is on Privacy and Trust. The topics include: Detecting anomalous ratings using matrix factorization for recommender systems; a novel spatial cloaking scheme using hierarchical hilbert curve for location-based services; efficient privacy-preserving content-based image retrieval in the cloud; preserving the d-reachability when anonymizing social networks; personalized location anonymity; detecting data-model-oriented anomalies in parallel business process; learning user credibility on aspects from review texts; detecting anomaly in traffic flow from road similarity analysis; progressive ant-colony-optimization-based keyword search over relational databases; enhanced query classification with millions of fine-grained topics; a hybrid machine-crowdsourcing approach for web table matching and cleaning; an update method for shortest path caching with burst paths based on sliding windows; low overhead log replication for main memory database system; diversification of keyword query result patterns; efficient approximate substring matching in compressed string; top-k similarity search for query-by-humming; restricted boltzmann machines for retweeting behaviours prediction; cross-collection emotion tagging for online news; online news emotion prediction with bidirectional LSTM; learning for search results diversification in twitter; adjustable time-window-based event detection on twitter; an online framework for hashtag suggestion in twitter; unifying user and message clustering information for retweeting behavior prediction; an efficient framework for high quality microblog extraction in time-frequency domain; active learning method for constraint-based clustering algorithms; an effective cluster assignment strategy for large time series data and a novel bayesian ranking approach for personal big-hit paper prediction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Peng201717,
	author = {Peng, Fengchao and Zhou, Xibo and Liu, Hao and Tan, Haoyu and Luo, Qiong and Hu, Jiye},
	title = {A time series classification method for battery event detection},
	year = {2017},
	journal = {Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS},
	volume = {2017-December},
	pages = {17 – 24},
	doi = {10.1109/ICPADS.2017.00014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048376500&doi=10.1109%2fICPADS.2017.00014&partnerID=40&md5=1c4bd4fd487bda367712c7781db0c3b4},
	abstract = {The maintenance of batteries used in wireless mobile communication is an important practical problem. The experts can easily recognize the battery events, such as turning on, by watching the monitoring data. However it is infeasible to have experts watch the data all the time. There are devices that can report battery events. These devices sometimes report incorrect event. In order to solve this problem, we propose a time series classification framework to use the expert knowledge to build an accurate classifier, and then use the classifier to monitor the batteries in real time. We first propose an active learning method to efficiently collect the experts' labels for each event. Then we apply various feature extraction methods to convert each time series segment into a feature vector. Finally, we apply random forest classifier to perform the classification. Moreover, in practice, the labeled data is unbalanced, i.e. >99% of the data instances belong to a single label. We use bootstrap to solve this problem. We test our method on a dataset for 500 batteries in 3 months. The results show that our method achieves a very high classification accuracy, using only less than 1% of the dataset as training set. © 2017 IEEE.},
	author_keywords = {Active Learning; Event Detection; Time Series Classification},
	keywords = {Artificial intelligence; Classification (of information); Electric batteries; Learning systems; Statistical tests; Time series; Active Learning; Active learning methods; Classification framework; Classification methods; Events detection; Expert knowledge; Practical problems; Real- time; Time series classifications; Wireless mobile communications; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Meenakshi2015245,
	author = {Meenakshi, S.P. and Raghavan, S.V.},
	title = {Forecasting and event detection in internet resource dynamics using time series models},
	year = {2015},
	journal = {Engineering Letters},
	volume = {23},
	number = {4},
	pages = {245 – 257},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947268525&partnerID=40&md5=13ef0eac200cad62ad9f30c6b9732eae},
	abstract = {At present, Internet emerges as a country’s predominant and viable data communication infrastructure. Autonomous System (AS) topology occupies the top position in the Internet infrastructure hierarchy. AS resources are building blocks of this topology, and consist of AS numbers, IPv4 and IPv6 prefixes. Further, the resource requirement in each country is dynamic and driven by various technical and socio-economic factors. Hence, the organizational and national competitiveness for socio economic development is reflected in AS growth pattern. Furthermore, to assess the competitiveness, future expansion, and policy development, there is a need for both study and forecast AS growth. For Internet infrastructure development, understanding long term trends and stochastic variation behaviour are essential to detecting significant events during growth periods. In this work, we use time series based approximation for mathematical modeling, system identification, and forecasting to determine the annual AS growth. The AS data of five countries, namely India, China, Japan, South Korea, and Taiwan were extracted from the APNIC (Asia Pacific Network Information Centre) archive for this purpose. The first two countries have larger economies and the next three countries are advanced technological nations in the APNIC region. The characterization of the time series is performed by analyzing the trend and fluctuation component of the data. The model identification is carried out by testing for non stationarity and autocorrelation significance. ARIMA (Auto Regressive Integrated Moving Average) models with different Auto Regressive (AR) and Moving Average (MA) parameters are identified for forecasting the AS growth of each country. Model validation, parameter estimation, point forecast, and prediction intervals with 95 % confidence levels for the five countries are reported in the paper. The statistical analysis on long term trends and Change Point Detection (CPD) on Inter Annual Absolute Variations (IAAV) are presented. The significant level of change in variations, positive growth percentage in IAAV, and higher percentage of advertised ASes when compared to other countries indicate India’s fast growth and wider global reachability of Internet infrastructure from 2007 onwards. The correlation between AS IAAV change points and GDP (gross domestic product) growth periods indicates that the service sector industry growth is the driving force behind significant annual changes. © International Association of Engineers.},
	author_keywords = {AS growth forecasting; AS topology; Inter annual absolute variation; Long term trend; Statistical analysis},
	keywords = {Autoregressive moving average model; Competition; Economic and social effects; Forecasting; Public policy; Service industry; Statistical methods; Stochastic systems; Time series; Time series analysis; Topology; AS topologies; Auto-regressive integrated moving average; Gross domestic products; Interannual; Internet infrastructure; Long-term trend; National competitiveness; Socio-economic development; Internet protocols},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Bačić2016295,
	author = {Bačić, Boris},
	title = {Echo state network for 3D motion pattern indexing: A case study on tennis forehands},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9431},
	pages = {295 – 306},
	doi = {10.1007/978-3-319-29451-3_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959020192&doi=10.1007%2f978-3-319-29451-3_24&partnerID=40&md5=391ad73b40fc59a6d95671eb0fa1334f},
	abstract = {Open skill sports such as tennis have a large number of swing execution techniques. This study presents a novel approach to event detection and motion pattern indexing of forehand swings captured from fixed location multi-camera represented as a 3D motion data set of multi-time series sampled at 50 Hz. The achieved results utilising Echo State Network (ESN) demonstrate 100% recognition of tennis forehands from previously unseen test data without ball impact information. In contrast to traditional, heuristic and feature extraction-based algorithmic approaches in exergames and augmented coaching technologies, the proposed ESN paradigm represents a viable and generic approach for future work in temporal and spatial detection and automated analysis of region of interest in human motion data processing. © Springer International Publishing Switzerland 2016.},
	author_keywords = {Augmented coaching systems (ACS); Biomechanics; Computational intelligence (CI); Reservoir computing (RC); Spiking neural network (SNN); Sport and rehabilitation},
	keywords = {Artificial intelligence; Biomechanics; Data handling; Face recognition; Feature extraction; Image segmentation; Indexing (of information); Motion analysis; Neural networks; Pattern recognition; Sports; Algorithmic approach; Augmented coaching systems (ACS); Automated analysis; Echo state networks; Region of interest; Reservoir Computing; Spiking neural network(SNN); Temporal and spatial; Time and motion study},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}@CONFERENCE{Gupta2013173,
	author = {Gupta, Rahul and Audhkhasi, Kartik and Lee, Sungbok and Narayanan, Shrikanth},
	title = {Paralinguistic event detection from speech using probabilistic time-series smoothing and masking},
	year = {2013},
	journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	pages = {173 – 177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906260971&partnerID=40&md5=5e77036707f937e959d2b424abc456e6},
	abstract = {Non-verbal speech cues serve multiple functions in human interaction such as maintaining the conversational flow as well as expressing emotions, personality, and interpersonal attitude. In particular, non-verbal vocalizations such as laughters are associated with affective expressions while vocal fillers are used to hold the floor during a conversation. The Interspeech 2013 Social Signals Sub-Challenge involves detection of these two types of non-verbal signals in telephonic speech dialogs. We extend the challenge baseline system by using filtering and masking techniques on probabilistic time series representing the occurrence of a vocal event. We obtain improved area under receiver operating characteristic (ROC) curve of 93.3% (10.4% absolute improvement) for laughters and 89.7% (6.1% absolute improvement) for fillers on the test set. This improvement suggests the importance of using temporal context for detecting these paralinguistic events. Copyright © 2013 ISCA.},
	author_keywords = {Non-verbal vocalizations; Receiver operating characteristic; Time series masking; Time series smoothing},
	keywords = {Fillers; Linguistics; Time series; Human interactions; Interpersonal attitudes; Masking technique; Multiple function; Non-verbal signals; Non-verbal vocalizations; Receiver operating characteristic curves; Receiver operating characteristics; Signal detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32}
}

@CONFERENCE{Sun2013282,
	author = {Sun, Yun and Tao, Yubo and Yang, Geng and Lin, Hai},
	title = {Visitpedia: Wiki article visit log visualization for event exploration},
	year = {2013},
	journal = {Proceedings - 13th International Conference on Computer-Aided Design and Computer Graphics, CAD/Graphics 2013},
	pages = {282 – 289},
	doi = {10.1109/CADGraphics.2013.44},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901418076&doi=10.1109%2fCADGraphics.2013.44&partnerID=40&md5=a44e9a886ef2025df44e74895d031e54},
	abstract = {This paper proposes an interactive visualization tool, Visitpedia, to detect and analyze social events based on Wikipedia visit history. It helps users discover real-world events behind the data and study how these events evolve over time. Different from previous work based on on-line news or similar text corpora, we choose Wikipedia visit counts as our data source since the visit count data better reflect user concerns of social events. We tackle the event-based task from a time-series pattern perspective rather than semantic perspective. Various visualization and user interaction techniques are integrated in Visitpedia. Two case studies are conducted to demonstrate the effectiveness of Visitpedia. © 2013 IEEE.},
	author_keywords = {Event detection; Event evolution; Visual analytics; Wikipedia visit counts},
	keywords = {Computer aided design; Semantics; Visualization; Event detection; Event evolutions; Interactive visualization tool; Social events; Text corpora; User interaction; Visual analytics; Wikipedia; Computer graphics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Yang20121255,
	author = {Yang, Xueyao and Boccelli, Dominic L.},
	title = {Real-time event detection: A model-based approach},
	year = {2012},
	journal = {14th Water Distribution Systems Analysis Conference 2012, WDSA 2012},
	volume = {2},
	pages = {1255 – 1264},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883114938&partnerID=40&md5=14643ff748a2b543166f0c384e4c14da},
	abstract = {Security issues have become increasingly important within distribution systems, which has led to the development of event detection algorithms (EDAs) to provide timely detection of intrusion events. The current study develops a model-based EDA utilizing non-specific water quality sensors to iden- tify water quality anomalies, which incorporates both the localized water quality information and operational changes. The proposed EDA focuses on estimating the likelihood of an observed error signal time series using a moving time-window of error statistics. The likelihood of the error signals are estimated based on two formulations of the underlying probability density function (pdf): 1) a Normal pdf estimation, which assumes the errors follow a normal distribution, and 2) a kernel density estimation (KDE), which is type of non-parametric representation of the error distribution. A prelim- inary analysis was performed using chlorine as the water quality parameter. Results suggest that the proposed EDA, using KDE to estimate the error pdf, performed reasonably well in differentiating a true water quality anomaly from the modeling error time series. Copyright © (2012) by Engineers Australia.},
	keywords = {Error statistics; Estimation; Intrusion detection; Normal distribution; Probability density function; Systems analysis; Water distribution systems; Distribution systems; Event detection algorithm; Kernel Density Estimation; Model based approach; Probability density function (pdf); Water quality information; Water quality parameters; Water quality sensors; Water quality},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Andrienko201059,
	author = {Andrienko, Gennady and Andrienko, Natalia and Mladenov, Martin and Mock, Michael and Pölitz, Christian},
	title = {Discovering bits of place histories from people's activity traces},
	year = {2010},
	journal = {VAST 10 - IEEE Conference on Visual Analytics Science and Technology 2010, Proceedings},
	pages = {59 – 66},
	doi = {10.1109/VAST.2010.5652478},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650953681&doi=10.1109%2fVAST.2010.5652478&partnerID=40&md5=3e2f6653f043e9c303294aaf48620272},
	abstract = {Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years. ©2010 IEEE.},
	author_keywords = {Event detection; Geovisualization; Scalable visualization; Spatio-temporal data; Time series analysis},
	keywords = {Behavioral research; Data visualization; Graphical user interfaces; Imaging systems; Mobile phones; Telecommunication equipment; Telephone; Telephone sets; Time series; Visualization; British Isles; Event detection; Geovisualization; Informed decision; Integrated analysis; Mobile phone operators; Photo sharing; Processable; Real data sets; Scalable visualization; Spatio-temporal data; Visual analytics; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@ARTICLE{Houdyer2015276,
	author = {Houdyer, Pierre and Zimmerman, Albrecht and Kaytoue, Mehdi and Plantevit, Marc and Mitchell, Joseph and Robardet, Céline},
	title = {Gazouille: Detecting and illustrating local events from geolocalized social media streams},
	year = {2015},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9286},
	pages = {276 – 280},
	doi = {10.1007/978-3-319-23461-8_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984604089&doi=10.1007%2f978-3-319-23461-8_29&partnerID=40&md5=ec610cbaf6fe7169be590cffba538c18},
	abstract = {We present Gazouille, a system for discovering local events in geo-localized social media streams. The system is based on three core modules: (i) social networks data acquisition on several urban areas, (ii) event detection through time series analysis, and (iii) a Web user interface to present events discovered in real-time in a city, associated to a gallery of social media that characterize the event. © Springer International Publishing Switzerland 2015.},
	keywords = {Artificial intelligence; Data acquisition; Learning systems; Media streaming; Time series analysis; User interfaces; Event detection; Real time; Social media; Urban areas; Web user interface; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access}
}

@CONFERENCE{Zhang2015149,
	author = {Zhang, Yuanxun and Calyam, Prasad and Debroy, Saptarshi and Sridharan, Mukundan},
	title = {PCA-based network-wide correlated anomaly event detection and diagnosis},
	year = {2015},
	journal = {2015 11th International Conference on the Design of Reliable Communication Networks, DRCN 2015},
	pages = {149 – 156},
	doi = {10.1109/DRCN.2015.7149006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944074661&doi=10.1109%2fDRCN.2015.7149006&partnerID=40&md5=0decadfe1142d1fd15a7450ed1e520b8},
	abstract = {High-performance computing environments supporting large-scale distributed computing applications need multi-domain network performance measurements from open frameworks such as perfSONAR. Network-wide correlated anomaly events that can potentially impact data throughput performance need to be quickly and accurately notified for smooth computing environment operations. Since network topology is not always available along with the measurements data, it is challenging to identify and locate network-wide correlated anomaly events that impact data throughput performance. In this paper, we present a novel PCA-based correlated anomaly event detection scheme that can fuse multiple time-series of measurements and transform them using principal component analysis. We demonstrate using actual perfSONAR one-way delay measurement datasets that our scheme can: (a) effectively distinguish between correlated and uncorrelated anomalies, (b) leverage a source-side vantage point to diagnose whether a correlated anomaly event location is local or in an external domain, (c) act as a 'black-box' correlation analysis tool for key insights in eventual root-cause identification. © 2015 IEEE.},
	keywords = {Computer networks; Information systems; Computing environments; Correlation analysis; High performance computing; Large scale distributed computing; Multidomain networks; Multiple time series; One way delay measurements; Root cause identification; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Huang2014410,
	author = {Huang, Dong and Yao, Shitong and Wang, Yi and De La Torre, Fernando},
	title = {Sequential max-margin event detectors},
	year = {2014},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8691 LNCS},
	number = {PART 3},
	pages = {410 – 424},
	doi = {10.1007/978-3-319-10578-9_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906489572&doi=10.1007%2f978-3-319-10578-9_27&partnerID=40&md5=e20b08272a0ef8389084ea8c3ea6eacb},
	abstract = {Many applications in computer vision (e.g., games, human computer interaction) require a reliable and early detector of visual events. Existing event detection methods rely on one-versus-all or multi-class classifiers that do not scale well to online detection of large number of events. This paper proposes Sequential Max-Margin Event Detectors (SMMED) to efficiently detect an event in the presence of a large number of event classes. SMMED sequentially discards classes until only one class is identified as the detected class. This approach has two main benefits w.r.t. standard approaches: (1) It provides an efficient solution for early detection of events in the presence of large number of classes, and (2) it is computationally efficient because only a subset of likely classes are evaluated. The benefits of SMMED in comparison with existing approaches is illustrated in three databases using different modalities: MSRDaliy Activity (3D depth videos), UCF101 (RGB videos) and the CMU-Multi-Modal Action Detection (MAD) database (depth, RGB and skeleton). The CMU-MAD was recorded to target the problem of event detection (not classification), and the data and labels are available at http://humansensing.cs.cmu.edu/mad/ . © 2014 Springer International Publishing.},
	author_keywords = {Activity Recognition; Event Detection; Multi-Modal Action Detection; Time Series Analysis},
	keywords = {Artificial intelligence; Computer science; Computers; Activity recognition; Computationally efficient; Event detection; Event detectors; Multi-class classifier; Multi-modal; Number of class; On-line detection; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 62; All Open Access, Bronze Open Access}
}

@ARTICLE{Cicconet201424,
	author = {Cicconet, Marcelo and Gutwein, Michelle and Gunsalus, Kristin C. and Geiger, Davi},
	title = {Label free cell-tracking and division detection based on 2D time-lapse images for lineage analysis of early embryo development},
	year = {2014},
	journal = {Computers in Biology and Medicine},
	volume = {51},
	pages = {24 – 34},
	doi = {10.1016/j.compbiomed.2014.04.011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901413983&doi=10.1016%2fj.compbiomed.2014.04.011&partnerID=40&md5=3894e53da4b9563b6165c0047f3514e7},
	abstract = {In this paper we report a database and a series of techniques related to the problem of tracking cells, and detecting their divisions, in time-lapse movies of mammalian embryos. Our contributions are (1) a method for counting embryos in a well, and cropping each individual embryo across frames, to create individual movies for cell tracking; (2) a semi-automated method for cell tracking that works up to the 8-cell stage, along with a software implementation available to the public (this software was used to build the reported database); (3) an algorithm for automatic tracking up to the 4-cell stage, based on histograms of mirror symmetry coefficients captured using wavelets; (4) a cell-tracking database containing 100 annotated examples of mammalian embryos up to the 8-cell sta≥ and (5) statistical analysis of various timing distributions obtained from those examples. © 2014 Elsevier Ltd.},
	author_keywords = {Cell counting; Database; Dynamic programming; Embryo development; Event detection; Time series; Tracking},
	keywords = {Animals; Blastomeres; Cell Division; Cell Tracking; Embryo, Mammalian; Embryonic Development; Image Processing, Computer-Assisted; Mice; Cytology; Database systems; Dynamic programming; Mammals; Surface discharges; Time series; Automatic tracking; Cell counting; Embryo development; Event detection; Mirror symmetry; Software implementation; Time lapse images; Tracking cells; algorithm; analytical equipment; animal embryo; article; automation; cell division; cell lineage; cell tracking; computer program; controlled study; embryo; embryo development; histogram; microscope; mouse; nonhuman; priority journal; procedures concerning cells; time lapse imaging; animal; blastoma; cell division; cell tracking; cytology; devices; embryo development; image processing; metabolism; physiology; procedures; Cells},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Green Open Access}
}

@ARTICLE{Schaff2014335,
	author = {Schaff, David P. and Richards, Paul G.},
	title = {Improvements in magnitude precision, using the statistics of relative amplitudes measured by cross correlation},
	year = {2014},
	journal = {Geophysical Journal International},
	volume = {197},
	number = {1},
	pages = {335 – 350},
	doi = {10.1093/gji/ggt433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897845972&doi=10.1093%2fgji%2fggt433&partnerID=40&md5=58df12696d2d887da6cdadbc6c2c1a4c},
	abstract = {Standard processing of seismic events for reporting in bulletins is usually done one-at-a time. State-of-the-art relative event methods, often involving cross correlation, are increasingly used and have improved estimates of event parameters for event detection, location and magnitude. This is because relative event techniques can simultaneously reduce measurement error and effects of model error. We showhowcross correlation can be used to assign relative magnitudes for neighbouring seismic events distributed over a large region in east Asia and quantify to what extent the uncertainty in these values increases aswaveform similarity breaks down. We find that cross correlation works well for magnitude comparison of two events when it is expected that they generate very similar signals evenif these may be almost buried in large amounts of noise. This may be the case when investigating repeating earthquakes or nuclear explosions within a few kilometres of each other. Cross correlation is the optimal detector in these cases assuming noise is white andGaussian, and also provides the least-squares solution for the relative amplitudes. However, when the waveform similarity of the underlying signals breaks down, due to interevent separation distance, source time function differences or focal mechanism differences, theseassumptions are no longer valid and a bias is introduced into the relative magnitud measurement. This bias due to degradation of waveform similarity is modelled here with synthetics and an analytic expression for it is derived based on three terms-the cross-correlation coefficient (CC), and the signal-to-noise ratio (SNR) of the larger and smaller events. The analytic expression is a good match to the observed bias in the data. If the equationfor relative magnitude is rewritten to correct for the bias due to the CC, a newequation results which is simply the log of the ratio of the L2 norms. The bias due to SNRs is still present because the observed waveforms inevitably contain both signal and noise. However, this bias is predicted to be minimal for typical detection thresholds. Making measurements of the ratio of the L2 norms is shown to remove the bias due to degradation of waveform similarity for real data. The scatter of these cross-correlation measurements of relative magnitude is much less than those obtained by differencing magnitudes in a traditional catalogue. Of 14 025 events in and near China, 34 per cent had over an order of magnitude reduction in the median standard deviation (0.0342 magnitude units) as compared to the estimated scatter in the catalogue (0.3454 magnitude units). And 78 per centof the events show a factor 3 improvement or better in the precision of relative event size measured as the ratio of the L2 norms as compared to the precision of the catalogue for relativemagnitudes. These results suggest that the ratio of the L2 norms is an appropriate measure of relative magnitudes for general seismicity of a monitoring region, when there is significant waveform dissimilarity for neighbouring events. This measuremaintains a higher degree of measurement precision as compared to the catalogue. © The Authors 2014. Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Asia; Computational seismology; Earthquake ground motions; Seismic monitoring and test-ban treaty verification; Time-series analysis},
	keywords = {China; Nuclear explosions; Signal to noise ratio; Source separation; Asia; Computational seismologies; Cross-correlation coefficient; Cross-correlation measurements; Earthquake ground motions; Least squares solutions; Seismic monitoring and test-ban treaty verifications; Signaltonoise ratio (SNR); amplitude; correlation; earthquake catalogue; earthquake magnitude; ground motion; seismicity; seismology; time series analysis; waveform analysis; Earthquakes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; All Open Access, Bronze Open Access}
}

@CONFERENCE{Xie2012,
	author = {Xie, Feng and Song, Andy and Ciesielski, Vic},
	title = {Event detection in time series by genetic programming},
	year = {2012},
	journal = {2012 IEEE Congress on Evolutionary Computation, CEC 2012},
	doi = {10.1109/CEC.2012.6256589},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866869848&doi=10.1109%2fCEC.2012.6256589&partnerID=40&md5=ff15db9be9a7b56647029b0649423873},
	abstract = {The aim of event detection in time series is to identify particular occurrences of user-interest in one or more time lines, such as finding an anomaly in electrocardiograms or reporting a sudden variation of voltage in a power supply. Current methods are not adequate for detecting certain kinds of events without any domain knowledge. Therefore, we propose a Genetic Programming (GP) based event detection methodology in which solutions can be built from raw time series data. The framework is applied to five synthetic data sets and one real world application. The experimental results show that working on raw data even with a dimensionality as high as 140 x 80, genetic programming can achieve superior performance to conventional methods operating on pre-defined features. Furthermore, analysis of the evolved event detectors shows that they have captured the regularities inserted into the synthetic data sets and some individuals can be readily understood by humans. © 2012 IEEE.},
	author_keywords = {event detection; feature extraction; genetic programming; time series},
	keywords = {Feature extraction; Genetic programming; Conventional methods; Domain knowledge; Event detection; Power supply; Real-world application; Synthetic datasets; Time line; Time-series data; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access}
}

@ARTICLE{Thompson201448,
	author = {Thompson, David R. and Burke-Spolaor, Sarah and Deller, Adam T. and Majid, Walid A. and Palaniswamy, Divya and Tingay, Steven J. and Wagstaff, Kiri L. and Wayth, Randall B.},
	title = {Real-time adaptive event detection in astronomical data streams},
	year = {2014},
	journal = {IEEE Intelligent Systems},
	volume = {29},
	number = {1},
	pages = {48 – 55},
	doi = {10.1109/MIS.2013.10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899671193&doi=10.1109%2fMIS.2013.10&partnerID=40&md5=f9b7c9ff6442ce9ecf7a3944a8738eed},
	abstract = {A new generation of observational science instruments is dramatically increasing collected data volumes in a range of fields. These instruments include the Square Kilometer Array (SKA), Large Synoptic Survey Telescope (LSST), terrestrial sensor networks, and NASA satellites participating in 'decadal survey" missions. Their unprecedented coverage and sensitivity will likely reveal wholly new categories of unexpected and transient events. Commensal methods passively analyze these data streams, recognizing anomalous events of scientific interest and reacting in real time. Here, the authors report on a case example: Very Long Baseline Array Fast Transients Experiment (V-FASTR), an ongoing commensal experiment at the Very Long Baseline Array (VLBA) that uses online adaptive pattern recognition to search for anomalous fast radio transients. V-FASTR triages a millisecond-resolution stream of data and promotes candidate anomalies for further offline analysis. It tunes detection parameters in real time, injecting synthetic events to continually retrain itself for optimum performance. This self-tuning approach retains sensitivity to weak signals while adapting to changing instrument configurations and noise conditions. The system has operated since July 2011, making it the longest-running real-time commensal radio transient experiment to date. © 2014 IEEE.},
	author_keywords = {fast radio transients; intelligent systems; pattern recognition; radio astronomy; real-time machine learning; time series analysis},
	keywords = {Data communication systems; Experiments; Instruments; Intelligent systems; NASA; Pattern recognition; Sensor networks; Surveys; Time series analysis; Transients; Adaptive pattern recognition; Astronomical data; Large synoptic survey telescopes; Long baseline array; Off-line analysis; Optimum performance; Square kilometer arrays; Transient experiments; Radio astronomy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Zhang20151523,
	author = {Zhang, Miao and Wen, Lianxing},
	title = {An effective method for small event detection: Match and locate (M & L)},
	year = {2015},
	journal = {Geophysical Journal International},
	volume = {200},
	number = {3},
	pages = {1523 – 1537},
	doi = {10.1093/gji/ggu466},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928179136&doi=10.1093%2fgji%2fggu466&partnerID=40&md5=d8dbd091b1a8a9f253413752af68f4e2},
	abstract = {Detection of low magnitude event is critical and challenging in seismology. We develop a new method, named the match and locate (M&L) method, for small event detection. The M&L method employs some template events and detects small events through stacking crosscorrelograms between waveforms of the template events and potential small event signals in the continuous waveforms over multiple stations and components, but the stacking is performed after making relative traveltime corrections based on the relative locations of the template event and potential small event scanning through a 3-D region around the template. Compared to the current methods of small event detection, the M&L method places event detection to a lower magnitude level and extends the capability of detecting small events that have large distance separations from the template. The method has little dependence on the accuracy of the velocity models used, and, at the same time, provides high-precision location information of the detected small-magnitude events. We demonstrate the effectiveness of the M&L method and its advantage over the matched filter method using examples of scaled-down earthquakes occurring in the Japan Island and foreshock detection before the 2011 Mw 9.0 Tohoku earthquake. In the foreshock detection, the M&L method detects four times more events (1427) than the templates and 9 per cent (134) more than the matched filter under the same detection threshold. Up to 41 per cent (580) of the detected events are not located at the template locations with the largest separation of 9.4 km. Based on the identified foreshocks, we observe five sequences of foreshock migration along the trench-parallel direction toward the epicentre of the Mw 9.0 main shock. © The Authors 2015. Published by Oxford University Press on behalf of The Royal Astronomical Society.},
	author_keywords = {Earthquake source observations; Seismic monitoring and test-ban treaty verification; Time-series analysis; Wave propagation},
	keywords = {Japan; Earthquakes; Location; Time series analysis; Wave propagation; 'current; Continuous waveforms; Earthquake source observations; Events detection; Relative location; Seismic monitoring and test-ban treaty verifications; Stackings; Time-series analysis; Travel-time; Waveforms; detection method; earthquake event; earthquake magnitude; foreshock; seismic source; seismology; time series analysis; wave propagation; Matched filters},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 113}
}

@CONFERENCE{Adnane201159,
	author = {Adnane, Mourad and Jiang, Zhongwei and Mori, Nobuaki and Matsumoto, Yoshiaki},
	title = {An automated program for mental stress and apnea/hypopnea events detection},
	year = {2011},
	journal = {7th International Workshop on Systems, Signal Processing and their Applications, WoSSPA 2011},
	pages = {59 – 62},
	doi = {10.1109/WOSSPA.2011.5931412},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960926503&doi=10.1109%2fWOSSPA.2011.5931412&partnerID=40&md5=6ee7414bd0be259f1e21c5af51ba7c5f},
	abstract = {The development of computer-aided diagnosis tools for detecting specific health-related events occurrences is of a great importance in the medical practice nowadays. Actually, health professionals still use manual methods for screening physiological data to get valuable information. This task becomes fastidious when the data is very long. In this paper, we present a new and simple method, we called windowed detrended fluctuation analysis (WDFA), for the detection of health-related events in physiological data. This method is based on the calculation of local energy of detrended profile of RR series obtained from the ECG signal. Data acquired during night containing apnea and hypopnea episodes and mental stress related data were used. Experiments showed that it is possible to detect apnea or hypopnea events and mental stress time episodes. Our method is well suited for the analysis of long time series data and the detection of abrupt changes in physiological data. © 2011 IEEE.},
	keywords = {Computer aided diagnosis; Health; Physiology; Program diagnostics; Time series; Time series analysis; Abrupt change; Detrended fluctuation analysis; ECG signals; Events detection; Health professionals; Local energy; Long time series; Manual methods; Medical practice; Mental stress; Physiological data; R-R series; SIMPLE method; Signal detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Parry20111747,
	author = {Parry, Matthew L. and Legg, Philip A. and Chung, David H.S. and Griffiths, Iwan W. and Chen, Min},
	title = {Hierarchical event selection for video storyboards with a case study on snooker video visualization},
	year = {2011},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	volume = {17},
	number = {12},
	pages = {1747 – 1756},
	doi = {10.1109/TVCG.2011.208},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80855139127&doi=10.1109%2fTVCG.2011.208&partnerID=40&md5=23152c02cf5b82861590bd5aa0a72869},
	abstract = {Video storyboard, which is a form of video visualization, summarizes the major events in a video using illustrative visualization. There are three main technical challenges in creating a video storyboard, (a) event classification, (b) event selection and (c) event illustration. Among these challenges, (a) is highly application-dependent and requires a significant amount of application specific semantics to be encoded in a system or manually specified by users. This paper focuses on challenges (b) and (c). In particular, we present a framework for hierarchical event representation, and an importance-based selection algorithm for supporting the creation of a video storyboard from a video. We consider the storyboard to be an event summarization for the whole video, whilst each individual illustration on the board is also an event summarization but for a smaller time window. We utilized a 3D visualization template for depicting and annotating events in illustrations. To demonstrate the concepts and algorithms developed, we use Snooker video visualization as a case study, because it has a concrete and agreeable set of semantic definitions for events and can make use of existing techniques of event detection and 3D reconstruction in a reliable manner. Nevertheless, most of our concepts and algorithms developed for challenges (b) and (c) can be applied to other application areas. © 2010 IEEE.},
	author_keywords = {Illustrative visualization; Multimedia visualization; Time series data},
	keywords = {Algorithms; Image retrieval; Semantics; Three dimensional; Time series; Visualization; 3D reconstruction; 3D Visualization; Application specific; Event classification; Event detection; Event selection; Illustrative visualization; Major events; Multimedia visualization; Other applications; Selection algorithm; Technical challenges; Time series data; Time windows; Video visualization; Three dimensional computer graphics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Green Open Access}
}

@ARTICLE{Gautam201578,
	author = {Gautam, A. and Ophus, C. and Lançon, F. and Denes, P. and Dahmen, U.},
	title = {Analysis of grain boundary dynamics using event detection and cumulative averaging},
	year = {2015},
	journal = {Ultramicroscopy},
	volume = {151},
	pages = {78 – 84},
	doi = {10.1016/j.ultramic.2014.11.008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925513701&doi=10.1016%2fj.ultramic.2014.11.008&partnerID=40&md5=7e18b0548337b7867cfbe8ffc0295dbe},
	abstract = {To analyze extended time series of high resolution images, we have employed automated frame-by-frame comparisons that are able to detect dynamic changes in the structure of a grain boundary in Au. Using cumulative averaging of images between events allowed high resolution measurements of the atomic relaxation in the interface with sufficient accuracy for comparison with atomistic models. Cumulative averaging was also used to observe the structural rearrangement of atomic columns at a moving step in the grain boundary. The technique of analyzing changing features in high resolution images by averaging between incidents can be used to deconvolute stochastic events that occur at random intervals and on time scales well beyond that accessible to single-shot imaging. © 2014 Elsevier B.V.},
	author_keywords = {Aberration correction; Atomic structure; Dynamics; Electron detector; Grain boundary; HAADF; HRTEM; Simulation; Step; Time average},
	keywords = {Atoms; Crystal atomic structure; Dynamics; Stochastic systems; gold; Aberration correction; Electron detectors; HAADF; HRTEM; Simulation; Step; Time averages; accuracy; Article; chemical structure; crystallization; electron microscopy; grain boundary dynamics; image analysis; image display; image processing; image quality; molecular dynamics; physical parameters; physical phase; signal noise ratio; Grain boundaries},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Neill2010261,
	author = {Neill, Daniel B. and Cooper, Gregory F.},
	title = {A multivariate Bayesian scan statistic for early event detection and characterization},
	year = {2010},
	journal = {Machine Learning},
	volume = {79},
	number = {3},
	pages = {261 – 282},
	doi = {10.1007/s10994-009-5144-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953023188&doi=10.1007%2fs10994-009-5144-4&partnerID=40&md5=c327c6deef070745882b388d2c73b457},
	abstract = {We present the multivariate Bayesian scan statistic (MBSS), a general framework for event detection and characterization in multivariate spatial time series data. MBSS integrates prior information and observations from multiple data streams in a principled Bayesian framework, computing the posterior probability of each type of event in each space-time region. MBSS learns a multivariate Gamma-Poisson model from historical data, and models the effects of each event type on each stream using expert knowledge or labeled training examples. We evaluate MBSS on various disease surveillance tasks, detecting and characterizing outbreaks injected into three streams of Pennsylvania medication sales data. We demonstrate that MBSS can be used both as a "general" event detector, with high detection power across a variety of event types, and a "specific" detector that incorporates prior knowledge of an event's effects to achieve much higher detection power. MBSS has many other advantages over previous event detection approaches, including faster computation and easy interpretation and visualization of results, and allows faster and more accurate event detection by integrating information from the multiple streams. Most importantly, MBSS can model and differentiate between multiple event types, thus distinguishing between events requiring urgent responses and other, less relevant patterns in the data. © 2009 Springer Science+Business Media, LLC.},
	author_keywords = {Biosurveillance; Event characterization; Event detection; Scan statistics},
	keywords = {Bayesian networks; Learning algorithms; Time series; Visualization; Bayesian; Bayesian frameworks; Biosurveillance; Disease surveillance; Early event detection; Event detection; Expert knowledge; Historical data; Integrating information; Multiple data streams; Multiple streams; Pennsylvania; Poisson model; Posterior probability; Prior information; Prior knowledge; Relevant patterns; Scan statistics; Space-time region; Time-series data; Training example; Detectors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 53; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Chaovalit2014,
	author = {Chaovalit, Pimwadee and Saiprasert, Chalermpol and Pholprasit, Thunyasit},
	title = {A method for driving event detection using SAX with resource usage exploration on smartphone platform},
	year = {2014},
	journal = {Eurasip Journal on Wireless Communications and Networking},
	volume = {2014},
	number = {1},
	doi = {10.1186/1687-1499-2014-135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928533824&doi=10.1186%2f1687-1499-2014-135&partnerID=40&md5=63e8e237834367498a20a10f2a7521cf},
	abstract = {Driver errors such as careless and aggressive driving behaviors are one of the key factors contributing to road traffic accidents. It is, therefore, essential that drivers are aware of their actions when they are in control of the wheel responsible for not only their own lives but also passengers and bystanders on the road. Driver monitoring and advanced driver assistance systems have already been utilized in fleet and logistic domain as well as built into high-end vehicles commercially available in the market. However, the majority of drivers on the road today do not have access to such systems. This paper proposes a novel methodology of driving event detection using a time series approximation algorithm known as symbolic aggregate approximation (SAX) on data collected from smartphone sensors. The use of smartphone allows the system to be easily accessible, widely available, and implemented at low cost. In addition, a resource usage exploration on a smartphone platform is conducted in order to demonstrate the flexibility of our proposed algorithm to match different smartphone specifications. Preliminary results from our experiments revealed that the precision of the proposed detection algorithm of aggressive driving events is fairly good as the precision values range from 50% to 100%. In terms of resource usage exploration, it has been found that there is a strong linear relationship between the parameter settings for data compression and the runtime of the algorithm. This is beneficial when a trade-off is required between the accuracy of the algorithm and the resource usage on the smartphone. © 2014, Chaovalit et al.; licensee Springer.},
	author_keywords = {Driving behavior; Driving event detection; SAX; Smartphone},
	keywords = {Accidents; Approximation algorithms; Automobile drivers; Economic and social effects; Fleet operations; Highway traffic control; Roads and streets; Smartphones; Aggressive driving; Aggressive driving behaviors; Detection algorithm; Driving behavior; Driving events; Linear relationships; Road traffic accidents; Symbolic aggregate approximation (SAX); Advanced driver assistance systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@ARTICLE{Matern201125,
	author = {Matern, Dierck and Condurache, Alexandru Paul and Mertins, Alfred},
	title = {Linear prediction based mixture models for event detection in video sequences},
	year = {2011},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {6669 LNCS},
	pages = {25 – 32},
	doi = {10.1007/978-3-642-21257-4_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960007427&doi=10.1007%2f978-3-642-21257-4_4&partnerID=40&md5=7da1edc398074802a26a0bf1e48aff5f},
	abstract = {In this paper, we propose a method for the detection of irregularities in time series, based on linear prediction. We demonstrate how we can estimate the linear predictor by solving the Yule Walker equations, and how we can combine several predictors in a simple mixture model. In several tests, we compare our model to a Gaussian mixture and a hidden Markov model approach. We successfully apply our method to event detection in a video sequence. © 2011 Springer-Verlag.},
	keywords = {Hidden Markov models; Image analysis; Pattern recognition; Time series; Video recording; Hidden Markov models; Image analysis; Markov processes; Signal detection; Trellis codes; Video recording; Event detection; Event detection in video; Gaussian mixtures; Linear prediction; Linear predictors; Markov model; Mixture model; Video sequences; Yule-walker equations; Event detection; Event detection in video; Gaussian mixtures; Linear prediction; Linear predictors; Mixture model; Video sequences; Yule-walker equations; Time series analysis; Pattern recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Yu2015329,
	author = {Yu, Shusi and Gu, Lei and Dai, Wentao},
	title = {Fast event detection on big time series},
	year = {2015},
	journal = {2014 IEEE/CIC International Conference on Communications in China, ICCC 2014},
	pages = {329 – 333},
	doi = {10.1109/ICCChina.2014.7008296},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922561531&doi=10.1109%2fICCChina.2014.7008296&partnerID=40&md5=8c7a42d0c80b85a7457848de003360f0},
	abstract = {Big data is exploding to facilitate our humans living by embedding smart devices everywhere, collecting realtime data, learning the daily habits and making the machines smarter. In addition to great advance in distributed computing with petabyte data, fast and real-time reaction on streaming data, which is know as fast event detection(FED) or anomaly detection, obtain wide attention which has a wide application in online fraud monitoring. In this paper, inspired by the time series analysis technique, a new algorithm of event detection is proposed to detect anomalous event. The proposed algorithm extensively reduce computation complexity of event detection from exponential to polynomial, which implies acceleration of more than thousand time. Verifications on four data sets confirm our theoretical prediction and promises fruitful results in further applications. © 2014 IEEE.},
	keywords = {Anomaly detection; Distributed computer systems; Anomalous events; Computation complexity; Event detection; Real time; Real-time data; Smart devices; Streaming data; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Wastian2013647,
	author = {Wastian, Matthias and Breitenecker, Felix and Landsiedl, Michael},
	title = {Using data mining and machine learning methods for server outage detection - Modelling normality and anomalies},
	year = {2013},
	journal = {25th European Modeling and Simulation Symposium, EMSS 2013},
	pages = {647 – 653},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886870174&partnerID=40&md5=059391ec624a4e447fdadca918b1b282},
	abstract = {This paper will discuss several approaches to detect abnormal events, which are considered to be worth further investigation by the modeler, in a time series of frequently collected data as early as possible and - wherever applicable - To predict them. The approaches to this task use various methods originating in the field of data mining, machine learning and soft computing in a hybrid manner. After a basic introduction including several areas of application, the paper will focus on the modular parts of the proposed methodology, starting with a discussion about different approaches to predict time series. After the presentation of several algorithms for outlier detection, which are applicable not only for time series, but also a chain of events, the results of the simulation gained in a project to detect server outages as early as possible are put up for discussion. The text ends with an outlook for possible future work. © 2013 DIME UNIVERSITÀ DI GENOVA.},
	author_keywords = {Abnormal event detection; Data mining; Machine learning; Prediction},
	keywords = {Computer simulation; Forecasting; Learning systems; Soft computing; Time series; Abnormal event detections; Machine learning methods; Outlier Detection; Possible futures; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bai20131,
	author = {Bai, Xue and Xiong, Yun and Zhu, Yangyong and Liu, Qi and Chen, Zhiyuan},
	title = {Co-anomaly event detection in multiple temperature series},
	year = {2013},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8041 LNAI},
	pages = {1 – 14},
	doi = {10.1007/978-3-642-39787-5_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880744294&doi=10.1007%2f978-3-642-39787-5_1&partnerID=40&md5=efdaa9754fe7d79570e6b90228856be5},
	abstract = {Co-anomaly event is one of the most significant climate phenomena characterized by the co-occurrent similar abnormal patterns appearing in different temperature series. Indeed, these co-anomaly events play an important role in understanding the abnormal behaviors and natural disasters in climate research. However, to the best of our knowledge the problem of automatically detecting co-anomaly events in climate is still under-addressed due to the unique characteristics of temperature series data. To that end, in this paper we propose a novel framework Sevent for automatic detection of co-anomaly climate events in multiple temperature series. Specifically, we propose to first map the original temperature series to symbolic representations. Then, we detect the co-anomaly patterns by statistical tests and finally generate the co-anomaly events that span different sub-dimensions and subsequences of multiple temperature series. We evaluate our detection framework on a real-world data set which contains rich temperature series collected by 97 weather stations over 11 years in Hunan province, China. The experimental results clearly demonstrate the effectiveness of Sevent. © 2013 Springer-Verlag Berlin Heidelberg.},
	author_keywords = {Co-anomaly Event; Event Mining; Time Series},
	keywords = {Artificial intelligence; Computer science; Computers; Time series; Abnormal behavior; Abnormal patterns; Automatic Detection; Detection framework; Event mining; Hunan province , China; Symbolic representation; Temperature series; Disasters},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hernandez-Garcia2011353,
	author = {Hernandez-Garcia, Luis and Ulfarsson, Magnus O.},
	title = {Neuronal event detection in fMRI time series using iterative deconvolution techniques},
	year = {2011},
	journal = {Magnetic Resonance Imaging},
	volume = {29},
	number = {3},
	pages = {353 – 364},
	doi = {10.1016/j.mri.2010.10.012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952538330&doi=10.1016%2fj.mri.2010.10.012&partnerID=40&md5=f7e19497d8849bdd28fc16d6adce8fb8},
	abstract = {An iterative estimation algorithm for deconvolution of neuronal activity from Blood Oxygen Level Dependent (BOLD) time series data is presented. The algorithm requires knowledge of the hemodynamic impulse response function but does not require knowledge of the stimulation function. The method uses majorization-minimization of a cost function to find an optimal solution to the inverse problem. The cost function includes penalties for the l1 norm, total variation and negativity. The algorithm is able to identify the occurrence of neuronal activity bursts from BOLD time series accurately. The accuracy of the algorithm was tested in simulations and experimental fMRI data using blocked and event-related designs. The simulations revealed that the algorithm is most sensitive to contrast-to-noise ratio levels and to errors in the assumed hemodynamic model and least sensitive to autocorrelation in the noise. Within normal fMRI conditions, the method is effective for event detection. © 2011 Elsevier Inc.},
	author_keywords = {Deconvolution; Event detection; FMRI; L1-norm; Non-negativity; Total variation},
	keywords = {Adult; Algorithms; Brain Mapping; Data Interpretation, Statistical; Evoked Potentials, Visual; Humans; Magnetic Resonance Imaging; Male; Neurons; Reproducibility of Results; Sensitivity and Specificity; Visual Cortex; Visual Perception; accuracy; algorithm; article; BOLD signal; controlled study; cost minimization analysis; event related potential; experimental design; functional magnetic resonance imaging; hemodynamics; priority journal; process model; sensitivity analysis; signal noise ratio; stimulus response; time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{2010,
	title = {Proceedings - 10th IEEE International Conference on Data Mining, ICDM 2010},
	year = {2010},
	journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951730098&partnerID=40&md5=07523e0ae64e3af8945c010c16506aa5},
	abstract = {The proceedings contain 158 papers. The topics discussed include: mining billion-node graphs: patterns, generators and tools; assessing the significance of groups in high-dimensional data; 10 years of data mining research: retrospect and prospect; detecting novel discrepancies in communication networks; multi-agent random walks for local clustering on graphs; spatiotemporal event detection in mobility network; an unsupervised approach to modeling personalized contexts of mobile users; fast and flexible multivariate time series subsequence search; abstraction augmented Markov models; a graph-based approach for multi-folder email classification; scalable influence maximization in social networks under the linear threshold model; finding local anomalies in very high dimensional space; sequential latent Dirichlet allocation: discover underlying topic structures within a document; and subgroup discovery meets Bayesian networks - an exceptional model mining approach.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kopsaftopoulos2013872,
	author = {Kopsaftopoulos, Fotis P. and Fassois, Spilios D.},
	title = {An adaptive time series framework for aircraft 4D trajectory conformance monitoring},
	year = {2013},
	journal = {2013 European Control Conference, ECC 2013},
	pages = {872 – 877},
	doi = {10.23919/ecc.2013.6669731},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893297614&doi=10.23919%2fecc.2013.6669731&partnerID=40&md5=ab2dec5874df89867837e5ffa23037b5},
	abstract = {The general problem of conformance monitoring with respect to preassigned 4-dimensional (4D) trajectories equipped with corresponding 4D margins (4D contracts) is considered within an adaptive statistical time series framework. The specific issues tackled within this context are: (a) Present conformance monitoring and quality of conformance evaluation via statistical tools, which also leads to abnormal event detection; (b) future conformance monitoring, in which the conformance is predicted ahead of time, allowing for potentially corrective or other actions. The performance of the developed methods is assessed via simulations. In present conformance monitoring, an alarm is shown to be issued instantaneously, following the emergence of an abnormal event. In future conformance monitoring, the comparison with a scheme based on nominal probabilistic trajectory prediction demonstrates the benefits of the adaptive statistical time series framework. © 2013 EUCA.},
	keywords = {Aircraft; Quality control; Statistical mechanics; Time series; Trajectories; 4D trajectories; Abnormal event detections; Conformance monitoring; Statistical tools; Trajectory prediction; Monitoring},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Oliker20121265,
	author = {Oliker, Nurit and Ostfeld, Avi},
	title = {A weighted support vector machine classifier for contamination event detection in water distribuation systems},
	year = {2012},
	journal = {14th Water Distribution Systems Analysis Conference 2012, WDSA 2012},
	volume = {2},
	pages = {1265 – 1272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883071032&partnerID=40&md5=0ce28699d97f47cd3b265dae276743e9},
	abstract = {This paper presents an application of a weighted support vector machine (SVM) for the problem of contamination event detection in water distribution systems (WDS). The method utilizes general water quality measurements to construct a classifier for detecting abnormal behaviour, which is believed to imply an occurrence of a contamination event. The paper new contribution is the simultaneous analysis of the multivariate data in a high dimensional space, differing from the onedimensional parallel analysis that was conducted previously. Weighted SVM extend the method by considering that different input vectors make different contributions to the classifier. The resulted weights vector obtains two goals: blurring the difference between the sizes of the two training classes' data sets, and dealing with the time series attribute. A time decay factor yields higher importance to recent observations in the model. The classifier is updated constantly and exploits an increasing data base. The method was applied on a real WDS dataset and showed promising results. Copyright © (2012) by Engineers Australia.},
	keywords = {Image retrieval; Systems analysis; Water distribution systems; Water quality; Abnormal behaviours; Contamination events; High dimensional spaces; Parallel analysis; Simultaneous analysis; Time-series attribute; Water quality measurement; Weighted support vector machine; Support vector machines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xie2013,
	author = {Xie, Ke and Xia, Chaolun and Grinberg, Nir and Schwartz, Raz and Naaman, Mor},
	title = {Robust detection of hyper-local events from geotagged social media data},
	year = {2013},
	journal = {Proceedings of the 13th International Workshop on Multimedia Data Mining, MDMKDD 2013 - Held in Conjunction with the ACM SIGKDD 2013 Conference},
	doi = {10.1145/2501217.2501219},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897480604&doi=10.1145%2f2501217.2501219&partnerID=40&md5=e0dff9f3dedaf58214f21bc6b8d1d317},
	abstract = {An increasing number of location-annotated content avail- able from social media channels like Twitter, Instagram, Foursquare and others are reflecting users' local activities and their attention like never before. In particular, we now have enough available data to start extracting real-time lo- cal information from social media. In this paper, we focus on the problem of hyper-local event detection, with the goal of enabling a monitoring and alerts system for public man- agement oficers, journalists and other users. We present a method for real-time hyper-local event detection from In- stagram photos data, using two computational steps. We first use time series analysis to detect abnormal signals in a small region. We then use a classifier to decide if the de- tected activity corresponds to an actual event. Testing on a large-scale dataset of New York City photos, our system detects hyper-local events with high accuracy. © Copyright 2013 ACM.},
	author_keywords = {Event detection; Social media},
	keywords = {Statistical tests; Time series analysis; Event detection; Large-scale dataset; Local activity; New York city; Robust detection; Small region; Social media; Social media datum; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@CONFERENCE{Lansdall-Welfare20121221,
	author = {Lansdall-Welfare, Thomas and Lampos, Vasileios and Cristianini, Nello},
	title = {Effects of the recession on public mood in the UK},
	year = {2012},
	journal = {WWW'12 - Proceedings of the 21st Annual Conference on World Wide Web Companion},
	pages = {1221 – 1226},
	doi = {10.1145/2187980.2188264},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861040061&doi=10.1145%2f2187980.2188264&partnerID=40&md5=88110332fb571394d00a985155326639},
	abstract = {Large scale analysis of social media content allows for real time discovery of macro-scale patterns in public opinion and sentiment. In this paper we analyse a collection of 484 million tweets generated by more than 9.8 million users from the United Kingdom over the past 31 months, a period marked by economic downturn and some social tensions. Our findings, besides corroborating our choice of method for the detection of public mood, also present intriguing patterns that can be explained in terms of events and social changes. On the one hand, the time series we obtain show that periodic events such as Christmas and Halloween evoke similar mood patterns every year. On the other hand, we see that a significant increase in negative mood indicators coincide with the announcement of the cuts to public spending by the government, and that this effect is still lasting. We also detect events such as the riots of summer 2011, as well as a possible calming effect coinciding with the run up to the royal wedding. Copyright is held by the International World Wide Web Conference Committee (IW3C2).},
	author_keywords = {Event detection; Mood analysis; Sentiment analysis; Social media; Twitter},
	keywords = {Hardware; Event detection; Mood analysis; Sentiment analysis; Social media; Twitter; World Wide Web},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 63}
}

@CONFERENCE{Min2011365,
	author = {Min, Cheol-Hong and Tewfik, Ahmed H.},
	title = {Semi-supervised event detection using higher order statistics for multidimensional time series accelerometer data},
	year = {2011},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	pages = {365 – 368},
	doi = {10.1109/IEMBS.2011.6090119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861955179&doi=10.1109%2fIEMBS.2011.6090119&partnerID=40&md5=64b988a058b6c1d85ec047b883956355},
	abstract = {In this study, we target to automatically detect stereotypical behavioral patterns (stereotypy) and self-injurious behaviors (SIB) of Autistic children which can lead to critical damages or wounds as they tend to repeatedly harm oneself. Our custom designed accelerometer based wearable sensors are placed at wrists, ankles and upper body to detect stereotypy and SIB. The analysis was done on four children diagnosed with ASD who showed repeated behaviors that involve part of the body such as flapping arms, body rocking and self-injurious behaviors such as punching their face, or hitting their legs. Our goal of detecting novel events relies on the fact that the limitation of training data and variability in the possible combination of signals and events also make it impossible to design a single algorithm to understand all events in natural setting. Therefore, a semi-supervised method to discover and track unknown events in a multidimensional sensor data rises as a very important topic in classification and detection problems. In this paper, we show how the Higher Order Statistics (HOS) features can be used to design dictionaries and to detect novel events in a multichannel time series data. We explain our methods to detect novel events in a multidimensional time series data and combine the proposed semi-supervised learning method to improve the adaptability of the system while maintaining comparable detection accuracy as the supervised method. We, compare our results to the supervised methods that we have previously developed and show that although semi-supervised method do not achieve better performance compared to supervised methods, it can efficiently find new events and anomalies in multidimensional time series data with similar performance of the supervised method. We show that our proposed method achieves recall rate of 93.3% compared to 94.1% for the supervised method studied earlier. © 2011 IEEE.},
	keywords = {Acceleration; Actigraphy; Child; Child Development Disorders, Pervasive; Data Interpretation, Statistical; Diagnosis, Computer-Assisted; Female; Humans; Male; Monitoring, Ambulatory; Reproducibility of Results; Sensitivity and Specificity; Accelerometers; Chemical detection; Damage detection; Sensors; Supervised learning; Accelerometer data; Autistic children; Behavioral patterns; Critical damage; Detection accuracy; Detection problems; Event detection; Higher order statistics; Multi-channel; Multidimensional time; Recall rate; Semi-supervised; Semi-supervised learning methods; Semi-supervised method; Sensor data; Time-series data; Training data; Wearable sensors; acceleration; actimetry; ambulatory monitoring; article; autism; child; computer assisted diagnosis; female; human; instrumentation; male; methodology; pathophysiology; reproducibility; sensitivity and specificity; statistical analysis; equipment; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Oliker2015558,
	author = {Oliker, Nurit and Ostfeld, Avi},
	title = {Comparison of two multivariate classification models for contamination event detection in water quality time series},
	year = {2015},
	journal = {Journal of Water Supply: Research and Technology - AQUA},
	volume = {64},
	number = {5},
	pages = {558 – 566},
	doi = {10.2166/aqua.2014.033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939138499&doi=10.2166%2faqua.2014.033&partnerID=40&md5=9243c1a8867d7517bf81cb8e9ca8065f},
	abstract = {This paper explores two applied classification models alerting for contamination events in water distribution systems. The models perform multivariate analysis of water quality online measurements for event detection. The developed models comprise an outlier detection algorithm and a following sequence analysis for the classification of events. The first model is an unsupervised minimum volume ellipsoid (MVE), which utilizes only normal operation measurements but requires calibration. The second is a supervised weighted support vector machine, which utilizes event examples and performs data-driven optimized calibration. The models were trained and tested on real water utility data with randomly simulated events that were superimposed on the original database. The models showed high accuracy and detection ability compared to previous studies. All in all, the MVE model achieved preferable results. © IWA Publishing 2015.},
	author_keywords = {Event detection; Minimum volume ellipsoid; Sequence analysis; Support vector machine; Water distribution systems; Water security},
	keywords = {Algorithms; Calibration; Data mining; Image retrieval; Multivariant analysis; Support vector machines; Water distribution systems; Water quality; Water supply systems; Event detection; Minimum volume ellipsoids; Multi variate analysis; Multivariate classification; Outlier detection algorithm; Sequence analysis; Water security; Weighted support vector machine; accuracy assessment; calibration; detection method; distribution system; multivariate analysis; software; support vector machine; time series; utility sector; water pollution; water quality; water supply; Quality control},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Fanaee-T2014113,
	author = {Fanaee-T, Hadi and Gama, Joao},
	title = {Event labeling combining ensemble detectors and background knowledge},
	year = {2014},
	journal = {Progress in Artificial Intelligence},
	volume = {2},
	number = {2-3},
	pages = {113 – 127},
	doi = {10.1007/s13748-013-0040-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040007509&doi=10.1007%2fs13748-013-0040-3&partnerID=40&md5=764a52df10bd0e72aac85c2d45b2d05e},
	abstract = {Event labeling is the process of marking events in unlabeled data. Traditionally, this is done by involving one or more human experts through an expensive and timeconsuming task. In this article we propose an event labeling system relying on an ensemble of detectors and background knowledge. The target data are the usage log of a real bike sharing system. We first label events in the data and then evaluate the performance of the ensemble and individual detectors on the labeled data set using ROC analysis and static evaluation metrics in the absence and presence of background knowledge. Our results show that when there is no access to human experts, the proposed approach can be an effective alternative for labeling events. In addition to the main proposal, we conduct a comparative study regarding the various predictive models performance, semi-supervised and unsupervised approaches, train data scale, time series filtering methods, online and offline predictive models, and distance functions in measuring time series similarity. © Springer-Verlag Berlin Heidelberg 2013.},
	author_keywords = {Background knowledge; Ensemble learning; Event detection; Event labeling},
	keywords = {Time series; Back-ground knowledge; Comparative studies; Distance functions; Ensemble learning; Event detection; Static evaluation; Time-consuming tasks; Unsupervised approaches; Predictive analytics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 177}
}

@CONFERENCE{Xu2012,
	author = {Xu, Jingxin and Denman, Simon and Sridharan, Sridha and Fookes, Clinton},
	title = {SAIVT-QUT@TRECViD 2012: Interactive surveillance event detection},
	year = {2012},
	journal = {2012 TREC Video Retrieval Evaluation Notebook Papers},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905241508&partnerID=40&md5=85fc10fdb2ad66e064c67c4c2703dd46},
	abstract = {1) Briefly, what approach or combination of approaches did you test in each of your submitted runs? -- We have only submitted 1 run to detect the events of 'PeopleMeet', 'PeopleSplitUp' and 'Embrace'. In our approach, the long video sequence is divided into a set of non-overlapping clips with a small temporal interval. Particle trajectories are approximated directly from the MPEG motion vector. The dense particle trajectories are further segmented into a sparse set of dominant trajectories. A histogram-based feature descriptor is proposed based on the angles among the piecewise trajectory-segments. A modified version of labelled LDA is applied to train a set of topics with a subset of topics reserved for the event of interest, and remainder used for the background activities. In the detection process, the system outputs the likelihood ratio, which can be viewed as a one-dimensional time series signal. The event of interest is detected using a watershed-like algorithm. 2) What if any significant differences (in terms of what measures) did you find among the runs? -- We only submitted a single run. 3) Based on the results, can you estimate the relative contribution of each component of your system/approach to its effectiveness? -- We have achieved real time performance by directly extracting features from compressed domain and limiting the size of the feature histogram to an acceptable size. We apply a modified version of labelled LDA to learn the feature for the event of interest which helps overcome the problem of the database only being temporally annotated (i.e. no location information). Following detection, the continuous tiny clips are grouped using a watershed-like algorithm to detect the event temporally. 4) Overall, what did you learn about runs/approaches and the research question(s) that motivated them? -- Our system achieves a level of performance similar to, or slightly above the state-of-the-art approaches for the detection of the 'PeopleMeet' and 'PeopleSplitUp' events. However, the results for the detection of the 'Embrace' event are poor. This is because the angles between piecewise representative trajectories fail to capture the features for the 'Embrace' event well. The proposed approach is also limited by the need to have the persons of interest moving within the sequence, as stationary people do not generate any trajectory features. However, the proposed feature from the compressed domain allows our system to run very fast, such that each iterative search (using pre-computed feature) can be completed within 1 seconds.},
	keywords = {Graphic methods; Image retrieval; Iterative methods; Motion Picture Experts Group standards; Watersheds; Histogram-based Feature Descriptor; Location information; One-dimensional time series; Particle trajectories; Persons of interests; Real time performance; Relative contribution; State-of-the-art approach; Trajectories},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Bennett20123355,
	author = {Bennett, D.P. and Cuss, R.J. and Vardon, P.J. and Harrington, J.F. and Philp, R.N. and Thomas, H.R.},
	title = {Data analysis toolkit for long-term, large-scale experiments},
	year = {2012},
	journal = {Mineralogical Magazine},
	volume = {76},
	number = {8},
	pages = {3355 – 3364},
	doi = {10.1180/minmag.2012.076.8.48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875741400&doi=10.1180%2fminmag.2012.076.8.48&partnerID=40&md5=0c85ddf0a06abb40ea2337ec037b29ba},
	abstract = {A new data analysis toolkit which is suitable for the analysis of large-scale, long-term datasets and the phenomenon/anomalies they represent is described. The toolkit aims to expose and quantify scientific information in a number of forms contained within a time-series based dataset in a quantitative and rigorous manner, reducing the subjectivity of observations made, thereby supporting the scientific observer. The features contained within the toolkit include the ability to handle non-uniform datasets, time-series component determination, frequency component determination, feature/event detection and characterization/parameterization of local behaviours. An application is presented of a case study dataset arising from the 'Lasgit' experiment. © 2012 The Mineralogical Society.},
	author_keywords = {Large dataset; Large-scale experiment; Lasgit; Non-uniform; Time-series analysis},
	keywords = {Geochemistry; Minerals; Analysis toolkits; Frequency components; Large dataset; Large scale experiments; Lasgit; Non-uniform; Scientific information; data set; experimental study; parameterization; quantitative analysis; time series analysis; Experiments},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Parent2011361,
	author = {Parent, Marc and Yuan, Li-Lian},
	title = {Automated detection and analysis of neuronal persistent activity},
	year = {2011},
	journal = {Journal of Neuroscience Methods},
	volume = {201},
	number = {2},
	pages = {361 – 367},
	doi = {10.1016/j.jneumeth.2011.08.029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053199731&doi=10.1016%2fj.jneumeth.2011.08.029&partnerID=40&md5=54c9ec1ee4fa918bece14f6ddb9c9e86},
	abstract = {Cortical neurons receive individual as well as synchronized synaptic events. The latter may drive a neuron into an active state where a persistently depolarized membrane potential lasts for several seconds. Visual inspection and manual detection of these persistent events is labor-intensive. We built a set of scripts in MATLAB with the goal of having a core software package for the systematic and objective detection of persistent neural activity out of large time-series data. This analysis software includes multiple steps, from a pre-processing stage, event detection, user-interactive detection reviewing, and filtering/graphing. Analysis scripts and brief usage information are freely available upon request. © 2011 Elsevier B.V.},
	author_keywords = {MATLAB; Software; Time-series analysis},
	keywords = {Action Potentials; Animals; Brain; Excitatory Postsynaptic Potentials; Membrane Potentials; Nerve Net; Organ Culture Techniques; Patch-Clamp Techniques; Prefrontal Cortex; Pyramidal Cells; Rats; Signal Processing, Computer-Assisted; Software; Software Validation; article; automation; brain cell; brain cortex; computer program; nerve cell; priority journal},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{20141,
	title = {6th International Conference on Computational Collective Intelligence, ICCCI 2014},
	year = {2014},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8733 LNAI},
	pages = {1 – 702},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032201753&partnerID=40&md5=e62b33d9e7e32d1b5a2c94e4c43a6b16},
	abstract = {The proceedings contain 70 papers. The special focus in this conference is on Computational Collective Intelligence. The topics include: Agreements technologies - towards sophisticated software agents; fuzzy splicing systems; a preference weights model for prioritizing software requirements; fuzzy logic-based adaptive communication management on wireless network; application of self-adapting genetic algorithms to generate fuzzy systems for a regression problem; analysis of profile convergence in personalized document retrieval systems; a recommendation system for scientific publication by discovering keyword relationships; grouping like-minded users based on text and sentiment analysis; a preferences based approach for better comprehension of user information needs; sustainable social shopping system; grey social networks - a facebook case study; event detection from social data stream based on time-frequency analysis; intelligent e-learning/tutoring - the flexible learning model in lms blackboard; building educational and marketing models of diffusion in knowledge and opinion transmission; semantic model of syllabus and learning ontology for intelligent learning system; creating collaborative learning groups in intelligent tutoring systems; method of driver state detection for safety vehicle by means of using pattern recognition; motion segmentation using optical flow for pedestrian detection from moving vehicle; enhanced face preprocessing and feature extraction methods robust to illumination variation and a cognitive integrated management support system for enterprises; combining time series and clustering to extract gamer profile evolution; rehandling problem of pickup containers under truck appointment system; emergent concepts on knowledge intensive processes and optimal partial rotation error for vehicle motion estimation based on omnidirectional camera.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Duan20111831,
	author = {Duan, Lei and Tang, Chang-Jie and Yang, Ning and Zuo, Jie and Wang, Yue and Zheng, Jiao-Ling and Xu, Kai-Kuo},
	title = {Concepts, tasks and research advances of intervention rule mining},
	year = {2011},
	journal = {Jisuanji Xuebao/Chinese Journal of Computers},
	volume = {34},
	number = {10},
	pages = {1831 – 1842},
	doi = {10.3724/SP.J.1016.2011.01831},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-81055129471&doi=10.3724%2fSP.J.1016.2011.01831&partnerID=40&md5=e3dc15fc6842cd4097b756547f0e7f89},
	abstract = {Intervention rule mining is an emerging data mining task, which is derived from the practice of intervention application. It aims at applying data mining techniques on detecting intervention events, discovering the best intervention time and intensity, and decision support for converting objects from undesirable state to desirable state. This paper introduces the research background, as well as the major related advances on intervention rule mining based on the four-year practice, and defines the task classification. Moreover, this paper surveys the research issues, difficulties and achievements in three aspects, i.e. intervention effect prediction, intervention method discovery, and unknown intervention event detection. Finally, this paper discusses the future work of intervention rule mining.},
	author_keywords = {Data mining; Data stream; Intervention rule; Time series; Uncertain data},
	keywords = {Decision support systems; Research; Time series; Data mining tasks; Data mining techniques; Data stream; Decision supports; Event detection; Intervention methods; Intervention rule; Research issues; Rule mining; Task classification; Uncertain datas; Undesirable state; Data mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Lampos2012,
	author = {Lampos, Vasileios and Cristianini, Nello},
	title = {Nowcasting events from the social web with statistical learning},
	year = {2012},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	volume = {3},
	number = {4},
	doi = {10.1145/2337542.2337557},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867410703&doi=10.1145%2f2337542.2337557&partnerID=40&md5=65d003d0304846fad62689b847846f33},
	abstract = {We present a general methodology for inferring the occurrence and magnitude of an event or phenomenon by exploring the rich amount of unstructured textual information on the social part of the Web. Having geotagged user posts on the microblogging service of Twitter as our input data, we investigate two case studies. The first consists of a benchmark problem, where actual levels of rainfall in a given location and time are inferred from the content of tweets. The second one is a real-life task, where we infer regional Influenzalike Illness rates in the effort of detecting timely an emerging epidemic disease. Our analysis builds on a statistical learning framework, which performs sparse learning via the bootstrapped version of LASSO to select a consistent subset of textual features from a large amount of candidates. In both case studies, selected features indicate close semantic correlation with the target topics and inference, conducted by regression, has a significant performance, especially given the short length -approximately one year- of Twitter's data time series. © 2012 ACM.},
	author_keywords = {Event detection; Feature selection; LASSO; Social network mining; Sparse learning; Twitter},
	keywords = {Epidemiology; Feature extraction; Semantics; Event detection; LASSO; Social Networks; Sparse learning; Twitter; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 147}
}

@CONFERENCE{Patri2014232,
	author = {Patri, Om P. and Panangadan, Anand V. and Chelmis, Charalampos and Prasanna, Viktor K.},
	title = {Extracting discriminative features for event-based electricity disaggregation},
	year = {2014},
	journal = {2014 IEEE Conference on Technologies for Sustainability, SusTech 2014},
	pages = {232 – 238},
	doi = {10.1109/SusTech.2014.7046249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946686773&doi=10.1109%2fSusTech.2014.7046249&partnerID=40&md5=3bb97aaf19fe441da405e93e1d5484c4},
	abstract = {We describe a novel method for electricity load disaggregation based on the machine learning method of time series shapelets. We frame the electricity disaggregation problem as that of event detection and event classification from time series data. We use existing shapelet-based algorithms to separate appliance activity periods (caused by switching on/off of appliances and denoted as events) from time periods without any such activity. We then identify which type of appliances in a household correspond to the events detected within the power consumption data. Such appliance-level feedback is critical for end-users in managing their energy use efficiently. We use the BLUED dataset for experimental evaluation of the proposed method. This dataset is a fully labeled publicly available dataset of electricity consumption of a household in the United States for one week, the data being recorded at a very high frequency and externally labeled with the times when specific appliances were switched on or off. The proposed approach is able to achieve approximately 98% accuracy for event detection and between 77% to 84% accuracy for event classification. The data segments that were identified as being most discriminative for electricity disaggregation are visually interpretable, and the appliances identified to be responsible for heavy energy consumption can be reported to consumers to encourage reduction in energy consumption. © 2014 IEEE.},
	keywords = {Artificial intelligence; Data visualization; Energy utilization; Equipment; Learning systems; Time series; Discriminative features; Electricity-consumption; Event classification; Experimental evaluation; Machine learning methods; Reduction in energy consumption; Time-series data; Very high frequency; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29}
}

@ARTICLE{Esmael2012392,
	author = {Esmael, Bilal and Arnaout, Arghad and Fruhwirth, Rudolf K. and Thonhauser, Gerhard},
	title = {Multivariate time series classification by combining trend-based and value-based approximations},
	year = {2012},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {7336 LNCS},
	number = {PART 4},
	pages = {392 – 403},
	doi = {10.1007/978-3-642-31128-4_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863894878&doi=10.1007%2f978-3-642-31128-4_29&partnerID=40&md5=5fbfcad37e6e70ec859ab799588c3703},
	abstract = {Multivariate time series data often have a very high dimensionality. Classifying such high dimensional data poses a challenge because a vast number of features can be extracted. Furthermore, the meaning of the normally intuitive term "similar to" needs to be precisely defined. Representing the time series data effectively is an essential task for decision-making activities such as prediction, clustering and classification. In this paper we propose a feature-based classification approach to classify real-world multivariate time series generated by drilling rig sensors in the oil and gas industry. Our approach encompasses two main phases: representation and classification. For the representation phase, we propose a novel representation of time series which combines trend-based and value-based approximations (we abbreviate it as TVA). It produces a compact representation of the time series which consists of symbolic strings that represent the trends and the values of each variable in the series. The TVA representation improves both the accuracy and the running time of the classification process by extracting a set of informative features suitable for common classifiers. For the classification phase, we propose a memory-based classifier which takes into account the antecedent results of the classification process. The inputs of the proposed classifier are the TVA features computed from the current segment, as well as the predicted class of the previous segment. Our experimental results on real-world multivariate time series show that our approach enables highly accurate and fast classification of multivariate time series. © 2012 Springer-Verlag.},
	author_keywords = {Event Detection; Symbolic Aggregate Approximation; Time Series Classification; Time Series Representation},
	keywords = {Gas industry; Classification process; Compact representation; Event detection; Fast classification; Feature-based classification; High dimensional data; High dimensionality; Multivariate time series; Oil and Gas Industry; Running time; Series representations; Symbolic Aggregate Approximation; Time series classifications; Time-series data; Value-based; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37}
}

@CONFERENCE{Al Bitar2010,
	author = {Al Bitar, Ahmad and Jacquette, Elsa and Kerr, Yann and Mialon, Arnaud and Cabot, Francois and Quesney, Arnaud and Merlin, Olivier and Richaume, Philippe},
	title = {Event detection of hydrological processes with passive L-band data from SMOS},
	year = {2010},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {7824},
	doi = {10.1117/12.865074},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649752493&doi=10.1117%2f12.865074&partnerID=40&md5=397567a9fafdea6d1fc304daf6fa4ba5},
	abstract = {Since it's launch, the ESA's Soil Moisture and Ocean Salinity (SMOS) satellite, is delivering new data from its LBand 1.4Ghz 2D interferometer [1]. The observations from SMOS are used to retrieve soil moisture in the first centimeters and ocean salinity at the surface of the water. The observations are multi-angular with a 3 days maximum revisit time. The spatial resolution of SMOS data is 40km. In this paper we present on event detection algorithm implemented at CATDS (Centre Aval de Traitement des Données SMOS) the CNES level 3 and level 4 SMOS enter. This algorithm is a three stage change detection algorithm. At stage one the possibility/probability of occurrence of the event is evaluated. This is done via spatiotemporal constraints maps. These maps are obtained from the analysis of NSIDC's freezing index products over the last century. Climate data from ancillary files are tested will taking into consideration the uncertainty of the data. Some selected retrieved variables are also tested. At stage two a time series analysis is applied. In the current version of the algorithm a direct change detection algorithm is used. The tests make use of available variables of polarization index, retrieved soil moisture...Finally at stage three a simple fuzzy logic approach is used to decide if the event occurred. This approaches takes into consideration the separation time of the data. Ascending and descending orbits are taken into consideration. In this study freezing detection is presented over central CONUS. The temporal and angular signature of SMOS will be presented. Comparison is done with the SCAN network © 2010 Copyright SPIE - The International Society for Optical Engineering.},
	author_keywords = {calibration/validation; event detection; freeze; L-Band; SMOS; soil moisture},
	keywords = {Agriculture; Algorithms; Ecosystems; Freezing; Fuzzy logic; Hydrology; Moisture determination; Remote sensing; Salinity measurement; Signal detection; Soil moisture; Time series; Water; Calibration/validation; Event detection; freeze; L-Band; SMOS; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Gál201587,
	author = {Gál, Zoltán and Tajti, Tibor and Terdik, György},
	title = {Surprise event detection of the supercomputer execution queues},
	year = {2015},
	journal = {Annales Mathematicae et Informaticae},
	volume = {44},
	pages = {87 – 97},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930741953&partnerID=40&md5=b92259313e83118677707d87965ee10c},
	abstract = {Huge amount of data is generated by and collected from the IoT (Internet of Things) physical and virtual devices. These sets of data series reflect in complex form the state of a given system in multidimensional space. Healthiness evaluation of a given system implies state analysis with enhanced methods. Special events can appear during the execution of jobs in a supercomputer (HPC – High Performance Computer) system. Depending on the HPC architecture hundreds or even thousands of computation nodes are working in parallel. The scheduler of the HPC front-end node manages different queues (parallel, serial, test, etc.) of the job execution. The multitude of data series captured periodically with several tens of thousands of samples creates a set of several dozen variables for each computation node. The healthiness of the whole HPC system is a temporal concept in the term of 2D or 4D multidimensional time-space domains. In this paper we propose a healthiness evaluation method for each execution queue of two different HPC system with 20 TFLOP/s and 5 TFLOP/s computation capacities, respectively. Time independent community structure is determined and controlled based on multiple similarity measures and ANN (Artificial Neural Network) based SOM (Self-Organized Map) algorithm. For each cluster of variables is determined a representing variable, including time specific and global characteristics of the own cluster. The resulting set of representing variables contains less than ten dissimilar time series. Wavelet methods are used for extreme event detection in time of each representing variable. The surprise event detection in time of the HPC execution queues is based on the simultaneity of extreme events’ fingerprints. © 2015, Eszterhazy Karoly College. All rights reserved.},
	author_keywords = {Artificial neural networks; Complex event processing; Event stream processing; FFT; High performance computer; IoT; Sensors/actuators; SOM; STFT; Wavelets},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Oehmcke2015279,
	author = {Oehmcke, Stefan and Zielinski, Oliver and Kramer, Oliver},
	title = {Event detection in marine time series data},
	year = {2015},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9324},
	pages = {279 – 286},
	doi = {10.1007/978-3-319-24489-1_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951875266&doi=10.1007%2f978-3-319-24489-1_24&partnerID=40&md5=0aa2abab4995579bd9ab89999a89646e},
	abstract = {Automatic detection of special events in large data is often more interesting for data analysis than regular patterns. In particular, the processes in multivariate time series data can be better understood, if a deviation from the normal behavior is found. In this work, we apply a machine learning event detection method to a new application in the marine domain. The marine long-term data from the stationary plat- form at Spiekeroog, called Time Series Station, are a challenge, because noise, sensor drifts and missing data complicate analysis of the data. We acquire labels for evaluation with help of experts and test different approaches, which include time context into patterns. The used event detection method is local outlier factor (LOF). To improve results, we apply dimensionality reduction to the data. The analysis of the results shows, that the machine learning techniques can find special events, which are of interest to experts in the field. © Springer International Publishing Switzerland 2015.},
	author_keywords = {Anomaly detection; Event detection; LOF; Marine systems; Time series; Wadden sea},
	keywords = {Artificial intelligence; Learning systems; Time series; Anomaly detection; Event detection; LOF; Marine systems; Wadden Sea; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@CONFERENCE{Simonov2015,
	author = {Simonov, Mikhail},
	title = {Coarse-grained cycle-accurate electricity metering},
	year = {2015},
	journal = {IEEE PES Innovative Smart Grid Technologies Conference Europe},
	volume = {2015-January},
	number = {January},
	doi = {10.1109/ISGTEurope.2014.7028791},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936972118&doi=10.1109%2fISGTEurope.2014.7028791&partnerID=40&md5=dbb5e3c1d6cea2057721c8981e9bd32b},
	abstract = {This article reviews different approaches to electricity metering and proposes novel coarse-grained but cycle-accurate measurement method which preserves the existing Legacy billing applications but supplies historical series of true RMS measurements. New method traces energy variations with cycle-accuracy. To reduce the quantity of data but keep high precision, it uses geometric integration. It transmits accumulated time-series upon timer-driven events. The method is designed in a way to remain compliant with the open APIs developed by Future Internet PPP projects FINESCE and FI-WARE. The proposed approach bridges the Legacy approach and the service-oriented one. © 2014 IEEE.},
	author_keywords = {Electricity metering; Energy management; Event detection; Smart grids},
	keywords = {Electric measuring instruments; Electric power transmission networks; Energy management; Electricity metering; Energy variations; Event detection; Future internet; Geometric integration; Legacy approach; Service Oriented; Smart grid; Smart power grids},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Batal2012280,
	author = {Batal, Iyad and Fradkin, Dmitriy and Harrison, James and Moerchen, Fabian and Hauskrecht, Milos},
	title = {Mining recent temporal patterns for event detection in multivariate time series data},
	year = {2012},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {280 – 288},
	doi = {10.1145/2339530.2339578},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866050050&doi=10.1145%2f2339530.2339578&partnerID=40&md5=1edabd3b8553f39ed0a0fe4b1bd836c1},
	abstract = {Improving the performance of classifiers using pattern mining techniques has been an active topic of data mining research. In this work we introduce the recent temporal pattern mining framework for finding predictive patterns for monitoring and event detection problems in complex multivariate time series data. This framework first converts time series into time-interval sequences of temporal abstractions. It then constructs more complex temporal patterns backwards in time using temporal operators. We apply our framework to health care data of 13,558 diabetic patients and show its benefits by efficiently finding useful patterns for detecting and diagnosing adverse medical conditions that are associated with diabetes. © 2012 ACM.},
	author_keywords = {event detection; patient classification; temporal abstractions; temporal pattern mining; time-interval patterns},
	keywords = {Abstracting; Diagnosis; Health care; Time series; Diabetic patient; Event detection; Medical conditions; Multivariate time series; Pattern mining; Performance of classifier; Temporal abstraction; Temporal operators; Temporal pattern; Temporal pattern minings; Time-interval patterns; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 128; All Open Access, Green Open Access}
}

@ARTICLE{Gangwar2010168,
	author = {Gangwar, Dheerendra Singh and Saini, Davinder Singh},
	title = {Arrogyam: Arrhythmia detection for ambulatory patient monitoring},
	year = {2010},
	journal = {Communications in Computer and Information Science},
	volume = {95 CCIS},
	number = {PART 2},
	pages = {168 – 180},
	doi = {10.1007/978-3-642-14825-5_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956991005&doi=10.1007%2f978-3-642-14825-5_15&partnerID=40&md5=ea3d3a86f7812fc4de4fecffda075717},
	abstract = {Biomedical Sensor Networks are event driven systems that rely on collective efforts of several sensor nodes. These nodes are used for acquisition of physiological information to monitor health status and physical wellbeing of an individual specifically suffering from chronic diseases. The reliable event detection for such networks is based on multi-sensor data fusion. The physiological signals are multi-dimensional and multi-parametric in nature. The major objective of this paper is to discuss challenges and opportunities for developing an ambulatory patient monitoring system. The proposed prototype model addresses design and development issues required to report any severe condition related to cardiovascular malfunctioning without compromising mobility and convenience of the patient. The analysis of fused cardio-respiratory time series data requires dimensionality reduction before drawing detection decisions related to cardiac arrhythmia. This paper briefs about a simulation model of arrhythmia detection for ambulatory patient monitoring. The early detection of cardiovascular risk factors can reduce expected cost pressure on healthcare and enhance social security issues. © 2010 Springer-Verlag Berlin Heidelberg.},
	author_keywords = {Base unit; cardiac arrhythmia; IEEE 802.15.4/ZigBee; physiological signals; sensor node},
	keywords = {Biosensors; Computer simulation; Health risks; Patient monitoring; Physiology; Sensor nodes; Signal detection; Telecommunication equipment; Time series; Time series analysis; Ambulatory patients; Arrhythmia detection; Base unit; Biomedical sensors; Cardiac arrhythmia; Cardio-vascular risk factors; Chronic disease; Design and Development; Dimensionality reduction; Early detection; Event detection; Event-driven system; Expected costs; Health status; IEEE 802.15.4; Multisensor data fusion; Physiological signals; Prototype models; Simulation model; Social Security; Time-series data; Wellbeing; Sensor data fusion},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Blocker2013177,
	author = {Blocker, Alexander W. and Protopapas, Pavlos},
	title = {Semi-parametric robust event detection for massive time-domain databases},
	year = {2013},
	journal = {Information Systems Development: Reflections, Challenges and New Directions},
	pages = {177 – 187},
	doi = {10.1007/978-1-4614-3520-4-16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894350065&doi=10.1007%2f978-1-4614-3520-4-16&partnerID=40&md5=bc0e4df0cb7c706f4f3e8410c23f0807},
	abstract = {The detection and analysis of events within massive collections of time-series has become an extremely important task for time-domain astronomy. In particular, many scientific investigations (e.g. the analysis of microlensing and other transients) begin with the detection of isolated events in irregularly-sampled series with both non-linear trends and non-Gaussian noise. We outline a semiparametric, robust, parallel method for identifying variability and isolated events at multiple scales in the presence of the above complications. This approach harnesses the power of Bayesian modeling while maintainingmuch of the speed and scalability of more ad-hoc machine learning approaches.We also contrast this work with event detection methods from other fields, highlighting the unique challenges posed by astronomical surveys. Finally, we present results from the application of this method to 87.2 million EROS-2 sources, where we have obtained a greater than 100-fold reduction in candidates for certain types of phenomena while creating high-quality features for subsequent analyses. © Springer Science+Business Media New York 2013.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lawhern2013,
	author = {Lawhern, Vernon and Hairston, W. David and Robbins, Kay},
	title = {DETECT: A MATLAB Toolbox for Event Detection and Identification in Time Series, with Applications to Artifact Detection in EEG Signals},
	year = {2013},
	journal = {PLoS ONE},
	volume = {8},
	number = {4},
	doi = {10.1371/journal.pone.0062944},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876519096&doi=10.1371%2fjournal.pone.0062944&partnerID=40&md5=692dab910bd631270ff85f6534f040ef},
	abstract = {Recent advances in sensor and recording technology have allowed scientists to acquire very large time-series datasets. Researchers often analyze these datasets in the context of events, which are intervals of time where the properties of the signal change relative to a baseline signal. We have developed DETECT, a MATLAB toolbox for detecting event time intervals in long, multi-channel time series. Our primary goal is to produce a toolbox that is simple for researchers to use, allowing them to quickly train a model on multiple classes of events, assess the accuracy of the model, and determine how closely the results agree with their own manual identification of events without requiring extensive programming knowledge or machine learning experience. As an illustration, we discuss application of the DETECT toolbox for detecting signal artifacts found in continuous multi-channel EEG recordings and show the functionality of the tools found in the toolbox. We also discuss the application of DETECT for identifying irregular heartbeat waveforms found in electrocardiogram (ECG) data as an additional illustration.},
	keywords = {Artifacts; Electroencephalography; Humans; Medical Informatics; Models, Statistical; Reproducibility of Results; Support Vector Machines; User-Computer Interface; accuracy; article; calculation; computer prediction; computer program; controlled study; electrocardiogram; electroencephalogram; heart beat; information processing; information retrieval; intermethod comparison; machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 39; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Arnaout2012508,
	author = {Arnaout, Arghad and Esmael, Bilal and Fruhwirth, Rudolf K. and Thonhauser, Gerhard},
	title = {Drilling events detection using hybrid intelligent segmentation algorithm},
	year = {2012},
	journal = {Proceedings of the 2012 12th International Conference on Hybrid Intelligent Systems, HIS 2012},
	pages = {508 – 511},
	doi = {10.1109/HIS.2012.6421386},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874134839&doi=10.1109%2fHIS.2012.6421386&partnerID=40&md5=5cdced0df87598ea0baa2520dfc75f9c},
	abstract = {Several sensor measurements are collected from drilling rig during oil well drilling process. These measurements carry information not only about the operational states of the drilling rig but also about all higher level operations and activities performed by drilling crew. Automatic detection and classification of such drilling operations and states is considered as a big challenge in drilling industry. Furthermore, the possibility of detecting such events opens the door to detect and analyze hidden lost time of the drilling process. This paper presents a novel algorithm for drilling time series segmentation using Expectation Maximization and Piecewise Linear Approximation algorithms. The suggested algorithm shows that the incorporation of prior-knowledge about the drilling process is a key step to segment drilling time series successfully. The Expectation Maximization algorithm is used to segment drilling time series based on hook-load sensor measurements. In addition, Piecewise Linear Approximation is hired in our approach to slice standpipe pressure, pump flow rate and rotational speed (RPM) and torque of the top drive motor. Merging the results from both, Expectation Maximization and Piecewise Linear Approximation, gives the suggested algorithm the dynamic ability to detect all drilling events and activities. © 2012 IEEE.},
	author_keywords = {Drilling Events Detection; Expectation Maximization; Piecewise Linear Approximation; Timeseries Segmentation},
	keywords = {Drilling rigs; Image segmentation; Intelligent systems; Maximum principle; Oil well drilling; Piecewise linear techniques; Sensors; Time series; Torque motors; Water towers; Automatic Detection; Drilling crew; Drilling industry; Drilling operation; Drilling process; Drilling time; Drive motors; Events detection; Expectation - maximizations; Expectation-maximization algorithms; Intelligent segmentation; Novel algorithm; Operational state; Piecewise linear approximations; Prior-knowledge; Pump flow rate; Rotational speed; Sensor measurements; Time-series segmentation; Approximation algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Liu2013235,
	author = {Liu, Yang and Hou, Dibo and Huang, Pingjie and Zhang, Guangxin},
	title = {Multiscale water quality contamination events detection based on sensitive time scales reconstruction},
	year = {2013},
	journal = {International Conference on Wavelet Analysis and Pattern Recognition},
	pages = {235 – 240},
	doi = {10.1109/ICWAPR.2013.6599323},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885439165&doi=10.1109%2fICWAPR.2013.6599323&partnerID=40&md5=e95d2596cf53a9d139c8a44c578d42dd},
	abstract = {With the help of statistical technology and artificial intelligence algorithms, online water quality monitoring and detecting have significant importance to national water security. This paper proposed amulti-scale and multivariate water quality event detection approach for detecting accidental or intentional water contamination events. The approach is based on the ensemble empirical mode decomposition (EEMD), which is a novel algorithm for the analysis of nonstationary and nonlinear data of the type used in this paper. With EEMD as a dyadic filter bank, original water quality time series are decomposed into a sequence of intrinsic mode functions (IMFs). The local time scale is an important feature for statistical analysis and multi-scale representation. In this paper, the fluctuation characteristic for newly available measurements is estimated dynamically, and the corresponding membership degree to the constructed time scale reference which depends on offline long-term normal data analysis is calculated with Gaussian fuzzy logic. Taking the various membership as weight values, the anomalous signal can be enhanced and sifted out by the selection and reconstruction of sensitive time scales. Compared with traditional water quality detection methods with receiver operating characteristic (ROC) curves, the proposed multi-scale method can improve the detection accuracy and reduce the false rate. © 2013 IEEE.},
	author_keywords = {Empirical mode decomposition; Event detection; Fuzzy logic; Multi-scale; Water quality},
	keywords = {Algorithms; Artificial intelligence; Filter banks; Fuzzy logic; Image retrieval; Pattern recognition; Time measurement; Water pollution; Wavelet analysis; Artificial intelligence algorithms; Empirical Mode Decomposition; Ensemble empirical mode decompositions (EEMD); Event detection; Fluctuation characteristics; Multi-scale; Multiscale representations; Receiver operating characteristic curves; Water quality},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Kapetanidis2011889,
	author = {Kapetanidis, V. and Papadimitriou, P.},
	title = {Estimation of arrival-times in intense seismic sequences using a Master-Events methodology based on waveform similarity},
	year = {2011},
	journal = {Geophysical Journal International},
	volume = {187},
	number = {2},
	pages = {889 – 917},
	doi = {10.1111/j.1365-246X.2011.05178.x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054696211&doi=10.1111%2fj.1365-246X.2011.05178.x&partnerID=40&md5=ed4b7bb849c0285ff43111333a5ce29c},
	abstract = {Intense seismic sequences involve a large number of earthquakes densely clustered in space and time. Their detailed analysis is important for the geometry of the activated faults, which contributes to studies of the seismotectonic characteristics of an area. The sheer number of small events as well as their low energy content renders their processing problematic. In this work, we have developed and applied a methodology to automatically pick the arrival-times of P- and S-waves using a correlation detector. Event detection is performed using the waveform recordings of a reference station located close to the epicentral area of an intense seismic sequence such as aftershocks or swarms. Cross-correlation matrices are constructed, followed by nearest-neighbour clustering and the formation of multiplets. A Master-Event is chosen from each cluster and its arrival-times are picked manually. The automatic algorithm uses the P- or S-wave of each Master-Event as a correlation detector, searches the waveforms of the other events of the same multiplet and imposes the corresponding arrival-time when the best fit is achieved. The picks are characterized by observation weights, which derive from the quality of the fit, the type of the available waveform components and the consistency between multiple measurements. The proposed methodology was applied to an important seismic sequence that occurred between 2010 January 18 and 26 near the city of Efpalio, Greece. This procedure has the potential to increase 10-fold the amount of information and provide sufficient detail for a subsequent analysis of the spatiotemporal distribution of a seismic series. © 2011 The Authors Geophysical Journal International © 2011 RAS.},
	author_keywords = {Computational seismology; Seismicity and tectonics; Time series analysis},
	keywords = {Correlation detectors; Shear waves; Tectonics; Time series; Time series analysis; Amount of information; Automatic algorithms; Best fit; Computational seismology; Cross correlations; Epicentral area; Event detection; Low energies; Multiple measurements; Nearest-neighbour; P- and S-waves; Reference stations; Seismic sequence; Seismicity and tectonics; Seismotectonics; Space and time; Spatiotemporal distributions; Wave forms; Waveform components; Waveform recording; Waveform similarity; aftershock; algorithm; arrival time; earthquake epicenter; estimation method; fault geometry; P-wave; S-wave; seismicity; seismology; seismotectonics; spatiotemporal analysis; time series analysis; waveform analysis; Seismology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Bronze Open Access}
}

@ARTICLE{Perelman20128212,
	author = {Perelman, Lina and Arad, Jonathan and Housh, Mashor and Ostfeld, Avi},
	title = {Event detection in water distribution systems from multivariate water quality time series},
	year = {2012},
	journal = {Environmental Science and Technology},
	volume = {46},
	number = {15},
	pages = {8212 – 8219},
	doi = {10.1021/es3014024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864723225&doi=10.1021%2fes3014024&partnerID=40&md5=304daf3aa11df9eaf53b60bfd7079180},
	abstract = {In this study, a general framework integrating a data-driven estimation model with sequential probability updating is suggested for detecting quality faults in water distribution systems from multivariate water quality time series. The method utilizes artificial neural networks (ANNs) for studying the interplay between multivariate water quality parameters and detecting possible outliers. The analysis is followed by updating the probability of an event, initially assumed rare, by recursively applying Bayes' rule. The model is assessed through correlation coefficient (R2), mean squared error (MSE), confusion matrices, receiver operating characteristic (ROC) curves, and true and false positive rates (TPR and FPR). The product of the suggested methodology consists of alarms indicating a possible contamination event based on single and multiple water quality parameters. The methodology was developed and tested on real data attained from a water utility. © 2012 American Chemical Society.},
	keywords = {Learning algorithms; Mean square error; Neural networks; Probability distributions; Time series; Water quality; chlorine; Confusion matrices; Contamination events; Correlation coefficient; Estimation models; False positive rates; Mean squared error; Receiver Operating Characteristic (ROC) curves; Water quality parameters; artificial neural network; correlation; detection method; distribution system; multivariate analysis; probability; time series; water quality; article; artificial neural network; Bayes theorem; correlation coefficient; pH; turbidity; waste management; water contamination; water quality; water supply; water temperature; Water distribution systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 125}
}

@CONFERENCE{Xia2014167,
	author = {Xia, Chaolun and Schwartz, Raz and Xie, Ke and Krebs, Adam and Langdon, Andrew and Ting, Jeremy and Naaman, Mor},
	title = {CityBeat: Real-time social media visualization of hyper-local city data},
	year = {2014},
	journal = {WWW 2014 Companion - Proceedings of the 23rd International Conference on World Wide Web},
	pages = {167 – 170},
	doi = {10.1145/2567948.2577020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990946612&doi=10.1145%2f2567948.2577020&partnerID=40&md5=b5401c03099a81f797f69b76c99d0583},
	abstract = {With the increasing volume of location-annotated content from various social media platforms like Twitter, Instagram and Foursquare, we now have real-time access to people's daily documentation of local activities, interests and atten- Tion. In this demo paper, we present CityBeat1, a real-time visualization of hyper-local social media content for cities. The main objective of CityBeat is to provide users - with a specific focus on journalists - with information about the city's ongoings, and alert them to unusual activities. The system collects a stream of geo-tagged photos as input, uses time series analysis and classification techniques to detect hyper-local events, and compute trends and statistics. The demo includes a visualization of this information that is de- signed to be installed on a large-screen in a newsroom, as an ambient display. © Copyright 2014 by the International World Wide Web Conferences Steering Committee.},
	author_keywords = {Data mining; Event detection; Social media; Visualization},
	keywords = {Data mining; Flow visualization; Social networking (online); Time series; Time series analysis; Visualization; World Wide Web; Ambient displays; Classification technique; Event detection; Local activity; Real time visualization; Real-time access; Social media; Social media platforms; Data visualization},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 66}
}

@CONFERENCE{Kühnert2015901,
	author = {Kühnert, Christian and Baruthio, Marc and Bernard, Thomas and Steinmetz, Claude and Weber, Jean-Marc},
	title = {Cloud-based event detection platform for water distribution networks using machine-learning algorithms},
	year = {2015},
	journal = {Procedia Engineering},
	volume = {119},
	number = {1},
	pages = {901 – 907},
	doi = {10.1016/j.proeng.2015.08.963},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941044539&doi=10.1016%2fj.proeng.2015.08.963&partnerID=40&md5=96a564129b8026e371484263d6ee5cee},
	abstract = {Modern water distribution networks are equipped with a large amount of sensors to monitor the drinking water quality. To detect anomalies, usually each sensor contains its own threshold, but machine-learning algorithms become an alternative to reduce the parametrization effort. Still, one reason why they are not used in practice is the geographical restricted data access. Data is stored at the plant, but data scientists needed for the data analysis are situated elsewhere. To overcome this challenge, this paper proposes a cloud-based event-detection and reporting platform, which provides a possibility to use machine learning algorithms. The plants measurements are cyclically transferred into a secure cloud service where they are downloaded and analyzed from the data scientist. Results are made available as reports. © 2015 The Authors. Published by Elsevier Ltd.},
	author_keywords = {Cloud-based service; Event-detection; Machine-learning; Time series analysis},
	keywords = {Climate change; Learning systems; Machine learning; Potable water; Time series analysis; Water distribution systems; Water quality; Cloud services; Cloud-based; Data access; Event detection; Large amounts; Parametrizations; Water distribution networks; Learning algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Mounce2014617,
	author = {Mounce, S.R. and Mounce, R.B. and Jackson, T. and Austin, J. and Boxall, J.B.},
	title = {Pattern matching and associative artificial neural networks for water distribution system time series data analysis},
	year = {2014},
	journal = {Journal of Hydroinformatics},
	volume = {16},
	number = {3},
	pages = {617 – 632},
	doi = {10.2166/hydro.2013.057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901028729&doi=10.2166%2fhydro.2013.057&partnerID=40&md5=72f379de62841c49b0c14c62c967ed80},
	abstract = {Water distribution systems, and other infrastructures, are increasingly being pervaded by sensing technologies, collecting a growing volume of data aimed at supporting operational and investment decisions. These sensors monitor system characteristics, i.e. flows, pressures and water quality, such as in pipes. This paper presents the application of pattern matching techniques and binary associative neural networks for novelty detection in such data. A protocol for applying pattern matching to automatically recognise specific waveforms in time series based on their shapes is described together with a system called Advanced Uncertain Reasoning Architecture (AURA) Alert for autonomous determination of novelty. AURA is a class of binary neural network that has a number of advantages over standard artificial neural network techniques for condition monitoring including a sound theoretical basis to determine the bounds of the system operation. Results from application to several case studies are provided including both hydraulic and water quality data. In the case of pattern matching, the results demonstrated some transferability of burst patterns across District Metered Areas; however limitations in performance and difficulties with assembling pattern libraries were found. Results for the AURA system demonstrate the potential for robust event detection across multiple parameters providing valuable information for diagnosis; one example also demonstrates the potential for detection of precursor information, vital for proactive management. © IWA Publishing 2014.},
	author_keywords = {Asset monitoring; Auto-associative neural network; Event detection system; Pattern matching; Water distribution systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 46; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Harris20101455,
	author = {Harris, David B. and Kvaerna, Tormod},
	title = {Superresolution with seismic arrays using empirical matched field processing},
	year = {2010},
	journal = {Geophysical Journal International},
	volume = {182},
	number = {3},
	pages = {1455 – 1477},
	doi = {10.1111/j.1365-246X.2010.04684.x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955733290&doi=10.1111%2fj.1365-246X.2010.04684.x&partnerID=40&md5=c6b85cf2e23131cd243ffcce705cbd5a},
	abstract = {Scattering and refraction of seismic waves can be exploited with empirical-matched field processing of array observations to distinguish sources separated by much less than the classical resolution limit. To describe this effect, we use the term 'superresolution', a term widely used in the optics and signal processing literature to denote systems that break the diffraction limit. We illustrate superresolution with Pn signals recorded by the ARCES array in northern Norway, using them to identify the origins with 98.2 per cent accuracy of 549 explosions conducted by closely spaced mines in northwest Russia. The mines are observed at 340-410 km range and are separated by as little as 3 km. When viewed from ARCES many are separated by just tenths of a degree in azimuth. This classification performance results from an adaptation to transient seismic signals of techniques developed in underwater acoustics for localization of continuous sound sources. Matched field processing is a potential competitor to frequency-wavenumber (FK) and waveform correlation methods currently used for event detection, classification and location. It operates by capturing the spatial structure of wavefields incident from a particular source in a series of narrow frequency bands. In the rich seismic scattering environment, closely spaced sources far from the observing array nonetheless produce distinct wavefield amplitude and phase patterns across the small array aperture. With observations of repeating events, these patterns can be calibrated over a wide band of frequencies (e.g. 2.5-12.5 Hz) for use in a power estimation technique similar to frequency-wavenumber analysis. The calibrations enable coherent processing at high frequencies at which wavefields normally are considered incoherent under a plane-wave model. No claim to original US government works Journal compilation © 2010 RAS.},
	author_keywords = {Body waves; Persistence, memory, correlations, clustering; Seismic monitoring and test-ban treaty verification; Statistical seismology; Time series analysis; Wave scattering and diffraction},
	keywords = {Norway; Russian Federation; Correlation methods; Diffraction; Electromagnetic wave scattering; Frequency bands; Frequency estimation; Optical resolving power; Seismic waves; Seismology; Signal processing; Time series; Underwater acoustics; Body waves; Persistence, memory, correlations, clustering; Seismic monitoring and test-ban treaty verification; Statistical seismology; Wave scattering and diffraction; amplitude; body wave; empirical analysis; seismic refraction; seismology; time series analysis; wave diffraction; wave field; wave scattering; waveform analysis; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Kattan201599,
	author = {Kattan, Ahmed and Fatima, Shaheen and Arif, Muhammad},
	title = {Time-series event-based prediction: An unsupervised learning framework based on genetic programming},
	year = {2015},
	journal = {Information Sciences},
	volume = {301},
	pages = {99 – 123},
	doi = {10.1016/j.ins.2014.12.054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922710300&doi=10.1016%2fj.ins.2014.12.054&partnerID=40&md5=587a6b72f9daa6f4ceccef1384f42afe},
	abstract = {In this paper, we propose an unsupervised learning framework based on Genetic Programming (GP) to predict the position of any particular target event (defined by the user) in a time-series. GP is used to automatically build a library of candidate temporal features. The proposed framework receives a training set S={(Va)|a=0n}, where each Va is a time-series vector such that VaS,Va={(xt)|t=0tmax} where tmax is the size of the time-series. All VaS are assumed to be generated from the same environment. The proposed framework uses a divide-and-conquer strategy for the training phase. The training process of the proposed framework works as follow. The user specifies the target event that needs to be predicted (e.g., Highest value, Second Highest value, ..., etc.). Then, the framework classifies the training samples into different Bins, where Bins={(bi)|i=0tmax}, based on the time-slot t of the target event in each Va training sample. Each biBins will contain a subset of S. For each bi, the proposed framework further classifies its samples into statistically independent clusters. To achieve this, each bi is treated as an independent problem where GP is used to evolve programs to extract statistical features from each bi's members and classify them into different clusters using the K-Means algorithm. At the end of the training process, GP is used to build an 'event detector' that receives an unseen time-series and predicts the time-slot where the target event is expected to occur. Empirical evidence on artificially generated data and real-world data shows that the proposed framework significantly outperforms standard Radial Basis Function Networks, standard GP system, Gaussian Process regression, Linear regression, and Polynomial Regression. © 2015 Elsevier Inc.},
	author_keywords = {Event detection; Genetic programming; K-Means; Prediction; Time-series; Unsupervised learning},
	keywords = {Forecasting; Genetic algorithms; K-means clustering; Polynomial regression; Radial basis function networks; Sampling; Time series; Unsupervised learning; Divide and conquer; Event detection; Gaussian process regression; Independent clusters; K-means; Statistical features; Temporal features; Time-series events; Genetic programming},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@ARTICLE{Pineau2014,
	author = {Pineau, Joelle and Moghaddam, Athena K. and Yuen, Hiu Kim and Archambault, Philippe S. and Routhier, François and Michaud, François and Boissy, Patrick},
	title = {Automatic detection and classification of unsafe events during power wheelchair use},
	year = {2014},
	journal = {IEEE Journal of Translational Engineering in Health and Medicine},
	volume = {2},
	doi = {10.1109/JTEHM.2014.2365773},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84913554275&doi=10.1109%2fJTEHM.2014.2365773&partnerID=40&md5=5ea095bfe6b8ed79663a7abe38fd16b0},
	abstract = {Using a powered wheelchair (PW) is a complex task requiring advanced perceptual and motor control skills. Unfortunately, PW incidents and accidents are not uncommon and their consequences can be serious. The objective of this paper is to develop technological tools that can be used to characterize a wheelchair user's driving behavior under various settings. In the experiments conducted, PWs are outfitted with a datalogging platform that records, in real-time, the 3-D acceleration of the PW. Data collection was conducted over 35 different activities, designed to capture a spectrum of PW driving events performed at different speeds (collisions with fixed or moving objects, rolling on incline plane, and rolling across multiple types obstacles). The data was processed using time-series analysis and data mining techniques, to automatically detect and identify the different events. We compared the classification accuracy using four different types of time-series features: 1) time-delay embeddings; 2) time-domain characterization; 3) frequency-domain features; and 4) wavelet transforms. In the analysis, we compared the classification accuracy obtained when distinguishing between safe and unsafe events during each of the 35 different activities. For the purposes of this study, unsafe events were defined as activities containing collisions against objects at different speed, and the remainder were defined as safe events. We were able to accurately detect 98% of unsafe events, with a low (12%) false positive rate, using only five examples of each activity. This proof-of-concept study shows that the proposed approach has the potential of capturing, based on limited input from embedded sensors, contextual information on PW use, and of automatically characterizing a user's PW driving behavior. © 2013 IEEE.},
	author_keywords = {accelerometers; assistive technologies; event detection; rehabilitation robotics; wheelchairs},
	keywords = {Accelerometers; Behavioral research; Data mining; Frequency domain analysis; Robotics; Time delay; Time domain analysis; Wavelet transforms; Wheelchairs; Assistive technology; Automatic Detection; Classification accuracy; Contextual information; Event detection; False positive rates; Powered wheel chairs; Rehabilitation robotics; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zurk201421,
	author = {Zurk, Lisa M. and Ou, Helen H. and Schecklman, Scott and Lutwak, Ayal},
	title = {Acoustic Monitoring of Marine Conservation Areas},
	year = {2014},
	journal = {Marine Technology Society Journal},
	volume = {48},
	number = {6},
	pages = {21 – 32},
	doi = {10.4031/MTSJ.48.6.7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930481651&doi=10.4031%2fMTSJ.48.6.7&partnerID=40&md5=82dc009c47347fb8723cc59adaac421e},
	abstract = {This paper introduces underwater sensing technologies for acoustic monitoringof marine conservation areas. Small networks of individual passive acoustic sensorshave been deployed to investigate a low-cost solution for monitoring motorizedvessels and marine ambient noise in large areas. A data processing package, called“Conservancy-Watch,” is introduced for environmental management and conservationof natural resources. The package includes passive sensing database creation,ambient noise monitoring to identify long-term trends and impacts, classification oforganic and boat vessel events, detection of marine mammals and estimation oftheir call density, and detection of motorized vessels. Test results on data collectedat several conservation sites in Hawaii have confirmed the detection capability ofindividual hydrophone sensors. © 2014, Marine Technology Society Inc. All rights reserved.},
	author_keywords = {Acoustic sensing; Marine vessels; Time series analysis},
	keywords = {Mammalia; Classification (of information); Data handling; Environmental management; Information management; Mammals; Natural resources management; Noise pollution; Time series analysis; Underwater acoustics; Acoustic monitoring; Acoustic sensing; Database creation; Detection capability; Marine conservations; Marine vessels; Passive acoustics; Sensing technology; acoustic method; data set; environmental management; marine park; monitoring; noise; remote sensing; vessel; Acoustic noise},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Baziw20122107,
	author = {Baziw, Erick and Verbeek, Gerald},
	title = {Passive (Micro-) Seismic Event Detection by Identifying Embedded "Event" Anomalies Within Statistically Describable Background Noise},
	year = {2012},
	journal = {Pure and Applied Geophysics},
	volume = {169},
	number = {12},
	pages = {2107 – 2126},
	doi = {10.1007/s00024-012-0481-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869747447&doi=10.1007%2fs00024-012-0481-9&partnerID=40&md5=f654f45c4efd7a89f239ca598c8ea047},
	abstract = {Among engineers there is considerable interest in the real-time identification of "events" within time series data with a low signal to noise ratio. This is especially true for acoustic emission analysis, which is utilized to assess the integrity and safety of many structures and is also applied in the field of passive seismic monitoring (PSM). Here an array of seismic receivers are used to acquire acoustic signals to monitor locations where seismic activity is expected: underground excavations, deep open pits and quarries, reservoirs into which fluids are injected or from which fluids are produced, permeable subsurface formations, or sites of large underground explosions. The most important element of PSM is event detection: the monitoring of seismic acoustic emissions is a continuous, real-time process which typically runs 24 h a day, 7 days a week, and therefore a PSM system with poor event detection can easily acquire terabytes of useless data as it does not identify crucial acoustic events. This paper outlines a new algorithm developed for this application, the so-called SEED™ (Signal Enhancement and Event Detection) algorithm. The SEED™ algorithm uses real-time Bayesian recursive estimation digital filtering techniques for PSM signal enhancement and event detection. © 2012 Springer Basel AG.},
	author_keywords = {Hidden Markov models; Kalman filter; Passive (micro-) seismic monitoring; real-time event detection},
	keywords = {Acoustic emission testing; Acoustic emissions; Acoustic noise; Algorithms; Hidden Markov models; Kalman filters; Underground explosions; Acoustic events; Acoustic signals; Background noise; Digital filtering techniques; Event detection; Low signal-to-noise ratio; Monitor location; Open pit; PSM systems; Real-time identification; Real-time process; Recursive estimation; Seismic activity; Seismic event; Seismic monitoring; Signal enhancement; Subsurface formations; Time-series data; Underground excavation; acoustic emission; algorithm; detection method; earthquake event; geophysical array; identification method; Kalman filter; Markov chain; numerical model; seismic data; seismicity; signal-to-noise ratio; structural response; time series analysis; underground construction; Seismology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Fang2013,
	author = {Fang, Yin-Ying and Liu, Meng-Chu and Chou, Shih-En and Chen, Chifang and Huang, Chien-Kang},
	title = {Event detection of underwater acoustic data from MACHO hydrophone},
	year = {2013},
	journal = {2013 IEEE International Underwater Technology Symposium, UT 2013},
	doi = {10.1109/UT.2013.6519887},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879424319&doi=10.1109%2fUT.2013.6519887&partnerID=40&md5=2f962ce1b159469b37d6a1bb5d0f3d85},
	abstract = {This paper presents an automated event detector of long time series of hydrophone data from Marine Cable Hosted Observatory (MACHO) system installed by the Central Weather Bureau in the offshore region of Taiwan's northeast coast. The detector includes time-varying ambient noise level estimation via SEL (Sound Exposure Level per second) and Leq (equivalent continuous sound level, averaged over 30 seconds), and an energy detector with the estimated ambient noise level as threshold. A user friendly UI (user interface) is written to enhance the utilization. A full year of data are analyzed with the detector, and the results are satisfactory in the robustness the detection rate and the efficiency of analysis of large amount of data. © 2013 IEEE.},
	keywords = {Acoustic noise; Underwater acoustics; User interfaces; Central weather bureaux; Detection rates; Energy detectors; Event detection; Event detectors; Long time series; Sound exposure levels; Underwater acoustic data; Detectors},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Chaovalit2013450,
	author = {Chaovalit, Pimwadee and Saiprasert, Chalermpol and Pholprasit, Thunyasit},
	title = {A method for driving event detection using SAX on smartphone sensors},
	year = {2013},
	journal = {2013 13th International Conference on ITS Telecommunications, ITST 2013},
	pages = {450 – 455},
	doi = {10.1109/ITST.2013.6685587},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893525894&doi=10.1109%2fITST.2013.6685587&partnerID=40&md5=a646b0e383a99326584161c9c40d4802},
	abstract = {Drivers errors such as careless and aggressive driving behaviors are one of the key factors contributing to road traffic accidents. It is, therefore, essential that drivers are aware of their actions when they are in control of the wheel responsible for not only their own lives but also passengers and bystanders on the road. Driver monitoring and advanced driver assistance systems have already been utilized in fleet and logistic domain as well as built into high end vehicles. However, the majority of drivers on the road today do not have access to such systems. This paper proposes a novel methodology of driving events detection using a time series approximation algorithm known as SAX on data collected from smartphone sensors. The use of smartphone allows the system to be easily accessible, widely available and implemented at low cost. Preliminary results from our experiments revealed that the precision of the proposed detection algorithm of aggressive driving events is fairly good as the precision values range from 50% to 66.67%. Further improvements can be made as our future work on the detection rate of the proposed algorithm as the detection rates reported range from 25% to 37.5%. © 2013 IEEE.},
	author_keywords = {Driving behavior; Driving event detection; SAX; Smartphone},
	keywords = {Approximation algorithms; Fleet operations; Highway accidents; Highway traffic control; Roads and streets; Sensors; Signal encoding; Aggressive driving; Aggressive driving behaviors; Detection algorithm; Driving behavior; Driving events; Road traffic accidents; SAX; Series approximations; Smartphones},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Bhattacharya20142243,
	author = {Bhattacharya, Subhabrata and Kalayeh, Mahdi M. and Sukthankar, Rahul and Shah, Mubarak},
	title = {Recognition of complex events: Exploiting temporal dynamics between underlying concepts},
	year = {2014},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	pages = {2243 – 2250},
	doi = {10.1109/CVPR.2014.287},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911400185&doi=10.1109%2fCVPR.2014.287&partnerID=40&md5=268ce7843c3e8948cf9740ffb167ebe0},
	abstract = {While approaches based on bags of features excel at low-level action classification, they are ill-suited for recognizing complex events in video, where concept-based temporal representations currently dominate. This paper proposes a novel representation that captures the temporal dynamics of windowed mid-level concept detectors in order to improve complex event recognition. We first express each video as an ordered vector time series, where each time step consists of the vector formed from the concatenated confidences of the pre-trained concept detectors. We hypothesize that the dynamics of time series for different instances from the same event class, as captured by simple linear dynamical system (LDS) models, are likely to be similar even if the instances differ in terms of low-level visual features. We propose a two-part representation composed of fusing: (1) a singular value decomposition of block Hankel matrices (SSID-S) and (2) a harmonic signature (HS) computed from the corresponding eigen-dynamics matrix. The proposed method offers several benefits over alternate approaches: our approach is straightforward to implement, directly employs existing concept detectors and can be plugged into linear classification frameworks. Results on standard datasets such as NIST's TRECVID Multimedia Event Detection task demonstrate the improved accuracy of the proposed method. © 2014 IEEE.},
	author_keywords = {Complex Event Recognition; Hankel Matrices; Harmonic signatures; Linear Dynamical Systems; Subspace state identification; Temporal Representation; TRECVID MED},
	keywords = {Content based retrieval; Dynamical systems; Dynamics; Image segmentation; Linear control systems; Singular value decomposition; Time series; Complex events; Hankel matrix; Harmonic signatures; Linear dynamical systems; State identification; Temporal representations; TRECVID; Pattern recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 58; All Open Access, Green Open Access}
}

@ARTICLE{Rude2012160,
	author = {Rude, Avinash and Beard, Kate},
	title = {High-level event detection in spatially distributed time series},
	year = {2012},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {7478 LNCS},
	pages = {160 – 172},
	doi = {10.1007/978-3-642-33024-7_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867593798&doi=10.1007%2f978-3-642-33024-7_12&partnerID=40&md5=6ed984da2d5defca955a18c5fd745494},
	abstract = {This paper presents an approach for the detection of high-level events from spatially distributed time series. The objective is to detect spatially evolving high-level events as aggregate patterns of primitive events. The approach starts with a segmentation of time series into primitive events as building blocks for high-level events. A high-level event ontology is then used to specify the composition of high-level events of interest in terms of initiating, body forming, and terminating primitive events. We illustrate the approach first with simulated time series data to identify traffic congestion events and then with real data to identify storm events from sensor time series collected as part of an ocean observing system deployed in the Gulf of Maine. Detected storm events are compared against NCDC reported storm events as an evaluation of the approach. © 2012 Springer-Verlag.},
	author_keywords = {event detection; primitive event; time series segmentation},
	keywords = {Geographic information systems; Information science; Spatial distribution; Storms; Traffic congestion; Building blockes; Distributed time; Event detection; Event ontology; Gulf of maine; Ocean observing systems; primitive event; Storm events; Time-series data; Time-series segmentation; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Hu2013525,
	author = {Hu, Xiao Bing},
	title = {Abnormal events detection in traffic data},
	year = {2013},
	journal = {Advanced Materials Research},
	volume = {779},
	pages = {525 – 529},
	doi = {10.4028/www.scientific.net/AMR.779-780.525},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886298048&doi=10.4028%2fwww.scientific.net%2fAMR.779-780.525&partnerID=40&md5=e9c8b2339067348502a4aaa629c4267e},
	abstract = {Detecting abnormal events such as crash is a practical problem that is important to Intelligent Transportation System. By taking advantage of the data recorded by the remote sensors which are deployed along the road, we can perform data mining techniques to see whether there are abnormal events happening on the road. This paper aims at proposing an abnormal-events-detecting method based on the traffic data, which first utilizes outlier detection to generate a fuzzy result set from source data, and then through the time series mining techniques to filter that to obtain an accurate experimental one. Experiment with real-world data shows that our method works satisfactorily in detecting abnormalities such crash, stall and hazard on the road. © (2013) Trans Tech Publications, Switzerland.},
	author_keywords = {Data Mining; Outlier Detection; Pattern Recognition; Traffic Pattern},
	keywords = {Anomaly detection; Data handling; Filtration; Fuzzy filters; Intelligent systems; Materials handling; Pattern recognition; Remote sensing; Roads and streets; Statistics; Detecting methods; Events detection; Intelligent transportation systems; Practical problems; Remote sensors; Time-series mining; Traffic data; Traffic pattern; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mounce2012187,
	author = {Mounce, Stephen R. and Mounce, Richard B. and Boxall, Joby B.},
	title = {Identifying sampling interval for event detection in water distribution networks},
	year = {2012},
	journal = {Journal of Water Resources Planning and Management},
	volume = {138},
	number = {2},
	pages = {187 – 191},
	doi = {10.1061/(ASCE)WR.1943-5452.0000170},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859321442&doi=10.1061%2f%28ASCE%29WR.1943-5452.0000170&partnerID=40&md5=050d69e41e7f3d4975203b660fccb8a6},
	abstract = {It is a generally adopted policy, albeit unofficially, to sample flow and pressure data at a 15-min interval for water distribution system hydraulic measurements. Further, for flow, this is usually averaged, whereas pressure is instantaneous. This paper sets out the findings of studies into the potential benefits of a higher sampling rate and averaging for flow and pressure measurements in water distribution systems. A data set comprising sampling at 5 s (in the case of pressure), 1 min, 5 min, and 15 min, both instantaneous and averaged, for a set of flow and pressure sensors deployed within two DMAs has been used. Engineered events conducted by opening fire hydrants/wash outs were used to form a controlled baseline detection comparison with known event start times. A data analysis system using support vector regression (SVR) was used to analyze the flow and pressure time series data from the deployed sensors and hence, detect these abnormal events. Results are analyzed over different sensors and events. The overall trend in the results is that a faster sampling rate leads to earlier event detection. However, it is concluded that a sampling interval of 1 or 5 min does not significantly improve detection to the point at which it is worth the added increase in power, communications, and data management requirements with current technologies. It was discovered that averaging pressure data can result in more rapid detection when compared with using the same instantaneous sampling rate. Averaging of pressure data is also likely to provide better regulatory compliance and provide improved data for EPS hydraulic modelling. This improvement can be achieved without any additional overheads on communications by a simple firmware alteration and hence, is potentially a very low cost upgrade with significant gains. © 2012 American Society of Civil Engineers.},
	author_keywords = {Field measurement data; Leakage; Model calibration; Sampling interval; Water distribution systems; Water management},
	keywords = {Firmware; Information management; Leakage (fluid); Regulatory compliance; Sensors; Water distribution systems; Water management; Baseline detection; Current technology; Data analysis system; Data sets; Event detection; Field measurement data; Hydraulic measurements; Hydraulic modelling; Low costs; Model calibration; Potential benefits; Pressure data; Pressure time; Rapid detection; Sampling interval; Sampling rates; Support vector regression (SVR); Water distribution networks; Water distributions; calibration; data set; numerical model; regression analysis; time series analysis; water management; water supply; Data flow analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Green Open Access}
}

@ARTICLE{Blocker2012177,
	author = {Blocker, Alexander W. and Protopapas, Pavlos},
	title = {Semi-parametric robust event detection for massive time-domain databases},
	year = {2012},
	journal = {Lecture Notes in Statistics},
	volume = {209},
	pages = {177 – 187},
	doi = {10.1007/978-1-4614-3520-4_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896598225&doi=10.1007%2f978-1-4614-3520-4_16&partnerID=40&md5=ad1a187bc5cf4392532be163386f53fd},
	abstract = {The detection and analysis of events within massive collections of time-series has become an extremely important task for time-domain astronomy. In particular, many scientific investigations (e.g. the analysis of microlensing and other transients) begin with the detection of isolated events in irregularly-sampled series with both non-linear trends and non-Gaussian noise. We outline a semiparametric, robust, parallel method for identifying variability and isolated events at multiple scales in the presence of the above complications. This approach harnesses the power of Bayesian modeling while maintainingmuch of the speed and scalability of more ad-hoc machine learning approaches.We also contrast this work with event detection methods from other fields, highlighting the unique challenges posed by astronomical surveys. Finally, we present results from the application of this method to 87.2 million EROS-2 sources, where we have obtained a greater than 100-fold reduction in candidates for certain types of phenomena while creating high-quality features for subsequent analyses. © Springer Science+Business Media New York 2013.},
	keywords = {Bayesian networks; Gaussian noise (electronic); Time series analysis; Astronomical surveys; Event detection; Multiple scale; Non-Gaussian noise; Non-linear trends; Parallel method; Scientific investigation; Semiparametric; Time domain analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Hsu2014359,
	author = {Hsu, Wei-Lieh and Wang, Yu-Cheng and Lin, Chih-Lung},
	title = {Abnormal crowd event detection based on outlier in time series},
	year = {2014},
	journal = {Proceedings - International Conference on Machine Learning and Cybernetics},
	volume = {1},
	pages = {359 – 363},
	doi = {10.1109/ICMLC.2014.7009142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921467438&doi=10.1109%2fICMLC.2014.7009142&partnerID=40&md5=28bb735490eff5a93f3386a49a12fd37},
	abstract = {Crowd management research shows a lack of depth in the literature insofar as most major incidents can be prevented or minimized by a proper management strategy. Specifically, if abnormal crowd events can be detected early and the relevant governing agency can take appropriate actions towards mitigating the dangers, accidental injury can be prevented or the incident can be contained. This paper presents a technical approach to gather the required crowd data using fixed cameras to collect visual data while using a grid model to describe the crowd distribution. The measured area will be divided into several unit areas and each unit area is considered to be a simple cell in a grid model. The state value of each unit area is determined by changes in the total number of active pixels within the unit area. Under the circumstances, the motion status of the measured area is represented by a dynamic state matrix, which will save computing time. © 2014 IEEE.},
	author_keywords = {Chebyshev moment; Crowd Abnormal event; Crowd analysis; Grid Model},
	keywords = {Artificial intelligence; Cybernetics; Accidental injuries; Chebyshev moments; Crowd Abnormal event; Crowd analysis; Crowd managements; Event detection; Grid model; Management strategies; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{20151,
	title = {38th Annual German Conference on Artificial Intelligence, KI 2015},
	year = {2015},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9324},
	pages = {1 – 367},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951873348&partnerID=40&md5=308bf2a57034bf9287f25d836330a2d3},
	abstract = {The proceedings contain 33 papers. The special focus in this conference is on Advances in Artificial Intelligence. The topics include: Safety constraints and ethical principles in collective decision making systems; complexity of interval relaxed numeric planning; oddness-based classifiers for Boolean or numerical data; packing irregular-shaped objects for 3d printing; towards a more efficient computation of weighted conditional impacts for relational probabilistic knowledge bases under maximum entropy semantics; assisting with goal formulation for domain independent planning; short-term wind power prediction with combination of speed and power time series; axiomatization of general concept inclusions in probabilistic description logics; an empirical case study on symmetry handling in cost-optimal planning as heuristic search; necessary observations in nondeterministic planning; analogical representation of rcc-8 for neighborhood-based qualitative spatial reasoning; abducing hypotheses about past events from observed environment changes; a software system using a sat solver for reasoning under complete, stable, preferred, and grounded argumentation semantics; on the KL divergence of probability mixtures for belief contraction; accurate online social network user profiling; an educational puzzle game combined with a multimodal machine learning environment; event detection in marine time series data; improving heuristics on-the-fly for effective search in plan space; hierarchical hybrid planning in a mobile service robot; towards an expert system for the field of neurology based on fuzzy logic and abductive reasoning using tableau methods for high-level image interpretation.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hoai20141523,
	author = {Hoai, Minh and Torresani, Lorenzo and De La Torre, Fernando and Rother, Carsten},
	title = {Learning discriminative localization from weakly labeled data},
	year = {2014},
	journal = {Pattern Recognition},
	volume = {47},
	number = {3},
	pages = {1523 – 1534},
	doi = {10.1016/j.patcog.2013.09.028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888332800&doi=10.1016%2fj.patcog.2013.09.028&partnerID=40&md5=d36ade66b1e722e6c4daa08a953f8524},
	abstract = {Visual categorization problems, such as object classification or action recognition, are increasingly often approached using a detection strategy: a classifier function is first applied to candidate subwindows of the image or the video, and then the maximum classifier score is used for class decision. Traditionally, the subwindow classifiers are trained on a large collection of examples manually annotated with masks or bounding boxes. The reliance on time-consuming human labeling effectively limits the application of these methods to problems involving very few categories. Furthermore, the human selection of the masks introduces arbitrary biases (e.g., in terms of window size and location) which may be suboptimal for classification. We propose a novel method for learning a discriminative subwindow classifier from examples annotated with binary labels indicating the presence of an object or action of interest, but not its location. During training, our approach simultaneously localizes the instances of the positive class and learns a subwindow SVM to recognize them. We extend our method to classification of time series by presenting an algorithm that localizes the most discriminative set of temporal segments in the signal. We evaluate our approach on several datasets for object and action recognition and show that it achieves results similar and in many cases superior to those obtained with full supervision. © 2013 Elsevier Ltd. All rights reserved.},
	author_keywords = {Discriminative discovery; Event detection; Image classification; Object detection; Time series classification; Weakly supervised learning},
	keywords = {Data processing; Object detection; Time series; Discriminative discovery; Event detection; Object Detection; Time series classifications; Weakly supervised learning; Action recognition; Discriminative discovery; Event detection; Object classification; Temporal segments; Time series classifications; Visual categorization; Weakly supervised learning; Image classification; Image classification},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@CONFERENCE{Kanhabua20122686,
	author = {Kanhabua, Nattiya and Stewart, Avaré and Nejdl, Wolfgang and Romano, Sara},
	title = {Supporting temporal analytics for health-related events in microblogs},
	year = {2012},
	journal = {ACM International Conference Proceeding Series},
	pages = {2686 – 2688},
	doi = {10.1145/2396761.2398726},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871079196&doi=10.1145%2f2396761.2398726&partnerID=40&md5=08b9c71bde5bf12aa005142a072aed91},
	abstract = {Microblogging services, such as Twitter, are gaining interests as a means of sharing information in social networks. Numerous works have shown the potential of using Twitter posts (or tweets) in order to infer the existence and magnitude of real-world events. In the medical domain, there has been a surge in detecting public health related tweets for early warning so that a rapid response from health authorities can take place. In this paper, we present a temporal analytics tool for supporting a comparative, temporal analysis of disease outbreaks between Twitter and official sources, such as, World Health Organization (WHO) and ProMED-mail. We automatically extract and aggregate outbreak events from official outbreak reports, producing time series data. Our tool can support a correlation analysis and an understanding of the temporal developments of outbreak mentions in Twitter, based on comparisons with official sources. © 2012 Authors.},
	author_keywords = {disease outbreaks; event detection; time series analysis; Twitter},
	keywords = {Health; Knowledge management; Time series analysis; Correlation analysis; Disease outbreaks; Early warning; Event detection; Medical domains; Microblogging; Rapid response; Sharing information; Social Networks; Temporal analysis; Temporal development; Time-series data; Twitter; World Health Organization; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}

@ARTICLE{Ali2012233,
	author = {Ali, Azad and Khelil, Abdelmajid and Shaikh, Faisal Karim and Suri, Neeraj},
	title = {Efficient predictive monitoring of wireless sensor networks},
	year = {2012},
	journal = {International Journal of Autonomous and Adaptive Communications Systems},
	volume = {5},
	number = {3},
	pages = {233 – 254},
	doi = {10.1504/IJAACS.2012.047657},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863641242&doi=10.1504%2fIJAACS.2012.047657&partnerID=40&md5=30fd5df3325c81e1cf07de3203656896},
	abstract = {Wireless sensor networks (WSNs) are deployed to monitor physical events such as fire, or the state of physical objects such as bridges in order to support appropriate reaction to avoid potential damages. However, many situations require immediate attention or long-reaction plan. Therefore, the classical approach of just detecting the physical events may not suffice in many cases. We present a generic WSN level event prediction framework to forecast the physical events, such as network partitioning, well in advance to support proactive self-actions. The framework collects the state of a specified attribute on the sink using an efficient spatio-temporal compression technique. The future state of the targeted attributes is then predicted using time series modelling. We propose a generic event prediction algorithm, which is adaptable to multiple application domains. Using simulations we show our framework's enhanced ability to accurately predict the network partitioning with very high accuracy and efficiency. Copyright © 2012 Inderscience Enterprises Ltd.},
	author_keywords = {Event detection and prediction; Predictive monitoring; Spatio-temporal compression; Time series analysis; Wireless sensor networks; WSNs},
	keywords = {Forecasting; Time series analysis; Event detection and predictions; Multiple applications; Network partitioning; Predictive monitoring; Spatio-temporal compressions; Time-series modelling; Wireless sensor network (WSNs); WSNs; Wireless sensor networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Garg2011144,
	author = {Garg, Ashish and Manikonda, Lydia and Kumar, Shashank and Krishna, Vikrant and Boriah, Shyam and Steinbach, Michael and Kumar, Vipin and Toshniwal, Durga and Potter, Christopher and Klooster, Steven},
	title = {A model-free time series segmentation approach for land cover change detection},
	year = {2011},
	journal = {Proceedings of the 2011 Conference on Intelligent Data Understanding, CIDU 2011},
	pages = {144 – 158},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873128998&partnerID=40&md5=0f40811ceca7d4e0622e0746f5ec1654},
	abstract = {Ecosystem-related observations from remote sensors on satellites offer significant possibility for understanding the location and extent of global land cover change. In this paper, we focus on time series segmentation techniques in the context of land cover change detection. We propose a model-based time series segmentation algorithm inspired by an event detection framework proposed in the field of statistics. We also present a novel model-free change detection algorithm for detecting land cover change that is computationally simple, efficient, non-parametric and takes into account the inherent variability present in the remote sensing data. A key advantage of this method is that it can be applied globally for a variety of vegetation without having to identify the right model for specific vegetation types. We evaluate the change detection capacity of the proposed techniques on both synthetic and MODIS EVI data sets. We illustrate the importance and relative ability of different algorithms to account for the natural variation in the EVI data set.},
	keywords = {NASA; Remote sensing; Signal detection; Vegetation; Change detection; Change detection algorithms; Event detection; Inherent variability; Land-cover change; Natural variation; Remote sensing data; Time-series segmentation; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Waidyanatha2010,
	author = {Waidyanatha, Nuwan and Sampath, Chamindu and Dubrawski, Artur and Sabhnani, Maheshkumar and Chen, Lujie and Ganesan, M. and Vincy, P.},
	title = {T-cube web interface as a tool for detecting disease outbreaks in real-time: A pilot in India and Sri Lanka},
	year = {2010},
	journal = {2010 IEEE-RIVF International Conference on Computing and Communication Technologies: Research, Innovation and Vision for the Future, RIVF 2010},
	doi = {10.1109/RIVF.2010.5633019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952140423&doi=10.1109%2fRIVF.2010.5633019&partnerID=40&md5=c815fed9d475fe1eb7c27c7cf4cdc18d},
	abstract = {Motivated by existing gaps and inefficiencies in the paper-based manually processed disease surveillance and notification systems in India and Sri Lanka [1], the Real-Time Biosurveillance Program (RTBP) introduces technology to health departments in Tamil Nadu, India and Sri Lanka, to answer the question: "Can software programs that detect events in public health data, and mobile phones that collect health data and receive health alerts, enable effective identification and mitigation of disease outbreaks in near-real-time?" The processes involve digitizing all clinical health records and analyzing them in near real-time to detect emerging unusual patterns in data to forewarn health workers before the diseases reach epidemic states. Health records from health facilities, namely the patient disease cases, syndrome, and demographic information, are transmitted through the mHealthSurvey mobile phone application [2] and fed in to the TCube data structure. T-Cube Web Interface (TCWI) is a browserbased software tool that uses the T-Cube data structure for fast retrieval and display of large volume multivariate time series and spatial information. Interface allows the user to execute complex queries quickly and to run various types of statistical tests on the loaded data [3,4,5]. Detected emerging patterns of potentially epidemic events are then disseminated to health workers in the vulnerable and surrounding areas in the form of SMS, Email, and Web published alerts [6]. This paper considers utility and importance of TCWI in support of rapid detection and mitigation of bio-medical threats in developing countries. ©2010 IEEE.},
	author_keywords = {Epidemiology; Event detection; India; Public health; Spatio-temporal analysis; Sri Lanka},
	keywords = {Cellular telephone systems; Computer software; Data structures; Developing countries; Diseases; Electronic publishing; Epidemiology; Geometry; Health; Innovation; Mobile phones; Real time systems; Statistical tests; Telecommunication equipment; Telephone; Telephone sets; Time series; Event detection; India; Public health; Spatiotemporal analysis; Sri Lanka; Health risks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@CONFERENCE{Xie2011123,
	author = {Xie, Shengkun and Lawniczak, Anna T.},
	title = {Detection of stationary network load increase using univariate network aggregate traffic data by dynamic PCA},
	year = {2011},
	journal = {IEEE SSCI 2011 - Symposium Series on Computational Intelligence - CISDA 2011: 2011 IEEE Symposium on Computational Intelligence for Security and Defense Applications},
	pages = {123 – 130},
	doi = {10.1109/CISDA.2011.5945952},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880943153&doi=10.1109%2fCISDA.2011.5945952&partnerID=40&md5=a284f5f3f5c09a69a36473e74a060557},
	abstract = {Network operators are now facing bandwidth outages as well as a growing pressure to ensure good Quality of Service (QoS). An important practical issue for network service providers is to pay close attention to the load changes of network traffic, in particular, the stationary increase of load from a normal demand. Many network monitoring applications and performance analysis tools are based on the study of an aggregate measure of network traffic, e.g. number of packets in transit (NPT), which is a long-term univariate time series. To classify this type of network traffic data and detect any increase of network source load, we propose a dynamic principal component analysis (PCA) method, first to extract data features and then to detect a stationary load increase of network traffic. The proposed detection schemes are based on either the major or the minor principal components of network traffic data. To demonstrate the applications of the proposed feature extraction method and the detection schemes, we applied them to network traffic data simulated from the packet switching network (PSN) model. Additionally, we propose a combined detection scheme that uses both the major and the minor principal components. The proposed detection schemes, based on dynamic PCA, show enhanced performance in detecting an increase of network load for the simulated network traffic data. These results offer a new feature extraction method based on dynamic PCA that creates additional feature variables for event detection in a univariate time series. © 2011 IEEE.},
	author_keywords = {Dynamic Principal Component Analysis; Feature Extraction; Load Change Detection; Network Performance Analysis},
	keywords = {Artificial intelligence; Computer simulation; Feature extraction; Network performance; Principal component analysis; Time series; Dynamic principal component analysis; Feature extraction methods; Load change detection; Network performance analysis; Network service providers; Number of packets in transits; Performance analysis; Univariate time series; Aggregates},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Yuan2012506,
	author = {Yuan, Bo and Chen, Qingcai and Xiang, Yang and Wang, Xiaolong},
	title = {Hot event detection method based on heterogeneous information},
	year = {2012},
	journal = {International Journal of Advancements in Computing Technology},
	volume = {4},
	number = {18},
	pages = {506 – 514},
	doi = {10.4156/ijact.vol4.issue18.60},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867861455&doi=10.4156%2fijact.vol4.issue18.60&partnerID=40&md5=6b64c2bbd65575f98e75fd820aabf51f},
	abstract = {The main issues of hot event auto detection methods include the predictions of threshold for alarming a new event and the actual number of events contained in the texts that are piped in etc., which affect the flexibility and performance of a hot topic detection system. It is really hard to address these issues by just depending on single information source, i.e., the text. Usually a hard threshold or a pre-given events number is provided for most of the topic detection and tracking methods. To provide a more flexible solution, in this paper, an event detection method based on heterogeneous information is proposed. At first, the classification of structured data is conducted, and the results are used to guide the classification of text. Then a multi-features based bi-clustering method is applied to improve the performance of event detection. The sharp fluctuation of a time series precise data is also tracked and the tracking results are used in determining the hotness of an event. Finally, the experiment results and our online prototype system show the effectiveness of the proposed method.},
	author_keywords = {Bi-clustering; Event auto detection; Heterogeneous information; Time series data},
	keywords = {Cluster analysis; Optical variables measurement; Pattern recognition systems; Text processing; Time series; Bi-clustering; Event auto detections; Heterogeneous information; Hot event detection; Hot topic detection; Information sources; Time-series data; Topic detection and tracking; Information retrieval systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Heymann201489,
	author = {Heymann, Sébastien and Le Grand, Bénédicte},
	title = {Visual investigation of events in a large link stream; [Investigation visuelle d'événements dans un grand flot de liens]},
	year = {2014},
	journal = {Revue des Nouvelles Technologies de l'Information},
	volume = {E.26},
	pages = {89 – 100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994217970&partnerID=40&md5=74bfaea0a58b64ccb0520608f1753b7c},
	abstract = {We introduce a novel method of exploratory analysis in large link streams, which we apply to significant event detection in more than 2 millions interactions (during 4 months) among users in the Github online social network.We combine a statistical method to automatically detect events in time series, Outskewer, with an interactive graph visualization system. Outskewer points to interesting moments of the graph evolution, then an analyst validates and interprets the events through visualization of abnormal patterns in the corresponding sub-graphs. We show using several examples that this approach allows to detect relevant events and to reject irrelevant ones, and is suitable for exploratory analysis because no prior knowledge is required.},
	keywords = {Extraction; Social networking (online); Visualization; Abnormal patterns; Event detection; Exploratory analysis; Graph visualization; Prior knowledge; Subgraphs; Visual investigation; Time series analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Arad20131899,
	author = {Arad, Jonathan and Housh, Mashor and Perelman, Lina and Ostfeld, Avi},
	title = {A dynamic thresholds scheme for contaminant event detection in water distribution systems},
	year = {2013},
	journal = {Water Research},
	volume = {47},
	number = {5},
	pages = {1899 – 1908},
	doi = {10.1016/j.watres.2013.01.017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873522833&doi=10.1016%2fj.watres.2013.01.017&partnerID=40&md5=888235c1a7f6618c7e4a4b5aeed0b547},
	abstract = {In this study, a dynamic thresholds scheme is developed and demonstrated for contamination event detection in water distribution systems. The developed methodology is based on a recently published article of the authors (Perelman et al., 2012). Event detection in water supply systems is aimed at disclosing abnormal hydraulic or water quality events by exploring the time series behavior of routine hydraulic (e.g., flow, pressure) and water quality measurements (e.g., residual chlorine, pH, turbidity). While event detection raises alerts to the possibility of an event occurrence, it does not relate to origins, thus an event may be hydraulically-driven, as a consequence of problems like sudden leakages or pump/pipe malfunctions. Most events, however, are related to deliberate, accidental, or natural contamination intrusions. The developed methodology herein is based on off-line and on-line stages. During the off-line stage, a genetic algorithm (GA) is utilized for tuning five decision variables: positive and negative filters, positive and negative dynamic thresholds, and window size. During the on-line stage, a recursively Bayes' rule is invoked, employing the five decision variables, for real time on-line event detection. Using the same database, the proposed methodology is compared to Perelman et al. (2012), showing considerably improved detection ability. Metadata and the computer code are provided as Supplementary material. © 2013 Elsevier Ltd.},
	author_keywords = {Bayesian analysis; Dynamic thresholds; Event detection; Water distribution systems; Water quality; Water security},
	keywords = {Decision making; Genetic algorithms; Water distribution systems; Water quality; Water supply; Bayesian Analysis; Contamination events; Decision variables; Dynamic threshold; Event detection; Residual chlorines; Water quality measurement; Water security; Bayesian analysis; database; detection method; environmental assessment; filter; genetic algorithm; leakage; threshold; time series analysis; water pollution; water quality; water supply; article; environmental parameters; genetic algorithm; priority journal; pump; time series analysis; water contamination; water quality; water supply; Pollution detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 90}
}

@ARTICLE{Andrienko2012675,
	author = {Andrienko, Gennady and Andrienko, Natalia and Mladenov, Martin and Mock, Michael and Pölitz, Christian},
	title = {Identifying place histories from activity traces with an eye to parameter impact},
	year = {2012},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	volume = {18},
	number = {5},
	pages = {675 – 688},
	doi = {10.1109/TVCG.2011.153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859000530&doi=10.1109%2fTVCG.2011.153&partnerID=40&md5=667bec9b30e60e8d778facbdd72c0047},
	abstract = {Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Important and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations, and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We also support interactive investigation of the sensitivity of the analysis results to the parameters used in the computations. For this purpose, statistical summaries of computation results obtained with different combinations of parameter values are visualized in a way facilitating comparisons. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years. © 2006 IEEE.},
	author_keywords = {Event detection; geovisualization; scalable visualization; scale effect; sensitivity analysis; spatiotemporal data; time series analysis; visual analytics},
	keywords = {Activities of Daily Living; Cellular Phone; Computer Graphics; Data Interpretation, Statistical; Databases, Factual; Geography; Humans; Time; Behavioral research; Cellular telephones; Data visualization; Electronic document exchange; Mobile phones; Parameter estimation; Sensitivity analysis; Telephone sets; Visualization; Event detection; Geo visualizations; Scalable visualization; Scale effects; Spatio-temporal data; Visual analytics; article; computer graphics; daily life activity; factual database; geography; human; mobile phone; statistical analysis; time; Time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Green Open Access}
}

@ARTICLE{Behera2010945,
	author = {Behera, H.S. and Dash, P.K. and Biswal, B.},
	title = {Power quality time series data mining using S-transform and fuzzy expert system},
	year = {2010},
	journal = {Applied Soft Computing Journal},
	volume = {10},
	number = {3},
	pages = {945 – 955},
	doi = {10.1016/j.asoc.2009.10.013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77649234308&doi=10.1016%2fj.asoc.2009.10.013&partnerID=40&md5=4982a4bb54a15fd568aeac6895c1a415},
	abstract = {This paper presents a new approach for power quality time series data mining using S-transform based fuzzy expert system (FES). Initially the power signal time series disturbance data are pre-processed through an advanced signal processing tool such as S-transform and various statistical features are extracted, which are used as inputs to the fuzzy expert system for power quality event detection. The proposed expert system uses a data mining approach for assigning a certainty factor for each classification rule, thereby providing robustness to the rule in the presence of noise. Further to provide a very high degree of accuracy in pattern classification, both the Gaussian and trapezoidal membership functions of the concerned fuzzy sets are optimized using a fuzzy logic based adaptive particle swarm optimization (PSO) technique. The proposed hybrid PSO-fuzzy expert system (PSOFES) provides accurate classification rates even under noisy conditions compared to the existing techniques, which show the efficacy and robustness of the proposed algorithm for power quality time series data mining. © 2009 Elsevier B.V. All rights reserved.},
	author_keywords = {Fuzzy expert system; Particle swarm optimization; Power quality; S-transform; Time-series data},
	keywords = {Algorithms; Data mining; Expert systems; Fuzzy logic; Fuzzy sets; Membership functions; Signal processing; Time series; Adaptive particle swarm optimizations; Advanced signal processing; Certainty factors; Classification rates; Classification rules; Fuzzy expert system; Fuzzy expert systems; Gaussians; High degree of accuracy; Hybrid PSO; New approaches; Pattern classification; Power quality event; Power signals; S transforms; Statistical features; Time series data mining; Time-series data; Particle swarm optimization (PSO)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 86}
}

@CONFERENCE{Chiappino20144364,
	author = {Chiappino, Simone and Marcenaro, Lucio and Regazzoni, Carlo S.},
	title = {Information Bottleneck-based relevant knowledge representation in large-scale video surveillance systems},
	year = {2014},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	pages = {4364 – 4368},
	doi = {10.1109/ICASSP.2014.6854426},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905270505&doi=10.1109%2fICASSP.2014.6854426&partnerID=40&md5=26cc345de4a2519bd8148e237ee215e6},
	abstract = {Extraction and representation of relevant information from large-scale surveillance systems constitute fundamental processes for allowing automatic interpretation of complex scenes. In particular, when the amount of information increases (i.e., due to a larger number of monitored areas), attention focusing techniques are needed to highlight most relevant parts within the overall acquired data. When wide area surveillance systems are considered, one of the major problems in event detections is the reconstruction of the scene as a whole, from spatially limited observations. In this paper, a novel representation technique for sparse information, based on information theory, is presented. Self Organizing Maps (SOMs) have been used for classifying and correlating observed sparse data time series. By means of Information Bottleneck theory, it is possible to determine the optimal data representation in the SOM-space as a tradeoff between the signal reconstruction capabilities and the original data statistical similarities preservation. Proposed experiments show how the so called information bottleneck-based SOM selection for knowledge modelling, can be applied to the field of crowd monitoring for people density map estimation and event detection. Results are presented on synthetic and real video sequences. © 2014 IEEE.},
	author_keywords = {Anomalous event detections; Cognitive systems; Crowd monitoring; Information bottleneck; Self-Organizing Maps},
	keywords = {Cognitive systems; Conformal mapping; Knowledge representation; Self organizing maps; Signal processing; Anomalous events; Information bottleneck; Information bottleneck theories; Large-scale video surveillances; Reconstruction capability; Representation techniques; Self organizing maps(soms); Wide-area surveillance systems; Security systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Bisoi2011277,
	author = {Bisoi, Ranjeeta and Dash, P.K.},
	title = {A PSO based time series data clustering using modified S-transform for data mining},
	year = {2011},
	journal = {International Journal of Data Mining, Modelling and Management},
	volume = {3},
	number = {3},
	pages = {277 – 302},
	doi = {10.1504/IJDMMM.2011.041810},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858408473&doi=10.1504%2fIJDMMM.2011.041810&partnerID=40&md5=7fa69704aeedfdf5e4c5909a9b7ca32b},
	abstract = {This paper presents a new approach for power signal time series data mining using S-transform (ST) based K-means clustering technique. Initially the power signal time series disturbance data are pre-processed through an advanced signal processing tool such as ST and various statistical features are extracted, which are used as inputs to the K-means algorithm for disturbance event detection. Particle swarm optimisation (PSO) technique is used to optimise cluster centres which can be inputs to a decision tree for pattern classification. The proposed hybrid PSO-K-means clustering technique provides accurate classification rates even under noisy conditions compared to the existing techniques, which shows the efficacy and robustness of the proposed algorithm for time varying database like the power signal data. Copyright © 2011 Inderscience Enterprises Ltd.},
	author_keywords = {Classification; Decision tree; K-means clustering; Particle swarm optimisation; PSO; S-transform; ST; Time-varying power signal data},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hossain201471,
	author = {Hossain, Syed Monowar and Ali, Amin Ahsan and Rahman, Md. Mahbubur and Ertin, Emre and Epstein, David and Kennedy, Ashley and Preston, Kenzie and Umbricht, Annie and Chen, Yixin and Kumar, Santosh},
	title = {Identifying drug (cocaine) intake events from acute physiological response in the presence of free-living physical activity},
	year = {2014},
	journal = {IPSN 2014 - Proceedings of the 13th International Symposium on Information Processing in Sensor Networks (Part of CPS Week)},
	pages = {71 – 82},
	doi = {10.1109/IPSN.2014.6846742},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904674926&doi=10.1109%2fIPSN.2014.6846742&partnerID=40&md5=1a74e549d21c5549f50d4d1c01474be8},
	abstract = {A variety of health and behavioral states can potentially be inferred from physiological measurements that can now be collected in the natural free-living environment. The major challenge, however, is to develop computational models for automated detection of health events that can work reliably in the natural field environment. In this paper, we develop a physiologically-informed model to automatically detect drug (cocaine) use events in the free-living environment of participants from their electrocardiogram (ECG) measurements. The key to reliably detecting drug use events in the field is to incorporate the knowledge of autonomic nervous system (ANS) behavior in the model development so as to decompose the activation effect of cocaine from the natural recovery behavior of the parasympathetic nervous system (after an episode of physical activity). We collect 89 days of data from 9 active drug users in two residential lab environments and 922 days of data from 42 active drug users in the field environment, for a total of 11,283 hours. We develop a model that tracks the natural recovery by the parasympathetic nervous system and then estimates the dampening caused to the recovery by the activation of the sympathetic nervous system due to cocaine. We develop efficient methods to screen and clean the ECG time series data and extract candidate windows to assess for potential drug use. We then apply our model on the recovery segments from these windows. Our model achieves 100% true positive rate while keeping the false positive rate to 0.87/day over (9+ hours/day of) lab data and to 1.13/day over (11+ hours/day of) field data. © 2014 IEEE.},
	author_keywords = {Drug Event Detection; Electrocardiogram; Wearable Sensors},
	keywords = {Chemical activation; Data processing; Electrocardiography; Physiology; Recovery; Sensor networks; Sensors; Autonomic nervous system; Event detection; False positive rates; Parasympathetic nervous systems; Physiological measurement; Physiological response; Sympathetic nervous systems; Wearable sensors; Physiological models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 35}
}

@ARTICLE{Hou2013,
	author = {Hou, Dibo and He, Huimei and Huang, Pingjie and Zhang, Guangxin and Loaiciga, Hugo},
	title = {Detection of water-quality contamination events based on multi-sensor fusion using an extented Dempster-Shafer method},
	year = {2013},
	journal = {Measurement Science and Technology},
	volume = {24},
	number = {5},
	doi = {10.1088/0957-0233/24/5/055801},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876766670&doi=10.1088%2f0957-0233%2f24%2f5%2f055801&partnerID=40&md5=665c3624451829885ecba3b2b269a54c},
	abstract = {This study presents a method for detecting contamination events of sources of drinking water based on the Dempster-Shafer (D-S) evidence theory. The detection method has the purpose of protecting water supply systems against accidental and intentional contamination events. This purpose is achieved by first predicting future water-quality parameters using an autoregressive (AR) model. The AR model predicts future water-quality parameters using recent measurements of these parameters made with automated (on-line) water-quality sensors. Next, a probabilistic method assigns probabilities to the time series of residuals formed by comparing predicted water-quality parameters with threshold values. Finally, the D-S fusion method searches for anomalous probabilities of the residuals and uses the result of that search to determine whether the current water quality is normal (that is, free of pollution) or contaminated. The D-S fusion method is extended and improved in this paper by weighted averaging of water-contamination evidence and by the analysis of the persistence of anomalous probabilities of water-quality parameters. The extended D-S fusion method makes determinations that have a high probability of being correct concerning whether or not a source of drinking water has been contaminated. This paper's method for detecting water-contamination events was tested with water-quality time series from automated (on-line) water quality sensors. In addition, a small-scale, experimental, water-pipe network was tested to detect water-contamination events. The two tests demonstrated that the extended D-S fusion method achieves a low false alarm rate and high probabilities of detecting water contamination events. © 2013 IOP Publishing Ltd.},
	author_keywords = {data fusion; Dempster-Shafer method; evidence-conflict resolution; water-contamination event detection},
	keywords = {Contamination; Data fusion; Pollution detection; Potable water; Probability; Time series; Water; Water pipelines; Water quality; Water supply; Water supply systems; Auto regressive models; Conflict Resolution; Dempster-Shafer evidence theory; Dempster-Shafer method; Intentional contaminations; Probabilistic methods; Water contamination; Water quality parameters; Water pollution},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 46; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Arroyo2013457,
	author = {Arroyo, D. and Chamorro, P. and Amigó, J.M. and Rodríguez, F.B. and Varona, P.},
	title = {Event detection, multimodality and non-stationarity: Ordinal patterns, a tool to rule them all?},
	year = {2013},
	journal = {European Physical Journal: Special Topics},
	volume = {222},
	number = {2},
	pages = {457 – 472},
	doi = {10.1140/epjst/e2013-01852-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879711793&doi=10.1140%2fepjst%2fe2013-01852-9&partnerID=40&md5=a067b3a43ab259e95d58eb5e374c1896},
	abstract = {In this work, we apply ordinal analysis of time series to the characterisation of neuronal activity. Automatic event detection is performed by means of the so-called permutation entropy, along with the quantification of the relative cardinality of forbidden patterns. In addition, multivariate time series are characterised using the joint permutation entropy. In order to illustrate the suitability of the ordinal analysis for characterising neurophysiological data, we have compared the measures based on ordinal patterns of time series to the tools typically used in the context of neurophysiology. © 2013 EDP Sciences and Springer.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Chae2012143,
	author = {Chae, Junghoon and Thom, Dennis and Bosch, Harald and Jang, Yun and Maciejewski, Ross and Ebert, David S. and Ertl, Thomas},
	title = {Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition},
	year = {2012},
	journal = {IEEE Conference on Visual Analytics Science and Technology 2012, VAST 2012 - Proceedings},
	pages = {143 – 152},
	doi = {10.1109/VAST.2012.6400557},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872940321&doi=10.1109%2fVAST.2012.6400557&partnerID=40&md5=6b96db7dfdcb58b83077403ec33dfc75},
	abstract = {Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process. © 2012 IEEE.},
	author_keywords = {H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval - Information filtering, relevance feedback; H.5.2 [Information Interfaces and Presentation]: User Interfaces - GUI},
	keywords = {Graphical user interfaces; Statistics; Control charts; Data sets; Data-sources; Event detection; H.5.2 [Information Interfaces and Presentation]: User Interfaces; Information search and retrieval; Interactive visual analysis; Internet users; Latent Dirichlet allocation; Seasonal trends; Situational awareness; Social media; Spatio-temporal data; Temporal trends; Visual analytics; YouTube; Data visualization},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 215}
}

@ARTICLE{Khalid20103636,
	author = {Khalid, Shehzad},
	title = {Activity classification and anomaly detection using m-mediods based modelling of motion patterns},
	year = {2010},
	journal = {Pattern Recognition},
	volume = {43},
	number = {10},
	pages = {3636 – 3647},
	doi = {10.1016/j.patcog.2010.05.006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953651708&doi=10.1016%2fj.patcog.2010.05.006&partnerID=40&md5=4d3534ac24bf995e9aa5d80215fdb319},
	abstract = {Techniques for video object motion analysis, behaviour recognition and event detection are becoming increasingly important with the rapid increase in demand for and deployment of video surveillance systems. Motion trajectories provide rich spatiotemporal information about an object's activity. This paper presents a novel technique for classification of motion activity and anomaly detection using object motion trajectory. In the proposed motion learning system, trajectories are treated as time series and modelled using modified DFT-based coefficient feature space representation. A modelling technique, referred to as m-mediods, is proposed that models the class containing n members with m mediods. Once the m-mediods based model for all the classes have been learnt, the classification of new trajectories and anomaly detection can be performed by checking the closeness of said trajectory to the models of known classes. A mechanism based on agglomerative approach is proposed for anomaly detection. Four anomaly detection algorithms using m-mediods based representation of classes are proposed. These includes: (i)global merged anomaly detection (GMAD), (ii) localized merged anomaly detection (LMAD), (iii) global un-merged anomaly detection (GUAD), and (iv) localized un-merged anomaly detection (LUAD). Our proposed techniques are validated using variety of simulated and complex real life trajectory datasets. © 2010 Elsevier Ltd. All rights reserved.},
	author_keywords = {Anomaly detection; Dimensionality reduction; Event mining; Motion recognition; Object trajectory; Trajectory modelling},
	keywords = {Mergers and acquisitions; Model checking; Security systems; Time series; Anomaly detection; Dimensionality reduction; Event mining; Motion recognition; Object trajectories; Object trajectory; Trajectories},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29}
}

@ARTICLE{Tian20141886,
	author = {Tian, Bo and Wang, Dian Hong and Chen, Fen Xiong and Zhang, Zheng Pu},
	title = {Based on ETEO pattern abnormal event detection in wireless sensor networks},
	year = {2014},
	journal = {Advanced Materials Research},
	volume = {926-930},
	pages = {1886 – 1889},
	doi = {10.4028/www.scientific.net/AMR.926-930.1886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902288729&doi=10.4028%2fwww.scientific.net%2fAMR.926-930.1886&partnerID=40&md5=7ea35181eeec15c429ec8bcb30de8515},
	abstract = {This paper presents a new algorithm for the detection of abnormal events in Wireless Sensor Networks (WSN). Abnormal events are sets of data points that correspond to interesting patterns in the underlying phenomenon that the network monitors. This algorithm is inspired from time-series data mining techniques and transforms a stream of sensor readings into an Extension Temporal Edge Operator (ETEO) of time series pattern representation, and then extracts the three eigenvalue of each sub-pattern, that is, pattern's length, pattern's slope and pattern's mean to map time series to feature space, and finally uses local outlier factor to detect abnormal pattern in this feature space. Experiments on synthetic and real data show that the definition of pattern outlier is reasonable and this algorithm is efficient to detect outliers in WSN. © (2014) Trans Tech Publications, Switzerland.},
	author_keywords = {Abnormal event detection; ETEO compressed pattern; Local outlier factor; WSN},
	keywords = {Algorithms; Eigenvalues and eigenfunctions; Time series; Abnormal event detections; Abnormal patterns; ETEO compressed pattern; Local Outlier Factor; Network monitors; Synthetic and real data; Time series patterns; WSN; Wireless sensor networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen2014632,
	author = {Chen, Xi C. and Mueen, Abdullah and Narayanan, Vijay K. and Karampatziakis, Nikos and Bansal, Gagan and Kumar, Vipin},
	title = {Online discovery of group level events in time series},
	year = {2014},
	journal = {SIAM International Conference on Data Mining 2014, SDM 2014},
	volume = {2},
	pages = {632 – 640},
	doi = {10.1137/1.9781611973440.73},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959934062&doi=10.1137%2f1.9781611973440.73&partnerID=40&md5=adfe013ec56694d25d6e698ef77760cc},
	abstract = {Recent advances in high throughput data collection and storage technologies have led to a dramatic increase in the availability of high-resolution time series data sets in various domains. These time series reflect the dynamics of the underlying physical processes in these domains. Detecting changes in a time series over time or changes in the relationships among the time series in a data set containing multiple contemporaneous time series can be useful to detect changes in these physical processes. Contextual events detection algorithms detect changes in the relationships between multiple related time series. In this work, we introduce a new type of contextual events, called group level contextual change events. In contrast to individual contextual change events that reflect the change in behavior of one target time series against a context, group level events reflect the change in behavior of a target group of time series relative to a context group of time series. We propose an online framework to detect two types of group level contextual change events: (i) group formation (i.e., detecting when a set of multiple unrelated timeseries or groups of time series with little prior relationship in their behavior forms a new group of related time series) and (ii) group disbanding (i.e., detecting when one stable set of related time series disbands into two or more subgroups with little relationship in their behavior). We demonstrate this framework using 2 real world datasets and show that the framework detects group level contextual change events that can be explained by plausible causes. © SIAM.},
	keywords = {Digital storage; Time series; Events detection; Group formations; High resolution; High-throughput data; Online discovery; Physical process; Real-world datasets; Storage technology; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{2012,
	title = {Geographic Information Science - 7th International Conference, GIScience 2012, Proceedings},
	year = {2012},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {7478 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867611129&partnerID=40&md5=19d05f4561b37b490c4f13ec152b4f27},
	abstract = {The proceedings contain 26 papers. The topics discussed include: automated centerline delineation to enrich the national hydrography dataset; evolution strategies for optimizing rectangular cartograms; context-aware similarity of trajectories; generating named road vector data from raster maps; an ordering of convex topological relations; toward web mapping with vector data; quantifying resolution sensitivity of spatial autocorrelation: a resolution correlogram approach; high-level event detection in spatially distributed time series; measuring the influence of built environment on walking behavior: an accessibility approach; investigations into the cognitive conceptualization and similarity assessment of spatial scenes; dynamic refuse collection strategy based on adjacency relationship between Euler cycles; ontology for the engineering of geospatial systems; and preserving detail in a combined land use ontology.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Andrienko201048,
	author = {Andrienko, Gennady and Andrienko, Natalia and Mladenov, Martin and Mock, Michael and Poelitz, Christian},
	title = {Extracting events from spatial time series},
	year = {2010},
	journal = {Proceedings of the International Conference on Information Visualisation},
	pages = {48 – 53},
	doi = {10.1109/IV.2010.17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78449309335&doi=10.1109%2fIV.2010.17&partnerID=40&md5=0ca00935bb3de812453c99a43ea07a84},
	abstract = {An important task in exploration of data about phenomena and processes that develop over time is detection of significant changes that happened to the studied phenomenon. Our research is focused on supporting detection of significant changes, called events, in multiple time series of numeric values. We developed a suite of visual analytics techniques that combines interactive visualizations on time-aware displays and maps with statistical event detection methods implemented in R. We demonstrate the utility of our approach using two large data sets. © 2010 IEEE.},
	author_keywords = {Event detection; Time series; Visual analytics},
	keywords = {Time series; Event detection; Interactive visualizations; Large datasets; Multiple time series; Numeric values; Visual analytics; Visualization},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@ARTICLE{Gabarda2010413,
	author = {Gabarda, S. and Cristóbal, G.},
	title = {Detection of events in seismic time series by time-frequency methods},
	year = {2010},
	journal = {IET Signal Processing},
	volume = {4},
	number = {4},
	pages = {413 – 420},
	doi = {10.1049/iet-spr.2009.0125},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952850891&doi=10.1049%2fiet-spr.2009.0125&partnerID=40&md5=382cde201afc81e37655016d6d472011},
	abstract = {The detection of events in seismic time series has been a subject of great interest during the last 30 years. Most of the works in this area were based on detecting special patterns or clusters in seismic data. The authors present here a event detection method based on a time-frequency analysis through the Wigner distribution (WD). The proposed method consists on defining an appropriate entropic measure through a suitable time-frequency distribution, acting as probability distribution function. It is known from previous studies in the field that the information entailed by time-frequency representations (TFR) of time signals can be explored by means of different Rényi entropy measures. The non-positivity character of the WD implies that the classical Shannon entropy cannot be used, and therefore it has been replaced by a generalised measure such as the Rényi entropy. However, owing to the existence of multiple TFR normalisations, the so-called quantum normalisation has been empirically selected here for this particular application. This method is based on the identification of the events as those temporal clusters having the highest amount of information (entropy). The method is described and applied to different earthquake signals and volcanic tremors, using both real and synthetic data. The results are compared to other existing event detection methods. 2010 © The Institution of Engineering and Technology.},
	keywords = {Distribution functions; Entropy; Seismology; Time series; Amount of information; Entropic measures; Entropy measure; Event detection; Normalisation; Seismic datas; Shannon entropy; Synthetic data; Time frequency analysis; Time signals; Time-frequency distributions; Time-frequency methods; Time-frequency representations; Volcanic tremor; Wigner distributions; Signal detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Green Open Access}
}

@CONFERENCE{Keane201335,
	author = {Keane, Tommy P. and Cahill, Nathan D. and Pelz, Jeff B.},
	title = {Image sequence event detection VIA recurrence analysis},
	year = {2013},
	journal = {2013 IEEE Western New York Image Processing Workshop, WNYIPW 2013 - Proceedings},
	pages = {35 – 38},
	doi = {10.1109/WNYIPW.2013.6890986},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928632763&doi=10.1109%2fWNYIPW.2013.6890986&partnerID=40&md5=4a2665f9899594c52726c4e4fefd82fc},
	abstract = {Recurrence analysis methods have been used in a wide array of fields for the purposes of obtaining some grasp of the characteristics of a chaotically dynamical system. At the heart of the recurrence plotting and quantification analysis algorithm, though, is a means of visualizing and measuring repeating sequences of time-dependent data. It is in this sense we present a novel means of extracting an event from an image sequence by analyzing selected features as multi-dimensional samples of the time-series. The analysis and development of recurrence plots (RPs) naturally lend themselves to sequence detection, and we are presenting an attempt to target eye-movement events as such time-series sequences. We can then apply relatively simple quantification measures through Recurrence Quantification Analysis (RQA), thereby immediately detecting an event and capturing some characteristic statistics. To highlight an application of this methodology, we are presenting an approach towards detecting fixational eye-movement events from a video recording of natural eye motions. © 2013 IEEE.},
	author_keywords = {eye-tracking; recurrence plots; recurrence quantification analysis; Video event detection},
	keywords = {Computer vision; Dynamical systems; Image analysis; Image processing; Multivariable control systems; Speech processing; Time series; Time series analysis; Video recording; Eye-tracking; Fixational eye movements; Quantification analysis; Recurrence analysis; Recurrence plot; Recurrence quantification analysis; Time-dependent data; Video event detections; Eye movements},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Takagi201081,
	author = {Takagi, Takashi and Kawashima, Hideyuki and Amagasa, Toshiyuki and Kitagawa, Hiroyuki},
	title = {Providing constructed buildings information by ASTER satellite DEM images and web contents},
	year = {2010},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {6193 LNCS},
	pages = {81 – 92},
	doi = {10.1007/978-3-642-14589-6_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956148946&doi=10.1007%2f978-3-642-14589-6_9&partnerID=40&md5=a1fbe6384f3b7085bb90993febee56f5},
	abstract = {It has become easy to accumulate and to deliver scientific data by the evolution of computer technologies. The GEO Grid project has collected global satellite images from 2000 to present, and the amount of the collection is about 150 TB. It is required to generate new values by integrating satellite images with heterogeneous information such as Web contents or geographical data. Using GEO Grid satellite images, some researches detect feature changes such as earthquakes, fires and newly constructed building. In this paper, detections of feature changes from time series satellite image are referred to as events, and we focus on events about newly constructed buildings. Usually, there are articles about such newly constructed buildings on the Web. For example, a newly started shopping center is usually introduced in a news report, and a newly constructed apartment is often on the lips of neighboring residents. So, we propose an event detection system that extracts candidate events from satellite images, collects information about them from the Web, and integrates them. This system consists of an event detection module and a Web contents collection module. The event detection module detects geographical regions that have differences with elevation values between two satellite images which are temporally different. The expressions of regions are translated from latitudes/longitudes to building names by using an inverse geocoder. Then, the contents collection module collects Web pages by querying names of buildings to a search engine. The collected pages are re-ranked based on temporal information which is close to event occurrence time. We developed a prototype system. The result of evaluation showed that the system detected some information of building construction events with appropriate web contents in Tsukuba, Japan. © 2010 Springer-Verlag Berlin Heidelberg.},
	keywords = {Buildings; Database systems; Geographical regions; Satellites; Search engines; Shopping centers; Technical presentations; Time series; Building construction; Computer technology; Event detection; Geographical data; Grid projects; Heterogeneous information; Prototype system; Satellite images; Scientific data; Temporal information; Web content; Web page; World Wide Web},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Drob2010437,
	author = {Drob, Douglas P. and Garcés, Milton and Hedlin, Michael and Brachet, Nicolas},
	title = {The temporal morphology of infrasound propagation},
	year = {2010},
	journal = {Pure and Applied Geophysics},
	volume = {167},
	number = {4-5},
	pages = {437 – 453},
	doi = {10.1007/s00024-010-0080-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951205246&doi=10.1007%2fs00024-010-0080-6&partnerID=40&md5=2eadd9379603208752a671fac753e29b},
	abstract = {Expert knowledge suggests that the performance of automated infrasound event association and source location algorithms could be greatly improved by the ability to continually update station travel-time curves to properly account for the hourly, daily, and seasonal changes of the atmospheric state. With the goal of reducing false alarm rates and improving network detection capability we endeavor to develop, validate, and integrate this capability into infrasound processing operations at the International Data Centre of the Comprehensive Nuclear Test-Ban Treaty Organization. Numerous studies have demonstrated that incorporation of hybrid ground-to-space (G2S) enviromental specifications in numerical calculations of infrasound signal travel time and azimuth deviation yields significantly improved results over that of climatological atmospheric specifications, specifically for tropospheric and stratospheric modes. A robust infrastructure currently exists to generate hybrid G2S vector spherical harmonic coefficients, based on existing operational and emperical models on a real-time basis (every 3- to 6-hours) (Drobet al.,2003). Thus the next requirement in this endeavor is to refine numerical procedures to calculate infrasound propagation characteristics for robust automatic infrasound arrival identification and network detection, location, and characterization algorithms. We present results from a new code that integrates the local (range-independent) τp ray equations to provide travel time, range, turning point, and azimuth deviation for any location on the globe given a G2S vector spherical harmonic coefficient set. The code employs an accurate numerical technique capable of handling square-root singularities. We investigate the seasonal variability of propagation characteristics over a five-year time series for two different stations within the International Monitoring System with the aim of understanding the capabilities of current working knowledge of the atmosphere and infrasound propagation models. The statistical behaviors or occurrence frequency of various propagation configurations are discussed. Representative examples of some of these propagation configuration states are also shown. © 2010 US Government.},
	author_keywords = {Atmospheric variability; Automated event detection; Climatology; CTBTO; IDC; IMS; Infrasound; Source location},
	keywords = {algorithm; azimuth; climatology; nuclear weapons testing; seasonal variation; signal processing; sound propagation; stratosphere; temporal analysis; travel time; troposphere},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55}
}

@ARTICLE{Tosi2014821,
	author = {Tosi, Stefania and Casolari, Sara and Colajanni, Michele},
	title = {Detecting correlation between server resources for system management},
	year = {2014},
	journal = {Journal of Computer and System Sciences},
	volume = {80},
	number = {4},
	pages = {821 – 836},
	doi = {10.1016/j.jcss.2014.01.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894073248&doi=10.1016%2fj.jcss.2014.01.002&partnerID=40&md5=8543f528434c909e5ec3679ab8b25d68},
	abstract = {Efficient system management requires continuous knowledge about the state of system and application resources that are typically represented through time series obtained by monitors. Capacity planning studies, forecasting, state aggregation, anomaly and event detection would be facilitated by evidence of data correlations. Unfortunately, the high variability characterizing most monitored time series affects the accuracy and robustness of existing correlation solutions. This paper proposes an innovative approach that is especially tailored to detect linear and non-linear correlation between time series characterized by high variability. We compare the proposed solution and existing algorithms in terms of accuracy and robustness for several synthetic and real settings characterized by low and high variability, linear and non-linear correlation. The results show that our proposal guarantees analogous performance for low variable time series, and improves state of the art in finding correlations in highly variable domains that are of interest for the application context. © 2014 Elsevier Inc.},
	author_keywords = {Correlation model; Data analysis; High variability},
	keywords = {Computer networks; Data reduction; Systems science; Application contexts; Capacity planning; Correlation modeling; High variability; Innovative approaches; Non-linear correlations; State aggregation; System management; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Ghaffari20115299,
	author = {Ghaffari, Ali and Homaeinezhad, Mohammad R. and Daevaeiha, Mohammad M.},
	title = {High resolution ambulatory holter ECG events detection-delineation via modified multi-lead wavelet-based features analysis: Detection and quantification of heart rate turbulence},
	year = {2011},
	journal = {Expert Systems with Applications},
	volume = {38},
	number = {5},
	pages = {5299 – 5310},
	doi = {10.1016/j.eswa.2010.10.028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79151480414&doi=10.1016%2fj.eswa.2010.10.028&partnerID=40&md5=46bef8614220145aceb2f1ffb9311072},
	abstract = {The presented study describes a false-alarm probability-FAP bounded solution for detecting and quantifying Heart Rate Turbulence (HRT) major parameters including heart rate (HR) acceleration/deceleration, turbulence jump, compensatory pause value and HR recovery rate. To this end, first, high resolution multi-lead holter electrocardiogram (ECG) signal is appropriately pre-processed via Discrete Wavelet Transform (DWT) and then, a fixed sample size sliding window is moved on the pre-processed trend. In each slid, the area under the excerpted segment is multiplied by its curve-length to generate the Area Curve Length (ACL) metric to be used as the ECG events detection- delineation decision statistic (DS). The ECG events detection-delineation algorithm was applied to various existing databases and as a result, the average values of sensitivity and positive predictivity Se = 99.95% and P+ = 99.92% were obtained for the detection of QRS complexes, with the average maximum delineation error of 7.4 msec, 4.2 msec and 8.3 msec for P-wave, QRS complex and T-wave, respectively. Because the heart-rate time series might include fast fluctuations which don't follow a premature ventricular contraction (PVC) causing high-level false alarm probability (false positive detections) of HRT detection, based on the binary two-dimensional Neyman-Pearson radius test (which is a FAP-bounded classifier), a new method for discrimination of PVCs from other beats using the geometrical-based features is proposed. The statistical performance of the proposed HRT detection-quantification algorithm was obtained as Se = 99.94% and P+ = 99.85% showing marginal improvement for the detection-quantification of this phenomenon. In summary, marginal performance improvement of ECG events detection-delineation process, high performance PVC detection and isolation from noisy holter data and reliable robustness against holter strong noise and artifacts can be mentioned as important merits and capabilities of the proposed HRT detection algorithm. © 2010 Elsevier Ltd. All rights reserved.},
	author_keywords = {Binary Neyman-Pearson radius test; Curve Length Method; Discrete wavelet transform; ECG Delineation; Heart rate turbulence; Multi lead analysis; Premature ventricular contraction},
	keywords = {Algorithms; Discrete wavelet transforms; Electrocardiography; Electrochromic devices; Error detection; Heart; Probability; Time series; Turbulence; Curve Length Method; Discrete wavelets; ECG Delineation; Heart rate turbulence; Multi lead analysis; Neyman-pearson; Premature ventricular contraction; Chemical detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@ARTICLE{Ba20157,
	author = {Ba, Amadou and McKenna, Sean A.},
	title = {Water quality monitoring with online change-point detection methods},
	year = {2015},
	journal = {Journal of Hydroinformatics},
	volume = {17},
	number = {1},
	pages = {7 – 19},
	doi = {10.2166/hydro.2014.126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924127990&doi=10.2166%2fhydro.2014.126&partnerID=40&md5=0bb0a4d8438610b7bb11898b3250e768},
	abstract = {We develop an approach for water quality time series monitoring and contamination event detection. The approach combines affine projection algorithms and an autoregressive (AR) model to predict water quality time series. Then, we apply online change-point detection methods to the estimated residuals to determine the presence, or not, of contamination events. Particularly, we compare the performance of four change-point detection methods, namely, sequential probability ratio test (SPRT), cumulative sum (CUSUM), binomial event discriminator (BED), and online Bayesian change-point detection (OBCPD), by using residuals obtained from four water quality time series, chlorine, conductivity, total organic carbon, and turbidity. Our fundamental criterion for the performance evaluation of the four change-point detection methods is given by the receiver operating characteristic (ROC) curve which is characterized by the true positive rate as a function of the false positive rate. We highlight with detailed experiments that OBCPD provides the best performance for large contamination events, and we also provide insight on the choice of change-point detection algorithms to consider for designing efficient contamination detection schemes.},
	author_keywords = {Change-point detection; Prediction; ROC; Time series; Water quality},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Victor Paul Raj2014,
	author = {Victor Paul Raj, Fredrick Robin Devadoss and Exner, Thomas E.},
	title = {Cα torsion angles as a flexible criterion to extract secrets from a molecular dynamics simulation},
	year = {2014},
	journal = {Journal of Molecular Modeling},
	volume = {20},
	number = {4},
	doi = {10.1007/s00894-014-2196-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898794207&doi=10.1007%2fs00894-014-2196-6&partnerID=40&md5=3f975dbdadbfe4546f22375fe1a7239e},
	abstract = {Given the increasing complexity of simulated molecular systems, and the fact that simulation times have now reached milliseconds to seconds, immense amounts of data (in the gigabyte to terabyte range) are produced in current molecular dynamics simulations. Manual analysis of these data is a very time-consuming task, and important events that lead from one intermediate structure to another can become occluded in the noise resulting from random thermal fluctuations. To overcome these problems and facilitate a semi-automated data analysis, we introduce in this work a measure based on Cα torsion angles: torsion angles formed by four consecutive Cα atoms. This measure describes changes in the backbones of large systems on a residual length scale (i.e., a small number of residues at a time). Cluster analysis of individual Cα torsion angles and its fuzzification led to continuous time patches representing (meta)stable conformations and to the identification of events acting as transitions between these conformations. The importance of a change in torsion angle to structural integrity is assessed by comparing this change to the average fluctuations in the same torsion angle over the complete simulation. Using this novel measure in combination with other measures such as the root mean square deviation (RMSD) and time series of distance measures, we performed an in-depth analysis of a simulation of the open form of DNA polymerase I. The times at which major conformational changes occur and the most important parts of the molecule and their interrelations were pinpointed in this analysis. The simultaneous determination of the time points and localizations of major events is a significant advantage of the new bottom-up approach presented here, as compared to many other (top-down) approaches in which only the similarity of the complete structure is analyzed. © Springer-Verlag 2014.},
	author_keywords = {C-alpha torsion angle; DNA polymerase I; Event detection; Fuzzy clustering},
	keywords = {Models, Molecular; Molecular Conformation; Molecular Dynamics Simulation; Protein Binding; Protein Structure, Tertiary; DNA directed DNA polymerase beta; article; cluster analysis; comparative study; conformational transition; data analysis; molecular dynamics; priority journal; time series analysis; torsion; torsion angle; chemical structure; conformation; protein binding; protein tertiary structure},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hassan201520,
	author = {Hassan, Ehtesham and Shroff, Gautam and Agarwal, Puneet},
	title = {Multi-sensor event detection using shape histograms},
	year = {2015},
	journal = {ACM International Conference Proceeding Series},
	volume = {18-21-March-2015},
	pages = {20 – 29},
	doi = {10.1145/2732587.2732591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958526095&doi=10.1145%2f2732587.2732591&partnerID=40&md5=6315d029a4542baf544d7ab391b51e15},
	abstract = {Vehicular sensor data consists of multiple time-series arising from a number of sensors. Using such multi-sensor data we would like to detect occurrences of specific events that vehicles encounter, e.g., corresponding to particular maneuvers that a vehicle makes or conditions that it encounters. Events are characterized by similar waveform patterns reappearing within one or more sensors. Further such patterns can be of variable duration. In this paper, we propose a method for detecting such events in time-series data using a novel feature descriptor motivated by similar ideas in image processing. We define the shape histogram: a constant dimension descriptor that nevertheless captures patterns of variable duration. We demonstrate the efficacy of using shape histograms as features to detect events in an SVM-based, multi-sensor, supervised learning scenario, i.e., multiple time-series are used to detect an event. We present results on real-life vehicular sensor data and show that our technique performs better than available pattern detection implementations on our data, and that it can also be used to combine features from multiple sensors resulting in better accuracy than using any single sensor. Since previous work on pattern detection in time-series has been in the single series context, we also present results using our technique on multiple standard time-series datasets and show that it is the most versatile in terms of how it ranks compared to other published results. Copyright 2015 ACM.},
	author_keywords = {Theory},
	keywords = {Graphic methods; Image processing; Pattern recognition; Time series; Feature descriptors; Multi-sensor data; Multiple sensors; Multiple standards; Multiple time series; Pattern detection; Theory; Waveform patterns; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Jeni2014135,
	author = {Jeni, László A. and Lorincz, András and Szabó, Zoltán and Cohn, Jeffrey F. and Kanade, Takeo},
	title = {Spatio-temporal event classification using time-series kernel based structured sparsity},
	year = {2014},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8692 LNCS},
	number = {PART 4},
	pages = {135 – 150},
	doi = {10.1007/978-3-319-10593-2_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906491165&doi=10.1007%2f978-3-319-10593-2_10&partnerID=40&md5=156d47820e9f91b96a3789dca82b1cb0},
	abstract = {In many behavioral domains, such as facial expression and gesture, sparse structure is prevalent. This sparsity would be well suited for event detection but for one problem. Features typically are confounded by alignment error in space and time. As a consequence, high-dimensional representations such as SIFT and Gabor features have been favored despite their much greater computational cost and potential loss of information. We propose a Kernel Structured Sparsity (KSS) method that can handle both the temporal alignment problem and the structured sparse reconstruction within a common framework, and it can rely on simple features. We characterize spatio-temporal events as time-series of motion patterns and by utilizing time-series kernels we apply standard structured-sparse coding techniques to tackle this important problem. We evaluated the KSS method using both gesture and facial expression datasets that include spontaneous behavior and differ in degree of difficulty and type of ground truth coding. KSS outperformed both sparse and non-sparse methods that utilize complex image features and their temporal extensions. In the case of early facial event classification KSS had 10% higher accuracy as measured by F 1 score over kernel SVM methods. © 2014 Springer International Publishing.},
	author_keywords = {facial expression classification; gesture recognition; structured sparsity; time-series kernels},
	keywords = {Gesture recognition; Computer vision; Gesture recognition; Time series; Computational costs; Event classification; Facial expression classification; Sparse reconstruction; Spatio-temporal events; Structured sparsities; Temporal extensions; Time-series kernels; Face recognition; Face recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Bansal2012218,
	author = {Bansal, Naveen K. and Feng, Xin and Zhang, Wenjing and Wei, Wutao and Zhao, Yuanhao},
	title = {Modeling temporal pattern and event detection using Hidden Markov Model with application to a sludge bulking data},
	year = {2012},
	journal = {Procedia Computer Science},
	volume = {12},
	pages = {218 – 223},
	doi = {10.1016/j.procs.2012.09.059},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896996165&doi=10.1016%2fj.procs.2012.09.059&partnerID=40&md5=b6d763a34cd9426bfd0863ff71ff048a},
	abstract = {This paper discusses a method of modeling temporal pattern and event detection based on Hidden Markov Model (HMM) for a continuous time series data. We also provide methods for checking model adequacy and predicting future events. These methods are applied to a real example of sludge bulking data for detecting sludge bulking for a water plant in Chicago. © 2012 Published by Elsevier B.V.},
	author_keywords = {Hidden Markov Model; Sludge Bulking; Temporal Patterns},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}@CONFERENCE{Zheng2009416,
	author = {Zheng, Aihua and Ma, Jixin and Luo, Bin and Petridis, Miltos and Zhai, Sulan and Tang, Jin},
	title = {Temporal pattern recognition in video clips detection},
	year = {2009},
	journal = {Proceedings of the 2009 8th IEEE/ACIS International Conference on Computer and Information Science, ICIS 2009},
	pages = {416 – 421},
	doi = {10.1109/ICIS.2009.144},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350743334&doi=10.1109%2fICIS.2009.144&partnerID=40&md5=b8c52ca95e08e31915ec4c1b36299498},
	abstract = {Temporal representation and reasoning plays an important role in Data Mining and Knowledge Discovery, particularly, in mining and recognizing patterns with rich temporal information. Based on a formal characterization of time-series and state-sequences, this paper presents the computational technique and algorithm for matching state-based temporal patterns. As a case study of real-life applications, zone-defense pattern recognition in basketball games is specially examined as an illustrating example. Experimental results demonstrate that it provides a formal and comprehensive temporal ontology for research and applications in video events detection. © 2009 IEEE.},
	author_keywords = {Algorithm; Basketball zone-defense; Temporal pattern recognition},
	keywords = {Computation theory; Information science; Knowledge representation; Ontology; Basketball zone-defense; Computational technique; Data mining and knowledge discovery; Real-life applications; Research and application; State-based; Temporal information; Temporal pattern; Temporal pattern recognition; Temporal representations; Video clips; Video events; Pattern recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Guo20061378,
	author = {Guo, Junwen and Qin, Zheng and He, Shengping and Huang, Hexiao},
	title = {Simulation of space group formation for maneuvering target},
	year = {2006},
	journal = {Hsi-An Chiao Tung Ta Hsueh/Journal of Xi'an Jiaotong University},
	volume = {40},
	number = {12},
	pages = {1378 – 1382},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846379551&partnerID=40&md5=92cd7dbe0635b451d9ef06f098328615},
	abstract = {In order to solve the problems of space group formation and event detection in battlefield, a novel group formation algorithm for maneuvering target was proposed. The property similarities, i.e. attribute similarity, position similarity and velocity similarity, were defined by the information obtained from fusion at level 1, and all were re-fused to calculate the result of group formation. The uncertainty of measurement space was mapped into the fuzzy similarity space and then resolved by the fuzzy match mechanism. The simulation results show that the proposed algorithm can accomplish the multilevel group formation in real time with lower calculation complexity, and better performance can be achieved in the situation assessment for space group formation.},
	author_keywords = {Maneuvering target; Situation assessment; Space group formation},
	keywords = {Algorithms; Computational complexity; Fuzzy sets; Simulation; Time series analysis; Attribute similarity; Battlefield; Fuzzy match mechanism; Fuzzy similarity space; Maneuvering target; Measurement space; Position similarity; Property similarity; Situation assessment; Space group formation; Velocity similarity; Sensor data fusion},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{DiCecco2006147,
	author = {DiCecco, John and Salisbury, Jack and Sun, Ying},
	title = {A sequential algorithm for biological event detection using statistical nonstationarity},
	year = {2006},
	journal = {Proceedings of the IEEE Annual Northeast Bioengineering Conference, NEBEC},
	volume = {2006},
	pages = {147 – 148},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751114183&partnerID=40&md5=4b774e00c167a66dadaef5f62720434f},
	abstract = {High dimension complex dynamical systems, such as those found in physiological processes, are often accompanied by nonstationarity. In many cases, the nonstationarity is caused by a physiologically significant event such as the prelude to ventricular fibrillation in cardiac arrest or the change of stasis by introducing pharmaceuticals. A need exists to be able to detect and monitor this change. Most conventional attempts at addressing this problem involve segmenting the time series and evaluating the statistics of the segments. The difficulty with this approach is that the nature of the nonstationarity can be transient, such that it is bounded by two, or more, regions of stationarity. Further, vacillation between stationary and nonstationary segments may continue for a significant portion of the time series. This paper will discuss the underlying statistical justification for asserting stationarity and the use of segmentation time series analysis techniques. © 2006 IEEE.},
	author_keywords = {Biomedical engineering; Electrophysiology; Neurophysiology; Nonlinearity; Nonstationarity; Stationarity},
	keywords = {Algorithms; Cardiology; Drug products; Physiological models; Statistical methods; Time series analysis; Cardiac arrest; Ventricular fibrillation; Disease control},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{LeBlanc19861,
	author = {LeBlanc, A.-Robert},
	title = {QUANTITATIVE ANALYSIS OF CARDIAC ARRHYTHMIAS.},
	year = {1986},
	journal = {Critical Reviews in Biomedical Engineering},
	volume = {14},
	number = {1},
	pages = {1 – 43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022540742&partnerID=40&md5=c1b1b00f7d64392e620a4217a5e68899},
	abstract = {Waveform-detection and measurement have been the bottleneck of advancement in arrhythmia analysis since highly reliable detection of events on a beat-to-beat basis are necessary to perform a valid analysis. Rare approaches have proposed probabilistic definition of event detection. The present review puts emphasis on the potential of several methods which have been demonstrated as powerful in identifying short- or long-duration heartbeat patterns, mode of heartbeat initiation, mode of heartbeat coupling, etc. Globally, these methods are referred to as time series analysis, modeling of rhythm patterns, simulation, and pattern recognition. A delay in the advancement of the study of arrhythmogenesis and limiting the analysis of arrhythmias to textbook descriptions is not justified when put in perspective of the potential of implementing powerful techniques which have been more or less neglected or used in a narrow way.},
	keywords = {Arrhythmia; Biomedical Engineering; Biometry; Computers; Diagnosis, Computer-Assisted; Electrocardiography; Electrophysiology; Human; Models, Cardiovascular; Monitoring, Physiologic; Time Factors; BIOMEDICAL EQUIPMENT - Applications; COMPUTER AIDED ANALYSIS; MATHEMATICAL TECHNIQUES; SIGNAL PROCESSING; WAVEFORM ANALYSIS; biological model; biomedical engineering; biometry; computer; computer assisted diagnosis; electrocardiography; electrophysiology; heart arrhythmia; human; methodology; monitoring; pathophysiology; review; time; CARDIAC ARRHYTHMIAS; HEARTBEAT PATTERNS; QUANTITATIVE ANALYSIS; WAVEFORM MEASUREMENT; WAVEFORM-DETECTION; BIOMEDICAL ENGINEERING},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Roerdink20082628,
	author = {Roerdink, Melvyn and Coolen, Bert (H.) and Clairbois, Bert (H.)E. and Lamoth, Claudine J.C. and Beek, Peter J.},
	title = {Online gait event detection using a large force platform embedded in a treadmill},
	year = {2008},
	journal = {Journal of Biomechanics},
	volume = {41},
	number = {12},
	pages = {2628 – 2632},
	doi = {10.1016/j.jbiomech.2008.06.023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-49449086743&doi=10.1016%2fj.jbiomech.2008.06.023&partnerID=40&md5=60af144e3399c6cba112827ed0f23e24},
	abstract = {Gait research and clinical gait training may benefit from movement-dependent event control, that is, technical applications in which events such as obstacle appearance or visual/acoustic cueing are (co)determined online on the basis of current gait properties. A prerequisite for successful gait-dependent event control is accurate online detection of gait events such as foot contact (FC) and foot off (FO). The objective of the present study was to assess the feasibility of online FC and FO detection using a single large force platform embedded in a treadmill. Center-of-pressure, total force output and kinematic data were recorded simultaneously in 12 healthy participants. Online FC and FO estimates and spatial and temporal gait parameters estimated from the force platform data-i.e., center-of-pressure profiles-were compared to offline kinematic counterparts, which served as the gold standard. Good correspondence was achieved between online FC detections using center-of-pressure profiles and those derived offline from kinematic data, whereas FO was detected 31 ms too late. A good relative and absolute agreement was achieved for both spatial and temporal gait parameters, which was improved further by applying more fine-grained FO estimation procedures using characteristic local minima in the total force output time series. These positive results suggest that the proposed system for gait-dependent event control may be successfully implemented in gait research as well as gait interventions in clinical practice. © 2008 Elsevier Ltd. All rights reserved.},
	author_keywords = {Center-of-pressure; Force data; Gait kinematics; Online event detection; Treadmill walking},
	keywords = {Adult; Equipment Design; Equipment Failure Analysis; Exercise Test; Female; Gait; Humans; Locomotion; Male; Manometry; Physical Examination; Stress, Mechanical; Transducers; Estimation; Gold; Kinematics; Maximum likelihood estimation; Spacecraft propulsion; Sporting goods; Standards; Time series analysis; adult; article; body movement; female; foot; gait; human; kinematics; male; normal human; priority journal; treadmill; Center-of-pressure; Clinical practices; Event detection; FO estimation; Force data; Force platform data; Force platforms; Gait kinematics; Gait parameters; Gait research; Gait training; Gold standards; Kinematic data; Local minimums; On-line detection; Online event detection; Output time series; Technical applications; Total force; Treadmill walking; Parameter estimation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 120}
}

@CONFERENCE{Fujimaki2008472,
	author = {Fujimaki, Ryohei and Nakata, Takayuki and Tsukahara, Hidenori and Sato, Akinori and Yamanishi, Kenji},
	title = {Mining abnormal patterns from heterogeneous time-series with irrelevant features for fault event detection},
	year = {2008},
	journal = {Society for Industrial and Applied Mathematics - 8th SIAM International Conference on Data Mining 2008, Proceedings in Applied Mathematics 130},
	volume = {2},
	pages = {472 – 482},
	doi = {10.1137/1.9781611972788.43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-52649167834&doi=10.1137%2f1.9781611972788.43&partnerID=40&md5=f4c0a403bfa142f2e274be55c8ebb16c},
	abstract = {We address the issue of detecting fault events in multivariate time series. We suppose the following realistic situation: A) the features to which multivariate time series correspond are heterogeneous; B) relative to a large number of normal examples, only a small number of examples of fault events are available in advance; and C) many features irrelevant to fault events are included. In such a situation, we require real-time, high-accuracy processing. We propose an algorithm to resolve the issue, Key ideas in it include: 1) transforming the time-series for each feature into a sequence of anomaly scores, in order to map heterogeneous features to homogeneous features (an anomaly score indicates the degree of anomaly relative to an ordinal sequence) and then representing the pattern of a fault event in terms of anomaly score vectors; 2) selecting features specifying a fault event by means of iterative optimization using both normal and fault anomaly score vectors. We then monitor the degree of abnormal with regard to test anomaly score vectors by matching with the abnormal patterns. We demonstrate the effectiveness of our proposed algorithm through an application to an actual automobile fault diagnosis data set. Copyright © by SIAM.},
	keywords = {Data mining; Fault slips; Iterative methods; Time series; Abnormal patterns; Fault event; Heterogeneous features; High-accuracy; Iterative Optimization; Multivariate time series; Ordinal sequence; Real time; Fault detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Les Cottrell200685,
	author = {Les Cottrell, R. and Logg, Connie and Chhaparia, Mahesh and Grigoriev, Maxim and Haro, Felipe and Nazir, Fawad and Sandford, Mark},
	title = {Evaluation of techniques to detect significant network performance problems using end-to-end active network measurements},
	year = {2006},
	journal = {IEEE Symposium Record on Network Operations and Management Symposium},
	pages = {85 – 94},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250719132&partnerID=40&md5=d5be13d3e36f9623a60a0e88f1d7cea0},
	abstract = {End-to-End fault and performance problems detection in wide area production networks is becoming increasingly hard as the complexity of the paths, the diversity of the performance, and dependency on the network increase. Several monitoring infrastructures are built to monitor different network metrics and collect monitoring information from thousands of hosts around the globe. Typically there are hundreds to thousands of time-series plots of network metrics which need to be looked at to identify network performance problems or anomalous variations in the traffic. Furthermore, most commercial products rely on a comparison with user configured static thresholds and often require access to SNMP-MIB information, to which a typical end-user does not usually have access. In our paper we propose new techniques to detect network performance problems proactively in close to real-time and we do not rely on static thresholds and SNMP-MIB information. We describe and compare the use of several different algorithms that we have implemented to detect persistent network problems using anomalous variations analysis in real end-to-end Internet performance measurements. We also provide methods and/or guidance for how to set the user settable parameters. The measurements are based on active probes running on 40 production network paths with bottlenecks varying from 0.5Mbits/s to 1000Mbit/s. For well behaved data (no missed measurements and no very large outliers) with small seasonal changes most algorithms identify similar events. We compare the algorithms' robustness with respect to false positives and missed events especially when there are large seasonal effects in the data. Our proposed techniques cover a wide variety of network paths and traffic patterns. We also discuss the applicability of the algorithms in terms of their intuitiveness, their speed of execution as implemented, and areas of applicability. Our encouraging results compare and evaluate the accuracy of our detection techniques when applied to step down/up, diurnal changes and congestion effects. © 2006 IEEE.},
	author_keywords = {Anomalous event detection; Forecasting; Holt-winters; Kolmogorov-smirnov; Network monitoring; Network performance; Performance analysis; Persistent anomalies; Plateau algorithm; Trouble shooting},
	keywords = {Algorithms; Information use; Real time control; Robustness (control systems); Telecommunication traffic; Anomalous event detection; Congestion effects; Network monitoring; Network performance; Computer networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Penta2004732,
	author = {Penta, Kiran Kumar and Khemani, Deepak},
	title = {Satellite health monitoring using CBR framework},
	year = {2004},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {3155},
	pages = {732 – 747},
	doi = {10.1007/978-3-540-28631-8_53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048898827&doi=10.1007%2f978-3-540-28631-8_53&partnerID=40&md5=cc49499ca8ca0fa1c293190b644e3bb2},
	abstract = {Satellite health monitoring is a specialized task usually carried out by human experts. In this paper, we address the task of monitoring by defining it as an anomaly and event detection task cast in Case Based Reasoning framework. We discuss how each CBR step is achieved in a time series domain such as the Satellite health monitoring. In the process, we define the case structure in a time series domain, discuss measures of distance between cases and address other issues such as building initial Case Base and determining similarity threshold. We briefly describe the system that we have built, and end the paper with a discussion on possible extensions to current work. © Springer-Verlag 2004.},
	keywords = {Health; Satellites; Time series; Case base; Case structures; CBr; Event detection; Health monitoring; Human expert; Measures of distance; Similarity threshold; Case based reasoning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Cheng2003109,
	author = {Cheng, Wen-Huang and Chu, Wei-Ta and Wu, Ja-Ling},
	title = {Semantic context detection based on hierarchical audio models},
	year = {2003},
	journal = {Proceedings of the 5th ACM SIGMM International Workshop on Multimedia Information Retrieval, MIR 2003},
	pages = {109 – 115},
	doi = {10.1145/973264.973282},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015012050&doi=10.1145%2f973264.973282&partnerID=40&md5=1960c8f5b7aba980303300ded2667c8c},
	abstract = {Semantic context detection is one of the key techniques to facilitate efficient multimedia retrieval. Semantic context is a scene that completely represents a meaningful information segment to human beings. In this paper, we propose a novel hierarchical approach that models the statistical characteristics of several audio events, over a time series, to accomplish semantic context detection. The approach consists of two stages: audio event and semantic context detections. HMMs are used to model basic audio events, and event detection is performed in the first stage. Then semantic context detection is achieved based on Gaussian mixture models, which model the correlations among several audio events temporally. With this framework, we bridge the gaps between low-level features and the semantic contexts that last in a time series. The experimental evaluations indicate that the approach is effective in detecting high-level semantics.},
	author_keywords = {Audio content analysis; Audio retrieval; Gaussian mixture model; Hidden markov model; Semantic context},
	keywords = {Communication channels (information theory); Gaussian distribution; Hidden Markov models; Information retrieval; Markov processes; Object recognition; Semantic Web; Time series; Trellis codes; Audio content analysis; Audio retrieval; Experimental evaluation; Gaussian Mixture Model; Hierarchical approach; High level semantics; Semantic context; Statistical characteristics; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 85; All Open Access, Green Open Access}
}

@CONFERENCE{Teredesai2006616,
	author = {Teredesai, Ankur M. and Zhu, Yuanfeng},
	title = {SoNEA: Sensing online novelty using event archives},
	year = {2006},
	journal = {2006 IEEE International Conference on Mobile Ad Hoc and Sensor Systems, MASS},
	volume = {1},
	pages = {616 – 621},
	doi = {10.1109/MOBHOC.2006.278622},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049162963&doi=10.1109%2fMOBHOC.2006.278622&partnerID=40&md5=2e64975603090947bf15afddf474d3c9},
	abstract = {Event detection and consequently novelty detection on time series data has recently attracted increasing attention from the computing community. In this paper, we describe a system that can detect novel events in wireless sensor networks termed SoNEA (Sensing online Novelty using Event Archives). This system is able to receive and process sensory data from sensor networks and dynamically detect novel events using intelligent novelty detection techniques. The detection is based on clustering techniques combined with cognitively motivated habituation theory. A novel scheme to predict missing values of sensor readings is also proposed based on this system. The results of the experiments exhibiting the performance of the proposed solution in detecting novel events and missing value predication are reported. © 2006 IEEE.},
	keywords = {Computation theory; Data processing; Time series analysis; Wireless sensor networks; Sensing online Novelty using Event Archives; Sensory data; Online systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wenus20091033,
	author = {Wenus, Jakub and Düssmann, Heiko and Paul, Perrine and Kalamatianos, Dimitrios and Rehm, Markus and Wellstead, Peter E. and Prehn, Jochen H. M. and Huber, Heinrich J.},
	title = {ALISSA: An automated live-cell imaging system for signal transduction analyses},
	year = {2009},
	journal = {BioTechniques},
	volume = {47},
	number = {6},
	pages = {1033 – 1040},
	doi = {10.2144/000113247},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954006171&doi=10.2144%2f000113247&partnerID=40&md5=080dea9b32ed9f0a91182b69acb91aaf},
	abstract = {Probe photobleaching and a specimen's sensitivity to phototoxicity severely limit the number of possible excitation cycles in time-lapse fluorescent microscopy experiments. Consequently, when a study of cellular processes requires measurements over hours or days, temporal resolution is limited, and spontaneous or rapid events may be missed, thus limiting conclusions about transduction events. We have developed ALISSA, a design framework and reference implementation for an automated live-cell imaging system for signal transduction analysis. It allows an adaptation of image modalities and laser resources tailored to the biological process, and thereby extends temporal resolution from minutes to seconds. The system employs online image analysis to detect cellular events that are then used to exercise microscope control. It consists of a reusable image analysis software for cell segmentation, tracking, and time series extraction, and a measurement-specific process control software that can be easily adapted to various biological settings. We have applied the ALISSA framework to the analysis of apoptosis as a demonstration case for slow onset and rapid execution signaling. The demonstration provides a clear proof-of-concept for ALISSA, and offers guidelines for its application in a broad spectrum of signal transduction studies.},
	author_keywords = {Apoptosis; Automated microscopy; Image analysis; Live cell imaging; Online event detection; Software engineering},
	keywords = {Apoptosis; Automation; Cell Line; Cell Survival; Cells; Computer Graphics; Fluorescence Resonance Energy Transfer; Imaging, Three-Dimensional; Mitochondria; Mitochondrial Membranes; Online Systems; Signal Transduction; Software; Time Factors; User-Computer Interface; caspase; yellow fluorescent protein; apoptosis; article; bleaching; computer program; digital imaging; fluorescence microscopy; fluorescence resonance energy transfer; gene expression; human; human cell; image analysis; live cell imaging; mitochondrial permeability; phototoxicity; process control; signal transduction; whole cell},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Olmedo2009275,
	author = {Olmedo, O. and Zhang, J. and Wechsler, H. and Poland, A. and Borne, K.},
	title = {Automatic detection and tracking of coronal mass ejections in coronagraph time series},
	year = {2009},
	journal = {Solar Image Analysis and Visualization},
	pages = {275 – 289},
	doi = {10.1007/978-0-387-98154-3_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889984976&doi=10.1007%2f978-0-387-98154-3_20&partnerID=40&md5=3a2dd6c88343ca34596df5162050d7ca},
	abstract = {We present the current capabilities of a software tool to automatically detect coronal mass ejections (CMEs) based on time series of coronagraph images: the solar eruptive event detection system (SEEDS). The software developed consists of several modules: preprocessing, detection, tracking, and event cataloging. The detection algorithm is based on a 2D to 1D projection method, where CMEs are assumed to be bright regions moving radially outward as observed in a running-difference time series. The height, velocity, and acceleration of the CME are automatically determined. A threshold-segmentation technique is applied to the individual detections to automatically extract an approximate shape of the CME leading edge. We have applied this method to a 12-month period of continuous coronagraph images sequence taken at a 20-minute cadence by the Large Angle and Spectrometric Coronagraph (LASCO) instrument (using the C2 instrument only) onboard the Solar and Heliospheric Observatory (SOHO) spacecraft. Our automated method, with a high computational efficiency, successfully detected about 75% of the CMEs listed in the CDAW CME catalog, which was created by using human visual inspection. Furthermore, the tool picked up about 100% more small-size or anomalous transient coronagraph events that were ignored by human visual inspection. The output of the software is made available online at http://spaceweather.gmu.edu/seeds/. The parameters of scientific importance extracted by the software package are the position angle, angular width, velocity, peak, and average brightness. Other parameters could easily be added if needed. The identification of CMEs is known to be somewhat subjective. As our system is further developed, we expect to make the process significantly more objective. © 2009 Springer New York.},
	author_keywords = {Automatic detection; Coronal mass ejection},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Saeed2001153,
	author = {Saeed, M. and Mark, R.G.},
	title = {Efficient hemodynamic event detection utilizing relational databases and wavelet analysis},
	year = {2001},
	journal = {Computers in Cardiology},
	pages = {153 – 156},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035714341&partnerID=40&md5=ea1c271e5e40d1d464578982a57020ce},
	abstract = {Development of a temporal query framework for time-oriented medical databases has hitherto been a challenging problem. We describe a novel method for the detection of hemodynamic events in multiparameter trends utilizing wavelet coefficients in a MySQL relational database. Storage of the wavelet coefficients allowed for a compact representation of the trends, and provided robust descriptors for the dynamics of the parameter time series. A data model was developed to allow for simplified queries along several dimensions and time scales. Of particular importance, the data model and wavelet framework allowed for queries to be processed with minimal table-join operations. A web-based search engine was developed to allow for user-defined queries. Typical queries required between 0.01 and 0.02 seconds, with at least two orders of magnitude improvement in speed over conventional queries. This powerful and innovative structure will facilitate research on large-scale time-oriented medical databases.},
	keywords = {Algorithms; Blood Pressure; Databases, Factual; Heart Rate; Hemodynamic Processes; Humans; Information Storage and Retrieval; Internet; Models, Statistical; Monitoring, Physiologic; Signal Processing, Computer-Assisted; Software; Data structures; Hemodynamics; Query languages; Search engines; Time series analysis; Wavelet transforms; NASA Discipline Cardiopulmonary; NASA Program Biomedical Research and Countermeasures; Non-NASA Center; algorithm; article; blood pressure; computer program; factual database; heart rate; hemodynamics; human; information retrieval; Internet; monitoring; NASA Discipline Cardiopulmonary; NASA Program Biomedical Research and Countermeasures; Non-NASA Center; physiology; signal processing; statistical model; statistics; Large scale time -oriented medical databases; Time-oriented medical databases; User-defined queries; Wavelet analysis; Medical computing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{McKenna2007,
	author = {McKenna, Sean A. and Hart, David and Klise, Katherine and Cruz, Victoria and Wilson, Mark},
	title = {Event detection from water quality time series},
	year = {2007},
	journal = {Restoring Our Natural Habitat - Proceedings of the 2007 World Environmental and Water Resources Congress},
	doi = {10.1061/40927(243)518},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088749030&doi=10.1061%2f40927%28243%29518&partnerID=40&md5=886d93f03472e366722773bca11f979d},
	abstract = {Detection of anomalous events in water distribution systems is of interest for both daily operations focused on delivery of high quality water as well as for identification of accidental or intentional contamination events. In lieu of network-wide deployment of in-situ contaminant-specific sensors, data streams resulting from in-situ monitoring of ambient water quality are employed as input to event detection algorithms to identify periods of anomalous water quality. The basis of these approaches is prediction of the future water quality values (state estimation) and then comparison of the prediction errors, the differences between predicted and measured water quality signals, to identify outliers in an on-line framework. These algorithms generally rely on a stationary time series and large, sudden changes within the time series make outlier detection difficult. Here we propose an approach to improving the identification of events, defined as a cluster of outliers, that will also identify changes in the baseline water quality. This approach is called the binomial event discriminator (BED) and it uses a failure model based on the binomial distribution to determine the probability of an event existing based on r outliers occurring within n time steps. If the consecutive number of outliers exceeds an upper limit, a change in the baseline water quality is declared. The BED is applied to observed water quality collected at a location within a utility distribution system. The BED is able to reduce the number of false positive event identifications by several orders of magnitude compared to not using the BED. The BED is also identifies two locations as baseline water quality changes. © 2007 ASCE.},
	keywords = {Pollution detection; Probability distributions; Time series; Water distribution systems; Water resources; Binomial distribution; Event detection algorithm; Event identification; In- situ monitoring; Intentional contaminations; Orders of magnitude; Stationary time series; Utility distribution system; Water quality},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 44; All Open Access, Green Open Access}
}

@CONFERENCE{Lu200876,
	author = {Lu, Hsin-Min and Zeng, Daniel and Chen, Hsinchun},
	title = {Bioterrorism event detection based on the Markov switching model: A simulated anthrax outbreak study},
	year = {2008},
	journal = {IEEE International Conference on Intelligence and Security Informatics, 2008, IEEE ISI 2008},
	pages = {76 – 81},
	doi = {10.1109/ISI.2008.4565033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51849096340&doi=10.1109%2fISI.2008.4565033&partnerID=40&md5=f54a96cec84c0e00d7d77635464ee060},
	abstract = {The threat of infectious disease outbreaks and bioterrorism attacks has stimulated the development of syndromic surveillance systems, which focus on using pre-diagnostic data such as emergency department chief complaints and over-the-counter (OTC) drug sales to detect bioterrorism events in a timely manner. A key function of syndromic surveillance systems is detecting possible bioterrorism events from time series data. In this paper, we propose a novel temporal outbreak detection method based on the Markov switching model, a special case of hidden Markov models. The model is motivated to address several computational problems with existing detection schemes concerning the inconsistency in parameter estimation and the resulting undesired detection performance. Preliminary evaluation using simulated outbreaks injected on authentic time series shows that our method outperforms benchmark methods in terms of outbreak detection speed and detection sensitivity at given levels of false alarm rates. ©2008 IEEE.},
	keywords = {Alarm systems; Biotechnology; Chemotherapy; Drug delivery; Drug dosage; Health; Intersymbol interference; Markov processes; Parameter estimation; Security systems; Sensitivity analysis; Signal detection; Systems analysis; Time series analysis; AND detection; Bio-terrorism; Computational problems; Detection performances; Detection schemes; Drug sales; Emergency department; Event detection; False alarm rates; Hidden Markov modeling; Infectious diseases; International conferences; Markov switching models; Outbreak detection; Over the counter; Security informatics; Syndromic surveillance systems; Time-series; Time-series data; Hidden Markov models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Dubrawski2009495,
	author = {Dubrawski, Artur and Sabhnani, Maheshkumar and Knight, Michael and Baysek, Michael and Neill, Daniel and Ray, Saswati and Michalska, Anna and Waidyanatha, Nuwan},
	title = {T-cube web interface in support of real-time bio-surveillance program},
	year = {2009},
	journal = {2009 International Conference on Information and Communication Technologies and Development, ICTD 2009 - Proceedings},
	pages = {495},
	doi = {10.1109/ICTD.2009.5426730},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951527030&doi=10.1109%2fICTD.2009.5426730&partnerID=40&md5=9da33419a3f1169576d6a33d0a1f409f},
	abstract = {T-Cube Web Interface is a generic tool to visualize and manipulate large scale multivariate time series datasets. The interface allows the user to execute complex queries quickly and to run various types of statistical tests on the loaded data. We show its utility in an important application scenario: real-time bio-surveillance system designed to support rapid detection and mitigation of bio-medical threats in developing countries.},
	author_keywords = {Bio-surveillance; Data cubes; Event detection; Interactive analytics},
	keywords = {Developing countries; Monitoring; Statistical tests; Time series; Application scenario; Bio-medical; Complex queries; Data sets; Event detection; Multivariate time series; Rapid detection; Surveillance data; Surveillance program; Surveillance systems; Web interface; Geometry},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Chen2007107,
	author = {Chen, Chen-Yu and Wang, Jia-Ching and Wang, Jhing-Fa and Hu, Yu-Hen},
	title = {Event-based segmentation of sports video using motion entropy},
	year = {2007},
	journal = {Proceedings - 9th IEEE International Symposium on Multimedia, ISM 2007},
	pages = {107 – 111},
	doi = {10.1109/ISM.2007.17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-48649110883&doi=10.1109%2fISM.2007.17&partnerID=40&md5=c1b22008b6341d5cd1e493434f159935},
	abstract = {An event-based segmentation method for sports videos is presented. A motion entropy criterion is employed to characterize the level of intensity of relevant object motion in individual frames of a video sequence. The resulting motion entropy curve then is approximated with a piece-wise linear model using a homoscedastic error model based time series change point detection algorithm. It is observed that interesting sports events are correlated with specific patterns of the piece-wise linear model. A set of empirically derived classification rules then is derived based on these observations. Application of these rules to the motion entropy curve leads to this motion entropy curve, one is able to segment the corresponding video sequence into individual sections, each consisting of a semantically relevant event. The proposed method is tested on six hours of sports videos including basketball, soccer and tennis. Excellent experimental results are observed. © 2007 IEEE.},
	author_keywords = {Entropy-based motion feature; Event detection; Homoscedastic error model; Video segmentation},
	keywords = {Eigenvalues and eigenfunctions; Error detection; Imaging techniques; Mathematical models; Photography; Technical presentations; Time series analysis; Video recording; Change point detection (CPD); Classification rules; Error modeling; Individual (PSS 544-7); Individual sections; International symposium; Object motions; Piece wise linear (PWL) models; Segmentation methods; Sports events; Sports videos; Time Series; Video sequencing; Entropy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Anttila1981495,
	author = {Anttila, H. and Gadzinowski, J. and Oja, R. and Kero, P. and Halkola, L. and Valimaki, I.},
	title = {TIME-SERIES ANALYSIS OF HEART RATE AND RESPIRATION RATE IN NEONATES.},
	year = {1981},
	volume = {2},
	pages = {495 – 497},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0019666986&partnerID=40&md5=d191c6b85e772f9be307a9c28c02c49e},
	keywords = {COMPUTER ANALYSIS; EVENT DETECTION; HEART-BEAT VARIATION; IMPEDANCE PNEUMOGRAM; MOBILE TERMINAL SIGNAL ACQUISITION; NON-INVASIVE METHODS FOR HUMANS; RESPIRATION AND HEART BEAT; TIME SERIES ANALYSIS; ANIMAL EXPERIMENTS; BIOMEDICAL ENGINEERING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{McKenna2007132,
	author = {McKenna, Sean A. and Klise, Katherine A. and Wilson, Mark P.},
	title = {Testing water quality change detection algorithms},
	year = {2007},
	journal = {8th Annual Water Distribution Systems Analysis Symposium 2006},
	pages = {132},
	doi = {10.1061/40941(247)132},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-40549124683&doi=10.1061%2f40941%28247%29132&partnerID=40&md5=cc247cfbe7788ed328cb91aa32b9a09f},
	abstract = {Rapid detection of anomalous operating conditions within a water distribution network is desirable for the protection of the network against both accidental and malevolent contamination events. In the absence of a suite of in-situ, real-time sensors that can accurately identify a wide range of contaminants, we focus on detecting changes in water quality through analysis of existing data streams from in-situ water quality sensors. Three different change detection algorithms are tested: time series increments, linear filter and multivariate distance. Each of these three algorithms uses previous observations of the water quality to predict future water quality values. Large deviations between the predicted or previously measured values and observed values at future times indicate a change in the expected water quality. The definition of what constitutes a large deviation is quantified by a threshold value applied to the observed differences. Both simulated time series of water quality as well as measured chlorine residual values from two different locations within a distribution network are used as the background water quality values. The simulated time series are created specifically to challenge the change detection algorithms with bimodally distributed water quality values having a square wave and sin wave time series, with and without correlated noise. Additionally, a simulated time series resembling observed water quality time series is created with different levels of variability. The algorithms are tested in two different ways. First, background water quality without any anomalous events are used to test the ability of each algorithm to identify the water quality value at the next time step. Summary statistics on the prediction errors as well as the number of false positive detections quantify the ability of each algorithm to predict the background water quality. The performance of the algorithms with respect to limiting false positives is also compared against a simpler "set point" approach to detecting water quality changes. The second mode of testing employs events in the form of square waves superimposed on top of modeled/measured background water quality data. Three different event strengths are examined and the event detection capabilities of each algorithm are evaluated through the use of receiver operating characteristic (ROC) curves. The area under the ROC curve provides a quantitative basis of comparison across the three algorithms. Results show that the multivariate algorithm produces the lowest prediction errors for all cases of background water quality. A comparison of the number of false positives reported from the change detection algorithms and a set point approach highlights the efficiency of the change detection algorithms. Across all three algorithms, most prediction errors are within one standard deviation of the mean water quality. The event detection results show that the best performing algorithm varies across different background water quality models and simulated event strength. Copyright ASCE 2006.},
	author_keywords = {Change detection; Contaminant warning system; ROC curves; Water quality},
	keywords = {Contamination; Real time systems; Sensors; Water distribution systems; Water quality; Change detection; Contaminant warning system; ROC curves; Algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@ARTICLE{Jin Wang1995308,
	author = {Jin Wang and Ta-Liang Teng},
	title = {Artificial neural network-based seismic detector},
	year = {1995},
	journal = {Bulletin - Seismological Society of America},
	volume = {85},
	number = {1},
	pages = {308 – 319},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029504530&partnerID=40&md5=1dbf24065165b68189249195029a6174},
	abstract = {An artificial neural network-based pattern classification system is applied to seismic event detection. Two types of Artificial Neural Detector (AND) have been designed for real-time earthquake detection. Type A artificial neural detector (AND-A) uses the recursive STA/LTA time series as input data, and type B (AND-B) uses moving window spectrograms as input data to detect earthquake signals. Results show that the accuracy of the artificial neural network-based seismic detectors is better than that of the conventional algorithms solely based on the STA/LTA threshold. -from Authors},
	keywords = {earthquake detection; neural network; seismic detector; seismicity},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 125}
}

@CONFERENCE{Li2007,
	author = {Li, Mo and Liu, Yunhao and Chen, Lei},
	title = {Non-threshold based event detection for 3D environment monitoring in sensor networks},
	year = {2007},
	journal = {Proceedings - International Conference on Distributed Computing Systems},
	doi = {10.1109/ICDCS.2007.123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34848856390&doi=10.1109%2fICDCS.2007.123&partnerID=40&md5=396598aa60c74e2942e38217cb8cc761},
	abstract = {Event detection is a crucial task for wireless sensor network applications, especially environment monitoring. Existing approaches for event detection are mainly based on some predefined threshold values, and thus are often inaccurate and incapable of capturing complex events. For example, in coal mine monitoring scenarios, gas leakage or water osmosis can hardly be described by the overrun of specified attribute thresholds, but some complex pattern in the full-scale view of the environmental data. To address this issue, we propose a non-threshold based approach for the real 3D sensor monitoring environment. We employ energy-efficient methods to collect a time series of data maps from the sensor network and detect complex events through matching the gathered data to spatio-temporal data patterns. Finally, we conduct trace driven simulations to prove the efficacy and efficiency of this approach on detecting events of complex phenomena from real-life records. © 2007 IEEE.},
	keywords = {Energy efficiency; Osmosis; Three dimensional; Time series analysis; Complex events; Data maps; Event detection; Full-scale view; Sensor networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 48; All Open Access, Green Open Access}
}

@CONFERENCE{Ihler2006207,
	author = {Ihler, Alexander and Hutchins, Jon and Smyth, Padhraic},
	title = {Adaptive event detection with time - Varying poisson processes},
	year = {2006},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	volume = {2006},
	pages = {207 – 216},
	doi = {10.1145/1150402.1150428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749540435&doi=10.1145%2f1150402.1150428&partnerID=40&md5=25c28aaf7c5a56de2eefe2ea79a2e309},
	abstract = {Time-series of count data are generated in many different contexts, such as web access logging, freeway traffic monitoring, and security logs associated with buildings. Since this data measures the aggregated behavior of individual human beings, it typically exhibits a periodicity in time on a number of scales (daily, weekly, etc.) that reflects the rhythms of the underlying human activity and makes the data appear non-homogeneous. At the same time, the data is often corrupted by a number of bursty periods of unusual behavior such as building events, traffic accidents, and so forth. The data mining problem of finding and extracting these anomalous events is made difficult by both of these elements. In this paper we describe a framework for unsupervised learning in this context, based on a time-varying Poisson process model that can also account for anomalous events. We show how the parameters of this model can be learned from count time series using statistical estimation techniques. We demonstrate the utility of this model on two data sets for which we have partial ground truth in the form of known events, one from freeway traffic data and another from building access data, and show that the model performs significantly better than a non-probabilistic, threshold-based technique. We also describe how the model can be used to investigate different degrees of periodicity in the data, including systematic day-of-week and time-of-day effects, and make inferences about the detected events (e.g., popularity or level of attendance). Our experimental results indicate that the proposed time-varying Poisson model provides a robust and accurate framework for adaptively and autonomously learning how to separate unusual bursty events from traces of normal human activity. Copyright 2006 ACM.},
	author_keywords = {Event detection; Markov modulated; Poisson},
	keywords = {Highway accidents; Highway traffic control; Poisson equation; Problem solving; Robustness (control systems); Time series analysis; Freeway traffic data; Freeway traffic monitoring; Security logs; Web access logging; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 202}
}

@ARTICLE{Sacchi199831,
	author = {Sacchi, M.D.},
	title = {Interpolation and extrapolation using a high-resolution discrete fourier transform},
	year = {1998},
	journal = {IEEE Transactions on Signal Processing},
	volume = {46},
	number = {1},
	pages = {31 – 38},
	doi = {10.1109/78.651165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031678519&doi=10.1109%2f78.651165&partnerID=40&md5=e4f977ef01e959cda4372fd3c83d93ea},
	abstract = {We present an iterative nonparametric approach to spectral estimation that is particularly suitable for estimation of line spectra. This approach minimizes a cost function derived from Bayes' theorem. The method is suitable for line spectra since a long tailed distribution is used to model the prior distribution of spectral amplitudes. An important aspect of this method is that since the data themselves are used as constraints, phase information can also be recovered and used to extend the data outside the original window. The objective function is formulated in terms of hyperparameters that control the degree of fit and spectral resolution. Noise rejection can also be achieved by truncating the number of iterations. Spectral resolution and extrapolation length are controlled by a single parameter. When this parameter is large compared with the spectral powers, the algorithm leads to zero extrapolation of the data, and the estimated Fourier transform yields the periodogram. When the data are sampled at a constant rate, the algorithm uses one Levinson recursion per iteration. For irregular sampling (unevenly sampled and/or gapped data), the algorithm uses one Cholesky decomposition per iteration. The performance of the algorithm is illustrated with three different problems that frequently arise in geophysical data processing: 1) harmonic retrieval from a time series contaminated with noise; 2) linear event detection from a finite aperture array of receivers [which, in fact, is an extension of 1)], 3) interpolation/extrapolation of gapped data. The performance of the algorithm as a spectral estimator is tested with the Kay and Marple data set. It is shown that the achieved resolution is comparable with parametric methods but with more accurate representation of the relative power in the spectral lines. © 1998 IEEE.},
	author_keywords = {Bayes procedures; Discrete fourier transforms; Interpolation; Inverse problems; Iterative methods; Signal restoration; Signal sampling/reconstruction; Spectral analysis},
	keywords = {Algorithms; Constraint theory; Fast Fourier transforms; Interpolation; Inverse problems; Iterative methods; Parameter estimation; Performance; Signal filtering and prediction; Extrapolation; Spectrum analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 317}
}

@ARTICLE{Balogh199765,
	author = {Balogh, A. and Dunlop, M.W. and Cowley, S.W.H. and Southwood, D.J. and Thomlinson, J.G. and Glassmeier, K.H. and Musmann, G. and Lühr, H. and Buchert, S. and Acuña, M.H. and Fairfield, D.H. and Slavin, J.A. and Riedler, W. and Schwingenschuh, K. and Kivelson, M.G.},
	title = {The cluster magnetic field investigation},
	year = {1997},
	journal = {Space Science Reviews},
	volume = {79},
	number = {1-2},
	pages = {65 – 91},
	doi = {10.1007/978-94-011-5666-0_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0008576975&doi=10.1007%2f978-94-011-5666-0_3&partnerID=40&md5=f534e779385a956c55998fa375901db0},
	abstract = {The Cluster mission provides a new opportunity to study plasma processes and structures in the near-Earth plasma environment. Four-point measurements of the magnetic field will enable the analysis of the three dimensional structure and dynamics of a range of phenomena which shape the macroscopic properties of the magnetosphere. Difference measurements of the magnetic field data will be combined to derive a range of parameters, such as the current density vector, wave vectors, and discontinuity normals and curvatures, using classical time series analysis techniques iteratively with physical models and simulation of the phenomena encountered along the Cluster orbit. The control and understanding of error sources which affect the four-point measurements are integral parts of the analysis techniques to be used. The flight instrumentation consists of two, tri-axial fluxgate magnetometers and an on-board data-processing unit on each spacecraft, built using a highly fault-tolerant architecture. High vector sample rates (up to 67 vectors s-1) at high resolution (up to 8 pT) are combined with on-board event detection software and a burst memory to capture the signature of a range of dynamic phenomena. Data-processing plans are designed to ensure rapid dissemination of magnetic-field data to underpin the collaborative analysis of magnetospheric phenomena encountered by Cluster.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 410}
}

@ARTICLE{Tsumoto2003135,
	author = {Tsumoto, Shusaku},
	title = {Chance discovery in medicine - Detection of rare risky events in chronic diseases},
	year = {2003},
	journal = {New Generation Computing},
	volume = {21},
	number = {2},
	pages = {135 – 147},
	doi = {10.1007/BF03037631},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037238504&doi=10.1007%2fBF03037631&partnerID=40&md5=59eeb547da1745c27fcdac02c7f92090},
	abstract = {One of the most important characteristics of chance discovery is that it focuses on the specific events or patterns in which the essential nature of an applied domain is implicitly included. The understanding and forecasting of such patterns and events will have a significant impact on decision making in the applied domain. This paper discusses the meaning of chance discovery from the viewpoint of medicine. Since chance discovery in medicine can be viewed as the way to find a suitable occasion for some critical actions or to check the dangerous possibilities, called rare risky events, detection and interpretation of rare but important events are ones of the components that supports chance discovery. According to this observation, several approaches for detecting rare events were introduced and evaluated by a small dataset on neurological diseases. Experimental results show that a set of events which include rare risky events can be detected by the introduced detection method, though interpretation by domain experts is required for selection of such events.},
	author_keywords = {Fuzzy qualitative trend; Rare risky events; Rough sets; Rule induction; Time-series analysis},
	keywords = {Diseases; Fuzzy sets; Rough set theory; Time series analysis; Fuzzy qualitative trend; Rule induction; Medical computing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Pownall1984161,
	author = {Pownall, R. and Gordon, K. and Knapp, M.S. and Smith, A.F.M.},
	title = {The development of new statistical methods for event detection in time series},
	year = {1984},
	journal = {Annual Review of Chronopharmacology},
	volume = {VOL. 1},
	pages = {161 – 164},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0021548743&partnerID=40&md5=b7f65206192f10a6836d33ca9c2e86df},
	keywords = {chronobiology; chronopharmacology; computer analysis; drug therapy; human; nonbiological model; statistics; therapy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang2009243,
	author = {Zhang, Chongming and Wang, Chunmei and Li, Dazhi and Zhou, Xi and Gao, Chuanshan},
	title = {Unspecific event detection in wireless sensor networks},
	year = {2009},
	journal = {Proceedings of the 2009 International Conference on Communication Software and Networks, ICCSN 2009},
	pages = {243 – 246},
	doi = {10.1109/ICCSN.2009.149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349488814&doi=10.1109%2fICCSN.2009.149&partnerID=40&md5=c1f49253b3079ad69d481044f25d6743},
	abstract = {Event detection has always been an important application in the practical deployment of Wireless Sensor Networks (WSNs). Although threshold based event detection method works well in some cases when significant characteristics exist for specific event, it has some limitations in many other application scenarios when we do not know much priori knowledge on incoming event. Inspired by the latest development of time series data mining technology, a flexible approach is proposed for unspecific event discovery in this paper. Event is defined as a pattern that is infrequent appeared. An algorithm is developed to find event patterns efficiently. We show how this approach outperforms threshold based method in Castalia simulation environment. © 2009 IEEE.},
	author_keywords = {Event detection; Linear pattern; Threshold; Wireless sensor networks},
	keywords = {Computer software; Sensor networks; Time series; Event detection; Event pattern; Latest development; Linear pattern; Other applications; Priori knowledge; Simulation environment; Threshold; Time series data mining; Wireless sensor networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Das2009116,
	author = {Das, Madirakshi and Loui, Alexander C.},
	title = {Detecting significant events in personal image collections},
	year = {2009},
	journal = {ICSC 2009 - 2009 IEEE International Conference on Semantic Computing},
	pages = {116 – 123},
	doi = {10.1109/ICSC.2009.36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-73449121080&doi=10.1109%2fICSC.2009.36&partnerID=40&md5=c86594124e1c38ebe9f8ff2d94b38a12},
	abstract = {The organization and retrieval of images and videos is a problem for the typical consumer. A typical image collection includes many pictures of common activities that are not considered to be important by the user. These images inflate the number of assets in a collection to the point where it is difficult to find significant events when browsing. It is useful for the user to be able to browse an overview of important events in their collection. This paper proposes a new approach for identifying a small sub-set of events in a large collection that have a high probability of being significant. Using techniques from time-series modeling, a representation of a user's picture-taking behavior is constructed. The detection of significant events is based on the deviation from this learned representation. The results match a user's judgment of significance and enables efficient browsing and searching of the collection by focusing on a small set of images. © 2009 IEEE.},
	author_keywords = {ARIMA; Event detection; Image collections; Modeling; Time-series},
	keywords = {Event detection; High probability; Image collections; New approaches; Personal image; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Xu2004758,
	author = {Xu, Min and Duan, Ling-Yu and Chia, Liang-Tien and Xu, Chang-Sheng},
	title = {Audio keyword generation for sports video analysis},
	year = {2004},
	journal = {ACM Multimedia 2004 - proceedings of the 12th ACM International Conference on Multimedia},
	pages = {758 – 759},
	doi = {10.1145/1027527.1027702},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-13444270431&doi=10.1145%2f1027527.1027702&partnerID=40&md5=029361686742f87768afc5dab6d15a35},
	abstract = {Semantic sports video analysis has attracted many research interests and audio cues have been shown to play an important role in semantics inference. To facilitate event detection using audio information, we have introduced the concept of audio keyword (e.g. excited/plain commentator speech, excited/plain audience sound, etc.) to describe the game-specific sound associated with an event. In our previous work, we have designed a hierarchical Support Vector Machine (SVM) classifier for audio keyword identification. However, there are two inherent weaknesses: 1) a frame-based SVM classifier does not incorporate any contextual information; 2) a robust recognizer relies on large amounts of training data in the case of different sports games videos. In this demo, we present a flexible Hidden Markov Model (HMM)-based audio keyword generation system. This is motivated by the successful story of applying HMM in speech recognition. Unlike the frame-based SVM classification followed by a major voting, our HMM-based system treats an audio keyword as a continuous time series data and employs hidden states transition to capture contexts. Moreover, our system introduces an adaptation mechanism to tune the initial HMM models (obtained from available training data) to improve performance by a small number of data from a new sports game video. Promising results has been demonstrated on the tennis, soccer and basketball videos with the total length of 2 hours.},
	author_keywords = {Adaptive HMM; Audio keywords; Semantics; Sports video},
	keywords = {Feature extraction; Game theory; Information retrieval; Markov processes; Parameter estimation; Personnel training; Semantics; Adaptive HMM; Audio keywords; Sports video; Support Vector Machine (SVM); Image analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Leach Jr.1999213,
	author = {Leach Jr., Richard R. and Dowla, Farid U. and Schultz, Craig A.},
	title = {Optimal filter parameters for low SNR seismograms as a function of station and event location},
	year = {1999},
	journal = {Physics of the Earth and Planetary Interiors},
	volume = {113},
	number = {1-4},
	pages = {213 – 226},
	doi = {10.1016/S0031-9201(99)00006-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0342514525&doi=10.1016%2fS0031-9201%2899%2900006-0&partnerID=40&md5=b705b08b226f6c96d80ba0fb2c25ca28},
	abstract = {Global seismic monitoring requires deployment of seismic sensors worldwide, in many areas that have not been studied or have few useable recordings. Using events with lower signal-to-noise ratios (SNR) would increase the amount of data from these regions. Lower SNR events can add significant numbers to data sets, but recordings of these events must be carefully filtered. For a given region, conventional methods of filter selection can be quite subjective and may require intensive analysis of many events. To reduce this laborious process, we have developed an automated method to provide optimal filters for low SNR regional or teleseismic events. As seismic signals are often localized in frequency and time with distinct time-frequency characteristics, our method is based on the decomposition of a time series into a set of subsignals, each representing a band with f/Δf constant (constant Q). The SNR is calculated on the pre-event noise and signal window. The band pass signals with high SNR are used to indicate the cutoff filter limits for the optimized filter. Results indicate a significant improvement in SNR, particularly for low SNR events. The method provides an optimum filter which can be immediately applied to unknown regions. The filtered signals are used to map the seismic frequency response of a region and may provide improvements in travel-time picking, azimuth estimation, regional characterization, and event detection. For example, when an event is detected and a preliminary location is determined, the computer could automatically select optimal filter bands for data from non-reporting stations. Results are shown for a set of low SNR events as well as 379 regional and teleseismic events recorded at stations ABKT, KIV, and ANTO in the Middle East.},
	author_keywords = {Calibrated seismic events; Constant Q filter banks; Middle East; Receiver operating characteristics; Scales; Signal-to-noise; Wavelet transform},
	keywords = {Middle East; filter; monitoring; nuclear explosion; seismometry},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Porikli2005366,
	author = {Porikli, Fatih},
	title = {Ambiguity detection by fusion and conformity: A spectral clustering approach},
	year = {2005},
	journal = {2005 International Conference on Integration of Knowledge Intensive Multi-Agent Systems, KIMAS'05: Modeling, Exploration, and Engineering},
	volume = {2005},
	pages = {366 – 372},
	doi = {10.1109/KIMAS.2005.1427110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745278215&doi=10.1109%2fKIMAS.2005.1427110&partnerID=40&md5=5e8360c14aceee8415c1862c90a4f504},
	abstract = {Event detection requires interpretation of the "semantically meaningful" object actions. To achieve this task, the gap between the numerical features of objects and the symbolic description of the meaningful activities needs to be bridged. We develop an ambiguity detection framework that has two significant advantages over past work. First, we introduce a fusion method for a set of time-wise and object-wise features including not only the trajectory coordinates but also the histograms and HMM based representations of object's speed, orientation, location, size, and aspect ratio. This fusion method enable detection of events that cannot be detected with the existing trajectory features reported so far. Second, we improve existing spectral clustering algorithms by automatically estimating the optimal number of clusters. Furthermore, we determine the conformity of the objects within the given data space. We compute a separate HMM for each object using a time-series that is composed of the mixture of its features. Then, we construct an aggregated affinity matrix from the pair-wise similarity scores of objects using the HMM's. We apply eigenvector decomposition and obtain object clusters. We show that the number of eigenvectors used in the decomposition is proportional to the optimal number of clusters. We examine the affinity matrix to determine the deviance of objects from common assemblages within the space. Our simulations reveal that the proposed detection methods accurately discover both usual and unusual events. © 2005 IEEE.},
	keywords = {Algorithms; Computer simulation; Database systems; Eigenvalues and eigenfunctions; Histology; Matrix algebra; Numerical methods; Ambiguity detection; Histograms; Spectral clustering approach; Symbolic description; Spectrum analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@CONFERENCE{Cline2009,
	author = {Cline, Danelle E. and Edgington, Duane R. and Smith, Ken L. and Vardaro, Michael F. and Kuhnz, Linda and Ellena, Jacob A.},
	title = {An automated event detection and classification system for abyssal time-series images of station M, NE Pacific},
	year = {2009},
	journal = {MTS/IEEE Biloxi - Marine Technology for Our Future: Global and Local Challenges, OCEANS 2009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951550553&partnerID=40&md5=703403fb7d3bdd531475a9f1e935a784},
	abstract = {The time-study data collected at the Station M site off the coast of central California includes high quality still-frame images taken in 1-hour time-lapse increments. The approximately 67,000 time-lapse images collected would take an unfeasible amount of time to fully analyze manually, and therefore would benefit from automated analysis. Towards this end, this work is an aid in the significant effort to analyze megafaunal activity and sedimentation events using an adapted version of the Automated Video Event Detection and Classification System (AVEDac) formerly designed by MBARI to analyze video collected from MBARI's remotely operated underwater vehicles (ROVs) video. This paper describes, in general, the automated system that will aid in the abundance and distribution studies of animals at the Station M site. ©2009 MTS.},
	keywords = {Animals; Marine engineering; Oceanography; Remotely operated vehicles; Submersibles; Water craft; Automated analysis; Automated systems; Automated video; California; Classification system; Event detection; High quality; Megafaunal activity; Time lapse images; Underwater vehicles; Automation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Kulchinskiy2010,
	author = {Kulchinskiy, R.G. and Agayan, S.M. and Bogoutdinov, Sh.R. and Gvishiani, A.D.},
	title = {Fuzzy logic methods for geomagnetic events detections and analysis},
	year = {2010},
	journal = {Geoinformatics 2010 - 9th International Conference on Geoinformatics: Theoretical and Applied Aspects},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907083223&partnerID=40&md5=9cfb3959af393c87aea018296f1b31a5},
	abstract = {Detailed study of the morphology of geomagnetic disturbances and their sources shows that various indexes of geomagnetic activity used nowadays show an activity of a geomagnetic field not on the whole Earth surface but in its separate regions. In the process of research of solar-terrestrial phenomena there emerged the necessity of simultaneous determination of the strength of geomagnetic disturbances in all observatories of the Intermagnet world stations net, i.e. an introduction of new parameters independent of geomagnetic latitudes and longitudes becomes necessary. To solve this problem a new geo-informational approach named "Discrete mathematical analysis", FCARS algorithm in particular, is suggested. The FCARS represents an attempt to model the logics of an interpreter. The algorithm gives an estimation of limits of anomalies sought and conducts morphological review of these anomalies. As the result of the execution of these works based on algorithms of separation and analysis of anomalies in time series using fuzzy logic methods there were: introduced concepts of inner and outer strength of an anomaly of a geomagnetic variation; suggested an analysis of geomagnetic events based on data from the global network of observatories Intermagnet; described a new way of study of the dynamics of geomagnetic disturbances spreading.},
	keywords = {Fuzzy logic; Observatories; Time series analysis; Analysis of anomaly; Fuzzy logic method; Geomagnetic activities; Geomagnetic disturbance; Geomagnetic fields; Geomagnetic variation; Mathematical analysis; Simultaneous determinations; Geomagnetism},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Radhakrishnan2005158,
	author = {Radhakrishnan, Regunathan and Divakaran, Ajay and Smaragdis, Paris},
	title = {Audio analysis for surveillance applications},
	year = {2005},
	journal = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
	pages = {158 – 161},
	doi = {10.1109/ASPAA.2005.1540194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749069115&doi=10.1109%2fASPAA.2005.1540194&partnerID=40&md5=465dd7bd706cb20ea621095cf33fbaff},
	abstract = {We proposed a time series analysis based approach for systematic choice of audio classes for detection of crimes in elevators in [1]. Since all the different sounds in a surveillance environment cannot be anticipated, a surveillance system for event detection cannot completely rely on a supervised audio classification framework. In this paper, we propose a hybrid solution that consists two parts; one that performs unsupervised audio analysis and another that performs analysis using an audio classification framework obtained from off-line analysis and training. The proposed system is capable of detecting new kinds of suspicious audio events that occur as outliers against a background of usual activity. It adaptively learns a Gaussian Mixture Model(GMM) to model the background sounds and updates the model incrementally as new audio data arrives. New types of suspicious events can be detected as deviants from this usual background model. The results on elevator audio data are promising. © 2005 IEEE.},
	keywords = {Acoustic signal processing; Adaptive systems; Elevators; Mathematical models; Time series analysis; Audio analysis; Audio classification; Gaussian Mixture Model (GMM); Audio acoustics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 143; All Open Access, Green Open Access}
}

@CONFERENCE{Wang2004633,
	author = {Wang, Fei and Ma, Yu-Fei and Zhang, Hong-Jiang and Li, Jin-Tao},
	title = {Dynamic bayesian network based event detection for soccer highlight extraction},
	year = {2004},
	journal = {Proceedings - International Conference on Image Processing, ICIP},
	volume = {1},
	pages = {633 – 636},
	doi = {10.1109/ICIP.2004.1418834},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-20444450880&doi=10.1109%2fICIP.2004.1418834&partnerID=40&md5=fdd11c25a4cebfabb7c34b74bb2daf98},
	abstract = {In this paper, we propose a novel approach to event detection in soccer videos using Dynamic Bayesian Networks (DBNs). Based on such high level semantics, say, events, more meaningful soccer highlights are extracted. As a powerful statistical tool for time series signal processing, DBNs provide us a feasible method to model sports events by combining contextual information and prior knowledge. In particular, we first develop a DBN model to interpret high-level events composed of low-level primitives in a soccer video. Then, we select a set of robust statistical features as observation input. Finally, the DBN model is leaned to figure out the most likely series of events. The effectiveness of the proposed method has been demonstrated by our experiments. © 2004 IEEE.},
	keywords = {Dynamic programming; Feature extraction; Markov processes; Mathematical models; Problem solving; Semantics; Statistical methods; Contextural information; Dynamic Bayesian network (DBN); Soccer highlight extraction; Soccer video; Video recording},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{Divakaran2006,
	author = {Divakaran, Ajay and Radhakrishnan, Regunathan and Peker, Kadir A.},
	title = {Blind summarization: Content-adaptive video summarization using time-series analysis},
	year = {2006},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {6073},
	doi = {10.1117/12.648419},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646007301&doi=10.1117%2f12.648419&partnerID=40&md5=37f96e305c8fe00591a0692ee96f8ef4},
	abstract = {Severe complexity constraints on consumer electronic devices motivate us to investigate general-purpose video summarization techniques that are able to apply a common hardware setup to multiple content genres. On the other hand, we know that high quality summaries can only be produced with domain-specific processing. In this paper, we present a time-series analysis based video summarization technique that provides a general core to which we are able to add small content-specific extensions for each genre. The proposed time-series analysis technique consists of unsupervised clustering of samples taken through sliding windows from the time series of features obtained from the content. We classify content into two broad categories, scripted content such as news and drama, and unscripted content such as sports and surveillance. The summarization problem then reduces to finding either finding semantic boundaries of the scripted content or detecting highlights in the unscripted content. The proposed technique is essentially an event detection technique and is thus best suited to unscripted content, however, we also find applications to scripted content. We thoroughly examine the trade-off between content-neutral and content-specific processing for effective summarization for a number of genres, and find that our core technique enables us to minimize the complexity of the content-specific processing and to postpone it to the final stage. We achieve the best results with unscripted content such as sports and surveillance video in terms of quality of summaries and minimizing content-specific processing. For other genres such as drama, we find that more content-specific processing is required. We also find that judicious choice of key audio-visual object detectors enables us to minimize the complexity of the content-specific processing while maintaining its applicability to a broad range of genres. We will present a demonstration of our proposed technique at the conference. © 2006 SPIE-IS&T.},
	keywords = {Adaptive systems; Computational complexity; Constraint theory; Detectors; Time series analysis; Complexity constraints; Content-adaptive video summarization; Video summarization; Consumer electronics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Li200987,
	author = {Li, Wan and Jianxin, Liao and Xiaomin, Zhu},
	title = {A frequent pattern based framework for event detection in sensor network stream data},
	year = {2009},
	journal = {Proceedings of the 3rd International Workshop on Knowledge Discovery from Sensor Data, SensorKDD'09 in Conjunction with the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD-09},
	pages = {87 – 96},
	doi = {10.1145/1601966.1601982},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449868133&doi=10.1145%2f1601966.1601982&partnerID=40&md5=5db5ee8cb7d9646244c65b1690ff37c7},
	abstract = {In this paper, we presented a frequent pattern based framework for event detection in stream data, it consists of frequent pattern discovery, frequent pattern selection and modeling three phases: In the first phase, a MNOE (Mining Non-Overlapping Episode) algorithm is proposed to find the non-overlapping frequent pattern in time series. In the frequent pattern selection phase, we proposed an EGMAMC (Episode Generated Memory Aggregation Markov Chain) model to help us selecting episodes which can describe stream data significantly. Then we defined feature flows to represent the instances of discovered frequent patterns and categorized the distribution of frequent pattern instances into three categories according to the spectrum of their feature flows. At last, we proposed a clustering algorithm EDPA (Event Detection by Pattern Aggregation) to aggregate strongly correlated frequent patterns together. We argue that strongly correlated frequent patterns form events and frequent patterns in different categories can be aggregated to form different kinds of events. Experiments on real-world sensor network datasets demonstrate that the proposed MNOE algorithm is more efficient than the existing non-overlapping episode mining algorithm and EDPA performs better when the input frequent patterns are maximal, significant and non-overlapping. Copyright 2009 ACM.},
	author_keywords = {Event detection; Frequent pattern; Sensor network; Temporal data mining},
	keywords = {Data mining; Hydraulics; Markov processes; Sensor networks; Time series; Data sets; Episode mining; Event detection; Frequent pattern discovery; Frequent patterns; Markov Chain; Real-world; Stream data; Temporal data mining; Three phasis; Clustering algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Hernandez1995102,
	author = {Hernandez, Jose N. and Moore, Kurt R. and Elphic, Richard C.},
	title = {Sensor fusion and nonlinear prediction for anomalous event detection},
	year = {1995},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {2484},
	pages = {102 – 112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029487563&partnerID=40&md5=64ecbeb7feb5381ddb3a5a0e007160a1},
	abstract = {We consider the problem of using the information from two time series, each characterizing a different physical quantity, to predict the future state of the system and, based on that information, to detect and classify anomalous events. We stress the application of principal components analysis (PCA) to analyze and combine data from the different sensors. We construct both linear and nonlinear predictors. In particular, for linear prediction we use the least-mean-square (LMS) algorithm and for nonlinear prediction we use both back-propagation (BP) networks and fuzzy predictors (FP). As an application, we consider the prediction of gamma counts from past values of electron and gamma counts recorded by the instruments of a high altitude satellite.},
	keywords = {Algorithms; Detectors; Least squares approximations; Mathematical techniques; Neural networks; Satellites; Signal filtering and prediction; Anomalous event detection; Back propagation networks; Fuzzy predictors; Gamma counts; Nonlinear prediction; Predictors; Principal component analysis; Sensor data fusion},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Peter20071075,
	author = {Peter, William and Najmi, Amir H and Burkom, Howard},
	title = {Data normalization in biosurveillance: an information-theoretic approach.},
	year = {2007},
	journal = {AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium},
	pages = {1075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-56149097095&partnerID=40&md5=1b9b885a7d44760f661a76bfa25c5f21},
	abstract = {An approach to identifying public health threats by characterizing syndromic surveillance data in terms of its surprisability is discussed. Surprisability in our model is measured by assigning a probability distribution to a time series, and then calculating its entropy, leading to a straightforward designation of an alert. Initial application of our method is to investigate the applicability of using suitably-normalized syndromic counts (i.e., proportions) to improve early event detection.},
	keywords = {Algorithms; Bioterrorism; Disease Outbreaks; Epidemiologic Measurements; Humans; Population Surveillance; Public Health Informatics; Statistics as Topic; algorithm; article; biological warfare; epidemic; health survey; human; medical informatics; methodology; population and population related phenomena; statistics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zoumboulakis2007270,
	author = {Zoumboulakis, Michael and Roussos, George},
	title = {Escalation: Complex event detection in wireless sensor networks},
	year = {2007},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {4793 LNCS},
	pages = {270 – 285},
	doi = {10.1007/978-3-540-75696-5_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38449087830&doi=10.1007%2f978-3-540-75696-5_17&partnerID=40&md5=ba1de8545e1dd9309b3ff629d11c3940},
	abstract = {We present a new approach for the detection of complex events in Wireless Sensor Networks. Complex events are sets of data points that correspond to interesting or unusual patterns in the underlying phenomenon that the network monitors. Our approach is inspired from time-series data mining techniques and transforms a stream of real-valued sensor readings into a symbolic representation. Complex event detection is then performed using distance metrics, allowing us to detect events that are difficult or even impossible to describe using traditional declarative SQL-like languages and thresholds. We have tested our approach with four distinct data sets and the experimental results were encouraging in all cases. We have implemented our approach for the TinyOS and Contiki Operating Systems, for the Sky mote platform. © Springer-Verlag Berlin Heidelberg 2007.},
	author_keywords = {Complex events; Data compression; Event detection; Network control; Parameter-free detection; Reactive sensor networks},
	keywords = {Data compression; Data mining; Query languages; Set theory; Complex events; Event detection; Network control; Parameter-free detection; Reactive sensor networks; Wireless sensor networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; All Open Access, Green Open Access}
}

@CONFERENCE{Kooptiwoot2004531,
	author = {Kooptiwoot, Suwimon and Abdus Salam, M.},
	title = {Mining the relationships in the form of predisposing factor and co-incident factor in time series data set by using the combination of some existing ideas with a new idea from the fact in the chemical reaction},
	year = {2004},
	journal = {ICEIS 2004 - Proceedings of the Sixth International Conference on Enterprise Information Systems},
	pages = {531 – 534},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-8444252977&partnerID=40&md5=ed8a80a216aebae8352334ac8dd60fb7},
	abstract = {In this work we propose new algorithms from the combination of many existing ideas consisting of the reference event as proposed in (Bettini, Wang et al. 1998), the event detection technique proposed in (Guralnik and Srivastava 1999), the causal inference proposed in (Blum 1982; Blum 1982) and the new idea about the character of the catalyst seen in the chemical reaction. We use all of these ideas to build up our algorithms to mine the predisposing factor and co-incident factor of the reference event of interest. We apply our algorithms with OSS (Open Source Software) data set and show the result.},
	author_keywords = {Catalyst; Chemical reaction; Co-incident factor; Numerical data; Predisposing factor; Temporal mining; Time series data},
	keywords = {Algorithms; Catalysts; Chemical reactions; Computer software; Data reduction; Mathematical models; Set theory; Numerical data; Predisposing factors; Temporal mining; Time series data; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Dash2007355,
	author = {Dash, P.K. and Nayak, Maya and Lee, I.W.C.},
	title = {Time series pattern recognition using s-transform and soft computing},
	year = {2007},
	journal = {International Journal of Knowledge-Based and Intelligent Engineering Systems},
	volume = {11},
	number = {6},
	pages = {355 – 370},
	doi = {10.3233/kes-2007-11601},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013584170&doi=10.3233%2fkes-2007-11601&partnerID=40&md5=8a6d22ff843ba4b74ac9518eaa2d0957},
	abstract = {This paper presents a new approach to time series pattern classification using a modified wavelet transform for feature extraction of non-stationary time series data and a fuzzy multilayer perceptron network to generate the rules and classify the patterns. Also simple rule based event detection systems are used in a hybrid manner to classify all the categories of the nonstationary data that occur in a power distribution network during faults, sudden switching operations, and transient disturbances. The choice of modified wavelet transform known as multiresolution S-transform is essential for transient time series data of very short duration as they can not be handled by conventional Fourier and other transform methods for extraction of relevant features pertinent for temporal pattern recognition applications. The trained network infers the output class membership value of an input pattern and a certainty measure is also presented to facilitate rule generation. Several simulated data patterns along with the classification scores are presented in this paper. © 2007 - IOS Press and the authors.},
	author_keywords = {And knowledge discovery; Feature extraction; Fuzzy MLP; Fuzzy rule based system; Rule generation; S-transform; Temporal data mining; Time series},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Jäger20081700,
	author = {Jäger, Mark and Knoll, Christian and Hamprecht, Fred A.},
	title = {Weakly supervised learning of a classifier for unusual event detection},
	year = {2008},
	journal = {IEEE Transactions on Image Processing},
	volume = {17},
	number = {9},
	pages = {1700 – 1708},
	doi = {10.1109/TIP.2008.2001043},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-50549095068&doi=10.1109%2fTIP.2008.2001043&partnerID=40&md5=952cd2d0539d9536e0a0f5bb15b0ba46},
	abstract = {In this paper, we present an automatic classification framework combining appearance based features and hidden Markov models (HMM) to detect unusual events in image sequences. One characteristic of the classification task is that anomalies are rare. This reflects the situation in the quality control of industrial processes, where error events are scarce by nature. As an additional restriction, class labels are only available for the complete image sequence, since frame-wise manual scanning of the recorded sequences for anomalies is too expensive and should, therefore, be avoided. The proposed framework reduces the feature space dimension of the image sequences by employing subspace methods and encodes characteristic temporal dynamics using continuous hidden Markov models (CHMMs). The applied learning procedure is as follows. 1) A generative model for the regular sequences is trained (one-class learning). 2) The regular sequence model (RSM) is used to locate potentially unusual segments within error sequences by means of a change detection algorithm (outlier detection). 3) Unusual segments are used to expand the RSM to an error sequence model (ESM). The complexity of the ESM is controlled by means of the Bayesian Information Criterion (BIC). The likelihood ratio of the data given the ESM and the RSM is used for the classification decision. This ratio is close to one for sequences without error events and increases for sequences containing error events. Experimental results are presented for image sequences recorded from industrial laser welding processes. We demonstrate that the learning procedure can significantly reduce the user interaction and that sequences with error events can be found with a small false positive rate. It has also been shown that a modeling of the temporal dynamics is necessary to reach these low error rates. © 2008 IEEE.},
	author_keywords = {One-class learning; Outlier detection; State-space models; Time series classification; Weak labels},
	keywords = {Algorithms; Artificial Intelligence; Computer Simulation; Image Enhancement; Image Interpretation, Computer-Assisted; Markov Chains; Models, Statistical; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Automatic indexing; Chlorine compounds; Classification (of information); Computational grammars; Customer satisfaction; Dynamics; Education; Error analysis; Financial data processing; Hidden Markov models; Laser beam welding; Learning systems; Markov processes; Maximum likelihood estimation; Object recognition; Problem solving; Process control; Quality assurance; Quality control; Quality function deployment; Signal detection; Speech recognition; Total quality management; Trellis codes; Welding; algorithm; article; artificial intelligence; automated pattern recognition; computer assisted diagnosis; computer simulation; image enhancement; methodology; probability; reproducibility; sensitivity and specificity; statistical model; Appearance based; Automatic classification; Bayesian Information Criterion; Change-detection; Class labels; Classification decision; Error events; Error rates; Event detection; False positive rate; Feature spaces; Generative modeling; Hidden Markov modeling; Image sequencing; Industrial processing; Laser welding processes; Learning procedures; Likelihood ratio; One-class learning; Outlier detection; State-space models; Sub-space methods; Temporal dynamics; Time series classification; User interactions; Weak labels; Error detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 51}
}

@ARTICLE{Baziw2004303,
	author = {Baziw, Erick and Nedilko, Bohdan and Weir-Jones, Iain},
	title = {Microseismic event detection Kalman filter: Derivation of the noise covariance matrix and automated first break determination for accurate source location estimation},
	year = {2004},
	journal = {Pure and Applied Geophysics},
	volume = {161},
	number = {2},
	pages = {303 – 329},
	doi = {10.1007/s00024-003-2443-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0842344450&doi=10.1007%2fs00024-003-2443-8&partnerID=40&md5=b51eb02afbfd16e264ef617afad81aab},
	abstract = {Since 1972, Weir-Jones Engineering Consultants (WJEC) has been involved in the development and installation of microseismic monitoring systems for the mining, heavy construction and oil/gas industries. To be of practical value in an industrial environment, microseismic monitoring systems must produce information which is both reliable and timely. The most critical parameters obtained from a microseismic monitoring system are the real-time location and magnitude of the seismic events. Location and magnitude are derived using source location algorithms that typically utilize forward modeling and iterative optimal estimation techniques to determine the location of the global minimum of a predefined cost function in a three-dimensional solution space. Generally, this cost function is defined as the RMS difference between measured seismic time series information and synthetic measurements generated by assuming a velocity structure for the area under investigation (forward modeling). The seismic data typically used in the source location algorithm includes P- und S-wave arrival times, and raypath angles of incidence obtained from P-wave hodogram analysis and P-wave first break identification. In order to obtain accurate and timely source location estimates it is of paramount importance that the extraction of accurate P-wave and S-wave information from the recorded time series be automated-in this way consistent data can be made available with minimal delay. WJEC has invested considerable resources in the development of real-time digital filters to optimize extraction, and this paper outlines some of the enhancements made to existing Kalman Filter designs to facilitate the automation of P-wave first break identification.},
	author_keywords = {Discrete covariance matrix; Hodograms; Kalman filter; Microseismic monitoring; Seismic wavelet first break; State-space},
	keywords = {data processing; induced seismicity; Kalman filter; microtremor; monitoring},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@ARTICLE{Wada200156,
	author = {Wada, Toshikazu and Sato, Masayuki and Matsuyama, Takashi},
	title = {Multiobject behavior recognition by selective attention},
	year = {2001},
	journal = {Electronics and Communications in Japan, Part III: Fundamental Electronic Science (English translation of Denshi Tsushin Gakkai Ronbunshi)},
	volume = {84},
	number = {9},
	pages = {56 – 66},
	doi = {10.1002/ecjc.1035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034986029&doi=10.1002%2fecjc.1035&partnerID=40&md5=6c7887a0dcabc849d168e3edccfa158f},
	abstract = {This study proposes a method for recognition of the behavior and number of multiple objects without separation of the objects from images. Most conventional techniques of behavior recognition have used bottom-up processing, in which features were first extracted from images, and then the extracted features were subjected to time-series analysis. However, separation of objects from images at the feature extraction stage resulted in unstable processing. This study aims at stable recognition of multiobject behavior. For this purpose, a mechanism of selective attention is proposed. With this mechanism, particular image regions (focusing regions) are allotted to all states of the NFA (nondeterministic finite automaton) that performs sequence analysis, and feature extraction (event detection) is performed inside such regions. This approach makes it possible to detect events irrespective of noise (that is, changes that may occur in the image beyond the focusing regions), while nondeterministic state transition means that all possible event sequences are analyzed; hence, the behavior of multiple objects can be recognized without separation of the objects from the images. Object-specific color tokens are assigned to NFA active state sets, and then are transferred along with the state transitions, which is referred to as the object discrimination mechanism. Introduction of this mechanism allows simultaneous multiobject behavior recognition and detection of the number of objects. In addition, the proposed system has been extended to treat multiview images, and its effectiveness has been proven experimentally. © 2001 Scripta Technica.},
	author_keywords = {Bottom-up; Event detection; Focusing region; Multiobject behavior recognition; Nondeterministic finite automaton; Top-down},
	keywords = {Feature extraction; Motion estimation; Time series analysis; Multiobject behavior recognition; Nondeterministic finite automaton (NFA); Object recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Edordu2009594,
	author = {Edordu, Chibuzor and Yang, Yang},
	title = {Dual prediction and probabilistic scheduling for efficient event detection in sensor networks},
	year = {2009},
	journal = {Proceedings of the 2009 1st International Conference on Wireless Communication, Vehicular Technology, Information Theory and Aerospace and Electronic Systems Technology, Wireless VITAE 2009},
	pages = {594 – 599},
	doi = {10.1109/WIRELESSVITAE.2009.5172513},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350767367&doi=10.1109%2fWIRELESSVITAE.2009.5172513&partnerID=40&md5=c7a8190865457d275fc5f5e7e728dc1e},
	abstract = {Energy efficient data collection protocols are required in order to better manage the limited energy, memory and processing capabilities of sensor networks. In applications where data are collected in real time, efficient management of sensor radio assumes critical significance because communication is energy intensive. Moreover, specialised sensors exist which consume even more energy than radio transceivers. This paper proposes a Dual Prediction and Probabilistic Scheduling (DPPS) algorithm to be used for event detection, with improvement of energy efficiency as a central purpose. Whereas previous studies focused solely on recording events within the sensor network environment, DPPS monitors event data while also considering the accuracy of the data collection process. This is done by using the same model for forecasting both at the sensors, where event data are transmitted, and also at the sink which receives and stores such data. By combining time series prediction with probabilistic scheduling, energy is conserved because forecasts within the application's accuracy constraints reduce the need for unnecessary sensing. Simulation results on real datasets indicate that DPPS improves energy efficiency by reducing sensor usage by up to 40% in comparison to another fundamental stochastic algorithm. DPPS also provides stronger quality guarantees for application users by producing fewer missed events during the monitoring process. © 2009 IEEE.},
	keywords = {Electronics engineering; Energy efficiency; Information theory; Network protocols; Sensor networks; Simulators; Technology; Time series; Wireless sensor networks; Wireless telecommunication systems; Data collection process; Data collection protocols; Energy efficient; Event detection; Monitoring process; Probabilistic scheduling; Processing capability; Radio transceivers; Real data sets; Real time; Sensor network environment; Sensor radios; Simulation result; Stochastic algorithms; Time series prediction; Data acquisition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ihler2007,
	author = {Ihler, Alexander and Hutchins, Jon and Smyth, Padhraic},
	title = {Learning to detect events with Markov-modulated poisson processes},
	year = {2007},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	volume = {1},
	number = {3},
	doi = {10.1145/1297332.1297337},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-37049023828&doi=10.1145%2f1297332.1297337&partnerID=40&md5=f8d76289773bec4784bdc9c72b139609},
	abstract = {Time-series of count data occur in many different contexts, including Internet navigation logs, freeway traffic monitoring, and security logs associated with buildings. In this article we describe a framework for detecting anomalous events in such data using an unsupervised learning approach. Normal periodic behavior is modeled via a time-varying Poisson process model, which in turn is modulated by a hidden Markov process that accounts for bursty events. We outline a Bayesian framework for learning the parameters of this model from count time-series. Two large real-world datasets of time-series counts are used as testbeds to validate the approach, consisting of freeway traffic data and logs of people entering and exiting a building. We show that the proposed model is significantly more accurate at detecting known events than a more traditional threshold-based technique. We also describe how the model can be used to investigate different degrees of periodicity in the data, including systematic day-of-week and time-of-day effects, and to make inferences about different aspects of events such as number of vehicles or people involved. The results indicate that the Markov-modulated Poisson framework provides a robust and accurate framework for adaptively and autonomously learning how to separate unusual bursty events from traces of normal human activity. © 2007 ACM.},
	author_keywords = {Event detection; Markov modulated; Poisson},
	keywords = {Bayesian networks; Internet; Markov processes; Time series analysis; Time varying systems; Unsupervised learning; Bayesian framework; Data periodicity; Event detection; Time-varying Poisson processes; Poisson distribution},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 44; All Open Access, Green Open Access}
}

@CONFERENCE{Naftel2005207,
	author = {Naftel, Andrew and Khalid, Shehzad},
	title = {Motion clustering using spatiotemporal approximations},
	year = {2005},
	journal = {Proceedings of the IASTED International Conference on Internet and Multimedia Systems and Applications, IMSA},
	pages = {207 – 212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-29844455132&partnerID=40&md5=581d10f0aae4f55e3796a8ba6e432fd7},
	abstract = {In this paper a new technique is proposed for the clustering and classification of spatio-temporal object trajectories extracted from video motion clips. The trajectories are represented as motion time series and modelled using Chebyshev polynomial approximations. Trajectory clustering is then performed to discover patterns of similar object motion. The coefficients of the basis functions are used as an input feature vector to a Self-Organising Map which can learn similarities between object trajectories in an unsupervised manner. It is shown that applying machine learning techniques in the Chebyshev parameter subspace leads to significant performance gains over previous approaches that encode trajectories as point-based flow (PBF) vectors. Experiments using the PETS'04 tracking dataset demonstrate the effectiveness of clustering in the parameter subspace and improvements in overall classification accuracy in comparison with PBF vector encoding. We also show how this technique can be further extended to the detection of anomalous motion paths. Applications to motion data mining and event detection in video surveillance systems are envisaged.},
	author_keywords = {Classification; Motion data mining; Multimedia databases; Trajectory clustering},
	keywords = {Classification (of information); Data mining; Multimedia systems; Polynomial approximation; Time series analysis; Vectors; Motion data mining; Multimedia databases; Trajectory clustering; Motion estimation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Bauer1998345,
	author = {Bauer, Bernard O. and Yi, Jianchun and Namikas, Steven L. and Sherman, Douglas J.},
	title = {Event detection and conditional averaging in unsteady aeolian systems},
	year = {1998},
	journal = {Journal of Arid Environments},
	volume = {39},
	number = {3},
	pages = {345 – 375},
	doi = {10.1006/jare.1998.0380},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032128093&doi=10.1006%2fjare.1998.0380&partnerID=40&md5=4941a300a03e0bff61547108921ef87c},
	abstract = {Traditional models of sediment flux ignore wind unsteadiness, and there are sound empirical and theoretical arguments that implicate this deficiency as being fundamental to explaining their limited predictive abilities. Drawing on concepts and theories from the fluid mechanics literature on turbulent boundary layers, and with the implementation of fast-response instrumentation (hot-film anemometers and continuously-weighing sand traps) this study begins to address a series of inter-related questions regarding the character of wind and transport events. Foremost among these is whether an event-based analysis of wind speed time series bears close resemblance to sediment flux events. The research demonstrates that fluid 'ejection' events identified by the Variable-Interval Time Averaging (VITA) method are only crudely associated with those identified using the quadrant-threshold method. Moreover, VITA events show poor correspondence with sediment flux events. The reasons for this are unclear, although it is likely that the character of events in this beach boundary layer differ substantively from the character of structural events typically associated with the sublayer bursting process. Additional unresolved issues include whether the inner/outer layer model applies to the grain-laden/grain-free zones of a saltation system, and whether the structural events evident in velocity time series from wind tunnels and natural beaches are analogous. Event-detection and conditional-averaging techniques hold promise for characterizing the fundamental nature of unsteadiness in aeolian systems.},
	author_keywords = {Aeolian transport; Bursting; Turbulent structures; VITA method; Wind unsteadiness},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 79}
}

@CONFERENCE{Yin2008678,
	author = {Yin, Jie and Gaber, Mohamed Medhat},
	title = {Clustering distributed time series in sensor networks},
	year = {2008},
	journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
	pages = {678 – 687},
	doi = {10.1109/ICDM.2008.58},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67049160138&doi=10.1109%2fICDM.2008.58&partnerID=40&md5=10afb9db274c8f3c5ce932c940a85c1f},
	abstract = {Event detection is a critical task in sensor networks, especially for environmental monitoring applications. Traditional solutions to event detection are based on analyzing one-shot data points, which might incur a high false alarm rate because sensor data is inherently unreliable and noisy. To address this issue, we propose a novel Distributed Single-pass Incremental Clustering (DSIC) technique to cluster the time series obtained at sensor nodes based on their underlying trends. In order to achieve scalability and energy-efficiency, our DSIC technique uses a hierarchical structure of sensor networks as the underlying infrastructure. The algorithm first compresses the time series produced at individual sensor nodes into a compact representation using Haar wavelet transform, and then, based on dynamic time warping distances, hierarchically groups the approximate time series into a global clustering model in an incremental manner. Experimental results on both real data and synthetic data demonstrate that ur DSIC algorithm is accurate, energy-efficient and robust with respect to network topology changes. © 2008 IEEE.},
	keywords = {Alarm systems; Cluster analysis; Electric network topology; Energy efficiency; Information management; Mining; Sensor nodes; Telecommunication equipment; Time series; Wavelet transforms; Wireless telecommunication systems; Compact representation; Critical tasks; Data points; Distributed time; Energy efficient; Environmental Monitoring; Event detection; False alarm rate; Global clustering; Haar wavelet transform; Hierarchical structures; Incremental clustering; Network topology; ON dynamics; Sensor data; Synthetic data; Sensor networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30; All Open Access, Green Open Access}
}

@ARTICLE{Olmedo2008485,
	author = {Olmedo, O. and Zhang, J. and Wechsler, H. and Poland, A. and Borne, K.},
	title = {Automatic detection and tracking of coronal mass ejections in coronagraph time series},
	year = {2008},
	journal = {Solar Physics},
	volume = {248},
	number = {2},
	pages = {485 – 499},
	doi = {10.1007/s11207-007-9104-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-42449104861&doi=10.1007%2fs11207-007-9104-5&partnerID=40&md5=41ffdedaccbc6efc594bb37d5f812906},
	abstract = {We present the current capabilities of a software tool to automatically detect coronal mass ejections (CMEs) based on time series of coronagraph images: the solar eruptive event detection system (SEEDS). The software developed consists of several modules: preprocessing, detection, tracking, and event cataloging. The detection algorithm is based on a 2D to 1D projection method, where CMEs are assumed to be bright regions moving radially outward as observed in a running-difference time series. The height, velocity, and acceleration of the CME are automatically determined. A threshold-segmentation technique is applied to the individual detections to automatically extract an approximate shape of the CME leading edge. We have applied this method to a 12-month period of continuous coronagraph images sequence taken at a 20-minute cadence by the Large Angle and Spectrometric Coronagraph (LASCO) instrument (using the C2 instrument only) onboard the Solar and Heliospheric Observatory (SOHO) spacecraft. Our automated method, with a high computational efficiency, successfully detected about 75% of the CMEs listed in the CDAW CME catalog, which was created by using human visual inspection. Furthermore, the tool picked up about 100% more small-size or anomalous transient coronagraph events that were ignored by human visual inspection. The output of the software is made available online at http://spaceweather.gmu.edu/seeds/ . The parameters of scientific importance extracted by the software package are the position angle, angular width, velocity, peak, and average brightness. Other parameters could easily be added if needed. The identification of CMEs is known to be somewhat subjective. As our system is further developed, we expect to make the process significantly more objective. © 2008 Springer Science+Business Media B.V.},
	author_keywords = {Automatic detection; Coronal mass ejection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 117}
}

@CONFERENCE{Kooptiwoot2004327,
	author = {Kooptiwoot, Suwimon and Salam, M. Abdus},
	title = {Mining the relationships in the form of the predisposing factors and co-incident factors among numerical dynamic attributes in time series data set by using the combination of some existing techniques},
	year = {2004},
	journal = {ICEIS 2004 - Proceedings of the Sixth International Conference on Enterprise Information Systems},
	pages = {327 – 334},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-8444233944&partnerID=40&md5=6428aca8c6bf30eb357a7a43cfaa18cf},
	abstract = {Temporal mining is a natural extension of data mining with added capabilities of discovering interesting patterns, inferring relationships of contextual and temporal proximity and may also lead to possible cause-effect associations. Temporal mining covers a wide range of paradigms for knowledge modeling and discovery. A common practice is to discover frequent sequences and patterns of a single variable. In this paper we present a new algorithm which is the combination of many existing ideas consists of the reference event as proposed in (Bettini, Wang et al. 1998), the event detection technique proposed in (Guralnik and Srivastava 1999), the large fraction proposed in (Mannila, Toivonen et al. 1997), the causal inference proposed in (Blum 1982) We use all of these ideas to build up our new algorithm for the discovery of multi-variable sequences in the form of the predisposing factor and co-incident factor of the reference event of interest. We define the event as positive direction of data change or negative direction of data change above a threshold value. From these patterns we infer predisposing and co-incident factors with respect to a reference variable. For this purpose we study the Open Source Software data collected from SourceForge website. Out of 240+ attributes we only consider thirteen time dependent attributes such as Page-views, Download, Bugs0, Bugs1, Support0, Support1, Patches0, Patches1, Tracker0, Tracker1, Tasks0, Tasks1 and CVS. These attributes indicate the degree and patterns of activities of projects through the course of their progress. The number of the Download is a good indication of the progress of the projects. So we use the Download as the reference attribute. We also test our algorithm with four synthetic data sets including noise up to 50 %. The results show that our algorithm can work well and tolerate the noise data.},
	author_keywords = {Co-incident factor; Numerical data; Predisposing factor; Temporal Mining; Time series data set},
	keywords = {Algorithms; Data reduction; Pattern matching; Problem solving; Research; Time series analysis; Co-incident factors; Numerical data; Predisposing factors; Temporal mining; Time series data sets; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Wriggers20092595,
	author = {Wriggers, Willy and Stafford, Kate A. and Shan, Yibing and Piana, Stefano and Maragakis, Paul and Lindorff-Larsen, Kresten and Miller, Patrick J. and Gullingsrud, Justin and Rendleman, Charles A. and Eastwood, Michael P. and Dror, Ron O. and Shaw, David E.},
	title = {Automated event detection and activity monitoring in long molecular dynamics simulations},
	year = {2009},
	journal = {Journal of Chemical Theory and Computation},
	volume = {5},
	number = {10},
	pages = {2595 – 2605},
	doi = {10.1021/ct900229u},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-73949097915&doi=10.1021%2fct900229u&partnerID=40&md5=3bbea41f598571c5cdb0616d1c0e8457},
	abstract = {Events of scientific interest in molecular dynamics (MD) simulations, including conformational changes, folding transitions, and translocations of ligands and reaction products, often correspond to high-level structural rearrangements that alter contacts between molecules or among different parts of a molecule. Due to advances in computer architecture and software, MD trajectories representing such structure-changing events have become easier to generate, but the length of these trajectories poses a challenge to scientific interpretation and analysis. In this paper, we present automated methods for the detection of potentially important structure-changing events in long MD trajectories. In contrast with traditional tools for the analysis of such trajectories, our methods provide a detailed report of broken and formed contacts that aids in the identification of specific time-dependent side-chain interactions. Our approach employs a coarse-grained representation of amino acid side chains, a contact metric based on higher order generalizations of Delaunay tetrahedralization, techniques for detecting significant shifts in the resulting contact time series, and a new kernel-based measure of contact alteration activity. The analysis methods we describe are incorporated in a newly developed package, called TimeScapes, which is freely available and compatible with trajectories generated by a variety of popular MD programs. Tests based on actual microsecond time scale simulations demonstrate that the package can be used to efficiently detect and characterize important conformational changes in realistic protein systems. © 2009 American Chemical Society.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 46}
}

@ARTICLE{Li20081699,
	author = {Li, Mo and Liu, Yunhao and Chen, Lei},
	title = {Nonthreshold-based event detection for 3D environment monitoring in sensor networks},
	year = {2008},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {20},
	number = {12},
	pages = {1699 – 1711},
	doi = {10.1109/TKDE.2008.114},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-55949105799&doi=10.1109%2fTKDE.2008.114&partnerID=40&md5=26224656561e38e7e4dca8bdd65fad9f},
	abstract = {Event detection is a crucial task for wireless sensor network applications, especially environment monitoring. Existing approaches for event detection are mainly based on some predefined threshold values and, thus, are often inaccurate and incapable of capturing complex events. For example, in coal mine monitoring scenarios, gas leakage or water osmosis can hardly be described by the overrun of specified attribute thresholds but some complex pattern in the full-scale view of the environmental data. To address this issue, we propose a nonthreshold-based approach for the real 3D sensor monitoring environment. We employ energy-efficient methods to collect a time series of data maps from the sensor network and detect complex events through matching the gathered data to spatiotemporal data patterns. Finally, we conduct trace-driven simulations to prove the efficacy and efficiency of this approach on detecting events of complex phenomena from real-life records. © 2008 IEEE.},
	author_keywords = {Data compaction and compression; Distributed applications; Query processing; Wireless sensor networks},
	keywords = {Coal gas; Coal mines; Compaction; Data compression; Data storage equipment; Energy efficiency; Hybrid sensors; Leakage (fluid); Mining; Query processing; Routing protocols; Sensor networks; Sensors; Time series analysis; Wireless telecommunication systems; 3d environments; 3d sensors; Complex patterns; Data compaction and compression; Data maps; Distributed applications; Energy-efficient; Environment monitoring; Environmental datums; Event detections; Gas leakages; Spatiotemporal datums; Time series; Trace-driven simulations; Wireless sensors; Wireless sensor networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 65; All Open Access, Green Open Access}
}

@ARTICLE{Pelech2006365,
	author = {Pelech, Tomasz and Duda, Jan T.},
	title = {Event detection in financial time series by immune-based approach},
	year = {2006},
	journal = {Advances in Soft Computing},
	volume = {35},
	pages = {365 – 369},
	doi = {10.1007/3-540-33521-8_38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70249123108&doi=10.1007%2f3-540-33521-8_38&partnerID=40&md5=f03f1d981da615d2c52c2776ddce4f80},
	abstract = {The paper presents a concept of immune paradigm application to monitoring of company environment. Short-time prediction of stock rates is used as a basic tool to vigil relevant events, viewed as switching between "healthy" and "ill" behavior of the monitored quotations. Two predictive formulas are applied alternatively to recognize the behavior kind. "Illness" detection rules are proposed, based on the prediction efficiency evaluated in moving windows. Parameters of the predictors are modified according to the immune paradigm. © 2006 Springer.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Bermudez2009,
	author = {Bermudez, Thomas and Lowe, David and Arlaud-Lamborelle, Anne-Marie},
	title = {EEG/ECG information fusion for epileptic event detection},
	year = {2009},
	journal = {DSP 2009: 16th International Conference on Digital Signal Processing, Proceedings},
	doi = {10.1109/ICDSP.2009.5201231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449555454&doi=10.1109%2fICDSP.2009.5201231&partnerID=40&md5=1932ed9d05f49f0da270938da1d0ae8b},
	abstract = {This paper addresses the automated false positives- free detection of epileptic events by the fusion of information extracted from simultaneously recorded electroencephalographic- and electrocardiographic time-series. The approach relies on the biomedical prior knowledge for the coupling of the Brain- and Heart systems through the central autonomic network during temporal lobe epileptic events: neurovegetative manifestations associated with temporal lobe epileptic events consist of alterations to the cardiac rhythm. From a neurophysiological perspective, epileptic episodes are characterised by a loss of complexity of the state of the brain. The description of arrhythmias, from a probabilistic perspective, observed during temporal lobe epileptic events and the description of the complexity of the state of the brain, from an information theory perspective, are integrated in a fusion-of-information framework towards temporal lobe epileptic seizure detection. We show that the biomedical data fusion of simultaneously recorded EEG and ECG time-series leads to the detection of genuine epileptic events and to the dramatic reduction of false-positives. © 2009 IEEE.},
	author_keywords = {Fusion-of-information; Temporal lobe epilepsy},
	keywords = {Digital signal processing; Digital signal processors; Information fusion; Information theory; Signal processing; Autonomic network; Biomedical data; Cardiac rhythms; Event detection; False positive; Fusion-of-information; Information framework; Prior knowledge; Temporal lobe epilepsy; Temporal-lobe epileptics; Signal detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Fukano200481,
	author = {Fukano, Takao and Hamanishi, You and Gunji, Yukio-Pegio},
	title = {Event detection by forward- and backward-prediction, illustrating the analysis for behaviors of black larder beetle Dermestes haemorrhoidalis Küster},
	year = {2004},
	journal = {BioSystems},
	volume = {78},
	number = {1-3},
	pages = {81 – 91},
	doi = {10.1016/j.biosystems.2004.07.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-8844256272&doi=10.1016%2fj.biosystems.2004.07.002&partnerID=40&md5=b11f2397eed2e0f319adbbd8a1ea3316},
	abstract = {There are several studies that estimate the emergent event from the time series of behavior in some organisms. However, they do not focus on the emergent event itself. Our aim is to detect the emergent event from the time series of individual's behavior, focusing on the transition from predictable machinery behavior to purpose-oriented behavior and vice versa. We recorded the behavior of larvae and adults of black larder beetle. To detect the emergent event of the beetle, we defined a forward- and backward-prediction model. In the forward-prediction, the next state in the time series of behavior was interpreted by precedent behavior. In the backward-prediction, the previous state in the time series of behavior was interpreted by subsequent behavior. The time step with conspicuous peak of the co-intensity of errors in the forward- and backward-prediction was regarded as the timing at which the emergent event occurs. At the same time, the time series of states was estimated to determine whether noise was stationary or non-stationary. The attribute of noise was estimated using the Allan variance. The time series of the larvae's velocity of walking showed stationary noise. But in the case of the adults, whole time series contained 1/f noise. And, when time series was divided before and after the detected event, the noise changed from stationary to non-stationary and vice versa. These results suggest that development enables an individual to change the internal mechanism of walk considering the slight change of environment. © 2004 Elsevier Ireland Ltd. All rights reserved.},
	author_keywords = {DNA; Dynamical system; Forward- and backward-predictions},
	keywords = {Animals; Beetles; Behavior, Animal; Walking; Coleoptera; Dermestes; Dermestes ater; Dermestes lardarius; beetle; article; beetle; behavioral science; developmental stage; error; larva; noise; prediction; theoretical model; time series analysis; velocity; walking},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{He2007207,
	author = {He, Qi and Chang, Kuiyu and Lim, Ee-Peng},
	title = {Analyzing feature trajectories for event detection},
	year = {2007},
	journal = {Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR'07},
	pages = {207 – 214},
	doi = {10.1145/1277741.1277779},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-36448936021&doi=10.1145%2f1277741.1277779&partnerID=40&md5=2044eb4cc7064df3e0407a5849e7b83a},
	abstract = {We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words. A set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner. The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point. In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each feature's burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events. All of the above methods can be applied to time series data in general. We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events. Copyright 2007 ACM.},
	author_keywords = {DFT; Event detection; Feature categorization; Gaussian},
	keywords = {Algorithms; Data acquisition; Information retrieval systems; Problem solving; Spectrum analysis; Detection algorithm; Event detection; Feature categorization; Feature extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 187; All Open Access, Green Open Access}
}

@ARTICLE{Naftel2006227,
	author = {Naftel, Andrew and Khalid, Shehzad},
	title = {Classifying spatiotemporal object trajectories using unsupervised learning in the coefficient feature space},
	year = {2006},
	journal = {Multimedia Systems},
	volume = {12},
	number = {3},
	pages = {227 – 238},
	doi = {10.1007/s00530-006-0058-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845335507&doi=10.1007%2fs00530-006-0058-5&partnerID=40&md5=25f4d99cd892c87db40b00e828f4568b},
	abstract = {This paper proposes a novel technique for clustering and classification of object trajectory-based video motion clips using spatiotemporal function approximations. Assuming the clusters of trajectory points are distributed normally in the coefficient feature space, we propose a Mahalanobis classifier for the detection of anomalous trajectories. Motion trajectories are considered as time series and modelled using orthogonal basis function representations. We have compared three different function approximations - least squares polynomials, Chebyshev polynomials and Fourier series obtained by Discrete Fourier Transform (DFT). Trajectory clustering is then carried out in the chosen coefficient feature space to discover patterns of similar object motions. The coefficients of the basis functions are used as input feature vectors to a Self- Organising Map which can learn similarities between object trajectories in an unsupervised manner. Encoding trajectories in this way leads to efficiency gains over existing approaches that use discrete point-based flow vectors to represent the whole trajectory. Our proposed techniques are validated on three different datasets - Australian sign language, hand-labelled object trajectories from video surveillance footage and real-time tracking data obtained in the laboratory. Applications to event detection and motion data mining for multimedia video surveillance systems are envisaged. © Springer-Verlag 2006.},
	author_keywords = {Anomaly detection; Event mining; Motion classification; Object trajectory; Trajectory clustering},
	keywords = {Approximation theory; Demodulation; Discrete Fourier transforms; Image processing; Learning systems; Motion pictures; Polynomials; Time series analysis; Anomaly detection; Event mining; Motion classification; Object trajectory; Trajectory clustering; Object recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 95}
}

@ARTICLE{Neill2009498,
	author = {Neill, Daniel B.},
	title = {Expectation-based scan statistics for monitoring spatial time series data},
	year = {2009},
	journal = {International Journal of Forecasting},
	volume = {25},
	number = {3},
	pages = {498 – 517},
	doi = {10.1016/j.ijforecast.2008.12.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67449160454&doi=10.1016%2fj.ijforecast.2008.12.002&partnerID=40&md5=975fd8746fe55ba627f1c1637b3fbb93},
	abstract = {We consider the simultaneous monitoring of a large number of spatially localized time series in order to detect emerging spatial patterns. For example, in disease surveillance, we detect emerging outbreaks by monitoring electronically available public health data, e.g. aggregate daily counts of Emergency Department visits. We propose a two-step approach based on the expectation-based scan statistic: we first compute the expected count for each recent day for each spatial location, then find spatial regions (groups of nearby locations) where the recent counts are significantly higher than expected. By aggregating information across multiple time series rather than monitoring each series separately, we can improve the timeliness, accuracy, and spatial resolution of detection. We evaluate several variants of the expectation-based scan statistic on the disease surveillance task (using synthetic outbreaks injected into real-world hospital Emergency Department data), and draw conclusions about which models and methods are most appropriate for which surveillance tasks. © 2008 International Institute of Forecasters.},
	author_keywords = {Biosurveillance; Event detection; Pattern detection; Spatial scan statistics; Time series monitoring},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 65; All Open Access, Green Open Access}
}

@ARTICLE{Nan200029,
	author = {Nan, Jiang and Wei, Shu and Zhendong, Wang},
	title = {Burst event detection in wall turbulence by WVITA method},
	year = {2000},
	journal = {Acta Mechanica Sinica/Lixue Xuebao},
	volume = {16},
	number = {1},
	pages = {29 – 34},
	doi = {10.1007/bf02487939},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034138767&doi=10.1007%2fbf02487939&partnerID=40&md5=4f8e586876572133135a02ddca766019},
	abstract = {Wavelet Variable Interval Time Average (WVITA) is introduced as a method incorporating burst event detection in wall turbulence. Wavelet transform is performed to unfold the longitudinal fluctuating velocity time series measured in the near wall region of a turbulent boundary layer using hot-film anemometer. This unfolding is both in time and in space simultaneously. The splitted kinetic of the longitudinal fluctuating velocity time series among different scales is obtained by integrating the square of wavelet coefficient modulus over temporal space. The time scale that related to burst events in wall turbulence passing through the fixed probe is ascertained by maximum criterion of the kinetic energy evolution across scales. Wavelet transformed localized variance of the fluctuating velocity time series at the maximum kinetic scale is put forward instead of localized short time average variance in Variable Interval Time Average (VITA) scheme. The burst event detection result shows that WVITA scheme can avoid erroneous judgement and solve the grouping problem more effectively which is caused by VITA scheme itself and can not be avoided by adjusting the threshold level or changing the short time average interval.},
	author_keywords = {Burst event; Maximum kinetic energy criteria; VITA; Wall turbulence; Wavelet analysis},
	keywords = {Turbulent flow; Wavelet transforms; Burst event; Longitudinal velocity fluctuation; Maximum energy criteria; Variable interval time average; Wall turbulence; Wavelet analysis; Turbulence},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Lara2010485,
	author = {Lara, Juan A. and Pérez, Aurora and Valente, Juan P. and López-Illescas, África},
	title = {Modelling stabilometric time series},
	year = {2010},
	journal = {HEALTHINF 2010 - 3rd International Conference on Health Informatics, Proceedings},
	pages = {485 – 488},
	doi = {10.5220/0002768904850488},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956307915&doi=10.5220%2f0002768904850488&partnerID=40&md5=868921d43ae75e368d937cecc45455d6},
	abstract = {Stabilometry is a branch of medicine that studies balance-related human functions. Stabilometric systems generate time series. The analysis of these time series using data mining techniques can be very useful for domain experts. In the field of stabilometry, as in many other domains, the key nuggets of information in a time series are concentrated within definite time periods known as events. In this paper, we propose a technique for creating reference models for stabilometric time series based on event analysis. After testing the technique on time series recorded by top-competition sportspeople, we conclude that stabilometric models can be used to classify individuals by their balance-related abilities.},
	author_keywords = {Data mining; Event detection; Stabilometry; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Pelech-Pilichowski200665,
	author = {Pelech-Pilichowski, Tomasz and Duda, Jan T.},
	title = {General structure of T-lymphocyte applied to event detection in financial time series},
	year = {2006},
	journal = {Systems Science},
	volume = {32},
	number = {4},
	pages = {65 – 71},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-46449124767&partnerID=40&md5=4af729a1d9b57d4c447bd90e4ebe1238},
	abstract = {The paper is focused on the T-lymphocyte construction applied to immune-inspired event detection in financial time series. The goal is to recognize symptoms of abrupt changes of long-time mean value of many processed series. The task of the T-lymphocyte is to distinguish between "healthy" and "illness" states through examining individual series, with algorithms based on weak and rigorous statistical tests (detailed operation of detection is shown). General structure of the T-lymphocyte algorithm is illustrated. A comparison of the number of detected symptoms is presented.},
	author_keywords = {Event detection; Financial time series; Immune-based approach},
	keywords = {Electric inverters; Health; Time series analysis; (+ mod 2N) operation; Applied (CO); Event detection; Financial time series; General structure; Individual (PSS 544-7); Mean value (MV); Statistical tests},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gao2003784,
	author = {Gao, Dayong and Kinouchi, Y. and Ito, K.},
	title = {Neural networks for event detection from time series: A BP algorithm approach},
	year = {2003},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {2658},
	pages = {784 – 793},
	doi = {10.1007/3-540-44862-4_85},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35248886734&doi=10.1007%2f3-540-44862-4_85&partnerID=40&md5=0c06a4d11fc8c8be0f51ac8630dd2d9c},
	abstract = {In this paper, a relatively new event detection method using neural networks is developed for financial time series. Such method can capture homeostatic dynamics of the system under the influence of exogenous event. The results show that financial time series include both predictable deterministic and unpredictable random components. Neural networks can identify the properties of homeostatic dynamics and model the dynamic relation between endogenous and exogenous variables in financial time series input-output system. We also investigate the impact of the number of model inputs and the number of hidden layer neurons on forecasting. ... © Springer-Verlag Berlin Heidelherg 2003.},
	keywords = {Algorithms; Finance; Time series; Dynamic relation; Event detection; Exogenous variables; Financial time series; Hidden layer neurons; Homeostatic dynamics; Input-output systems; Random components; Financial data processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@CONFERENCE{Hubey200214,
	author = {Hubey, H.M.},
	title = {O(1) DETECTION OF CHANCE EVENTS, REAL-TIME PROCESSING OF HIGH-DIMENSIONAL STREAMING DATA, AND DATAMINING},
	year = {2002},
	journal = {AAAI Fall Symposium - Technical Report},
	volume = {FS-02-01},
	pages = {14 – 21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169439463&partnerID=40&md5=c1d24c81279880e701cd8df96cf4ca9a},
	abstract = {A scalable/parallelizable/distributed method is shown that was originally developed for data mining but which is extended to perform web mining, text mining, mining of time-series or temporal data, mining mixed-type data, and mine high-dimensional data. It is implicitly stochastic thus it can incorporate statistical methods such as Bayesian. It is based on the automatic generation of assocation rules. Since it also uses a multiplicative fuzzy logic the neural network tuned to the data is easily comprehensible. It lends itself to visualization, and interactive exploration. Since it uses a unique hashing algorithm (for storage and data manipulation), one that works with associative access, it can be used for other techniques such as nearest-neighbor methods. It is shown here that it is a perfect solution for chance-event detection and processing. It lends itself to hardware acceleration and thus can be used for very large scale projects such as streaming data for “homeland defense”. The method is an ideal platform for integration of data warehousing, OLAP and data mining. Copyright © 2002, AAAI (www.aaai.org). All rights reserved.},
	keywords = {Associative processing; Clustering algorithms; Data warehouses; Digital storage; Fuzzy logic; Fuzzy neural networks; Stochastic systems; Distributed methods; High-dimensional; Higher-dimensional; Mixed type; Realtime processing; Streaming data; Temporal data mining; Text-mining; Time-series data; Web Mining; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Naftel200647,
	author = {Naftel, Andrew and Khalid, Shehzad},
	title = {Motion trajectory learning in the DFT-coefficient feature space},
	year = {2006},
	journal = {Proceedings of the Fourth IEEE International Conference on Computer Vision Systems, ICVS'06},
	volume = {2006},
	pages = {47},
	doi = {10.1109/ICVS.2006.41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749376149&doi=10.1109%2fICVS.2006.41&partnerID=40&md5=1f123c8c27edece61b9184388491d06c},
	abstract = {Techniques for understanding video object motion activity are becoming increasingly important with the widespread adoption of CCTV surveillance systems. In this paper we propose a novel vision system for clustering and classification of object-based video motion clips using spatiotemporal models. Object trajectories are modeled as motion time series using the lowest order Fourier coefficients obtained by Discrete Fourier Transform. Trajectory clustering is then carried out in the DFT-coefficlent feature space to discover patterns of similar object motion activity. The DFT coefficients are used as input feature vectors to a Self-Organising Map which can learn similarities between object trajectories in an unsupervised manner. Encoding trajectories in this way leads to efficiency gains over existing approaches that use discrete point-based flow vectors to represent the whole trajectory. Assuming the clusters of trajectory points are distributed normally in the coefficient feature space, we propose a simple Mahalanobis classifier for the detection of anomalous trajectories. Our proposed techniques are validated on three different datasets - Australian sign language, hand-labelled object trajectories from video surveillance footage and real-time tracking data obtained in the laboratory. Applications to event detection and motion data mining for visual surveillance systems are envisaged. © 2006 IEEE.},
	keywords = {Closed circuit television systems; Computer vision; Database systems; Mathematical models; Motion estimation; Probability density function; Self organizing maps; Time series analysis; DFT-coefficlent; Fourier coefficients; Object-based video; Video object motion; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43}
}

@ARTICLE{Hunter1999271,
	author = {Hunter, Jim and McIntosh, Neil},
	title = {Knowledge-based event detection in complex time series data},
	year = {1999},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {1620},
	pages = {271 – 280},
	doi = {10.1007/3-540-48720-4_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956869760&doi=10.1007%2f3-540-48720-4_30&partnerID=40&md5=90070f7aba0dde0f0e7dcdf02ae3b12f},
	abstract = {This paper describes an approach to the detection of events in complex, multi-channel, high frequency data. The example used is that of detecting the re-siting of a transcutaneous O2/CO2 probe on a baby in a neonatal intensive care unit (ICU) from the available monitor data. A software workbench has been developed which enables the expert clinician to display the data and to mark up features of interest. This knowledge is then used to define the parameters for a pattern matcher which runs over a set of intervals derived from the raw data by a new iterative interval merging algorithm. The approach has been tested on a set of 45 probe changes; the preliminary results are encouraging, with an accuracy of identification of 89%. © Springer-Verlag Berlin Heidelberg 1999.},
	keywords = {Artificial intelligence; Decision making; Iterative methods; Knowledge based systems; Medicine; Probes; Complex time series; Event detection; High frequency data; Knowledge based; Merging algorithms; Multi channel; Neonatal intensive care units; Transcutaneous; Intensive care units},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 64}
}

@CONFERENCE{Nasution2009,
	author = {Nasution, Arie Hans and Zhang, Peng and Emmanuel, Sabu},
	title = {Video surveillance for elderly monitoring and safety},
	year = {2009},
	journal = {IEEE Region 10 Annual International Conference, Proceedings/TENCON},
	doi = {10.1109/TENCON.2009.5395849},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951116711&doi=10.1109%2fTENCON.2009.5395849&partnerID=40&md5=a527e67d4a54617fc883c0d16c71406f},
	abstract = {In this paper we propose a novel method to detect and record various posture-based and movement-based events of interest in a typical elderly monitoring application in a home surveillance scenario. Posture-based events include standing, sitting, bending/squatting, side lying and lying toward the camera. While movement-based events include running, jumping, active and inactive events. For posture classification, we use the projection histograms of foreground as the main feature vector. k-Nearest Neighbor (k-NN) algorithm and evidence accumulation technique is proposed to infer human postures. With this technique, we have achieved a robust posture recognition rate of above 90% and a stable classifier's output. Furthermore, we use the speed of fall to differentiate real fall incident and an event where the person is simply lying without falling. On the other hand, time series signal change detection techniques are used for movement classification task. The accuracy obtained for movement-based events detection is above 90%. ©2009 IEEE.},
	keywords = {Signal detection; Time series; Classification tasks; Events detection; Evidence accumulation; Feature vectors; Human postures; K-nearest neighbors; Monitoring applications; Movement-based; Novel methods; Posture classification; Posture recognition; Projection histograms; Time series signals; Video surveillance; Security systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Bunke2007227,
	author = {Bunke, Horst and Dickinson, P. and Humm, A. and Irniger, Ch. and Kraetzl, M.},
	title = {Graph sequence visualisation and its application to computer network monitoring and abnormal event detection},
	year = {2007},
	journal = {Studies in Computational Intelligence},
	volume = {52},
	pages = {227 – 245},
	doi = {10.1007/978-3-540-68020-8_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34147194284&doi=10.1007%2f978-3-540-68020-8_9&partnerID=40&md5=8b62d62c4d4eb93d4027e5996a15bd86},
	abstract = {In this chapter, a new visualisation method for time series of graphs is introduced. This method is based on graph edit distance and multidimensional scaling. The proposed procedure maps each graph in a time series of graphs to a point on the two-dimensional real plane, such that graphs with a high (low) similarity are mapped to points with a small (large) Euclidean distance. In this way, similar graphs in the time series can be easily identified. As a potential application of this method, we consider the problem of computer network monitoring and abnormal event detection. A number of results on simulated data and graphs obtained from real computer networks are presented, highlighting the advantages of the proposed method over previous approaches. © Springer-Verlag Berlin Heidelberg 2007.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Naftel2006,
	author = {Naftel, Andrew and Anwar, Fahad Bin},
	title = {Visual recognition of manual tasks using object motion trajectories},
	year = {2006},
	journal = {Proceedings - IEEE International Conference on Video and Signal Based Surveillance 2006, AVSS 2006},
	doi = {10.1109/AVSS.2006.117},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547274223&doi=10.1109%2fAVSS.2006.117&partnerID=40&md5=b443eeb20a9fe13bf6b43514089b0adf},
	abstract = {Motion trajectories are powerful cues for event detection and recognition. In this paper we present a system for manual task analysis that distinguishes between skin and object motion and learns activity patterns through analysing object trajectories. It is particularly suited to the recognition of common object handling tasks. Our vision system performs hand skin detection and object segmentation for each frame in a sequence. The object trajectories are then modelled as motion time series. We have compared the performance of several different time series indexing schemes: symbolic, polynomial and orthonormal basis functions used for trajectory similarity retrieval and classification. We then attempt to cluster object-centred motion patterns in the coefficient feature space. The proposed technique is validated on two different datasets, Australian Sign Language and object handling data obtained in the laboratory. Applications to task recognition and motion data mining in industrial surveillance applications are envisaged. © 2006 IEEE.},
	keywords = {Computer vision; Data handling; Image segmentation; Object recognition; Skin; Time series analysis; Australian Sign Language; Manual tasks; Object motion trajectories; Object segmentation; Motion estimation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Von Wegner2007925,
	author = {Von Wegner, Frederic and Both, Martin and Fink, Rainer H.A. and Friedrich, Oliver},
	title = {Fast XYT imaging of elementary calcium release events in muscle with multifocal multiphoton microscopy and wavelet denoising and detection},
	year = {2007},
	journal = {IEEE Transactions on Medical Imaging},
	volume = {26},
	number = {7},
	pages = {925 – 934},
	doi = {10.1109/TMI.2007.895471},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547290494&doi=10.1109%2fTMI.2007.895471&partnerID=40&md5=ab204c6e215d5b6d1a7bd4394f12ff7f},
	abstract = {We used multifocal multiphoton microscopy to image fast, localized elevations of the cytosolic Ca2+ concentration in two spatial dimensions plus time (XYT). This technique extends the common spatially 1-D XT imaging and allows the acquisition of more than ten times longer time series (>500 images) and ten times larger areas of interest than for previously used confocal XYT imaging techniques due to lower phototoxicity and fast multifocal scanning. We recorded spontaneously occurring elementary Ca2+ release events in chemically permeabilized adult mammalian skeletal muscle fibers using two-photon excitation of the fluorescent dye Fluo-4. The resulting time series were analyzed with an automated denoising and detection algorithm based on the à trous implementation of the discrete wavelet transform. Wavelet coefficient hard-thresholding is used for denoising and event detection is performed across several wavelet scales. The spatiotemporal characteristics of the detected Ca2+ release events are followed throughout the XYT stack and are parametrized using a biophysically valid anisotropic Gaussian event model. The proposed method allows a detailed spatiotemporal analysis of elementary Ca2+ release events underlying the excitation-contraction coupling process in muscle. © 2007 IEEE.},
	author_keywords = {Ca<sup>2+</sup> imaging; Multifocal microscopy; Multiphoton microscopy; Wavelet denoising},
	keywords = {Algorithms; Animals; Calcium; Calcium Signaling; Cells, Cultured; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Metabolic Clearance Rate; Mice; Microscopy, Fluorescence, Multiphoton; Muscle Fibers; Muscle, Skeletal; Reproducibility of Results; Sensitivity and Specificity; Calcium; Microscopic examination; Multiphoton processes; Muscle; Time series analysis; calcium; algorithm; animal; article; calcium signaling; cell culture; computer assisted diagnosis; cytology; evaluation; image enhancement; metabolic clearance rate; metabolism; methodology; mouse; multiphoton microscopy; muscle cell; physiology; reproducibility; sensitivity and specificity; skeletal muscle; three dimensional imaging; Multifocal microscopy; Multiphoton microscopy; Wavelet denoising; Medical imaging},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@ARTICLE{Papadimitriou199655,
	author = {Papadimitriou, S. and Bezerianos, A.},
	title = {Multiresolution analysis and denoising of computer performance evaluation data with the wavelet transform},
	year = {1996},
	journal = {Journal of Systems Architecture},
	volume = {42},
	number = {1},
	pages = {55 – 65},
	doi = {10.1016/1383-7621(96)00007-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003986194&doi=10.1016%2f1383-7621%2896%2900007-0&partnerID=40&md5=65fb5c3ac58ab3c3ab5a2c3ff7002493},
	abstract = {The Wavelet Transform Analysis (WTA) offers the possibility to decompose a time series into both time and scale components. The paper applies Wavelet Transform to analyze computer performance measurement data. This type of data forms a time series that is treated and analyzed as any other signal. A noise reduction technique that detects noise components by analyzing the evolution of the Wavelet Transform modulus maxima across scales is adapted in order to improve the quality of computer performance data. This method allows to effectively remove the induced noise from measurement inaccuracies and transient random events. © 1996 Elsevier Science All rights reserved.},
	author_keywords = {Denoising; Event detection; Lipschitz regularity; Measurements; Multiresolution analysis; Performance evaluation; Random noise; Singularity detection; Wavelet transform},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Ratkovic200957,
	author = {Ratkovic, Marc T. and Eng, Kevin H.},
	title = {Finding jumps in otherwise smooth curves: Identifying critical events in political processes},
	year = {2009},
	journal = {Political Analysis},
	volume = {18},
	number = {1},
	pages = {57 – 77},
	doi = {10.1093/pan/mpp032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951561466&doi=10.1093%2fpan%2fmpp032&partnerID=40&md5=99e55b6dabb4c92ff946ca43b6f36421},
	abstract = {Many social processes are stable and smooth in general, with discrete jumps. We develop a sequential segmentation spline method that can identify both the location and the number of discontinuities in a series of observations with a time component, while fitting a smooth spline between jumps, using a modified Bayesian Information Criterion statistic as a stopping rule. We explore the method in a large-n, unbalanced panel setting with George W. Bush's approval data, a small-n time series with median DW-NOMINATE scores for each Congress over time, and a series of simulations. We compare the method to several extant smoothers, and the method performs favorably in terms of visual inspection, residual properties, and event detection. Finally, we discuss extensions of the method. © The Author 2009. Published by Oxford University Press on behalf of the Society for Political Methodology. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@ARTICLE{Fujimaki20091,
	author = {Fujimaki, Ryohei and Nakata, Takayuki and Tsukahara, Hidenori and Sato, Akinori and Yamanishi, Kenji},
	title = {Mining abnormal patterns from heterogeneous time-series with irrelevant features for fault event detection},
	year = {2009},
	journal = {Statistical Analysis and Data Mining},
	volume = {2},
	number = {1},
	pages = {1 – 17},
	doi = {10.1002/sam.10030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949112755&doi=10.1002%2fsam.10030&partnerID=40&md5=9a10c73268ca55e06c7ac610c2b081c6},
	abstract = {We address the issue of detecting fault events in multivariate time series. We suppose the following realistic and challenging situations: (A) the features to which multivariate time series correspond are heterogeneous; (B) only a small number of examples of fault events are available in advance relative to a large number of normal examples; and (C) many features irrelevant to fault events are included. To resolve these situations, detecting faults specifically in machine systems such as automobile, train, etc. is usually required. We propose an algorithm to resolve the issue. Key ideas in it include: (1) transforming the time-series for each feature into a sequence of anomaly scores, in order to map heterogeneous features to homogeneous ones (an anomaly score indicates the degree of anomalousness relative to an ordinal sequence) and then representing the pattern of a fault event in terms of fault anomaly score vectors; (2) selecting features specifying a fault event by means of iterative optimization using both normal and fault anomaly score vectors. We then monitor the degree of anomalousness with respect to target anomaly score vectors by comparing them with the abnormal patterns. We demonstrate the effectiveness of our proposed algorithm through an application to an actual automobile fault diagnosis data set as well as an artificial dataset. © 2009 Wiley Periodicals, Inc.},
	author_keywords = {Fault event detection; Feature selection; Heterogeneous time series},
	keywords = {Algorithms; Failure analysis; Time series; Abnormal patterns; Data sets; Fault diagnosis; Fault event; Fault event detection; Feature selection; Heterogeneous features; Heterogeneous time series; Iterative Optimization; Machine systems; Multivariate time series; Ordinal sequence; Fault detection},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Pelech-Pilichowski2006159,
	author = {Pelech-Pilichowski, Tomasz and Duda, Jan T.},
	title = {General structure of T-lymphocyte applied to immune-based event detection in financial time series},
	year = {2006},
	journal = {Proceedings of the International Multiconference on Computer Science and Information Technology, IMCSIT},
	volume = {1},
	pages = {159 – 167},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83755171751&partnerID=40&md5=4f5920df52b287522032aa176fc0a224},
	abstract = {The paper is focused on the T-lymphocyte construction applied to immune-inspired event detection in financial time series. The goal is to recognize symptoms of abrupt changes of long-time mean value of many processed series. The task of the T-lymphocyte is to distinguish between 'healthy' and 'illness' states through examining individual series, with algorithms based on weak and rigorous statistical tests (detailed operation of detection is showed). General structure of the T-lymphocyte algorithm is illustrated. Comparison of the number of detected symptoms is presented. © 2006 PIPS.},
	keywords = {Algorithms; Computer science; Data processing; Information technology; Statistical tests; Time series; Event detection; Financial time series; Mean values; Financial data processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lara2008293,
	author = {Lara, Juan A. and Moreno, Guillermo and Pérez, Aurora and Valente, Juan P. and López-Illescas, África},
	title = {Comparing posturographic time series through events detection},
	year = {2008},
	journal = {Proceedings - IEEE Symposium on Computer-Based Medical Systems},
	pages = {293 – 295},
	doi = {10.1109/CBMS.2008.61},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51849155612&doi=10.1109%2fCBMS.2008.61&partnerID=40&md5=7225c8a9decf57ca9fc3f4904b31da70},
	abstract = {The comparison of two time series and the extraction of subsequences that are common to the two is a complex data mining problem. Many existing techniques, like the Discrete Fourier Transform (DFT), offer solutions for comparing two whole time series. Often, however, the important thing is to analyse certain regions, known as events, rather than the whole times series. This applies to domains like the stock market, seismography or medicine. In this paper, we propose a method for comparing two time series by analysing the events present in the two. The proposed method is applied to time series generated by stabilometric and posturographic systems within a branch of medicine studying balance-related functions in human beings. © 2008 IEEE.},
	keywords = {Data mining; Discrete Fourier transforms; Time series; Complex data; Events detection; Human being; Related functions; Times series; Fourier series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@ARTICLE{Gao20051096,
	author = {Gao, D. and Kinouchi, Y. and Ito, K. and Zhao, X.},
	title = {Neural networks for event extraction from time series: A back propagation algorithm approach},
	year = {2005},
	journal = {Future Generation Computer Systems},
	volume = {21},
	number = {7},
	pages = {1096 – 1105},
	doi = {10.1016/j.future.2004.03.009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-27544467089&doi=10.1016%2fj.future.2004.03.009&partnerID=40&md5=0ab09813be8ea95a7da382da9160db63},
	abstract = {This paper presents a relatively new event detection method using neural networks for time series analysis. Such method can capture homeostatic dynamics of the system under the influence of exogenous event. The results show that financial time series include both predictable deterministic and unpredictable random components. Neural networks can identify the properties of homeostatic dynamics and model the dynamic relation between endogenous and exogenous variables in financial time series input-output system. We explore the signaling mechanisms that transfer information in such dynamic system and investigate the impact of the number of model inputs and the number of hidden layer neurons on financial analysis. © 2004 Elsevier B.V. All rights reserved.},
	author_keywords = {Back propagation; Neural network; Time series},
	keywords = {Backpropagation; Finance; Time series analysis; Financial analysis; Homeostatic dynamics; Transfer information; Neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Browne20021403,
	author = {Browne, M. and Cutmore, T.R.H.},
	title = {Low-probability event-detection and separation via statistical wavelet thresholding: An application to psychophysiological denoising},
	year = {2002},
	journal = {Clinical Neurophysiology},
	volume = {113},
	number = {9},
	pages = {1403 – 1411},
	doi = {10.1016/S1388-2457(02)00194-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036342992&doi=10.1016%2fS1388-2457%2802%2900194-3&partnerID=40&md5=fd6dcbfd1810e9f3b487b1404e27ac7f},
	abstract = {Objectives: The aim of this paper is to introduce and test a general, wavelet-based method for the automatic removal of noise and artefact from psychophysiological data. Methods: Statistical wavelet thresholding (SWT) performs blind source separation by transforming data to the wavelet domain, and subsequent filtering of wavelet coefficients based on a statistical framework. The observed wavelet coefficients are modelled using a Gaussian distribution, from which low-probability outliers are attenuated based on their z-scores. Results: The technique was applied to both simulated and real event-related potentials (ERP) data. SWT applied to artificial data displayed increased signal-to-noise ratio (SNR) improvements as noise amplitude increased. ERP averages of filtered experimental data displayed a correlation of 0.93 with operator-filtered data, compared with a correlation of 0.56 for unfiltered data. The energy of operator-designated contaminated trials was attenuated by a factor of 7.46 relative to uncontaminated trials. SNR improvement was observed in simulated tests. Conclusions: Variations of SWT may be useful in situations where one wishes to separate uncommon/uncharacteristic structures from time series data sets. For artefact removal applications, SWT appears to be a valid alternative to expert operator screening. © 2002 Elsevier Science Ireland Ltd. All rights reserved.},
	author_keywords = {Denoising; Event-related potential; Filtering; Pre-processing; Psychophysiology; Wavelet},
	keywords = {Artifacts; Clinical Trials; Computer Simulation; Electricity; Electroencephalography; Electromyography; Evoked Potentials; Evoked Potentials, Visual; Eye Movements; Humans; Psychophysiology; Reproducibility of Results; Signal Processing, Computer-Assisted; article; artifact reduction; correlation analysis; event related potential; human; mathematical analysis; noise reduction; priority journal; probability; psychophysiology; signal noise ratio; simulation; task performance; technique},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Bronze Open Access}
}

@CONFERENCE{Satoh2002623,
	author = {Satoh, Yutaka and Tanahashit, Hideki and Wang, Caihua and Kaneko, Shun'ichi and Niwa, Yoshinori and Yamamoto, Kazuhiko},
	title = {Robust event detection by radial reach filter (RRF)},
	year = {2002},
	journal = {Proceedings - International Conference on Pattern Recognition},
	volume = {2},
	pages = {623 – 626},
	doi = {10.1109/ICPR.2002.1048379},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949653871&doi=10.1109%2fICPR.2002.1048379&partnerID=40&md5=da9088f8a319bb2cb7e76310fef8624c},
	abstract = {We propose a novel statistical measure for robust event detection, called 'Radial Reach filter' (RRF). The capability of detecting new objects (events) from a time-series image is an important problem of vision systems. The usual method of detecting new objects is simple background sub-traction that is to subtract current image from a background image. However, simple background subtraction is susceptible to illumination change such as shadows. And when the brightness difference between events and a background is small, it cannot detect the difference. In order to solve such kind of problems, we propose the RRF which evaluates a local texture and realize robust event detection. The experiment using the real image shows the effectiveness of the proposed methods. Furthermore, the experiment using all-directional image from a stereo omni-directional system (SOS) shows the possibility of the application to an environment-monitoring system etc. © 2002 IEEE.},
	keywords = {Computer vision; Pattern recognition; Background image; Background subtraction; Brightness difference; Directional images; Environment monitoring system; Illumination changes; Radial reach filter; Statistical measures; Object detection},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@ARTICLE{Bunke2006576,
	author = {Bunke, H. and Dickinson, P. and Humm, A. and Irniger, Ch. and Kraetzl, M.},
	title = {Computer network monitoring and abnormal event detection using graph matching and multidimensional scaling},
	year = {2006},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {4065 LNAI},
	pages = {576 – 590},
	doi = {10.1007/11790853_45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746452169&doi=10.1007%2f11790853_45&partnerID=40&md5=2aee4b04259ce4d707361579a9f31fd3},
	abstract = {Computer network monitoring and abnormal event detection have become important areas of research. In previous work, it has been proposed to represent a computer network as a time series of graphs and to compute the difference, or distance, of consecutive graphs in such a time series. Whenever the distance of two graphs exceeds a given thresh-old, an abnormal event is reported. In the present paper we go one step further and compute graph distances between all pairs of graphs in a time series. Given these distances, a multidimensional scaling procedure is applied that maps each graph onto a point in the two-dimensional real plane, such that the distances between the graphs are reflected, as closely as possible, in the distances between the points in the two-dimensional plane. In this way the behaviour of a network can be visualised and abnormal events as well as states or clusters of states of the network can be graphically represented. We demonstrate the feasibility of the proposed method by means of synthetically generated graph sequences and data from real computer networks. © Springer-Verlag Berlin Heidelberg 2006.},
	author_keywords = {Abnormal event detection; Computer network monitoring; Graph matching, multidimensional scaling.},
	keywords = {Computer graphics; Data processing; Graph theory; Research and development management; Time series analysis; Abnormal event detection; Computer network monitoring; Graph matching, multidimensional scaling; Two-dimensional planes; Computer networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@CONFERENCE{Vatsavai200949,
	author = {Vatsavai, Ranga Raju},
	title = {Phenological event detection from multitemporal image data},
	year = {2009},
	journal = {Proceedings of the 3rd International Workshop on Knowledge Discovery from Sensor Data, SensorKDD'09 in Conjunction with the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD-09},
	pages = {49 – 55},
	doi = {10.1145/1601966.1601976},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449904514&doi=10.1145%2f1601966.1601976&partnerID=40&md5=3315b2a99bd1de534d2814b21a5ac1d9},
	abstract = {Monitoring biomass over large geographic regions for seasonal changes in vegetation and crop phenology is important for many applications. In this paper we a present a novel clustering based change detection method using MODIS NDVI time series data. We used well known EM technique to find GMM parameters and Bayesian Information Criteria (BIC) for determining the number of clusters. KL Divergence measure is then used to establish the cluster correspondence across two years (2001 and 2006) to determine changes between these two years. The changes identified were further analyzed for understanding phenological events. This preliminary study shows interesting relationships between key phenological events such as onset, length, end of growing seasons. Copyright 2009 ACM.},
	author_keywords = {Clustering; EM; GMM; MODIS; NDVI; Remote sensing},
	keywords = {Biomass; Magnetostrictive devices; Radiometers; Remote sensing; Spectrometers; Time series; Bayesian information criterion; Change detection; Clustering; Crop phenology; Determining the number of clusters; EM techniques; End of growing seasons; Event detection; Geographic regions; KL-divergence; Multi-temporal image; NDVI time series; Novel clustering; Seasonal changes; Cluster analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Tsien2000858,
	author = {Tsien, C.L.},
	title = {Event discovery in medical time-series data.},
	year = {2000},
	journal = {Proceedings / AMIA ... Annual Symposium. AMIA Symposium},
	pages = {858 – 862},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034575783&partnerID=40&md5=83399587c75ebe33d3db75a8d86de493},
	abstract = {Vast amounts of clinical information are generated daily on patients in the health care setting. Increasingly, this information is collected and stored for its potential utility in advancing health care. Knowledge-based systems, for example, might be able to apply rules to the collected data to determine whether a patient has a certain condition. Often, however, the underlying knowledge needed to write such rules is not well understood. How could these clinical data be useful then? Use of machine learning is one answer. We present a pipeline for discovering the knowledge needed for event detection in medical time-series data. We demonstrate how this process can be applied in the development of intelligent patient monitoring for the intensive care unit (ICU). Specifically, we develop a system for detecting Otrue alarmO situations in the ICU, where currently as many as 86% of bedside monitor alarms are false.},
	keywords = {Artificial Intelligence; Blood Pressure; Decision Trees; Humans; Hypertension; Intensive Care Units; Linear Models; Monitoring, Physiologic; Neural Networks (Computer); Point-of-Care Systems; ROC Curve; Time; article; artificial intelligence; artificial neural network; blood pressure; decision tree; evaluation; hospital information system; human; hypertension; intensive care unit; monitoring; roc curve; statistical model; time},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}